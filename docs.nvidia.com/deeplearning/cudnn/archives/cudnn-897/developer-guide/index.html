<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-us" xml:lang="en-us">
   
<!-- Mirrored from docs.nvidia.com/deeplearning/cudnn/archives/cudnn-897/developer-guide/index.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 06 Aug 2024 07:09:11 GMT -->
<head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>
      <meta name="copyright" content="(C) Copyright 2005"></meta>
      <meta name="DC.rights.owner" content="(C) Copyright 2005"></meta>
      <meta name="DC.Type" content="concept"></meta>
      <meta name="DC.Title" content="Abstract"></meta>
      <meta name="abstract" content="This cuDNN 8.9.7 Developer Guide explains how to use the NVIDIA cuDNN library. While the NVIDIA cuDNN API Reference provides per-function API documentation, the Developer Guide gives a more informal end-to-end story about cuDNN’s key capabilities and how to use them."></meta>
      <meta name="description" content="This cuDNN 8.9.7 Developer Guide explains how to use the NVIDIA cuDNN library. While the NVIDIA cuDNN API Reference provides per-function API documentation, the Developer Guide gives a more informal end-to-end story about cuDNN’s key capabilities and how to use them."></meta>
      <meta name="DC.Coverage" content="Developer Guide"></meta>
      <meta name="DC.subject" content="cuDNN Developer Guide"></meta>
      <meta name="keywords" content="cuDNN Developer Guide"></meta>
      <meta name="DC.Format" content="XHTML"></meta>
      <meta name="DC.Identifier" content="abstract"></meta>
      <link rel="stylesheet" type="text/css" href="../common/formatting/commonltr.css"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/site.css"></link>
      <title>Developer Guide :: NVIDIA cuDNN Documentation</title>
      <!--[if lt IE 9]>
      <script src="../common/formatting/html5shiv-printshiv.min.js"></script>
      <![endif]-->
      <script src="../../../../../../assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
      <script type="text/javascript" src="../../../../../../cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-svg.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.ba-hashchange.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.scrollintoview.min.js"></script>
      <script type="text/javascript" src="../search/htmlFileList.js"></script>
      <script type="text/javascript" src="../search/htmlFileInfoList.js"></script>
      <script type="text/javascript" src="../search/nwSearchFnt.min.js"></script>
      <script type="text/javascript" src="../search/stemmers/en_stemmer.min.js"></script>
      <script type="text/javascript" src="../search/index-1.js"></script>
      <script type="text/javascript" src="../search/index-2.js"></script>
      <script type="text/javascript" src="../search/index-3.js"></script>
      <link rel="canonical" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/qwcode.highlight.css"></link>
   </head>
   <body>
      
      <header id="header"><span id="company">NVIDIA</span><span id="site-title">NVIDIA cuDNN Documentation</span><form id="search" method="get" action="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-897/developer-guide/search">
            <input type="text" name="search-text"></input><fieldset id="search-location">
               <legend>Search In:</legend>
               <label><input type="radio" name="search-type" value="site"></input>Entire Site</label>
               <label><input type="radio" name="search-type" value="document"></input>Just This Document</label></fieldset>
            <button type="reset">clear search</button>
            <button id="submit" type="submit">search</button></form>
      </header>
      <div id="site-content">
         <nav id="site-nav">
            <div class="category closed"><a href="../index.html" title="The root of the site.">Getting Started</a></div>
            <div class="category"><a href="index.html" title="Developer Guide">Developer Guide</a></div>
            <ul>
               <li>
                  <div class="section-link"><a href="#overview">1.&nbsp;Overview</a></div>
               </li>
               <li>
                  <div class="section-link"><a href="#core-concepts">2.&nbsp;Core Concepts</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#programming-model">2.1.&nbsp;cuDNN Handle</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#tensors-layouts">2.2.&nbsp;Tensors and Layouts</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#tensor-descriptor">2.2.1.&nbsp;Tensor Descriptor</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#WXWZ-tensor-descriptor">2.2.1.1.&nbsp;WXYZ Tensor Descriptor</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#three-D-tensor-descriptor">2.2.1.2.&nbsp;3-D Tensor Descriptor</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#four-D-tensor-descriptor">2.2.1.3.&nbsp;4-D Tensor Descriptor</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#five-D-tensor-descriptor">2.2.1.4.&nbsp;5-D Tensor Descriptor</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#Fully-packed-tensors">2.2.1.5.&nbsp;Fully-Packed Tensors</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#Partially-packed-tensors">2.2.1.6.&nbsp;Partially-Packed Tensors</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#Spatially-packed-tensors">2.2.1.7.&nbsp;Spatially Packed Tensors</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#Overlapping-tensors">2.2.1.8.&nbsp;Overlapping Tensors</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#data-layout-formats">2.2.2.&nbsp;Data Layout Formats</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#data-layout-formats-example-x32">2.2.2.1.&nbsp;Example Tensor</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#convolution-layout">2.2.2.2.&nbsp;Convolution Layouts</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#nchw-layout-x32">2.2.2.2.1.&nbsp;NCHW Memory Layout</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#nhwc-layout-x32">2.2.2.2.2.&nbsp;NHWC Memory Layout</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#nc32hw32-layout-x32">2.2.2.2.3.&nbsp;NC/32HW32 Memory Layout</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#row-column-major">2.2.2.3.&nbsp;MatMul Layouts</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#tensor_ops">2.3.&nbsp;Tensor Core Operations</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-tensor-transformations-fp16">2.3.1.&nbsp;Notes on Tensor Core Precision</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#op-fusion">3.&nbsp;Graph API</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#key-concepts">3.1.&nbsp;Key Concepts</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#op-op-graphs">3.1.1.&nbsp;Operations and Operation Graphs</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#engine-engine-config">3.1.2.&nbsp;Engines and Engine Configurations</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#heuristics">3.1.3.&nbsp;Heuristics</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#graph-api-ex">3.2.&nbsp;Graph API Example with Operation Fusion</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#create-op-tensor-desc">3.2.1.&nbsp;Creating Operation and Tensor Descriptors to Specify the Graph Dataflow</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#finalize-op-graph">3.2.2.&nbsp;Finalizing The Operation Graph</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#config-engine-execute-op">3.2.3.&nbsp;Configuring An Engine That Can Execute The Operation Graph</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#execute-the-engine">3.2.4.&nbsp;Executing The Engine</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#support-graph-patterns">3.3.&nbsp;Supported Graph Patterns</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#compile-single-op-engine">3.3.1.&nbsp;Pre-compiled Single Operation Engines</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#convolutionfwd">3.3.1.1.&nbsp;ConvolutionFwd</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#convolutionbwfilter">3.3.1.2.&nbsp;ConvolutionBwFilter</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#convolutionbwdata">3.3.1.3.&nbsp;ConvolutionBwData</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#normalizationforward">3.3.1.4.&nbsp;NormalizationForward</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#normalizationbackward">3.3.1.5.&nbsp;NormalizationBackward</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#runtime-fusion-engine">3.3.2.&nbsp;Generic Runtime Fusion Engines</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#limitations">3.3.2.1.&nbsp;Limitations</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#examples-sup-patterns">3.3.2.2.&nbsp;Examples of Supported Patterns</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#single-op">3.3.2.2.1.&nbsp;Single Operation</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#pointwise-op-conv1">3.3.2.2.2.&nbsp;Pointwise Operations After Convolution 1</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#pointwise-op-conv2">3.3.2.2.3.&nbsp;Pointwise Operations After Convolution 2</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#pointwise-op-matrix-multi">3.3.2.2.4.&nbsp;Pointwise Operations Before Matrix Multiplication</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#conv-prod-node">3.3.2.2.5.&nbsp;Convolution Producer Node in Middle of DAG</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#op-specific-contraints-runtime-fusion-engine">3.3.2.3.&nbsp;Operation specific Constraints for the Runtime Fusion Engines</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#conv-runtime-fusion-engine">3.3.2.3.1.&nbsp;Convolutions</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#matmul-runtime-fusion-engine">3.3.2.3.2.&nbsp;MatMul</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#pointwise-runtime-fusion-engine">3.3.2.3.3.&nbsp;Pointwise</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#genstats-runtime-fusion-engine">3.3.2.3.4.&nbsp;GenStats</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#reduction-runtime-fusion-engine">3.3.2.3.5.&nbsp;Reduction</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#resamplefwd-runtime-fusion-engine">3.3.2.3.6.&nbsp;ResampleFwd</a></div>
                                          <ul>
                                             <li>
                                                <div class="section-link"><a href="#resample-forward-index-dump">3.3.2.3.6.1.&nbsp;Resampling Index Tensor Dump for Training</a></div>
                                             </li>
                                          </ul>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#resamplebwd-runtime-fusion-engine">3.3.2.3.7.&nbsp;ResampleBwd</a></div>
                                       </li>
                                    </ul>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#specialized-runtime-fusion-engines">3.3.3.&nbsp;Specialized Runtime Fusion Engines</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#bnaddrelu">3.3.3.1.&nbsp;BnAddRelu</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#dreluforkdbn">3.3.3.2.&nbsp;DReluForkDBn</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#fused-multi-head-att-fprop">3.3.3.3.&nbsp;Fused Attention fprop</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#fused-multi-head-att-bprop">3.3.3.4.&nbsp;Fused Attention bprop</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#flash-fused-multi-head-att-fprop">3.3.3.5.&nbsp;Fused Flash Attention fprop</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#flash-fused-multi-head-att-bprop">3.3.3.6.&nbsp;Fused Flash Attention bprop</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#compile-specialized-engine">3.3.4.&nbsp;Specialized Pre-Compiled Engines</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#convbnfprop">3.3.4.1.&nbsp;ConvBNfprop</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#convbnwgrad">3.3.4.2.&nbsp;ConvBNwgrad</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#convbiasact">3.3.4.3.&nbsp;ConvBiasAct</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#convscalebiasact">3.3.4.4.&nbsp;ConvScaleBiasAct</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#dgraddrelubnbwdweight">3.3.4.5.&nbsp;DgradDreluBNBwdWeight</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#flash-fused-multi-head-att-fp8">3.3.4.6.&nbsp;FP8 Fused Flash Attention</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#mapping-backend-desc">3.3.5.&nbsp;Mapping with Backend Descriptors</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#legacy-api">4.&nbsp;Legacy API</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#tensor-ops-conv-functions">4.1.&nbsp;Convolution Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-conv-functions-pre-req">4.1.1.&nbsp;Prerequisites</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-conv-functions-supported-algos">4.1.2.&nbsp;Supported Algorithms</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-conv-functions-data-filter-formats">4.1.3.&nbsp;Data and Filter Formats</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#tensor-ops-rnn-functions">4.2.&nbsp;RNN Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-rnn-functions-pre-req">4.2.1.&nbsp;Prerequisites</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-rnn-functions-supported-algos">4.2.2.&nbsp;Supported Algorithms</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-rnn-functions-data-filter-formats">4.2.3.&nbsp;Data and Filter Formats</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#features-of-rnn-functions">4.2.4.&nbsp;Features of RNN Functions</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#tensor-ops-tensor-transformations">4.3.&nbsp;Tensor Transformations </a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-tensor-transformations-fp32-to-fp16">4.3.1.&nbsp;Conversion Between FP32 and FP16 </a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-tensor-transformations-padding">4.3.2.&nbsp;Padding </a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-tensor-transformations-folding">4.3.3.&nbsp;Folding </a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-tensor-transformations-conversion">4.3.4.&nbsp;Conversion Between NCHW And NHWC </a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#mixed-precision-numerical-accuracy">4.4.&nbsp;Mixed Precision Numerical Accuracy</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#misc">5.&nbsp;Odds and Ends</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#thread-safety">5.1.&nbsp;Thread Safety</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#reproducibility">5.2.&nbsp;Reproducibility (Determinism)</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#scaling-parameters">5.3.&nbsp;Scaling Parameters</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#api-compat">5.4.&nbsp;cuDNN API Compatibility</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#backward-compatibility">5.5.&nbsp;Deprecation Policy</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#requirements">5.6.&nbsp;GPU And Driver Requirements</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#convolutions">5.7.&nbsp;Convolutions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#convolution-formulas">5.7.1.&nbsp;Convolution Formulas</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#grouped-convolutions">5.7.2.&nbsp;Grouped Convolutions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#best-practices-convolutions">5.7.3.&nbsp;Best Practices for 3D Convolutions</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#rec-settings-3d-conv">5.7.3.1.&nbsp;Recommended Settings</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#conv-limits">5.7.3.2.&nbsp;Limitations</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#environ-variables">5.8.&nbsp;Environment Variables</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#sm-carveout">5.9.&nbsp;SM Carveout</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#troubleshooting">6.&nbsp;Troubleshooting</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#api-logging">6.1.&nbsp;Error Reporting And API Logging</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#faq">6.2.&nbsp;FAQs</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#support">6.3.&nbsp;Support</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#acknowledgments">7.&nbsp;Acknowledgments</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#university-of-tennessee">7.1.&nbsp;University of Tennessee</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#university-of-california-berkeley">7.2.&nbsp;University of California, Berkeley</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#facebook-ai-research">7.3.&nbsp;Facebook AI Research, New York</a></div>
                     </li>
                  </ul>
               </li>
            </ul>
         </nav>
         <div id="resize-nav"></div>
         <nav id="search-results">
            <h2>Search Results</h2>
            <ol></ol>
         </nav>
         
         <div id="contents-container">
            <div id="breadcrumbs-container">
               <div id="release-info">Developer Guide (<a href="../pdf/cuDNN-Developer-Guide.pdf">PDF</a>)
                  -
                  
                  
                  
                  -
                  
                  Last updated April 20, 2024
               </div>
            </div>
            <article id="contents">
               <div class="topic nested0" id="abstract"><a name="abstract" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#abstract" name="abstract" shape="rect">Abstract</a></h2>
                  <div class="body conbody">
                     <p class="shortdesc">This cuDNN 8.9.7 Developer Guide explains how to use the NVIDIA cuDNN library. While the
                        NVIDIA cuDNN API Reference provides per-function API documentation, the Developer Guide
                        gives a more informal end-to-end story about cuDNN’s key capabilities and how to use them. 
                     </p>
                  </div>
               </div>
               <div class="topic concept nested0" id="overview"><a name="overview" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#overview" name="overview" shape="rect">1.&nbsp;Overview</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">NVIDIA<sup>®</sup> CUDA<sup>®</sup> Deep Neural Network LIbrary
                           (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. It provides
                           highly tuned implementations of operations arising frequently in DNN
                           applications:</span></div><a name="overview__ul_u1j_bvx_r1b" shape="rect">
                        <!-- --></a><ul class="ul" id="overview__ul_u1j_bvx_r1b">
                        <li class="li liexpand">Convolution forward and backward, including cross-correlation</li>
                        <li class="li liexpand">Matrix multiplication</li>
                        <li class="li liexpand">Pooling forward and backward</li>
                        <li class="li liexpand">Softmax forward and backward</li>
                        <li class="li liexpand">Neuron activations forward and backward: <samp class="ph codeph">relu</samp>,
                           <samp class="ph codeph">tanh</samp>, <samp class="ph codeph">sigmoid</samp>, <samp class="ph codeph">elu</samp>,
                           <samp class="ph codeph">gelu</samp>, <samp class="ph codeph">softplus</samp>, <samp class="ph codeph">swish</samp></li>
                        <li class="li liexpand">Arithmetic, mathematical, relational, and logical pointwise operations (including
                           various flavors of forward and backward neuron activations)
                        </li>
                        <li class="li liexpand">Tensor transformation functions</li>
                        <li class="li liexpand">LRN, LCN, batch normalization, instance normalization, and layer normalization
                           forward and backward
                        </li>
                     </ul>
                     <p class="p">Beyond just providing performant implementations of individual operations, the library
                        also supports a flexible set of multi-operation fusion patterns for further
                        optimization. The goal is to achieve the best available performance on NVIDIA GPUs for
                        important deep learning use cases.
                     </p>
                     <p class="p">In cuDNN version 7 and older, the API was designed to support a fixed set of operations
                        and fusion patterns. We informally call this the “legacy API”. Starting in cuDNN version
                        8, to address the quickly expanding set of popular fusion patterns, we added a <a class="xref" href="index.html#op-fusion" title="The cuDNN library provides a declarative programming model for describing computation as a graph of operations. This graph API was introduced in cuDNN 8.0 to provide a more flexible API, especially with the growing importance of operation fusion." shape="rect">graph API</a>, which allows the user to express a computation
                        by defining an operation graph, rather than by selecting from a fixed set of API calls.
                        This offers better flexibility versus the legacy API, and for most use cases, is the
                        recommended way to use cuDNN.
                     </p>
                     <p class="p">Note that while the cuDNN library exposes a C API, we also provide an <a class="xref" href="https://github.com/NVIDIA/cudnn-frontend" target="_blank" shape="rect">open
                           source C++ layer</a> which wraps the C API and is considered more convenient for
                        most users. It is, however, limited to just the graph API, and does not support the
                        legacy API.
                     </p>
                  </div>
               </div>
               <div class="topic concept nested0" id="core-concepts"><a name="core-concepts" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#core-concepts" name="core-concepts" shape="rect">2.&nbsp;Core Concepts</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">Before we discuss the details of the graph and legacy APIs, this section
                           introduces the key concepts that are common to both.</span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="programming-model"><a name="programming-model" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#programming-model" name="programming-model" shape="rect">2.1.&nbsp;cuDNN Handle</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The cuDNN library exposes a host API but assumes that for operations using the
                              GPU, the necessary data is directly accessible from the device.</span></div>
                        <p class="p">An application using cuDNN must initialize a handle to the library context by calling
                           <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnCreate" target="_blank" shape="rect"><samp class="ph codeph">cudnnCreate()</samp></a>. This handle is
                           explicitly passed to every subsequent library function that operates on GPU data. Once
                           the application finishes using cuDNN, it can release the resources associated with the
                           library handle using <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnDestroy" target="_blank" shape="rect"><samp class="ph codeph">cudnnDestroy()</samp></a>. This approach
                           allows the user to explicitly control the library's functioning when using multiple host
                           threads, GPUs, and CUDA streams. 
                        </p>
                        <p class="p">For example, an application can use <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" target="_blank" shape="rect"><samp class="ph codeph">cudaSetDevice</samp></a> (prior to
                           creating a cuDNN handle) to associate different devices with different host threads, and
                           in each of those host threads, create a unique cuDNN handle that directs the subsequent
                           library calls to the device associated with it. In this case, the cuDNN library calls
                           made with different handles would automatically run on different devices.
                        </p>
                        <p class="p">The device associated with a particular cuDNN context is assumed to remain unchanged
                           between the corresponding <samp class="ph codeph">cudnnCreate()</samp> and
                           <samp class="ph codeph">cudnnDestroy()</samp> calls. In order for the cuDNN library to use a
                           different device within the same host thread, the application must set the new device to
                           be used by calling <samp class="ph codeph">cudaSetDevice()</samp> and then create another cuDNN
                           context, which will be associated with the new device, by calling
                           <samp class="ph codeph">cudnnCreate()</samp>. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="tensors-layouts"><a name="tensors-layouts" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tensors-layouts" name="tensors-layouts" shape="rect">2.2.&nbsp;Tensors and Layouts</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">Whether using the graph API or the legacy API, cuDNN operations take tensors as
                              input and produce tensors as output.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="tensor-descriptor"><a name="tensor-descriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-descriptor" name="tensor-descriptor" shape="rect">2.2.1.&nbsp;Tensor Descriptor</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">The cuDNN library describes data with a generic n-D tensor descriptor defined
                                 with the following parameters:</span></div><a name="tensor-descriptor__ul_v12_h1y_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="tensor-descriptor__ul_v12_h1y_r1b">
                              <li class="li liexpand">a number of dimensions from 3 to 8</li>
                              <li class="li liexpand">a data type (32-bit floating-point, 64 bit-floating point, 16-bit
                                 floating-point...)
                              </li>
                              <li class="li liexpand">an integer array defining the size of each dimension</li>
                              <li class="li liexpand">an integer array defining the stride of each dimension (for example, the number of
                                 elements to add to reach the next element from the same dimension)
                              </li>
                           </ul>
                           <p class="p">This tensor definition allows, for example, to have some dimensions overlapping each
                              other within the same tensor by having the stride of one dimension smaller than the
                              product of the dimension and the stride of the next dimension. In cuDNN, unless
                              specified otherwise, all routines will support tensors with overlapping dimensions for
                              forward-pass input tensors, however, dimensions of the output tensors cannot overlap.
                              Even though this tensor format supports negative strides (which can be useful for data
                              mirroring), cuDNN routines do not support tensors with negative strides unless specified
                              otherwise. 
                           </p>
                        </div>
                        <div class="topic concept nested3" id="WXWZ-tensor-descriptor"><a name="WXWZ-tensor-descriptor" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#WXWZ-tensor-descriptor" name="WXWZ-tensor-descriptor" shape="rect">2.2.1.1.&nbsp;WXYZ Tensor Descriptor</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">Tensor descriptor formats are identified using acronyms, with each letter
                                    referencing a corresponding dimension. In this document, the usage of this terminology
                                    implies: </span></div><a name="WXWZ-tensor-descriptor__ul_fss_n1y_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="WXWZ-tensor-descriptor__ul_fss_n1y_r1b">
                                 <li class="li">all the strides are strictly positive</li>
                                 <li class="li">the dimensions referenced by the letters are sorted in decreasing order of their
                                    respective strides
                                 </li>
                              </ul>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="three-D-tensor-descriptor"><a name="three-D-tensor-descriptor" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#three-D-tensor-descriptor" name="three-D-tensor-descriptor" shape="rect">2.2.1.2.&nbsp;3-D Tensor Descriptor</a></h3>
                           <div class="body conbody">
                              <div class="abstract">A 3-D tensor is commonly used for matrix multiplications, with three letters: B, M,
                                 and N. B represents the batch size (for batch GEMM, set to 1 for single GEMM), M represents
                                 the number of rows, and N represents the number of columns. Refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</samp></a> operation for
                                 more information. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="four-D-tensor-descriptor"><a name="four-D-tensor-descriptor" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#four-D-tensor-descriptor" name="four-D-tensor-descriptor" shape="rect">2.2.1.3.&nbsp;4-D Tensor Descriptor</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">A 4-D tensor descriptor is used to define the format for batches of 2D images
                                    with 4 letters: <samp class="ph codeph">N,C,H,W</samp> for respectively the batch size, the number of
                                    feature maps, the height and the width. The letters are sorted in decreasing order of
                                    the strides. The commonly used 4-D tensor formats are:</span></div><a name="four-D-tensor-descriptor__ul_trf_t1y_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="four-D-tensor-descriptor__ul_trf_t1y_r1b">
                                 <li class="li"><samp class="ph codeph">NCHW</samp></li>
                                 <li class="li"><samp class="ph codeph">NHWC</samp></li>
                                 <li class="li"><samp class="ph codeph">CHWN</samp></li>
                              </ul>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="five-D-tensor-descriptor"><a name="five-D-tensor-descriptor" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#five-D-tensor-descriptor" name="five-D-tensor-descriptor" shape="rect">2.2.1.4.&nbsp;5-D Tensor Descriptor</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">A 5-D tensor descriptor is used to define the format of the batch of 3D images
                                    with 5 letters: <samp class="ph codeph">N,C,D,H,W</samp> for respectively the batch size, the number
                                    of feature maps, the depth, the height, and the width. The letters are sorted in
                                    decreasing order of the strides. The commonly used 5-D tensor formats are
                                    called:</span></div><a name="five-D-tensor-descriptor__ul_gk5_w1y_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="five-D-tensor-descriptor__ul_gk5_w1y_r1b">
                                 <li class="li"><samp class="ph codeph">NCDHW</samp></li>
                                 <li class="li"><samp class="ph codeph">NDHWC</samp></li>
                                 <li class="li"><samp class="ph codeph">CDHWN</samp></li>
                              </ul>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="Fully-packed-tensors"><a name="Fully-packed-tensors" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#Fully-packed-tensors" name="Fully-packed-tensors" shape="rect">2.2.1.5.&nbsp;Fully-Packed Tensors</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">A tensor is defined as <samp class="ph codeph">XYZ-fully-packed</samp> if, and only
                                    if:</span></div><a name="Fully-packed-tensors__ul_zxr_1by_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="Fully-packed-tensors__ul_zxr_1by_r1b">
                                 <li class="li">the number of tensor dimensions is equal to the number of letters preceding the
                                    <samp class="ph codeph">fully-packed</samp> suffix
                                 </li>
                                 <li class="li">the stride of the i-th dimension is equal to the product of the (i+1)-th dimension
                                    by the (i+1)-th stride
                                 </li>
                                 <li class="li">the stride of the last dimension is 1</li>
                              </ul>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="Partially-packed-tensors"><a name="Partially-packed-tensors" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#Partially-packed-tensors" name="Partially-packed-tensors" shape="rect">2.2.1.6.&nbsp;Partially-Packed Tensors</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">The partially <samp class="ph codeph">XYZ-packed</samp> terminology only applies in the context
                                    of a tensor format described with a superset of the letters used to define a
                                    partially-packed tensor. A <samp class="ph codeph">WXYZ</samp> tensor is defined as
                                    <samp class="ph codeph">XYZ-packed</samp> if, and only if: </span></div><a name="Partially-packed-tensors__ul_ty1_2by_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="Partially-packed-tensors__ul_ty1_2by_r1b">
                                 <li class="li">the strides of all dimensions NOT referenced in the <samp class="ph codeph">-packed</samp> suffix
                                    are greater or equal to the product of the next dimension by the next stride
                                 </li>
                                 <li class="li">the stride of each dimension referenced in the <samp class="ph codeph">-packed</samp> suffix in
                                    position <samp class="ph codeph">i</samp> is equal to the product of the (<samp class="ph codeph">i+1</samp>)-st
                                    dimension by the (<samp class="ph codeph">i+1</samp>)-st stride
                                 </li>
                                 <li class="li">if the last tensor's dimension is present in the <samp class="ph codeph">-packed</samp> suffix,
                                    its stride is <samp class="ph codeph">1</samp></li>
                              </ul>
                              <p class="p">For example, an <samp class="ph codeph">NHWC</samp> tensor WC-packed means that the
                                 <samp class="ph codeph">c_stride</samp> is equal to 1 and <samp class="ph codeph">w_stride</samp> is equal to
                                 <samp class="ph codeph">c_dim x c_stride</samp>. In practice, the <samp class="ph codeph">-packed</samp> suffix
                                 is usually applied to the minor dimensions of a tensor but can be applied to only the
                                 major dimensions; for example, an <samp class="ph codeph">NCHW</samp> tensor that is only
                                 N-packed.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="Spatially-packed-tensors"><a name="Spatially-packed-tensors" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#Spatially-packed-tensors" name="Spatially-packed-tensors" shape="rect">2.2.1.7.&nbsp;Spatially Packed Tensors</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">Spatially-packed tensors are defined as partially-packed in spatial dimensions.
                                    For example, a spatially-packed 4D tensor would mean that the tensor is either NCHW
                                    HW-packed or CNHW HW-packed.</span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="Overlapping-tensors"><a name="Overlapping-tensors" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#Overlapping-tensors" name="Overlapping-tensors" shape="rect">2.2.1.8.&nbsp;Overlapping Tensors</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">A tensor is defined to be overlapping if iterating over a full range of
                                    dimensions produces the same address more than once. In practice an overlapped tensor
                                    will have <samp class="ph codeph">stride[i-1] &lt; stride[i]*dim[i]</samp> for some of the
                                    <samp class="ph codeph">i</samp> from <samp class="ph codeph">[1,nbDims]</samp> interval.</span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="data-layout-formats"><a name="data-layout-formats" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#data-layout-formats" name="data-layout-formats" shape="rect">2.2.2.&nbsp;Data Layout Formats</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This section describes how cuDNN tensors are arranged in memory according to
                                 several data layout formats.</span></div>
                           <p class="p">The recommended way to specify the layout format of a tensor is by setting its strides
                              accordingly. For compatibility with the v7 API, a subset of the layout formats can also
                              be configured through the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnTensorFormat_t" target="_blank" shape="rect"><samp class="ph codeph">cudnnTensorFormat_t</samp></a> enum. The
                              enum is only supplied for legacy reasons and is deprecated.
                           </p>
                        </div>
                        <div class="topic concept nested3" id="data-layout-formats-example-x32"><a name="data-layout-formats-example-x32" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#data-layout-formats-example-x32" name="data-layout-formats-example-x32" shape="rect">2.2.2.1.&nbsp;Example Tensor</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">Consider a batch of images with the following dimensions: </span></div>
                              <div class="p"><a name="data-layout-formats-example-x32__ul_ldz_f2d_mhb" shape="rect">
                                    <!-- --></a><ul class="ul" id="data-layout-formats-example-x32__ul_ldz_f2d_mhb">
                                    <li class="li"><strong class="ph b">N</strong> is the batch size; 1 
                                    </li>
                                    <li class="li"><strong class="ph b">C</strong> is the number of feature maps (that is,, number of channels); 64
                                    </li>
                                    <li class="li"><strong class="ph b">H</strong> is the image height; 5
                                    </li>
                                    <li class="li"><strong class="ph b">W</strong> is the image width; 4
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">To keep the example simple, the image pixel elements are expressed as a sequence of integers,
                                 			0, 1, 2, 3, and so on. Refer to <a class="xref" href="index.html#data-layout-formats-example-x32__fig-example-x32" shape="rect">Figure 1</a>.
                              </p>
                              <div class="p">
                                 <div class="fig fignone" id="data-layout-formats-example-x32__fig-example-x32"><a name="data-layout-formats-example-x32__fig-example-x32" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 1. Example with N=1, C=64, H=5, W=4</span><br clear="none"></br><a name="data-layout-formats-example-x32__image_cb5_pgn_mpb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="data-layout-formats-example-x32__image_cb5_pgn_mpb" src="graphics/fig-example-x32.png" alt="Example with N=1, C=64, H=5, W=4"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">In the following subsections, we’ll use the above example to demonstrate the different
                                 			layout formats.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="convolution-layout"><a name="convolution-layout" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convolution-layout" name="convolution-layout" shape="rect">2.2.2.2.&nbsp;Convolution Layouts</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">cuDNN supports several layouts for convolution, as described in the following
                                    			sections.</span></div>
                              <p class="p"></p>
                           </div>
                           <div class="topic concept nested4" id="nchw-layout-x32"><a name="nchw-layout-x32" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#nchw-layout-x32" name="nchw-layout-x32" shape="rect">2.2.2.2.1.&nbsp;NCHW Memory Layout</a></h3>
                              <div class="body conbody">
                                 <div class="abstract">The above 4D tensor is laid out in the memory in the NCHW format as
                                    		below: <span class="shortdesc"></span></div>
                                 <div class="p"><a name="nchw-layout-x32__ol_dty_m41_3jb" shape="rect">
                                       <!-- --></a><ol class="ol" id="nchw-layout-x32__ol_dty_m41_3jb">
                                       <li class="li">Beginning with the first channel (c=0), the elements are arranged contiguously
                                          					in row-major order.
                                       </li>
                                       <li class="li">Continue with second and subsequent channels until the elements of all the channels are laid
                                          					out. Refer to <a class="xref" href="index.html#nchw-layout-x32__fig-nchw-layout-x32" shape="rect">Figure 2</a>.
                                       </li>
                                       <li class="li">Proceed to the next batch (if <strong class="ph b">N</strong> is &gt; 1).
                                       </li>
                                    </ol>
                                 </div>
                                 <div class="p">
                                    <div class="fig fignone" id="nchw-layout-x32__fig-nchw-layout-x32"><a name="nchw-layout-x32__fig-nchw-layout-x32" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 2. NCHW Memory Layout</span><br clear="none"></br><a name="nchw-layout-x32__image_abh_441_3jb" shape="rect">
                                          <!-- --></a><div class="imageleft">
                                          <embed class="image imageleft" id="nchw-layout-x32__image_abh_441_3jb" src="graphics/fig-nchw-layout-x32.svg"></embed>
                                       </div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="nhwc-layout-x32"><a name="nhwc-layout-x32" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#nhwc-layout-x32" name="nhwc-layout-x32" shape="rect">2.2.2.2.2.&nbsp;NHWC Memory Layout</a></h3>
                              <div class="body conbody">
                                 <div class="abstract">For the NHWC memory layout, the corresponding elements in all the <strong class="ph b">C</strong> channels
                                    		are laid out first, as below: <span class="shortdesc"></span></div>
                                 <div class="p"><a name="nhwc-layout-x32__ol_sv3_p41_3jb" shape="rect">
                                       <!-- --></a><ol class="ol" id="nhwc-layout-x32__ol_sv3_p41_3jb">
                                       <li class="li">Begin with the first element of channel 0, then proceed to the first element of
                                          					channel 1, and so on, until the first elements of all the <strong class="ph b">C</strong> channels are
                                          					laid out.
                                       </li>
                                       <li class="li">Next, select the second element of channel 0, then proceed to the second element
                                          					of channel 1, and so on, until the second element of all the channels are laid
                                          					out.
                                       </li>
                                       <li class="li">Follow the row-major order of channel 0 and complete all the elements. Refer to <a class="xref" href="index.html#nhwc-layout-x32__fig-nchw-layout-x32" shape="rect">Figure 3</a>.
                                       </li>
                                       <li class="li">Proceed to the next batch (if <strong class="ph b">N</strong> is &gt; 1).
                                       </li>
                                    </ol>
                                 </div>
                                 <div class="p">
                                    <div class="fig fignone" id="nhwc-layout-x32__fig-nchw-layout-x32"><a name="nhwc-layout-x32__fig-nchw-layout-x32" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 3. NHWC Memory Layout</span><br clear="none"></br><a name="nhwc-layout-x32__image_vcs_q41_3jb" shape="rect">
                                          <!-- --></a><div class="imageleft">
                                          <embed class="image imageleft" id="nhwc-layout-x32__image_vcs_q41_3jb" src="graphics/fig-nhwc-layout-x32.svg"></embed>
                                       </div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="nc32hw32-layout-x32"><a name="nc32hw32-layout-x32" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#nc32hw32-layout-x32" name="nc32hw32-layout-x32" shape="rect">2.2.2.2.3.&nbsp;NC/32HW32 Memory Layout</a></h3>
                              <div class="body conbody">
                                 <div class="abstract">The NC/32HW32 is similar to NHWC, with a key difference. For the NC/32HW32 memory
                                    		layout, the 64 channels are grouped into two groups of 32 channels each - first group
                                    		consisting of channels <samp class="ph codeph">c0</samp> through <samp class="ph codeph">c31</samp>, and the second
                                    		group consisting of channels <samp class="ph codeph">c32</samp> through <samp class="ph codeph">c63</samp>. Then each
                                    		group is laid out using the NHWC format. Refer to <a class="xref" href="index.html#nc32hw32-layout-x32__fig-nc32hw32-layout-x32" shape="rect">Figure 4</a>. <span class="shortdesc"></span></div>
                                 <div class="p">
                                    <div class="fig fignone" id="nc32hw32-layout-x32__fig-nc32hw32-layout-x32"><a name="nc32hw32-layout-x32__fig-nc32hw32-layout-x32" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 4. NC/32HW32 Memory Layout</span><br clear="none"></br><a name="nc32hw32-layout-x32__image_odz_wgn_mpb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="nc32hw32-layout-x32__image_odz_wgn_mpb" src="graphics/fig-nc32hw32-layout-x32.png" alt="NC/32HW32 Memory Layout"></img></div><br clear="none"></br></div>
                                 </div>
                                 <div class="p">For the generalized NC/xHWx layout format, the following observations apply:<a name="nc32hw32-layout-x32__ul_fb3_wj1_3jb" shape="rect">
                                       <!-- --></a><ul class="ul" id="nc32hw32-layout-x32__ul_fb3_wj1_3jb">
                                       <li class="li liexpand">Only the channel dimension, <samp class="ph codeph">C</samp>, is grouped into <samp class="ph codeph">x</samp> channels
                                          					each.
                                       </li>
                                       <li class="li liexpand">When <samp class="ph codeph">x = 1</samp>, each group has only one channel. Hence, the elements of one
                                          					channel (that is, one group) are arranged contiguously (in the row-major order),
                                          					before proceeding to the next group (that is, next channel). This is the same as
                                          					NCHW format.
                                       </li>
                                       <li class="li liexpand">When <samp class="ph codeph">x = C</samp>, then NC/xHWx is identical to NHWC, that is, the entire channel
                                          					depth <samp class="ph codeph">C</samp> is considered as a single group. The case <samp class="ph codeph">x =
                                             						C</samp> can be thought of as vectorizing the entire <samp class="ph codeph">C</samp>
                                          					dimension as one big vector, laying out all the <samp class="ph codeph">C</samp>s, followed by
                                          					the remaining dimensions, just like NHWC.
                                       </li>
                                       <li class="li liexpand">The tensor format <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnTensorFormat_t" target="_blank" shape="rect"><samp class="ph codeph">cudnnTensorFormat_t</samp></a>
                                          					can also be interpreted in the following way: The NCHW INT8x32 format is really
                                          						<samp class="ph codeph">N x (C/32) x H x W x 32</samp> (32 <samp class="ph codeph">C</samp>s for every
                                          						<samp class="ph codeph">W</samp>), just as the NCHW INT8x4 format is <samp class="ph codeph">N x (C/4) x H
                                             						x W x 4</samp> (4 <samp class="ph codeph">C</samp>s for every <samp class="ph codeph">W</samp>). Hence
                                          					the <samp class="ph codeph">VECT_C</samp> name - each <samp class="ph codeph">W</samp> is a vector (4 or 32)
                                          					of <samp class="ph codeph">C</samp>s.
                                       </li>
                                    </ul>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="row-column-major"><a name="row-column-major" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#row-column-major" name="row-column-major" shape="rect">2.2.2.3.&nbsp;MatMul Layouts</a></h3>
                           <div class="body conbody">
                              <div class="abstract">As discussed in <a class="xref" href="index.html#three-D-tensor-descriptor" shape="rect">3-D Tensor Descriptor</a>, matmul uses 3D tensors,
                                 described using BMN dimensions. The layout can be specified through the following strides.
                                 The following are two examples of recommended layouts: <span class="shortdesc"></span></div>
                              <div class="p"><a name="row-column-major__ul_ppp_pzb_k5b" shape="rect">
                                    <!-- --></a><ul class="ul" id="row-column-major__ul_ppp_pzb_k5b">
                                    <li class="li">Packed Row-major: dim [B,M,N] with stride [MN, N, 1], or</li>
                                    <li class="li">Packed Column-major: dim [B,M,N] with stride [MN, 1, M]</li>
                                 </ul>
                              </div>
                              <p class="p">Unpacked layouts for 3-D tensors are supported as well, but their support surface is more
                                 ragged.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="tensor_ops"><a name="tensor_ops" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tensor_ops" name="tensor_ops" shape="rect">2.3.&nbsp;Tensor Core Operations</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The cuDNN v7 library introduced the acceleration of compute-intensive routines
                              using Tensor Core hardware on supported GPU SM versions. Tensor Core operations are
                              supported beginning with the NVIDIA Volta GPU.</span></div>
                        <p class="p">Tensor Core operations accelerate matrix math operations; cuDNN uses Tensor Core
                           operations that accumulate into FP16, FP32, and INT32 values. Setting the math mode to
                           <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> via the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnMathType_t" target="_blank" shape="rect"><samp class="ph codeph">cudnnMathType_t</samp></a> enumerator
                           indicates that the library will use Tensor Core operations. This enumerator specifies
                           the available options to enable the Tensor Core and should be applied on a per-routine
                           basis.
                        </p>
                        <p class="p">The default math mode is <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>, which indicates that the
                           Tensor Core operations will be avoided by the library. Because the
                           <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> mode uses the Tensor Cores, it is possible
                           that these two modes generate slightly different numerical results due to different
                           sequencing of the floating-point operations.
                        </p>
                        <p class="p">For example, the result of multiplying two matrices using Tensor Core operations is very
                           close, but not always identical, to the result achieved using a sequence of scalar
                           floating-point operations. For this reason, the cuDNN library requires an explicit user
                           opt-in before enabling the use of Tensor Core operations.
                        </p>
                        <p class="p">However, experiments with training common deep learning models show negligible
                           differences between using Tensor Core operations and scalar floating point paths, as
                           measured by both the final network accuracy and the iteration count to convergence.
                           Consequently, the cuDNN library treats both modes of operation as functionally
                           indistinguishable and allows for the scalar paths to serve as legitimate fallbacks for
                           cases in which the use of Tensor Core operations is unsuitable.
                        </p>
                        <div class="p">Kernels using Tensor Core operations are available for:<a name="tensor_ops__ul_gjb_dtl_jrb" shape="rect">
                              <!-- --></a><ul class="ul" id="tensor_ops__ul_gjb_dtl_jrb">
                              <li class="li">Convolutions</li>
                              <li class="li">RNNs</li>
                              <li class="li">Multi-Head Attention</li>
                           </ul>
                        </div>
                        <p class="p">For more information, refer to <a class="xref" href="http://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html" target="_blank" shape="rect">NVIDIA Training with Mixed Precision</a>.
                        </p>
                        <div class="p">For a deep learning compiler, the following are the key guidelines:<a name="tensor_ops__ul_cl3_mw1_jwb" shape="rect">
                              <!-- --></a><ul class="ul" id="tensor_ops__ul_cl3_mw1_jwb">
                              <li class="li">Make sure that the convolution operation is eligible for Tensor Cores by
                                 avoiding any combinations of large padding and large filters.
                              </li>
                              <li class="li">Transform the inputs and filters to NHWC, pre-pad channel and batch size to be a
                                 multiple of 8.
                              </li>
                              <li class="li">Make sure that all user-provided tensors, workspace, and reserve space are
                                 aligned to 128-bit boundaries. Note that 1024-bit alignment may deliver better
                                 performance.
                              </li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-tensor-transformations-fp16"><a name="tensor-ops-tensor-transformations-fp16" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-fp16" name="tensor-ops-tensor-transformations-fp16" shape="rect">2.3.1.&nbsp;Notes on Tensor Core Precision</a></h3>
                        <div class="body conbody">
                           <div class="abstract">For FP16 data, Tensor Cores operate on FP16 input, output in FP16, and may accumulate
                              		in FP16 or FP32. The FP16 multiply leads to a full-precision result that is accumulated in
                              		FP32 operations with the other products in a given dot product for a matrix with <samp class="ph codeph">m x
                                 			n x k</samp> dimensions. Refer to <a class="xref" href="index.html#tensor-ops-tensor-transformations-fp16__fig-tensor-op-fp16-inputs" shape="rect">Figure 5</a>. <span class="shortdesc"></span></div>
                           <p class="p">For an FP32 accumulation, with FP16 output, the output of the accumulator is
                              			down-converted to FP16. Generally, the accumulation type is of greater or equal
                              			precision to the output type.
                           </p>
                           <div class="p">
                              <div class="fig fignone" id="tensor-ops-tensor-transformations-fp16__fig-tensor-op-fp16-inputs"><a name="tensor-ops-tensor-transformations-fp16__fig-tensor-op-fp16-inputs" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 5. Tensor operation with FP16 inputs. The accumulation is in FP32, which could be the input
                                    					for other kernel features (for example, activation/bias, beta blending, etc).
                                    					The final output in this example would be FP16.</span><br clear="none"></br><a name="tensor-ops-tensor-transformations-fp16__image_vwp_fhn_mpb" shape="rect">
                                    <!-- --></a><div class="imageleft">
                                    <embed class="image imageleft" id="tensor-ops-tensor-transformations-fp16__image_vwp_fhn_mpb" src="graphics/tensor-op-fp16-input.svg"></embed>
                                 </div><br clear="none"></br></div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="op-fusion"><a name="op-fusion" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#op-fusion" name="op-fusion" shape="rect">3.&nbsp;Graph API</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">The cuDNN library provides a declarative programming model for describing
                           computation as a graph of operations. This <em class="ph i">graph API</em> was introduced in cuDNN 8.0
                           to provide a more flexible API, especially with the growing importance of operation
                           fusion.</span></div>
                     <p class="p">The user starts by building a graph of operations. At a high level, the user is
                        describing a dataflow graph of operations on tensors. Given a <em class="ph i">finalized</em> graph,
                        the user then selects and configures an engine that can execute that graph. There are
                        several methods for selecting and configuring engines, which have tradeoffs with respect
                        to ease-of-use, runtime overhead, and engine performance. 
                     </p>
                     <div class="p">The graph API has two entry points:<a name="op-fusion__ul_xnx_ppp_1tb" shape="rect">
                           <!-- --></a><ul class="ul" id="op-fusion__ul_xnx_ppp_1tb">
                           <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnn-backend-api" target="_blank" shape="rect">NVIDIA cuDNN Backend API</a> (lowest level
                              entry point into the graph API)
                           </li>
                           <li class="li"><a class="xref" href="https://github.com/NVIDIA/cudnn-frontend" target="_blank" shape="rect">NVIDIA cuDNN Frontend API</a> (convenience layer on top
                              of the C backend API)
                           </li>
                        </ul>
                     </div>
                     <div class="p">We expect that most users prefer the cuDNN frontend API because:<a name="op-fusion__ul_upp_tpp_1tb" shape="rect">
                           <!-- --></a><ul class="ul" id="op-fusion__ul_upp_tpp_1tb">
                           <li class="li">It is less verbose without loss of control - all functionality accessible
                              through the backend API is also accessible through the frontend API.
                           </li>
                           <li class="li">It adds functionality on top of the backend API, like errata filters and
                              autotuning.
                           </li>
                           <li class="li">It is open source.</li>
                        </ul>
                     </div>
                     <p class="p">In either case (that is, the backend or frontend API), the high level concepts are the
                        same.
                     </p>
                  </div>
                  <div class="topic concept nested1" id="key-concepts"><a name="key-concepts" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#key-concepts" name="key-concepts" shape="rect">3.1.&nbsp;Key Concepts</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">As mentioned previously, the key concepts in the graph API are:</span></div>
                        <div class="p"><a name="key-concepts__ul_oqg_tzx_kwb" shape="rect">
                              <!-- --></a><ul class="ul" id="key-concepts__ul_oqg_tzx_kwb">
                              <li class="li"><a class="xref" href="index.html#op-op-graphs" title="An operation graph is a dataflow graph of operations on tensors. It is meant to be a mathematical specification and is decoupled from the underlying engines that can implement it, as there may be more than one engine available for a given graph." shape="rect">Operations and Operation Graphs</a></li>
                              <li class="li"><a class="xref" href="index.html#engine-engine-config" title="For a given operation graph, there are some number of engines that are candidates for implementing that graph. The typical way to query for a list of candidate engines is through a heuristics query, covered below." shape="rect">Engines and Engine Configurations</a></li>
                              <li class="li"><a class="xref" href="index.html#heuristics" title="A heuristic is a way to get a list of engine configurations that are intended to be sorted from the most performant to least performant for the given operation graph. There are three modes:" shape="rect">Heuristics</a></li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="op-op-graphs"><a name="op-op-graphs" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#op-op-graphs" name="op-op-graphs" shape="rect">3.1.1.&nbsp;Operations and Operation Graphs</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">An operation graph is a dataflow graph of operations on tensors. It is meant to
                                 be a mathematical specification and is decoupled from the underlying <em class="ph i">engines</em> that
                                 can implement it, as there may be more than one engine available for a given
                                 graph.</span></div>
                           <p class="p">I/O tensors connect the operations implicitly, for example, an operation A may produce a
                              tensor X, which is then consumed by operation B, implying that operation B depends on
                              operation A.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="engine-engine-config"><a name="engine-engine-config" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#engine-engine-config" name="engine-engine-config" shape="rect">3.1.2.&nbsp;Engines and Engine Configurations</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">For a given operation graph, there are some number of engines that are candidates
                                 for implementing that graph. The typical way to query for a list of candidate engines is
                                 through a heuristics query, covered below.</span></div>
                           <p class="p">An engine has knobs for configuring properties of the engine, like tile size (refer to
                              <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnBackendKnobType_t" target="_blank" shape="rect"><samp class="ph codeph">cudnnBackendKnobType_t</samp></a>).
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="heuristics"><a name="heuristics" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#heuristics" name="heuristics" shape="rect">3.1.3.&nbsp;Heuristics</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">A <em class="ph i">heuristic</em> is a way to get a list of engine configurations that are intended to
                                 			be sorted from the most performant to least performant for the given operation graph.
                                 			There are three modes:</span></div>
                           <div class="p">
                              <dl class="dl">
                                 <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_HEUR_MODE_A</samp></dt>
                                 <dd class="dd">Intended to be fast and be able to handle most operation graph patterns. It returns a list
                                    						of engine configs ranked by the expected performance.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_HEUR_MODE_B</samp></dt>
                                 <dd class="dd">Intended to be more generally accurate than mode A, but with the tradeoff of
                                    						higher CPU latency to return the list of engine configs. The underlying
                                    						implementation may fall back to the mode A heuristic in cases where we know
                                    						mode A can do better.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_HEUR_MODE_FALLBACK</samp></dt>
                                 <dd class="dd">Intended to be fast and provide functional fallbacks without expectation of
                                    						optimal performance.
                                 </dd>
                              </dl>
                           </div>
                           <p class="p">The recommended workflow is to query either mode A or B and check for support. The first
                              			engine config with support is expected to have the best performance.
                           </p>
                           <p class="p">You can “auto-tune”, that is, iterate over the list and time for each engine config and choose
                              			the best one for a particular problem on a particular device. The cuDNN frontend API
                              			provides a convenient function, <samp class="ph codeph">cudnnFindPlan()</samp>, which does this.
                           </p>
                           <p class="p">If all the engine configs are not supported, then use the mode fallback to find the
                              			functional fallbacks.
                           </p>
                           <p class="p">Expert users may also want to filter engine configs based on properties of the engine,
                              			such as numerical notes, behavior notes, or adjustable knobs. Numerical notes inform the
                              			user about the numerical properties of the engine such as whether it does datatype down
                              			conversion at the input or during output reduction. The behavior notes can signal
                              			something about the underlying implementation like whether or not it uses runtime
                              			compilation. The adjustable knobs allow fine grained control of the engine’s behavior
                              			and performance.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="graph-api-ex"><a name="graph-api-ex" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#graph-api-ex" name="graph-api-ex" shape="rect">3.2.&nbsp;Graph API Example with Operation Fusion</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following example implements a fusion of convolution, bias, and activation. </span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="create-op-tensor-desc"><a name="create-op-tensor-desc" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#create-op-tensor-desc" name="create-op-tensor-desc" shape="rect">3.2.1.&nbsp;Creating Operation and Tensor Descriptors to Specify the Graph Dataflow</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">First, create three cuDNN backend operation descriptors.</span></div>
                           <p class="p">As can be seen in <a class="xref" href="index.html#create-op-tensor-desc__fig2" shape="rect">Figure 6</a>, the user specified one
                              forward convolution operation (using
                              <samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</samp>), a
                              pointwise operation for the bias addition (using
                              <samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp> with mode
                              <samp class="ph codeph">CUDNN_POINTWISE_ADD</samp>), and a pointwise operation for the ReLU
                              activation (using <samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp> with
                              mode <samp class="ph codeph">CUDNN_POINTWISE_RELU_FWD</samp>). Refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnn-backend-api" target="_blank" shape="rect">NVIDIA cuDNN Backend API</a> for more details on
                              setting the attributes of these descriptors. For an example of how a forward convolution
                              can be set up, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#use-case-op-graph-group-convo" target="_blank" shape="rect">Setting Up An Operation Graph For A Grouped
                                 Convolution use case</a> in the cuDNN backend API.
                           </p>
                           <div class="p">You should also create tensor descriptors for the inputs and outputs of all of the
                              operations in the graph. The graph dataflow is implied by the assignment of tensors
                              (refer to <a class="xref" href="index.html#create-op-tensor-desc__fig2" shape="rect">Figure 6</a>), for example, by specifying the
                              backend tensor <em class="ph i">Tmp0</em> as both the output of the convolution operation and the input
                              of the bias operation, cuDNN infers that the dataflow runs from the convolution into the
                              bias. The same applies to tensor <em class="ph i">Tmp1</em>. If the user doesn’t need the intermediate
                              results <em class="ph i">Tmp0</em> and <em class="ph i">Tmp1</em> for any other use, then the user can specify them to
                              be virtual tensors, so the memory I/Os can later be optimized out.<a name="create-op-tensor-desc__ul_vkc_nqp_1tb" shape="rect">
                                 <!-- --></a><ul class="ul" id="create-op-tensor-desc__ul_vkc_nqp_1tb">
                                 <li class="li">Note that graphs with more than one operation node do not support in-place
                                    operations (that is, where any of the input UIDs matches any of the output
                                    UIDs). Such in-place operations are considered cyclic in later graph analysis
                                    and deemed unsupported. In-place operations are supported for single-node
                                    graphs.
                                 </li>
                                 <li class="li">Also note that the operation descriptors can be created and passed into cuDNN in
                                    any order, as the tensor UIDs are enough to determine the dependencies in the
                                    graph.
                                 </li>
                              </ul>
                           </div>
                           <div class="p">
                              <div class="fig fignone" id="create-op-tensor-desc__fig2"><a name="create-op-tensor-desc__fig2" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 6. A set of operation descriptors the user passes to the operation graph</span><br clear="none"></br><a name="create-op-tensor-desc__image_am5_pxv_nhb" shape="rect">
                                    <!-- --></a><div class="imageleft"><img class="image imageleft" id="create-op-tensor-desc__image_am5_pxv_nhb" src="graphics/Intro_ops.png" alt="A set of operation descriptors the user passes to the operation graph"></img></div><br clear="none"></br></div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="finalize-op-graph"><a name="finalize-op-graph" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#finalize-op-graph" name="finalize-op-graph" shape="rect">3.2.2.&nbsp;Finalizing The Operation Graph</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Second, the user finalizes the operation graph. As part of finalization, cuDNN
                                 performs the dataflow analysis to establish the dependency relationship between
                                 operations and connect the edges, as illustrated in the following figure. In this step,
                                 cuDNN performs various checks to confirm the validity of the graph.</span></div>
                           <div class="p">
                              <div class="fig fignone" id="finalize-op-graph__fig19"><a name="finalize-op-graph__fig19" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 7. The operation graph after finalization</span><br clear="none"></br><a name="finalize-op-graph__image_tny_hl2_yz" shape="rect">
                                    <!-- --></a><div class="imageleft"><img class="image imageleft" id="finalize-op-graph__image_tny_hl2_yz" src="graphics/Intro_connected.png" alt="The operation graph after finalization"></img></div><br clear="none"></br></div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="config-engine-execute-op"><a name="config-engine-execute-op" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#config-engine-execute-op" name="config-engine-execute-op" shape="rect">3.2.3.&nbsp;Configuring An Engine That Can Execute The Operation Graph</a></h3>
                        <div class="body conbody">
                           <div class="abstract">Third, given the finalized operation graph, the user must select and configure an
                              engine to execute that graph, which results in an execution plan. As mentioned in <a class="xref" href="index.html#heuristics" title="A heuristic is a way to get a list of engine configurations that are intended to be sorted from the most performant to least performant for the given operation graph. There are three modes:" shape="rect">Heuristics</a>, the typical way to do this is: <span class="shortdesc"></span></div>
                           <div class="p"><a name="config-engine-execute-op__ol_e14_jsp_1tb" shape="rect">
                                 <!-- --></a><ol class="ol" id="config-engine-execute-op__ol_e14_jsp_1tb">
                                 <li class="li liexpand">Query heuristics mode A or B.</li>
                                 <li class="li liexpand">Look for the first engine config with functional support (or auto-tune all the
                                    engine configs with functional support).
                                 </li>
                                 <li class="li liexpand">If no engine config was found in (2), try querying the fallback heuristic for
                                    more options.
                                 </li>
                              </ol>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="execute-the-engine"><a name="execute-the-engine" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#execute-the-engine" name="execute-the-engine" shape="rect">3.2.4.&nbsp;Executing The Engine</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Finally, with the execution plan constructed and when it comes time to run it,
                                 the user should construct the backend variant pack by providing the workspace pointer,
                                 an array of UIDs, and an array of device pointers. The UIDs and the pointers should be
                                 in the corresponding order. With the handle, the execution plan and variant pack, the
                                 execution API can be called and the computation is carried out on the GPU.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="support-graph-patterns"><a name="support-graph-patterns" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#support-graph-patterns" name="support-graph-patterns" shape="rect">3.3.&nbsp;Supported Graph Patterns</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The cuDNN Graph API supports a set of graph patterns. These patterns are
                              supported by a large number of engines, each with their own support surfaces. These
                              engines are grouped into four different classes, as reflected by the following four
                              subsections: pre-compiled single operation engines, generic runtime fusion engines,
                              specialized runtime fusion engines, and specialized pre-compiled fusion engines. The
                              specialized engines, whether they use runtime compilation or pre-compilation, are
                              targeted to a set of important use cases, and thus have a fairly limited set of patterns
                              they currently support. Over time, we expect to support more of those use cases with the
                              generic runtime fusion engines, whenever practical.</span></div>
                        <p class="p">Since these engines have some overlap in the patterns they support, a given pattern may
                           result in zero, one, or more engines.
                        </p>
                     </div>
                     <div class="topic concept nested2" id="compile-single-op-engine"><a name="compile-single-op-engine" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#compile-single-op-engine" name="compile-single-op-engine" shape="rect">3.3.1.&nbsp;Pre-compiled Single Operation Engines</a></h3>
                        <div class="body conbody">
                           <div class="abstract">One basic class of engines includes pre-compiled engines that support an operation
                              graph with just one operation; specifically: <samp class="ph codeph">ConvolutionFwd</samp>,
                              <samp class="ph codeph">ConvolutionBwFilter</samp>, <samp class="ph codeph">ConvolutionBwData</samp>, or
                              <samp class="ph codeph">ConvolutionBwBias</samp>. Their more precise support surface can be found in
                              the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html" target="_blank" shape="rect">NVIDIA cuDNN API Reference</a>. <span class="shortdesc"></span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="convolutionfwd"><a name="convolutionfwd" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convolutionfwd" name="convolutionfwd" shape="rect">3.3.1.1.&nbsp;<kbd class="ph userinput">ConvolutionFwd</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">ConvolutionFwd</samp> computes the convolution of X with filter data W. In
                                 addition, it uses scaling factors 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">α</mi>
                                    </mrow>
                                 </math>
                                 and 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">β</mi>
                                    </mrow>
                                 </math>
                                 to blend this result with the previous output. This graph operation is similar
                                 to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionForward()</samp></a>. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                              <div class="p">
                                 <div class="fig fignone" id="convolutionfwd__fig19"><a name="convolutionfwd__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 8. <samp class="ph codeph">ConvolutionFwd</samp> Engine</span><br clear="none"></br><a name="convolutionfwd__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convolutionfwd__image_am5_pxv_nhb" src="graphics/ConvFwd.png" alt="ConvolutionFwd Engine"></img></div><br clear="none"></br></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="convolutionbwfilter"><a name="convolutionbwfilter" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convolutionbwfilter" name="convolutionbwfilter" shape="rect">3.3.1.2.&nbsp;<kbd class="ph userinput">ConvolutionBwFilter</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">ConvolutionBwFilter</samp> computes the convolution filter gradient of the
                                 tensor dy. In addition, it uses scaling factors 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">α</mi>
                                    </mrow>
                                 </math>
                                 and 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">β</mi>
                                    </mrow>
                                 </math>
                                 to blend this result with the previous output. This graph operation is similar
                                 to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionBackwardFilter" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp></a>. <span class="shortdesc"></span></div>
                              <div class="p">
                                 <div class="fig fignone" id="convolutionbwfilter__fig19"><a name="convolutionbwfilter__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 9. <samp class="ph codeph">ConvolutionBwFilter</samp> Engine</span><br clear="none"></br><a name="convolutionbwfilter__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convolutionbwfilter__image_am5_pxv_nhb" src="graphics/ConvBwFilter.png" alt="ConvolutionBwFilter Engine"></img></div><br clear="none"></br></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="convolutionbwdata"><a name="convolutionbwdata" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convolutionbwdata" name="convolutionbwdata" shape="rect">3.3.1.3.&nbsp;<kbd class="ph userinput">ConvolutionBwData</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">ConvolutionBwData</samp> computes the convolution data gradient of the
                                 tensor dy. In addition, it uses scaling factors 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">α</mi>
                                    </mrow>
                                 </math>
                                 and 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">β</mi>
                                    </mrow>
                                 </math>
                                 to blend this result with the previous output. This graph operation is similar
                                 to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionBackwardData" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardData()</samp></a>. <span class="shortdesc"></span></div>
                              <div class="p">
                                 <div class="fig fignone" id="convolutionbwdata__fig19"><a name="convolutionbwdata__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 10. <samp class="ph codeph">ConvolutionBwData</samp> Engine</span><br clear="none"></br><a name="convolutionbwdata__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convolutionbwdata__image_am5_pxv_nhb" src="graphics/ConvBwData.png" alt="ConvolutionBwData Engine"></img></div><br clear="none"></br></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="normalizationforward"><a name="normalizationforward" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#normalizationforward" name="normalizationforward" shape="rect">3.3.1.4.&nbsp;<kbd class="ph userinput">NormalizationForward</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">NormalizationForward</samp> computes the normalization output
                                    <samp class="ph codeph">Y</samp> from the input <samp class="ph codeph">X</samp>. This operation is used in both
                                    the inference and training phase. The phases are distinguished by the attribute
                                    <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_PHASE</samp>. </span></div>
                              <div class="p">
                                 <div class="fig fignone" id="normalizationforward__fig19"><a name="normalizationforward__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 11. <samp class="ph codeph">NormalizationForward</samp> Engine</span><br clear="none"></br><a name="normalizationforward__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="normalizationforward__image_am5_pxv_nhb" src="graphics/normalizationforward.png" alt="NormalizationForward Engine"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">This operation supports different normalization modes which are set by the attribute
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_MODE</samp>. The dashed lines indicate
                                 optional inputs, which are typically used in the batch norm mode of this operation.
                                 Currently, instance norm and layer norm are supported via both precompiled and
                                 specialized runtime compiled engines while batch norm and RMS norm are supported using
                                 specialized runtime compiled engines (refer to <a class="xref" href="index.html#bnaddrelu" title="In ResNet-like vision models, batch normalization followed by ReLU activation is a commonly occurring pattern. The BNAddRelu fusion pattern, supported using a runtime compiled engine, aims to optimize this recurring operation graph. It also supports single node multi-GPU batch normalization for speeding up batch norm computation in multi-GPU systems. The pattern is intended for use in the forward pass during the training phase. The full pattern BNAddRelu with the add node is used in cases where there are skip connections in the model." shape="rect">BnAddRelu</a>).
                              </p>
                              <div class="p">
                                 <div class="tablenoborder"><a name="normalizationforward__table_l3x_dks_bxb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="normalizationforward__table_l3x_dks_bxb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 1. Instance Norm, Layer Norm, and RMS Norm For
                                             <samp class="ph codeph">NormalizationForward</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="25%" id="d54e1716" rowspan="1" colspan="1">Node and Other Attributes</th>
                                             <th class="entry" valign="top" width="25%" id="d54e1719" rowspan="1" colspan="1">Instance Normalization Forward</th>
                                             <th class="entry" valign="top" width="25%" id="d54e1722" rowspan="1" colspan="1">Layer Normalization Forward</th>
                                             <th class="entry" valign="top" width="25%" id="d54e1725" rowspan="1" colspan="1">RMS Normalization Forward</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">operation</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1"><samp class="ph codeph">normFwd</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1"><samp class="ph codeph">normFwd</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1"><samp class="ph codeph">normFwd</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">X</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">Mean</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">[N,C,(1),1,1], output, compute type, only applicable to
                                                <samp class="ph codeph">fmode</samp><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">[N,1,(1),1,1], output, compute type, only applicable to
                                                <samp class="ph codeph">fmode</samp><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">N/A</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">InvVariance</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">[N,C,(1),1,1], output, compute type, only applicable to
                                                <samp class="ph codeph">fmode</samp><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">[N,1,(1),1,1], output, compute type, only applicable to
                                                <samp class="ph codeph">fmode</samp><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">[N,1,(1),1,1], output, compute type,only applicable to
                                                <samp class="ph codeph">fmode</samp><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">Scale</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">[1,C,(1),1,1], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">[1,C,(D),H,W], input, compute type or I/O type depending on the
                                                engine used
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">[1,C,(D),H,W], input, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">Bias</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">[1,C,(1),1,1], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">[1,C,(D),H,W], input, compute type or I/O type depending on the
                                                engine used
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">Optional (no bias by default)</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">Y</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">[N, C, (D), H, W], output, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">[N, C, (D), H, W], output, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">[N, C, (D), H, W], output, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">epsilonDesc</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">[1,1,1,1], input, constant</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">[1,1,1,1], input, constant</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">[1,1,1,1], input, constant</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1"><samp class="ph codeph">mode</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_INSTANCE_NORM</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_LAYER_NORM</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_RMS_NORM</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1">Supported <samp class="ph codeph">fmode</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp>,
                                                <samp class="ph codeph">CUDNN_NORM_FWD_INFERENCE</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp>,
                                                <samp class="ph codeph">CUDNN_NORM_FWD_INFERENCE</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp>,
                                                <samp class="ph codeph">CUDNN_NORM_FWD_INFERENCE</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1">Supported layout</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">NC(D)HW, N(D)HWC</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">NC(D)HW, N(D)HWC</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">NC(D)HW, N(D)HWC</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1">Supported I/O types</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">FP16, FP32, BF16</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">FP16, FP32, BF16</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">FP16, FP32, BF16</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1">Supported compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">FP32</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">FP32</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">FP32</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e1716" rowspan="1" colspan="1">Alignment requirements for I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1719" rowspan="1" colspan="1">8 bytes aligned</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1722" rowspan="1" colspan="1">16 bytes aligned</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e1725" rowspan="1" colspan="1">16 bytes aligned</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="note note"><span class="notetitle">Note:</span> For each operation, all applicable tensors must have the same layout. 
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="normalizationbackward"><a name="normalizationbackward" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#normalizationbackward" name="normalizationbackward" shape="rect">3.3.1.5.&nbsp;<kbd class="ph userinput">NormalizationBackward</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">NormalizationBackward</samp> computes the gradient <samp class="ph codeph">dX</samp> and
                                 the scale and bias gradients <samp class="ph codeph">dScale</samp> and <samp class="ph codeph">dBias</samp>. This
                                 operation supports multiple modes which are set by the attribute
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_MODE</samp>. The precompiled engines support
                                 instance and layer norm backward while batch norm backward is supported by a specialized
                                 runtime compiled engine (refer to <a class="xref" href="index.html#dreluforkdbn" title="Similar to the BnAddRelu pattern, the DReluForkDBn pattern also targets ResNet-like vision networks. It is intended to be used in backpropagation during the training phase. The DReluForkDBn pattern is supported through a runtime compiled engine that usually complements the BnAddRelu pattern. It also supports single node multi-GPU batch normalization for speeding up batch norm backward computation in multi-GPU systems." shape="rect">DReluForkDBn</a>). The mean and variance
                                 saved during the forward training pass is passed as input to the<samp class="ph codeph">
                                    NormBackward</samp> operation. <span class="shortdesc"></span></div>
                              <div class="p">
                                 <div class="fig fignone" id="normalizationbackward__fig19"><a name="normalizationbackward__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 12. <samp class="ph codeph">NormalizationBackward</samp> Engine</span><br clear="none"></br><a name="normalizationbackward__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="normalizationbackward__image_am5_pxv_nhb" src="graphics/normalizationbackward.png" alt="NormalizationBackward Engine"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="normalizationbackward__table_l3x_dks_bxb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="normalizationbackward__table_l3x_dks_bxb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 2. Instance Norm, Layer Norm, and RMS Norm For
                                             <samp class="ph codeph">NormalizationBackward</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="25%" id="d54e2093" rowspan="1" colspan="1">Node and Other Attributes</th>
                                             <th class="entry" valign="top" width="25%" id="d54e2096" rowspan="1" colspan="1">Instance Normalization Backward</th>
                                             <th class="entry" valign="top" width="25%" id="d54e2099" rowspan="1" colspan="1">Layer Normalization Backward</th>
                                             <th class="entry" valign="top" width="25%" id="d54e2102" rowspan="1" colspan="1">RMS Normalization Backward</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">operation</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1"><samp class="ph codeph">normBwd</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1"><samp class="ph codeph">normBwd</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1"><samp class="ph codeph">normBwd</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">X</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">Mean</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[N,C,(1),1,1], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[N,1,(1),1,1], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">N/A</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">InvVariance</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[N,C,(1),1,1], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[N,1,(1),1,1], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">[N,1,(1),1,1], input, compute type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">Scale</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[1,C,(1),1,1], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[1,C,(D),H,W], input, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">[1,C,(D),H,W], input, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">DY</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">[N, C, (D), H, W], input, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">DX</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[N, C, (D), H, W], output, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[N, C, (D), H, W], output, I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">[N, C, (D), H, W], output, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">Dscale</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[1,C,(1),1,1], output, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[1,C,(D),H,W], output, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">[1,C,(D),H,W], output, I/O type</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">Dbias</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">[1,C,(1),1,1], output, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">[1,C,(D),H,W], output, compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">Optional</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1"><samp class="ph codeph">mode</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_INSTANCE_NORM</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_LAYER_NORM</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_RMS_NORM</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1">Supported layout</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">NC(D)HW, N(D)HWC</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">NC(D)HW, N(D)HWC</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">NC(D)HW, N(D)HWC</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1">Supported I/O types</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">FP16, FP32, BF16</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">FP16, FP32, BF16</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">FP16, FP32, BF16</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1">Supported compute type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">FP32</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">FP32</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">FP32</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e2093" rowspan="1" colspan="1">Alignment requirements for I/O type</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2096" rowspan="1" colspan="1">8 bytes aligned</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2099" rowspan="1" colspan="1">16 bytes aligned</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e2102" rowspan="1" colspan="1">16 bytes aligned</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="note note"><span class="notetitle">Note:</span> For each operation, all applicable tensors must have the same layout. Neither
                                    mixed I/O types, nor mixed compute types are supported.
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="runtime-fusion-engine"><a name="runtime-fusion-engine" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#runtime-fusion-engine" name="runtime-fusion-engine" shape="rect">3.3.2.&nbsp;Generic Runtime Fusion Engines</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">The engines documented in the previous section support single-op patterns. Of
                                 course, for fusion to be interesting, the graph needs to support multiple operations.
                                 And ideally, we want the supported patterns to be flexible to cover a diverse set of use
                                 cases. To accomplish this generality, cuDNN has runtime fusion engines that generate the
                                 kernel (or kernels) at runtime based on the graph pattern. This section outlines the
                                 patterns supported by these runtime fusion engines (that is, engines with
                                 <samp class="ph codeph">CUDNN_BEHAVIOR_NOTE_RUNTIME_COMPILATION</samp> behavioral
                                 note).</span></div>
                           <div class="p">We can think of the support surface as covering the follwing generic patterns:<a name="runtime-fusion-engine__ol_qnc_pn3_rtb" shape="rect">
                                 <!-- --></a><ol class="ol" id="runtime-fusion-engine__ol_qnc_pn3_rtb">
                                 <li class="li liexpand"><samp class="ph codeph">ConvolutionFwd</samp> fusions
                                    <p class="p">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>g</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                             <mo>(</mo>
                                             <mrow>
                                                <mtext>Y</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">convolutionFwd</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <mtext>X</mtext>
                                                   <mo>=</mo>
                                                   <msub>
                                                      <mi>g</mi>
                                                      <mtext>1</mtext>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mtext>inputs</mtext>
                                                   <mo>)</mo>
                                                   <mtext>,</mtext>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mtext fontfamily="Times New Roman">W</mtext>
                                                </mrow>
                                                <mo>)</mo>
                                                <mtext>,</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mtext fontfamily="Times New Roman">inputs</mtext>
                                             </mrow>
                                             <mo>)</mo>
                                          </mrow>
                                       </math>
                                    </p>
                                 </li>
                                 <li class="li liexpand"><samp class="ph codeph">ConvolutionBwFilter</samp> fusions
                                    <p class="p">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>g</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                             <mo>(</mo>
                                             <mrow>
                                                <mtext>dw</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">convolutionBwFilter</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <mtext>dy</mtext>
                                                   <mo>=</mo>
                                                   <msub>
                                                      <mi>g</mi>
                                                      <mtext>1</mtext>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mtext>inputs</mtext>
                                                   <mo>)</mo>
                                                   <mtext>,</mtext>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mtext fontfamily="Times New Roman">X</mtext>
                                                </mrow>
                                                <mo>)</mo>
                                                <mtext>,</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mtext fontfamily="Times New Roman">inputs</mtext>
                                             </mrow>
                                             <mo>)</mo>
                                          </mrow>
                                       </math>
                                    </p>
                                 </li>
                                 <li class="li liexpand"><samp class="ph codeph">ConvolutionBwData</samp> fusions
                                    <p class="p">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>g</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                             <mo>(</mo>
                                             <mrow>
                                                <mtext>dx</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">convolutionBwData</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mtext>dy, W</mtext>
                                                <mo>)</mo>
                                                <mtext>,</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mtext fontfamily="Times New Roman">inputs</mtext>
                                             </mrow>
                                             <mo>)</mo>
                                          </mrow>
                                       </math>
                                    </p>
                                 </li>
                                 <li class="li liexpand"><samp class="ph codeph">MatMul</samp> fusions
                                    <p class="p">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>g</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                             <mo>(</mo>
                                             <mrow>
                                                <mtext>C</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">matmul</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <mtext>A</mtext>
                                                   <mo>=</mo>
                                                   <msub>
                                                      <mtext>g</mtext>
                                                      <mtext>1</mtext>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mtext>inputs</mtext>
                                                   <mo>)</mo>
                                                   <mtext>,</mtext>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mtext fontfamily="Times New Roman">B</mtext>
                                                </mrow>
                                                <mo>)</mo>
                                                <mtext>,</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mtext fontfamily="Times New Roman">inputs</mtext>
                                             </mrow>
                                             <mo>)</mo>
                                          </mrow>
                                       </math>
                                    </p>
                                 </li>
                                 <li class="li liexpand">Pointwise fusions
                                    <p class="p">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>g</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                             <mo>(</mo>
                                             <mtext>inputs</mtext>
                                             <mo>)</mo>
                                          </mrow>
                                       </math>
                                    </p>
                                 </li>
                              </ol>
                           </div>
                           <div class="p">
                              <div class="fig fignone" id="runtime-fusion-engine__fig19"><a name="runtime-fusion-engine__fig19" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 13. Graphical Representation of the Generic Patterns Supported by the Runtime
                                    Fusion Engines</span><br clear="none"></br><a name="runtime-fusion-engine__image_am5_pxv_nhb" shape="rect">
                                    <!-- --></a><div class="imageleft"><img class="image imageleft" id="runtime-fusion-engine__image_am5_pxv_nhb" src="graphics/diagrams.png" alt="Graphical Representation of the Generic Patterns Supported by the Runtime Fusion Engines"></img></div><br clear="none"></br></div>
                           </div>
                           <div class="p">g<sub class="ph sub">1</sub> is a directed acyclic graph (DAG) that can consist of zero or any number of
                              the following operation:<a name="runtime-fusion-engine__ul_j3l_rp3_rtb" shape="rect">
                                 <!-- --></a><ul class="ul" id="runtime-fusion-engine__ul_j3l_rp3_rtb">
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR</samp></li>
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR</samp></li>
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp></li>
                              </ul>
                           </div>
                           <div class="p">g<sub class="ph sub">2</sub> is a DAG that can consist of zero or any number of the following
                              operations:<a name="runtime-fusion-engine__ul_jfn_sp3_rtb" shape="rect">
                                 <!-- --></a><ul class="ul" id="runtime-fusion-engine__ul_jfn_sp3_rtb">
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp></li>
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR</samp></li>
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR</samp></li>
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</samp></li>
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR</samp></li>
                                 <li class="li"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR</samp></li>
                              </ul>
                              <div class="note note"><span class="notetitle">Note:</span><a name="runtime-fusion-engine__ul_xcv_bps_bxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="runtime-fusion-engine__ul_xcv_bps_bxb">
                                    <li class="li">The arrow going into g<sub class="ph sub">2</sub> can go into any of g<sub class="ph sub">2</sub>’s nodes
                                       and does not necessarily need to feed into a root node.
                                    </li>
                                    <li class="li">The abbreviated notations for operations are used in the diagrams and
                                       throughout the text for visualization purposes.
                                    </li>
                                 </ul>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="limitations"><a name="limitations" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#limitations" name="limitations" shape="rect">3.3.2.1.&nbsp;Limitations</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">While the generic patterns listed previously are widely applicable, there are
                                    some cases where we do not have full support.</span></div>
                              <div class="section">
                                 <h5 class="title sectiontitle">Limitations Common to all Generic Patterns</h5>
                                 <div class="p">Limitations to g<sub class="ph sub">1</sub>:<a name="limitations__ul_i5r_4q3_rtb" shape="rect">
                                       <!-- --></a><ul class="ul" id="limitations__ul_i5r_4q3_rtb">
                                       <li class="li liexpand">Concatenation or signaling operations, if present, should be before any
                                          pointwise operations.
                                       </li>
                                       <li class="li liexpand">For compute capability &lt; 8.0, g<sub class="ph sub">1</sub> is not supported.
                                       </li>
                                    </ul>
                                 </div>
                                 <div class="p">Limitations to g<sub class="ph sub">2</sub>:<a name="limitations__ul_kmg_rq3_rtb" shape="rect">
                                       <!-- --></a><ul class="ul" id="limitations__ul_kmg_rq3_rtb">
                                       <li class="li liexpand">For compute capability &lt; 7.0, g<sub class="ph sub">2</sub> is not supported.
                                       </li>
                                       <li class="li liexpand">As specified in the previous section, g<sub class="ph sub">2</sub> can include only
                                          <samp class="ph codeph">Pointwise</samp> operations, <samp class="ph codeph">ResampleFwd</samp>,
                                          <samp class="ph codeph">ResampleBwd</samp>, <samp class="ph codeph">GenStats</samp>,
                                          <samp class="ph codeph">Signal</samp>, and <samp class="ph codeph">Reduction</samp>.
                                       </li>
                                       <li class="li liexpand">The I/O (that is, non-virtual) tensor data type can be any of <samp class="ph codeph">{FP32,
                                             INT32, FP16, BF16, INT8, FP8_E4M3, FP8_E5M2,
                                             packed-BOOLEAN}</samp>.
                                       </li>
                                       <li class="li liexpand">For pointwise operations, non-virtual tensors need to be either all NCHW (or
                                          row-major), or all NHWC (or column-major).
                                       </li>
                                       <li class="li liexpand">The intermediate virtual tensor data type can be any of <samp class="ph codeph">{FP32,
                                             INT32, FP16, BF16, INT8, BOOLEAN}</samp>, and this intermediate
                                          storage type is obeyed by the code-generator. Generally, FP32 is
                                          recommended.
                                       </li>
                                       <li class="li liexpand">The input tensor to a <samp class="ph codeph">ResampleFwd</samp> or
                                          <samp class="ph codeph">ResampleBwd</samp> operation should not be produced by another
                                          operation within this graph, but should come from global memory. <a name="limitations__ul_cw5_4k3_ywb" shape="rect">
                                             <!-- --></a><ul class="ul" id="limitations__ul_cw5_4k3_ywb">
                                             <li class="li">The two operations cannot be used in the
                                                <samp class="ph codeph">ConvolutionBwFilter</samp>,
                                                <samp class="ph codeph">ConvolutionBwData</samp>, and <samp class="ph codeph">MatMul</samp>
                                                fusion patterns.
                                             </li>
                                             <li class="li">Only compute capability &gt;= 7.5 is supported.</li>
                                          </ul>
                                       </li>
                                       <li class="li liexpand">Reduction operations can only be the exit nodes of g<sub class="ph sub">2</sub>.
                                       </li>
                                       <li class="li liexpand">Signaling operations, if present, must be the final nodes in g<sub class="ph sub">2</sub>.
                                          Hence, signaling operations cannot be used in conjunction with reduction
                                          operations.
                                       </li>
                                    </ul>
                                 </div>
                              </div>
                              <div class="section" id="limitations__section_v5h_yq3_rtb"><a name="limitations__section_v5h_yq3_rtb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Limitations per Generic Pattern for Compute Capability &lt; 9.0</h5>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="limitations__table_zgx_zq3_rtb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="limitations__table_zgx_zq3_rtb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 3. Limitations to g<sub class="ph sub">1</sub></span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e3001" rowspan="1" colspan="1">&nbsp;</th>
                                                <th class="entry" valign="top" width="50%" id="d54e3003" rowspan="1" colspan="1">Limitations to g<sub class="ph sub">1</sub></th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3001" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionFwd</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3003" rowspan="1" colspan="1"><a name="limitations__ul_sps_cr3_rtb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="limitations__ul_sps_cr3_rtb">
                                                      <li class="li">Fusion operations on input tensors can be only a chain
                                                         of three specific pointwise operations, in this exact
                                                         order: <samp class="ph codeph">Pointwise:mul</samp>,
                                                         <samp class="ph codeph">Pointwise:add</samp>, and
                                                         <samp class="ph codeph">Pointwise:ReLU</samp>. This specific
                                                         support is added to realize convolution batch norm
                                                         fusion use cases.
                                                      </li>
                                                      <li class="li">All tensors involved can only be FP16.</li>
                                                      <li class="li"><samp class="ph codeph">Pointwise:mul</samp> can only be with a tensor
                                                         of scalars per channel.
                                                      </li>
                                                      <li class="li"><samp class="ph codeph">Pointwise:add</samp> can only be a column
                                                         broadcast.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3001" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwFilter</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3003" rowspan="1" colspan="1">Same limitations specified for
                                                   <samp class="ph codeph">ConvolutionFwd</samp> fusions apply here.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3001" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwData</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3003" rowspan="1" colspan="1">No fusion on input tensors for backward data convolution is
                                                   supported.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3001" rowspan="1" colspan="1"><samp class="ph codeph">MatMul</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3003" rowspan="1" colspan="1"><a name="limitations__ul_xrf_hr3_rtb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="limitations__ul_xrf_hr3_rtb">
                                                      <li class="li">Can be any combination of pointwise operations.</li>
                                                      <li class="li">Only fusible with operand A, not with B.</li>
                                                      <li class="li">Operand A should have an FP16 data type.</li>
                                                      <li class="li">Broadcasted input can have any data type.</li>
                                                      <li class="li">Compute type is FP32 only.</li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3001" rowspan="1" colspan="1">Pointwise fusions</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3003" rowspan="1" colspan="1">Not Applicable</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                              <div class="section" id="limitations__section_h1z_vzn_lzb"><a name="limitations__section_h1z_vzn_lzb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Limitations per Generic Pattern for Compute Capability &gt;= 9.0</h5>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="limitations__table_i1z_vzn_lzb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="limitations__table_i1z_vzn_lzb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 4. Limitations to g<sub class="ph sub">1</sub></span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e3143" rowspan="1" colspan="1">&nbsp;</th>
                                                <th class="entry" valign="top" width="50%" id="d54e3145" rowspan="1" colspan="1">Limitations to g<sub class="ph sub">1</sub></th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3143" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionFwd</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3145" rowspan="1" colspan="1"><a name="limitations__ul_j1z_vzn_lzb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="limitations__ul_j1z_vzn_lzb">
                                                      <li class="li">Can be any combination of pointwise operations, but only
                                                         fusible with operand X, not with W.
                                                      </li>
                                                      <li class="li">The I/O tensor data types can be a mixture of any data
                                                         types within <samp class="ph codeph">{FP32, INT32, FP16, BF16, INT8,
                                                            FP8_E4M3, FP8_E5M2}</samp>. The
                                                         <samp class="ph codeph">packed-BOOLEAN</samp> data type is not
                                                         supported at this time.
                                                      </li>
                                                      <li class="li">For the mixed precision GEMM cases, the user still needs
                                                         to make sure the tensor types fed into the
                                                         <samp class="ph codeph">ConvolutionFwd</samp> operation are
                                                         matching. Simply, the user can apply a
                                                         <samp class="ph codeph">Pointwise:identity</samp> operation to
                                                         perform the data type conversion in the graph.
                                                      </li>
                                                      <li class="li">Compute type is <samp class="ph codeph">FP32</samp> only, except for
                                                         the sequence of <samp class="ph codeph">Pointwise:mul</samp>,
                                                         <samp class="ph codeph">Pointwise:add</samp>, and
                                                         <samp class="ph codeph">Pointwise:ReLU</samp> operations where
                                                         FP16 is allowed.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3143" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwFilter</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3145" rowspan="1" colspan="1">Same limitations specified for
                                                   <samp class="ph codeph">ConvolutionFwd</samp> fusions apply here.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3143" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwData</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3145" rowspan="1" colspan="1">Same limitations specified for ConvolutionFwd fusions apply
                                                   here.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3143" rowspan="1" colspan="1"><samp class="ph codeph">MatMul</samp> fusions
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3145" rowspan="1" colspan="1">Same limitations specified for
                                                   <samp class="ph codeph">ConvolutionFwd</samp> fusions apply here.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3143" rowspan="1" colspan="1">Pointwise fusions</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3145" rowspan="1" colspan="1">Not Applicable</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                              <div class="section" id="limitations__section_g44_3kr_g5b"><a name="limitations__section_g44_3kr_g5b" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Tensor Layout Requirements</h5>
                                 <p class="p">Lastly, there are some layout requirements to the I/O tensors involved in fusion
                                    graphs. For more information, refer to the <a class="xref" href="index.html#tensor-descriptor" title="The cuDNN library describes data with a generic n-D tensor descriptor defined with the following parameters:" shape="rect">Tensor Descriptor</a> and
                                    <a class="xref" href="index.html#data-layout-formats" title="This section describes how cuDNN tensors are arranged in memory according to several data layout formats." shape="rect">Data Layout Formats</a> sections. The following table describes the
                                    requirements per fusion pattern:
                                 </p>
                                 <div class="tablenoborder"><a name="limitations__table_gcm_glr_g5b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="limitations__table_gcm_glr_g5b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 5. Layout Requirements per Pattern</span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e3292" rowspan="1" colspan="1">Pattern</th>
                                             <th class="entry" valign="top" width="50%" id="d54e3295" rowspan="1" colspan="1">Layout Requirement</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e3292" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionFwd</samp>,
                                                <samp class="ph codeph">ConvolutionBwFilter</samp>,
                                                <samp class="ph codeph">ConvolutionBwData</samp> fusions
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e3295" rowspan="1" colspan="1"><a name="limitations__ul_hcm_glr_g5b" shape="rect">
                                                   <!-- --></a><ul class="ul" id="limitations__ul_hcm_glr_g5b">
                                                   <li class="li">All tensors are fully packed NHWC.</li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e3292" rowspan="1" colspan="1"><samp class="ph codeph">MatMul</samp> fusions
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e3295" rowspan="1" colspan="1"><a name="limitations__ul_fhc_nlr_g5b" shape="rect">
                                                   <!-- --></a><ul class="ul" id="limitations__ul_fhc_nlr_g5b">
                                                   <li class="li">Input operands can have either row-major or all
                                                      column-major.
                                                   </li>
                                                   <li class="li">In g<sub class="ph sub">1</sub>, the tensor operating with Matrix A (dim[B,
                                                      M, K]) can be either a scalar with dim[1, 1, 1], a row
                                                      vector with dim[B, M, 1], a column vector with dim[B, 1, K],
                                                      or a full matrix with dim[B, M, K].
                                                   </li>
                                                   <li class="li">In g<sub class="ph sub">2</sub>, all I/O tensors should be either all
                                                      row-major or all column-major.
                                                   </li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e3292" rowspan="1" colspan="1">Pointwise fusions</td>
                                             <td class="entry" valign="top" width="50%" headers="d54e3295" rowspan="1" colspan="1"><a name="limitations__ul_u4v_bmr_g5b" shape="rect">
                                                   <!-- --></a><ul class="ul" id="limitations__ul_u4v_bmr_g5b">
                                                   <li class="li">If all tensors are 3D, the same layout requirements as
                                                      matmul g<sub class="ph sub">2</sub>.
                                                   </li>
                                                   <li class="li">If all tensors are 4D or 5D, the same requirements as
                                                      <samp class="ph codeph">ConvolutionFwd</samp>,
                                                      <samp class="ph codeph">ConvolutionBwFilter</samp>,
                                                      <samp class="ph codeph">ConvolutionBwData</samp> layout.
                                                   </li>
                                                </ul>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="examples-sup-patterns"><a name="examples-sup-patterns" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#examples-sup-patterns" name="examples-sup-patterns" shape="rect">3.3.2.2.&nbsp;Examples of Supported Patterns</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">The following sections provide examples of supported patterns, in order of
                                    increasing complexity. We employ the same color scheme as in the overall pattern to aid
                                    in identifying the structure of g<sub class="ph sub">1</sub> (blue) and g<sub class="ph sub">2</sub>
                                    (purple).</span></div>
                              <p class="p">For illustration purposes, we abbreviated the operations used. For a full mapping to the
                                 actual backend descriptors, refer to the <a class="xref" href="index.html#mapping-backend-desc" title="For readability, the operations used in this section are abbreviated. The mapping with the actual backend descriptors can be found in this table:" shape="rect">Mapping with Backend Descriptors</a>.
                              </p>
                           </div>
                           <div class="topic concept nested4" id="single-op"><a name="single-op" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#single-op" name="single-op" shape="rect">3.3.2.2.1.&nbsp;Single Operation</a></h3>
                              <div class="body conbody">
                                 <div class="abstract"><span class="shortdesc">The following example illustrates a convolution operation without any operations
                                       before or after it. This means, g<sub class="ph sub">1</sub> and g<sub class="ph sub">2</sub>, are empty
                                       graphs.</span></div>
                                 <div class="p">
                                    <div class="fig fignone" id="single-op__fig19"><a name="single-op__fig19" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 14. This example illustrates the Runtime Fusion Engines with a Single
                                          Operation</span><br clear="none"></br><a name="single-op__image_am5_pxv_nhb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="single-op__image_am5_pxv_nhb" src="graphics/example_conv.png" alt="This example illustrates the Runtime Fusion Engines with a Single Operation"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="pointwise-op-conv1"><a name="pointwise-op-conv1" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#pointwise-op-conv1" name="pointwise-op-conv1" shape="rect">3.3.2.2.2.&nbsp;Pointwise Operations After Convolution 1</a></h3>
                              <div class="body conbody">
                                 <div class="abstract"><span class="shortdesc">In this example, g<sub class="ph sub">2</sub> consists of a sequential set of two pointwise
                                       operations after the convolution.</span></div>
                                 <div class="p">
                                    <div class="fig fignone" id="pointwise-op-conv1__fig19"><a name="pointwise-op-conv1__fig19" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 15. <samp class="ph codeph">ConvolutionFwd</samp> Followed by a DAG with Two Operations</span><br clear="none"></br><a name="pointwise-op-conv1__image_am5_pxv_nhb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="pointwise-op-conv1__image_am5_pxv_nhb" src="graphics/example_conv_pw.png" alt="ConvolutionFwd Followed by a DAG with Two Operations"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="pointwise-op-conv2"><a name="pointwise-op-conv2" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#pointwise-op-conv2" name="pointwise-op-conv2" shape="rect">3.3.2.2.3.&nbsp;Pointwise Operations After Convolution 2</a></h3>
                              <div class="body conbody">
                                 <div class="abstract"><span class="shortdesc">Similar to the previous example, g<sub class="ph sub">2</sub> consists of a sequential set of
                                       multiple pointwise operations.</span></div>
                                 <div class="p">
                                    <div class="fig fignone" id="pointwise-op-conv2__fig19"><a name="pointwise-op-conv2__fig19" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 16. <samp class="ph codeph">ConvolutionFwd</samp> Followed by a DAG with Three
                                          Operations</span><br clear="none"></br><a name="pointwise-op-conv2__image_am5_pxv_nhb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="pointwise-op-conv2__image_am5_pxv_nhb" src="graphics/mxnet.png" alt="ConvolutionFwd Followed by a DAG with Three Operations"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="pointwise-op-matrix-multi"><a name="pointwise-op-matrix-multi" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#pointwise-op-matrix-multi" name="pointwise-op-matrix-multi" shape="rect">3.3.2.2.4.&nbsp;Pointwise Operations Before Matrix Multiplication</a></h3>
                              <div class="body conbody">
                                 <div class="abstract"><span class="shortdesc">Pointwise operations can also precede a convolution or matrix multiplication,
                                       that is, g<sub class="ph sub">1</sub> is composed of pointwise operations.</span></div>
                                 <div class="p">
                                    <div class="fig fignone" id="pointwise-op-matrix-multi__fig19"><a name="pointwise-op-matrix-multi__fig19" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 17. MatMul Preceded by a DAG with Two Operations</span><br clear="none"></br><a name="pointwise-op-matrix-multi__image_am5_pxv_nhb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="pointwise-op-matrix-multi__image_am5_pxv_nhb" src="graphics/matmul.png" alt="MatMul Preceded by a DAG with Two Operations"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="conv-prod-node"><a name="conv-prod-node" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#conv-prod-node" name="conv-prod-node" shape="rect">3.3.2.2.5.&nbsp;Convolution Producer Node in Middle of DAG</a></h3>
                              <div class="body conbody">
                                 <div class="abstract"><span class="shortdesc">The following pattern shows g<sub class="ph sub">1</sub> as a DAG of pointwise operations
                                       feeding into a convolution. In addition, g<sub class="ph sub">2</sub> is a DAG consisting of two
                                       pointwise operations. Note that the convolution is being consumed in the middle of
                                       g<sub class="ph sub">2</sub> as opposed to g<sub class="ph sub">2</sub>’s first node. This is a valid
                                       pattern.</span></div>
                                 <div class="p">
                                    <div class="fig fignone" id="conv-prod-node__fig19"><a name="conv-prod-node__fig19" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 18. This example illustrates fusion of operations before and after the
                                          <samp class="ph codeph">ConvolutionFwd </samp>operation. In addition we observe that the
                                          output of <samp class="ph codeph">ConvolutionFwd </samp>can feed anywhere in
                                          g<sub class="ph sub">2</sub>.</span><br clear="none"></br><a name="conv-prod-node__image_am5_pxv_nhb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="conv-prod-node__image_am5_pxv_nhb" src="graphics/conv_DAG.png" alt="This example illustrates fusion of operations before and after the ConvolutionFwd operation. In addition we observe that the output of ConvolutionFwd can feed anywhere in g2."></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="op-specific-contraints-runtime-fusion-engine"><a name="op-specific-contraints-runtime-fusion-engine" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#op-specific-contraints-runtime-fusion-engine" name="op-specific-contraints-runtime-fusion-engine" shape="rect">3.3.2.3.&nbsp;Operation specific Constraints for the Runtime Fusion Engines</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">Every operation in the supported generic patterns of the runtime fusion engines
                                    is subject to a few specific constraints regarding their parameter surface. The
                                    following subsections document these.</span></div>
                              <p class="p">Note that these constraints are in addition to (1) any constraints mentioned in the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnn-backend-api" target="_blank" shape="rect">NVIDIA cuDNN Backend API</a>, and (2) limitations
                                 in relation to other operations in the directed acyclic graph (DAG), as mentioned in the
                                 <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a> section.
                              </p>
                           </div>
                           <div class="topic concept nested4" id="conv-runtime-fusion-engine"><a name="conv-runtime-fusion-engine" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#conv-runtime-fusion-engine" name="conv-runtime-fusion-engine" shape="rect">3.3.2.3.1.&nbsp;Convolutions</a></h3>
                              <div class="body conbody">
                                 <div class="abstract"><span class="shortdesc">There are three operation nodes that represent different types of convolutions
                                       namely:</span></div>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dlterm"><samp class="ph codeph">ConvolutionFwd</samp></dt>
                                       <dd class="dd">This operation represents forward convolution, that is, computing the
                                          response tensor of image tensor convoluted with filter tensor. For complete
                                          details on the interface, as well as general constraints, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</samp></a>
                                          section.
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">ConvolutionBwFilter</samp></dt>
                                       <dd class="dd">This operation represents convolution backward filters, that is, computing
                                          filter gradients from a response and an image tensor. For complete details
                                          on the interface, as well as general constraints, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR</samp></a>
                                          section.
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">ConvolutionBwData</samp></dt>
                                       <dd class="dd">This operation represents convolution backward data, that is, computing
                                          input data gradients from a response and a filter tensor. For complete
                                          details on the interface, as well as general constraints, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR</samp></a>
                                          section.
                                       </dd>
                                    </dl>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="conv-runtime-fusion-engine__table_yqv_cls_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="conv-runtime-fusion-engine__table_yqv_cls_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 6. Tensor Attributes for all Three Operations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e3732" rowspan="1" colspan="1">&nbsp;</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e3734" rowspan="1" colspan="1">Input Tensor Attribute Name</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e3737" rowspan="1" colspan="1">Output Tensor Attribute Name</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3732" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionFwd</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3734" rowspan="1" colspan="1">
                                                   <p class="p"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_X</samp></p>
                                                   <p class="p"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_W</samp></p>
                                                </td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3737" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_Y</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3732" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwFilter</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3734" rowspan="1" colspan="1">
                                                   <p class="p"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DX</samp></p>
                                                   <p class="p"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DY</samp></p>
                                                </td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3737" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_W</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3732" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwData</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3734" rowspan="1" colspan="1">
                                                   <p class="p"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DW</samp></p>
                                                   <p class="p"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DY</samp></p>
                                                </td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e3737" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_X</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">The following tables list the constraints for all three operations, in addition to any
                                    constraints mentioned in the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnn-backend-api" target="_blank" shape="rect">NVIDIA cuDNN Backend API</a>, and any constraints
                                    listed in the <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a> section, in relation to other operations.
                                    Note that these additional constraints only apply when these operations are used in the
                                    runtime fusion engines.
                                    
                                    
                                    <div class="tablenoborder"><a name="conv-runtime-fusion-engine__table_t14_mls_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="conv-runtime-fusion-engine__table_t14_mls_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 7. Constraints for all Three Operations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e3840" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="50%" id="d54e3843" rowspan="1" colspan="1">Support</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3840" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_MODE</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3843" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3840" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_COMP_TYPE</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3843" rowspan="1" colspan="1"><a name="conv-runtime-fusion-engine__ul_w3p_zbt_g5b" shape="rect">
                                                      <!-- --></a><ul class="ul" id="conv-runtime-fusion-engine__ul_w3p_zbt_g5b">
                                                      <li class="li">For <samp class="ph codeph">ConvolutionFwd</samp><samp class="ph codeph">CUDNN_DATA_HALF</samp>,<samp class="ph codeph">CUDNN_DATA_INT32</samp>,
                                                         and<samp class="ph codeph">CUDNN_DATA_FLOAT</samp></li>
                                                      <li class="li">For <samp class="ph codeph">ConvolutionBwData</samp>and
                                                         <samp class="ph codeph">ConvolutionBwFilter</samp></li>
                                                      <li class="li">Only <samp class="ph codeph">CUDNN_DATA_FLOAT</samp></li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3840" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3843" rowspan="1" colspan="1"><samp class="ph codeph">2</samp> or <samp class="ph codeph">3</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3840" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3843" rowspan="1" colspan="1"><samp class="ph codeph">1.0f</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e3840" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e3843" rowspan="1" colspan="1"><samp class="ph codeph">0.0f</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="conv-runtime-fusion-engine__table_ccv_fhy_4zb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="conv-runtime-fusion-engine__table_ccv_fhy_4zb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 8. I/O and Compute Datatype Requirements</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="20%" id="d54e3964" rowspan="1" colspan="1">Tensor X Data Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e3967" rowspan="1" colspan="1">Tensor W Data Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e3970" rowspan="1" colspan="1">Convolution Compute Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e3973" rowspan="1" colspan="1">Tensor Y Data Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e3976" rowspan="1" colspan="1">Supported Architecture</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">INT32</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">INT32</samp>/<samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Ampere or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">FP16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">FP16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">FP16</samp>/<samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Volta or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">BF16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">BF16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Volta or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e3964" rowspan="1" colspan="1"><samp class="ph codeph">FP32(TF32)</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3967" rowspan="1" colspan="1"><samp class="ph codeph">FP32(TF32)</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3970" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3973" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e3976" rowspan="1" colspan="1">Ampere or newer</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="conv-runtime-fusion-engine__table_l2f_s1t_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="conv-runtime-fusion-engine__table_l2f_s1t_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 9. I/O Tensors Alignment Requirements</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="25%" id="d54e4203" rowspan="1" colspan="1">Tensor Data Type</th>
                                                <th class="entry" valign="top" width="25%" id="d54e4206" rowspan="1" colspan="1">Number of input and output channels for NVIDIA Hopper
                                                   Architecture
                                                </th>
                                                <th class="entry" valign="top" width="25%" id="d54e4209" rowspan="1" colspan="1">Number of input and output channels for NVIDIA Ampere and Ada
                                                   Lovelace
                                                </th>
                                                <th class="entry" valign="top" width="25%" id="d54e4212" rowspan="1" colspan="1">Number of input and output channels for NVIDIA Volta/Turing
                                                   Architecture
                                                </th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4203" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4206" rowspan="1" colspan="1">Multiple of 4</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4209" rowspan="1" colspan="1">Multiple of 4</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4212" rowspan="1" colspan="1">Multiple of 16</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4203" rowspan="1" colspan="1"><samp class="ph codeph">FP8</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4206" rowspan="1" colspan="1">Multiple of 16</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4209" rowspan="1" colspan="1">N/A</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4212" rowspan="1" colspan="1">N/A</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4203" rowspan="1" colspan="1"><samp class="ph codeph">FP16/BF16</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4206" rowspan="1" colspan="1">Multiple of 2</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4209" rowspan="1" colspan="1">Multiple of 2</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4212" rowspan="1" colspan="1">Multiple of 8</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4203" rowspan="1" colspan="1"><samp class="ph codeph">FP32(TF32)</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4206" rowspan="1" colspan="1">Any value</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4209" rowspan="1" colspan="1">Any value</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4212" rowspan="1" colspan="1">Multiple of 4</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">Lastly, there are some batch size requirements per operation:
                                    
                                    
                                    <div class="tablenoborder"><a name="conv-runtime-fusion-engine__table_i2w_vp3_lvb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="conv-runtime-fusion-engine__table_i2w_vp3_lvb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 10. Batch Size Requirements Per Operation</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e4308" rowspan="1" colspan="1">Operation</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e4311" rowspan="1" colspan="1">Batch size for FP8 data type on NVIDIA Hopper
                                                   Architecture
                                                </th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e4314" rowspan="1" colspan="1">Batch size for other data types</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4308" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionFwd</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4311" rowspan="1" colspan="1">Any</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4314" rowspan="1" colspan="1">Any</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4308" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwFilter</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4311" rowspan="1" colspan="1">Multiple of 16</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4314" rowspan="1" colspan="1">Any</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4308" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwData</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4311" rowspan="1" colspan="1">Multiple of 16</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4314" rowspan="1" colspan="1">Any</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <p class="p">The FP8 data type since Hopper architecture has two variants:
                                    <samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp> and <samp class="ph codeph">CUDNN_DATA_FP8_E5M2</samp> as I/O
                                    data types. Using them as inputs to the operation will result in FP8 Tensor Cores being
                                    used. The precision of the accumulation inside the FP8 Tensor Cores is controlled by the
                                    compute type, which may have one of two possible values:
                                    <samp class="ph codeph">CUDNN_DATA_FLOAT</samp> and
                                    <samp class="ph codeph">CUDNN_DATA_FAST_FLOAT_FOR_FP8</samp>.
                                 </p>
                                 <p class="p"><samp class="ph codeph">CUDNN_DATA_FAST_FLOAT_FOR_FP8</samp> is faster and sufficiently accurate for
                                    inference or the forward pass of training. However, for FP8 training backward pass
                                    computations (that is, computing weight and activation gradients), we recommend choosing
                                    the more accurate <samp class="ph codeph">CUDNN_DATA_FLOAT</samp> compute type to preserve a higher
                                    level of accuracy which may be necessary for some models.
                                 </p>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="conv-runtime-fusion-engine__table_rkg_lq3_lvb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="conv-runtime-fusion-engine__table_rkg_lq3_lvb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 11. Recommended compute type for FP8 tensor computations for Hopper
                                                architecture</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e4405" rowspan="1" colspan="1">Operation</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e4408" rowspan="1" colspan="1">Recommended I/O type</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e4411" rowspan="1" colspan="1">Recommended compute type</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4405" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionFwd</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4408" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4411" rowspan="1" colspan="1"><a name="conv-runtime-fusion-engine__ul_mrl_mg2_nvb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="conv-runtime-fusion-engine__ul_mrl_mg2_nvb">
                                                      <li class="li"><samp class="ph codeph">CUDNN_DATA_FAST_FLOAT_FOR_FP8</samp></li>
                                                      <li class="li"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4405" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwData</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4408" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4411" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4405" rowspan="1" colspan="1"><samp class="ph codeph">BatchNorm</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4408" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4411" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4405" rowspan="1" colspan="1"><samp class="ph codeph">Pooling</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4408" rowspan="1" colspan="1"><a name="conv-runtime-fusion-engine__ul_chr_vb5_lvb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="conv-runtime-fusion-engine__ul_chr_vb5_lvb">
                                                      <li class="li"><samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp></li>
                                                      <li class="li"><samp class="ph codeph">CUDNN_DATA_FP8_E5M2</samp></li>
                                                   </ul>
                                                </td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4411" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4405" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4408" rowspan="1" colspan="1"><a name="conv-runtime-fusion-engine__ul_fxk_wb5_lvb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="conv-runtime-fusion-engine__ul_fxk_wb5_lvb">
                                                      <li class="li"><samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp></li>
                                                      <li class="li"><samp class="ph codeph">CUDNN_DATA_FP8_E5M2</samp></li>
                                                   </ul>
                                                </td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e4411" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="matmul-runtime-fusion-engine"><a name="matmul-runtime-fusion-engine" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#matmul-runtime-fusion-engine" name="matmul-runtime-fusion-engine" shape="rect">3.3.2.3.2.&nbsp;MatMul</a></h3>
                              <div class="body conbody">
                                 <div class="abstract">This operation represents matrix-matrix multiplication: A * B = C. For complete
                                    details on the interface, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</samp></a>
                                    section. <span class="shortdesc"></span></div>
                                 <p class="p">The following two tables list the constraints for MatMul operations, in addition to any
                                    general constraints as listed in the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR" target="_blank" shape="rect">NVIDIA cuDNN Backend API</a>, and any constraints
                                    listed in the <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a> section, in relation to other operations.
                                    Note that these additional constraints only apply when MatMul is used in the runtime
                                    fusion engines. Besides the layouts of operand A, B, and C, there must be row major,
                                    column major, and row major, respectively, for the INT8 tensor data type.
                                 </p>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="matmul-runtime-fusion-engine__table_zt5_cbt_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="matmul-runtime-fusion-engine__table_zt5_cbt_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 12. Constraints for MatMul Operations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e4573" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="50%" id="d54e4576" rowspan="1" colspan="1">Support</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e4573" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_MATMUL_COMP_TYPE</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e4576" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp>,<samp class="ph codeph">CUDNN_DATA_INT32</samp>,
                                                   and <samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="matmul-runtime-fusion-engine__table_ccv_fhy_4zb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="matmul-runtime-fusion-engine__table_ccv_fhy_4zb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 13. I/O and Compute Datatype Requirements</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="20%" id="d54e4628" rowspan="1" colspan="1">Tensor A Data Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e4631" rowspan="1" colspan="1">Tensor B Data Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e4634" rowspan="1" colspan="1">Matmul Compute Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e4637" rowspan="1" colspan="1">Tensor C Data Type</th>
                                                <th class="entry" valign="top" width="20%" id="d54e4640" rowspan="1" colspan="1">Supported Architecture</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">INT32</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">INT32</samp>/<samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Ampere or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E4M3</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">FP8_E5M2</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp>/<samp class="ph codeph">FAST_FLOAT_FOR_FP8</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Hopper or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">FP16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">FP16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">FP16</samp>/<samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Volta or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">BF16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">BF16</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Volta or newer</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="20%" headers="d54e4628" rowspan="1" colspan="1"><samp class="ph codeph">FP32(TF32)</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4631" rowspan="1" colspan="1"><samp class="ph codeph">FP32(TF32)</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4634" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4637" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                                <td class="entry" valign="top" width="20%" headers="d54e4640" rowspan="1" colspan="1">Ampere or newer</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="matmul-runtime-fusion-engine__table_rm5_fbt_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="matmul-runtime-fusion-engine__table_rm5_fbt_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 14. MatMul Alignment Requirements</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="25%" id="d54e4867" rowspan="1" colspan="1">Tensor Data Type</th>
                                                <th class="entry" valign="top" width="25%" id="d54e4870" rowspan="1" colspan="1">Number of input and output channels for NVIDIA Hopper
                                                   architecture
                                                </th>
                                                <th class="entry" valign="top" width="25%" id="d54e4873" rowspan="1" colspan="1">Innermost dimension for NVIDIA Ampere architecture and NVIDIA Ada
                                                   Lovelace
                                                </th>
                                                <th class="entry" valign="top" width="25%" id="d54e4876" rowspan="1" colspan="1">Innermost dimension for NVIDIA Volta and NVIDIA Turing
                                                   architecture
                                                </th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4867" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4870" rowspan="1" colspan="1">Multiple of 4</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4873" rowspan="1" colspan="1">Multiple of 4</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4876" rowspan="1" colspan="1">Multiple of 16</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4867" rowspan="1" colspan="1"><samp class="ph codeph">FP8</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4870" rowspan="1" colspan="1">Multiple of 16</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4873" rowspan="1" colspan="1">N/A</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4876" rowspan="1" colspan="1">N/A</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4867" rowspan="1" colspan="1"><samp class="ph codeph">FP16/BF16</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4870" rowspan="1" colspan="1">Multiple of 2</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4873" rowspan="1" colspan="1">Multiple of 2</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4876" rowspan="1" colspan="1">Multiple of 8</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="25%" headers="d54e4867" rowspan="1" colspan="1"><samp class="ph codeph">FP32(TF32)</samp></td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4870" rowspan="1" colspan="1">Any value</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4873" rowspan="1" colspan="1">Any value</td>
                                                <td class="entry" valign="top" width="25%" headers="d54e4876" rowspan="1" colspan="1">Multiple of 4</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="pointwise-runtime-fusion-engine"><a name="pointwise-runtime-fusion-engine" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#pointwise-runtime-fusion-engine" name="pointwise-runtime-fusion-engine" shape="rect">3.3.2.3.3.&nbsp;Pointwise</a></h3>
                              <div class="body conbody">
                                 <div class="abstract">Represents a pointwise operation that implements the equation <samp class="ph codeph">Y = op (alpha1 *
                                       X)</samp> or <samp class="ph codeph">Y = op (alpha1 * X, alpha2 * B)</samp>. Refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp></a> and <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_POINTWISE_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_POINTWISE_DESCRIPTOR</samp></a> sections for more
                                    information and general constraints. <span class="shortdesc"></span></div>
                                 <p class="p">The following table lists the constraints for pointwise operations, in addition to the
                                    general constraints listed above, and any constraints listed in the <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a> section, in relation to other operations. Note that these
                                    additional constraints only apply when these operations are used in the runtime fusion
                                    engines.
                                 </p>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="pointwise-runtime-fusion-engine__table_fpl_pbt_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="pointwise-runtime-fusion-engine__table_fpl_pbt_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 15. Constraints for Pointwise Operations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e5006" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="50%" id="d54e5009" rowspan="1" colspan="1">Requirement</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5006" rowspan="1" colspan="1">Tensor data type for
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_XDESC</samp>,
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_YDESC</samp> and, if
                                                   applicable,
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_BDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5009" rowspan="1" colspan="1"><a name="pointwise-runtime-fusion-engine__ul_i5g_5bt_g5b" shape="rect">
                                                      <!-- --></a><ul class="ul" id="pointwise-runtime-fusion-engine__ul_i5g_5bt_g5b">
                                                      <li class="li">For any of the logical operators
                                                         (<samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_AND</samp>,
                                                         <samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_OR</samp>, and
                                                         <samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_NOT</samp>), data type
                                                         can be any of <samp class="ph codeph">CUDNN_DATA_INT32</samp>,
                                                         <samp class="ph codeph">CUDNN_DATA_INT8</samp>, or
                                                         <samp class="ph codeph">CUDNN_DATA_BOOLEAN</samp>.
                                                      </li>
                                                      <li class="li">For all other operators, all data types are supported.</li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5006" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_MATH_PREC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5009" rowspan="1" colspan="1"><a name="pointwise-runtime-fusion-engine__ul_ohr_vbt_g5b" shape="rect">
                                                      <!-- --></a><ul class="ul" id="pointwise-runtime-fusion-engine__ul_ohr_vbt_g5b">
                                                      <li class="li">For any of the logical operators
                                                         (<samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_AND</samp>,
                                                         <samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_OR</samp>, and
                                                         <samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_NOT</samp>), math
                                                         precision needs to be
                                                         <samp class="ph codeph">CUDNN_DATA_BOOLEAN</samp>.
                                                      </li>
                                                      <li class="li">For all other operators, only <samp class="ph codeph">CUDNN_DATA_FLOAT
                                                            </samp>is supported.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5006" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_ALPHA1</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5009" rowspan="1" colspan="1"><samp class="ph codeph">1.0f</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5006" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_ALPHA2</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5009" rowspan="1" colspan="1"><samp class="ph codeph">1.0f</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="genstats-runtime-fusion-engine"><a name="genstats-runtime-fusion-engine" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#genstats-runtime-fusion-engine" name="genstats-runtime-fusion-engine" shape="rect">3.3.2.3.4.&nbsp;GenStats</a></h3>
                              <div class="body conbody">
                                 <div class="abstract">Represents an operation that generates per-channel statistics. Refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</samp></a> section for
                                    more information and general constraints. <span class="shortdesc"></span></div>
                                 <p class="p">The following table lists the constraints for GenStats operations, in addition to the
                                    general constraints listed above, and any constraints listed in the <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a> section, in relation to other operations. Note that these
                                    additional constraints only apply when GenStats operations are used in the runtime
                                    fusion engines.
                                 </p>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="genstats-runtime-fusion-engine__table_b15_cct_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="genstats-runtime-fusion-engine__table_b15_cct_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 16. Constraints for GenStats Operations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e5164" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="50%" id="d54e5167" rowspan="1" colspan="1">Requirement</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5164" rowspan="1" colspan="1">Tensor data type for
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_XDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5167" rowspan="1" colspan="1"><a name="genstats-runtime-fusion-engine__ul_cjh_3ct_g5b" shape="rect">
                                                      <!-- --></a><ul class="ul" id="genstats-runtime-fusion-engine__ul_cjh_3ct_g5b">
                                                      <li class="li">Prior to the NVIDIA Ampere architecture GPU:
                                                         <samp class="ph codeph">CUDNN_DATA_HALF</samp></li>
                                                      <li class="li">On NVIDIA Ampere architecture and later:
                                                         <samp class="ph codeph">CUDNN_DATA_HALF</samp> and
                                                         <samp class="ph codeph">CUDNN_DATA_FLOAT</samp></li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5164" rowspan="1" colspan="1">Tensor shape for <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SUMDESC
                                                      </samp>and
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SQSUMDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5167" rowspan="1" colspan="1">Both should be of shape [1, C, 1, 1] for 2D conv or [1, C, 1, 1,
                                                   1] for 3D conv.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5164" rowspan="1" colspan="1">Tensor data type for
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SUMDESC </samp>and
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SQSUMDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5167" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5164" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_MATH_PREC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5167" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5164" rowspan="1" colspan="1">Tensor layout for
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_XDESC</samp>,
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SUMDESC </samp>and
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SQSUMDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5167" rowspan="1" colspan="1">NHWC fully packed</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="reduction-runtime-fusion-engine"><a name="reduction-runtime-fusion-engine" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#reduction-runtime-fusion-engine" name="reduction-runtime-fusion-engine" shape="rect">3.3.2.3.5.&nbsp;Reduction</a></h3>
                              <div class="body conbody">
                                 <div class="abstract">This operation represents reducing values of a tensor in one or more dimensions. Refer
                                    to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR</samp></a> section for
                                    more information and general constraints. <span class="shortdesc"></span></div>
                                 <p class="p">The following two tables are constraints for Reduction forward operations, in addition to
                                    the general constraints listed above, and any constraints listed in the <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a> section, in relation to other operations. Note that these
                                    additional constraints only apply when Reduction operations are used in the runtime
                                    fusion engines.
                                 </p>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="reduction-runtime-fusion-engine__table_izh_n2t_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="reduction-runtime-fusion-engine__table_izh_n2t_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 17. Constraints for Reduction Operations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e5305" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="50%" id="d54e5308" rowspan="1" colspan="1">Requirement</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5305" rowspan="1" colspan="1">Tensor data type for
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_YDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5308" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5305" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_REDUCTION_COMP_TYPE</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5308" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5305" rowspan="1" colspan="1">Tensor layout for
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_XDESC</samp> and
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_YDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5308" rowspan="1" colspan="1">NHWC/NDHWC/BMN fully packed</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5305" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_REDUCTION_OPERATOR</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5308" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_ADD</samp>,
                                                   <samp class="ph codeph">CUDNN_REDUCE_TENSOR_MIN</samp>, and
                                                   <samp class="ph codeph">CUDNN_REDUCE_TENSOR_MAX</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="reduction-runtime-fusion-engine__table_mff_s2t_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="reduction-runtime-fusion-engine__table_mff_s2t_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 18. Supported Reduction Patterns</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" rowspan="2" valign="top" width="33.33333333333333%" id="d54e5392" colspan="1">Reduction Operation</th>
                                                <th class="entry" colspan="2" valign="top" id="d54e5395" rowspan="1">Reduction Pattern</th>
                                             </tr>
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e5401" rowspan="1" colspan="1">Input</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e5404" rowspan="1" colspan="1">Output</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5392 d54e5401" colspan="1">Standalone reduction operation</td>
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5395 d54e5404" colspan="1">[N, C, H, W]</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[N, 1, H, W]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, C, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5392 d54e5401" colspan="1">Reduction fused after convolution
                                                   <samp class="ph codeph">fprop</samp></td>
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5395 d54e5404" colspan="1">[N, K, P, Q]</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[N, 1, P, Q]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, K, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5392 d54e5401" colspan="1">Reduction fused after convolution backward data
                                                   gradient
                                                </td>
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5395 d54e5404" colspan="1">[N, C, H, W]</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[N, 1, H, W]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, C, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5392 d54e5401" colspan="1">Reduction fused after convolution backward filter
                                                   gradient
                                                </td>
                                                <td class="entry" rowspan="3" valign="top" width="33.33333333333333%" headers="d54e5395 d54e5404" colspan="1">[K, C, R, S]</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[K, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, C, R, S]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" rowspan="2" valign="top" width="33.33333333333333%" headers="d54e5392 d54e5401" colspan="1">Reduction fused after matrix multiplication
                                                   operation
                                                </td>
                                                <td class="entry" rowspan="2" valign="top" width="33.33333333333333%" headers="d54e5395 d54e5404" colspan="1">[B, M, N]</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[B, M, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5395" rowspan="1" colspan="1">[B, 1, N]</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="resamplefwd-runtime-fusion-engine"><a name="resamplefwd-runtime-fusion-engine" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#resamplefwd-runtime-fusion-engine" name="resamplefwd-runtime-fusion-engine" shape="rect">3.3.2.3.6.&nbsp;<kbd class="ph userinput">ResampleFwd</kbd></a></h3>
                              <div class="body conbody">
                                 <div class="abstract">This operation represents resampling of the spatial dimensions of an image to a
                                    desired value. Resampling is supported in both directions, upsampling and downsampling.
                                    Downsampling represents the standard operation of pooling, commonly used in convolutional
                                    neural networks. Refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR</samp></a> section for
                                    more information and general constraints. <span class="shortdesc"></span></div>
                                 <p class="p">The following are constraints for Resample operations, in addition to the general
                                    constraints listed above, and any constraints listed in the <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a>
                                    section, in relation to other operations. Note that these additional constraints only
                                    apply when Resample forward operations are used in the runtime fusion engines.
                                 </p>
                                 <div class="p">We allow a choice amongst four modes for resample. All modes have the following common
                                    support specifications:<a name="resamplefwd-runtime-fusion-engine__ul_hgh_kft_g5b" shape="rect">
                                       <!-- --></a><ul class="ul" id="resamplefwd-runtime-fusion-engine__ul_hgh_kft_g5b">
                                       <li class="li">Supported layout: NHWC or NDHWC, NCHW or NCDHW</li>
                                       <li class="li">Spatial dimensions supported: 2 or 3</li>
                                       <li class="li">Input dimensions supported: 4 or 5</li>
                                       <li class="li">Packed boolean data type is not supported.</li>
                                       <li class="li">If specified, the index tensor dimension should be equal to the response tensor
                                          dimension.
                                       </li>
                                    </ul>
                                 </div>
                                 <div class="p">When the tensor format is NCHW/NCDHW, the following additional restrictions apply:<a name="resamplefwd-runtime-fusion-engine__ul_xwl_5k3_ywb" shape="rect">
                                       <!-- --></a><ul class="ul" id="resamplefwd-runtime-fusion-engine__ul_xwl_5k3_ywb">
                                       <li class="li">Upsampling is not supported.</li>
                                       <li class="li"><samp class="ph codeph">Int64_t</samp> indices are not supported.
                                       </li>
                                       <li class="li">Only supports symmetric padding using the prepadding backend API.</li>
                                    </ul>
                                 </div>
                                 <p class="p">There are some mode specific restrictions also. The following tables list the values that
                                    are allowed for particular parameters. For the parameters not listed, we allow any value
                                    which is mathematically correct.
                                 </p>
                                 <div class="p">The following downsampling modes are supported:<a name="resamplefwd-runtime-fusion-engine__ul_unq_xhx_p5b" shape="rect">
                                       <!-- --></a><ul class="ul" id="resamplefwd-runtime-fusion-engine__ul_unq_xhx_p5b">
                                       <li class="li"><samp class="ph codeph">CUDNN_RESAMPLE_AVGPOOL_INCLUDE_PADDING</samp></li>
                                       <li class="li"><samp class="ph codeph">CUDNN_RESAMPLE_AVGPOOL_EXCLUDE_PADDING</samp></li>
                                       <li class="li"><samp class="ph codeph">CUDNN_RESAMPLE_MAXPOOL</samp></li>
                                    </ul>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="resamplefwd-runtime-fusion-engine__table_aql_4ft_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="resamplefwd-runtime-fusion-engine__table_aql_4ft_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 19. Specific Restrictions for the Downsampling Modes</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e5636" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e5639" rowspan="1" colspan="1">Average Pooling</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e5642" rowspan="1" colspan="1">Max Pooling</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5636" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_PADDING_MODE</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5639" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ZERO_PAD</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5642" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_NEG_INF_PAD</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5636" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_ALPHA</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5639" rowspan="1" colspan="1"><samp class="ph codeph">1.0</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5642" rowspan="1" colspan="1"><samp class="ph codeph">1.0</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5636" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_BETA</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5639" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5642" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5636" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_COMP_TYPE</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5639" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e5642" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <p class="p">For the upsampling modes, <samp class="ph codeph">CUDNN_RESAMPLE_NEAREST</samp> is not supported for
                                    any combination of parameters. <samp class="ph codeph">CUDNN_RESAMPLE_BILINEAR</samp> has the
                                    following support specifications.
                                 </p>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="resamplefwd-runtime-fusion-engine__table_dnt_yft_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="resamplefwd-runtime-fusion-engine__table_dnt_yft_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 20. Specific Restrictions for Upsampling Mode
                                                <samp class="ph codeph">CUDNN_RESAMPLE_BILINEAR</samp></span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e5741" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="50%" id="d54e5744" rowspan="1" colspan="1">Bilinear</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1">Input dimensions</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1">Equal to 0.5 x output dimensions</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_PRE_PADDINGS</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">0.5</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_POST_PADDINGS</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">1</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_STRIDES</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">0.5</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_WINDOW_DIMS</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">2</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1">Data type for <samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_XDESC
                                                      </samp>and
                                                   <samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_YDESC</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_COMP_TYPE</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_ALPHA</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">1.0</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_BETA</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e5741" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_PADDING_MODE</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e5744" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_EDGE_VAL_PAD</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                              <div class="topic concept nested5" id="resample-forward-index-dump"><a name="resample-forward-index-dump" shape="rect">
                                    <!-- --></a><h3 class="title topictitle2"><a href="#resample-forward-index-dump" name="resample-forward-index-dump" shape="rect">3.3.2.3.6.1.&nbsp;Resampling Index Tensor Dump for Training</a></h3>
                                 <div class="body conbody">
                                    <div class="abstract"><span class="shortdesc">For max-pooling resampling mode, an index tensor can be provided to be used as a
                                          mask for backpropagation. </span></div>
                                    <div class="p">Values in the index tensors are:<a name="resample-forward-index-dump__ul_eq3_j3m_z5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="resample-forward-index-dump__ul_eq3_j3m_z5b">
                                          <li class="li">Zero-indexed row-major position of maximum value of input tensor in the
                                             resampling window.
                                          </li>
                                          <li class="li">In case of multiple input pixels with maximum value, the first index in a
                                             left-to-right top-to-bottom scan is selected.
                                          </li>
                                       </ul>
                                    </div>
                                    <div class="p">Example of index element selection: 
                                       <div class="fig fignone" id="resample-forward-index-dump__fig19"><a name="resample-forward-index-dump__fig19" shape="rect">
                                             <!-- --></a><span class="figcap">Figure 19. Values In the Index Tensors</span><br clear="none"></br><a name="resample-forward-index-dump__image_am5_pxv_nhb" shape="rect">
                                             <!-- --></a><div class="imageleft"><img class="image imageleft" id="resample-forward-index-dump__image_am5_pxv_nhb" src="graphics/value-input-tensor.png" alt="Values In the Index Tensors"></img></div><br clear="none"></br></div>
                                    </div>
                                    <p class="p">Select an appropriate element size for the index tensor. As a reference, any element size
                                       such that the maximum zero-indexed window position fits should be sufficient.
                                    </p>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" id="resamplebwd-runtime-fusion-engine"><a name="resamplebwd-runtime-fusion-engine" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#resamplebwd-runtime-fusion-engine" name="resamplebwd-runtime-fusion-engine" shape="rect">3.3.2.3.7.&nbsp;<kbd class="ph userinput">ResampleBwd</kbd></a></h3>
                              <div class="body conbody">
                                 <div class="abstract">This operation represents backward resampling of the spatial dimensions of an output
                                    response to a desired value. Resampling is supported in both directions, upsampling and
                                    downsampling. Backwards downsampling represents the standard operation of backward pooling,
                                    commonly used in convolutional neural networks. Refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR" target="_blank" shape="rect"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR</samp></a> section for
                                    more information and general constraints. <span class="shortdesc"></span></div>
                                 <p class="p">The following are constraints for Resample backward operations, in addition to the
                                    general constraints listed above, and any constraints listed in the <a class="xref" href="index.html#limitations" title="While the generic patterns listed previously are widely applicable, there are some cases where we do not have full support." shape="rect">Limitations</a> section, in relation to other operations. Note that these
                                    additional constraints only apply when Resample backward operations are used in the
                                    runtime fusion engines.
                                 </p>
                                 <div class="p">We allow a choice amongst four modes for resample. All modes have the following common
                                    support specifications:<a name="resamplebwd-runtime-fusion-engine__ul_hgh_kft_g5b" shape="rect">
                                       <!-- --></a><ul class="ul" id="resamplebwd-runtime-fusion-engine__ul_hgh_kft_g5b">
                                       <li class="li">Supported layout: NHWC or NDHWC, NCHW or NCDHW</li>
                                       <li class="li">Spatial dimensions supported: 2 or 3</li>
                                       <li class="li">Input dimensions supported: 4 or 5</li>
                                    </ul>
                                 </div>
                                 <div class="p">For layout NHWC or NDHWC:<a name="resamplebwd-runtime-fusion-engine__ul_sct_zk3_ywb" shape="rect">
                                       <!-- --></a><ul class="ul" id="resamplebwd-runtime-fusion-engine__ul_sct_zk3_ywb">
                                       <li class="li">The index tensor should be provided for only max pooling mode, and should adhere
                                          to the format described in the <a class="xref" href="index.html#resample-forward-index-dump" title="For max-pooling resampling mode, an index tensor can be provided to be used as a mask for backpropagation." shape="rect">resampling forward index dump</a> section.
                                       </li>
                                       <li class="li">The index tensor dimensions should be equal to the input gradient tensor
                                          dimensions.
                                       </li>
                                    </ul>
                                 </div>
                                 <div class="p">For layout NCHW or NCDHW:<a name="resamplebwd-runtime-fusion-engine__ul_pfv_bl3_ywb" shape="rect">
                                       <!-- --></a><ul class="ul" id="resamplebwd-runtime-fusion-engine__ul_pfv_bl3_ywb">
                                       <li class="li">X, Y, and DY are required when max pooling mode is used.</li>
                                       <li class="li"><samp class="ph codeph">Int64_t</samp> indices are not supported.
                                       </li>
                                    </ul>
                                 </div>
                                 <p class="p">There are some mode specific restrictions also. The following tables list the values that
                                    are allowed for particular parameters. For the parameters not listed, we allow any value
                                    which is mathematically correct.
                                 </p>
                                 <div class="p">The following backward downsampling modes are supported:<a name="resamplebwd-runtime-fusion-engine__ul_unq_xhx_p5b" shape="rect">
                                       <!-- --></a><ul class="ul" id="resamplebwd-runtime-fusion-engine__ul_unq_xhx_p5b">
                                       <li class="li"><samp class="ph codeph">CUDNN_RESAMPLE_AVGPOOL_INCLUDE_PADDING</samp></li>
                                       <li class="li"><samp class="ph codeph">CUDNN_RESAMPLE_AVGPOOL_EXCLUDE_PADDING</samp></li>
                                       <li class="li"><samp class="ph codeph">CUDNN_RESAMPLE_MAXPOOL</samp></li>
                                    </ul>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="resamplebwd-runtime-fusion-engine__table_aql_4ft_g5b" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="resamplebwd-runtime-fusion-engine__table_aql_4ft_g5b" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 21. Specific Restrictions for the Backwards Downsampling Modes</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e6022" rowspan="1" colspan="1">Attribute</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e6025" rowspan="1" colspan="1">Average Pooling</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e6028" rowspan="1" colspan="1">Max Pooling</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6022" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_PADDING_MODE</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6025" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ZERO_PAD</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6028" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_NEG_INF_PAD</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6022" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_ALPHA</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6025" rowspan="1" colspan="1"><samp class="ph codeph">1.0</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6028" rowspan="1" colspan="1"><samp class="ph codeph">1.0</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6022" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_BETA</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6025" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6028" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6022" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_COMP_TYPE</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6025" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e6028" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <p class="p">Backward upsampling modes are currently not supported.</p>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="specialized-runtime-fusion-engines"><a name="specialized-runtime-fusion-engines" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#specialized-runtime-fusion-engines" name="specialized-runtime-fusion-engines" shape="rect">3.3.3.&nbsp;Specialized Runtime Fusion Engines</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">The specialized runtime fusion engines target and optimize specialized graph
                                 patterns that commonly occur in popular deep learning models. These engines offer
                                 limited flexibility regarding supported fusion patterns, supported data types, and
                                 supported tensor layouts. Long term, these patterns are expected to be more
                                 generic.</span></div>
                           <p class="p">The following sections highlight the supported patterns.</p>
                        </div>
                        <div class="topic concept nested3" id="bnaddrelu"><a name="bnaddrelu" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#bnaddrelu" name="bnaddrelu" shape="rect">3.3.3.1.&nbsp;<kbd class="ph userinput">BnAddRelu</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">In ResNet-like vision models, batch normalization followed by ReLU activation is
                                    a commonly occurring pattern. The <samp class="ph codeph">BNAddRelu</samp> fusion pattern, supported
                                    using a runtime compiled engine, aims to optimize this recurring operation graph. It
                                    also supports single node multi-GPU batch normalization for speeding up batch norm
                                    computation in multi-GPU systems. The pattern is intended for use in the forward pass
                                    during the training phase. The full pattern <samp class="ph codeph">BNAddRelu</samp> with the add node
                                    is used in cases where there are skip connections in the model. </span></div>
                              <div class="p">The pattern is illustrated in the following diagram and its options and limitations
                                 include:<a name="bnaddrelu__ul_zdk_lj4_1xb" shape="rect">
                                    <!-- --></a><ul class="ul" id="bnaddrelu__ul_zdk_lj4_1xb">
                                    <li class="li liexpand">The pointwise nodes: <samp class="ph codeph">Add</samp>, <samp class="ph codeph">ReLU</samp>, and
                                       <samp class="ph codeph">GT</samp> (greater than) are optional.
                                    </li>
                                    <li class="li liexpand">All tensors should be in NHWC packed layout format.</li>
                                    <li class="li liexpand">Both 4D and 5D tensors are supported.</li>
                                    <li class="li liexpand">Only ReLU activation is supported.</li>
                                    <li class="li liexpand">The attribute <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_MODE</samp> for the norm
                                       forward operation must be set to <samp class="ph codeph">CUDNN_BATCH_NORM</samp>.
                                    </li>
                                    <li class="li liexpand">The attribute <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_PHASE</samp> for the norm
                                       forward operation must be set to <samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp>.
                                    </li>
                                    <li class="li liexpand">The batch norm input tensors: <samp class="ph codeph">Scale</samp>, <samp class="ph codeph">Bias</samp>,
                                       <samp class="ph codeph">Input_running_mean</samp>, and <samp class="ph codeph">Input_running_var</samp>
                                       must be of float data type.
                                    </li>
                                    <li class="li liexpand">The batch norm output tensors: <samp class="ph codeph">output_running_mean</samp>,
                                       <samp class="ph codeph">output_running var</samp>, <samp class="ph codeph">mean</samp>, and
                                       <samp class="ph codeph">InvVariance</samp> must be of float data type. 
                                    </li>
                                    <li class="li liexpand">The batch norm input tensor <samp class="ph codeph">BN_x</samp>, residual input Z and output
                                       tensor Y can be any of <samp class="ph codeph">{FP32, FP16, BF16}</samp> data types. For
                                       <samp class="ph codeph">FP16</samp> and <samp class="ph codeph">BF16</samp> data types, the channel
                                       count C for the tensors must be a multiple of 8 while for float data type the
                                       channel count must be a multiple of 4.
                                    </li>
                                    <li class="li liexpand">These patterns are supported on devices with compute capability &gt;= 8.0.</li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="bnaddrelu__fig19"><a name="bnaddrelu__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 20. <samp class="ph codeph">BnAddRelu</samp> cuDNN Operation Graph</span><br clear="none"></br><a name="bnaddrelu__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="bnaddrelu__image_am5_pxv_nhb" src="graphics/bnaddrelu.png" alt="BnAddRelu cuDNN Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">In case of single node multi-GPU batch norm, each GPU computes the local statistics based
                                 on its input data and writes out the local statistics to the
                                 <samp class="ph codeph">peerTensors</samp>. Each <samp class="ph codeph">peerTensor</samp> resides on a separate
                                 GPU on the node and is used for reading and writing local statistics from the peer GPUs.
                                 This is followed by a global stats computation phase where each GPU aggregates the
                                 statistics from the peers and computes the global mean and variance for the batch norm
                                 output computation on its local data. Apart from the options and limitations listed
                                 above, the following additional restrictions apply for using multi-GPU batch norm:<a name="bnaddrelu__ul_ddj_sjk_bxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="bnaddrelu__ul_ddj_sjk_bxb">
                                    <li class="li liexpand">The attribute <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_PEER_STAT_DESCS</samp> of
                                       the <samp class="ph codeph">NormForward</samp> operation must be set.
                                    </li>
                                    <li class="li liexpand">The size of the <samp class="ph codeph">peerTensors</samp> vector should be equal to the
                                       number of GPUs in the node participating in the batch norm computation.
                                    </li>
                                    <li class="li liexpand">The maximum size of the <samp class="ph codeph">peerTensors</samp> vector is 32.
                                    </li>
                                    <li class="li liexpand">Each GPU should operate on the same size of input data [N,C,H,W].</li>
                                    <li class="li liexpand">The size of each <samp class="ph codeph">peerTensor</samp> in the <samp class="ph codeph">peerTensors</samp>
                                       vector should be equal to <samp class="ph codeph">num_gpu</samp> * 4 * C where C is the
                                       channel count of the <samp class="ph codeph">BN_x</samp> tensor and <samp class="ph codeph">num_gpu</samp>
                                       is the number of GPUs in the node participating in the batch norm
                                       computation.
                                    </li>
                                    <li class="li liexpand">All the elements of each tensor in the <samp class="ph codeph">peerTensors</samp> vector
                                       should be <samp class="ph codeph">memset</samp> to 0 before passing that tensor in the variant
                                       pack.
                                    </li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="bnaddrelu__fig_ctw_fkk_bxb"><a name="bnaddrelu__fig_ctw_fkk_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 21. Single Node Multi-GPU Batch Norm</span><br clear="none"></br><a name="bnaddrelu__image_dtw_fkk_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="bnaddrelu__image_dtw_fkk_bxb" src="graphics/multi-gpu-batch-norm.png" alt="Single Node Multi-GPU Batch Norm"></img></div><br clear="none"></br></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="dreluforkdbn"><a name="dreluforkdbn" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#dreluforkdbn" name="dreluforkdbn" shape="rect">3.3.3.2.&nbsp;<kbd class="ph userinput">DReluForkDBn</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">Similar to the <samp class="ph codeph">BnAddRelu</samp> pattern, the
                                    <samp class="ph codeph">DReluForkDBn</samp> pattern also targets ResNet-like vision networks. It
                                    is intended to be used in backpropagation during the training phase. The
                                    <samp class="ph codeph">DReluForkDBn</samp> pattern is supported through a runtime compiled engine
                                    that usually complements the <samp class="ph codeph">BnAddRelu</samp> pattern. It also supports single
                                    node multi-GPU batch normalization for speeding up batch norm backward computation in
                                    multi-GPU systems.</span></div>
                              <div class="p">The pattern is illustrated in the following diagram and its options and limitations
                                 include:<a name="dreluforkdbn__ul_ngx_blk_bxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="dreluforkdbn__ul_ngx_blk_bxb">
                                    <li class="li liexpand">The pointwise node <samp class="ph codeph">dRelu</samp> is optional.
                                    </li>
                                    <li class="li liexpand">The intermediate tensor <samp class="ph codeph">dZ</samp> can be virtual or non-virtual. 
                                    </li>
                                    <li class="li liexpand">All tensors should be in NHWC packed layout format.</li>
                                    <li class="li liexpand">Both 4D and 5D tensors are supported.</li>
                                    <li class="li liexpand">Only <samp class="ph codeph">dRelu</samp> activation is supported.
                                    </li>
                                    <li class="li liexpand">Bitmask tensor input is needed for the <samp class="ph codeph">dRelu</samp> node.
                                    </li>
                                    <li class="li liexpand">The attribute <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_MODE</samp> for the norm
                                       backward operation must be set to <samp class="ph codeph">CUDNN_BATCH_NORM</samp>.
                                    </li>
                                    <li class="li liexpand">The batch norm backward input tensors: <samp class="ph codeph">Scale</samp>,
                                       <samp class="ph codeph">Mean</samp>, <samp class="ph codeph">InvVariance</samp> and the output tensors
                                       <samp class="ph codeph">dScale</samp> and <samp class="ph codeph">dBias</samp> must be of float data
                                       type.
                                    </li>
                                    <li class="li liexpand"><samp class="ph codeph">dRelu</samp> input tensor <samp class="ph codeph">dY</samp>, batch norm backward
                                       input <samp class="ph codeph">BN_x</samp>, bias gradient <samp class="ph codeph">dZ</samp>, and output
                                       tensor <samp class="ph codeph">dX</samp> can be any of <samp class="ph codeph">{FP32, FP16, BF16}</samp>
                                       data types. For <samp class="ph codeph">FP16</samp> and <samp class="ph codeph">BF16</samp> data types, the
                                       channel count C for the tensors must be a multiple of 8 while for float data
                                       type the channel count must be a multiple of 4.
                                    </li>
                                    <li class="li liexpand">These patterns are supported on devices with compute capability &gt;= 8.0.</li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="dreluforkdbn__fig19"><a name="dreluforkdbn__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 22. <samp class="ph codeph">DReluForkDBn</samp> cuDNN Operation Graph</span><br clear="none"></br><a name="dreluforkdbn__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="dreluforkdbn__image_am5_pxv_nhb" src="graphics/dreluforkdbn.png" alt="DReluForkDBn cuDNN Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">The single node multi-GPU version of this pattern is typically used for
                                 <samp class="ph codeph">dScale</samp> and <samp class="ph codeph">dBias</samp> gradient aggregation across GPUs.
                                 For using the multi-GPU version, the attribute
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_PEER_STAT_DESCS</samp> of the
                                 <samp class="ph codeph">NormBackward</samp> operation must be set. Other restrictions for the
                                 <samp class="ph codeph">peerTensors</samp> vector listed in the previous section apply for this
                                 pattern as well. 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="fused-multi-head-att-fprop"><a name="fused-multi-head-att-fprop" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#fused-multi-head-att-fprop" name="fused-multi-head-att-fprop" shape="rect">3.3.3.3.&nbsp;Fused Attention <kbd class="ph userinput">fprop</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">Mha-Fprop</samp> fusions 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mtext fontfamily="Times New Roman">O</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mtext fontfamily="Times New Roman">matmul</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <mtext>S</mtext>
                                          <mo>=</mo>
                                          <msub>
                                             <mtext>g</mtext>
                                             <mtext>4</mtext>
                                          </msub>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>(</mo>
                                          <mrow>
                                             <mtext>P</mtext>
                                             <mo>=</mo>
                                             <mtext fontfamily="Times New Roman">matmul</mtext>
                                             <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                             <mo>(</mo>
                                             <mrow>
                                                <mtext fontfamily="Times New Roman">Q,</mtext>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mtext>g</mtext>
                                                   <mtext>3</mtext>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mtext>K</mtext>
                                                <mo>)</mo>
                                             </mrow>
                                             <mo>)</mo>
                                             <mtext>,</mtext>
                                             <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                             <mtext>V</mtext>
                                          </mrow>
                                          <mo>)</mo>
                                       </mrow>
                                       <mo>)</mo>
                                    </mrow>
                                 </math>
                                 have been added to the runtime fusion engine to serve patterns that are
                                 commonly used in attention. These patterns can be used in BERT, T5, and so
                                 on. <span class="shortdesc"></span></div>
                              <div class="p">There are two key differences to the flash fused attention patterns described in later
                                 sections:<a name="fused-multi-head-att-fprop__ol_oy1_zqs_bxb" shape="rect">
                                    <!-- --></a><ol class="ol" id="fused-multi-head-att-fprop__ol_oy1_zqs_bxb">
                                    <li class="li">Input sizes supported contain small sequence lengths (&lt;= 512).</li>
                                    <li class="li">The operation graph is flexible to switch between different types of masks,
                                       different operations between the two matrix multiplications, and so on.
                                    </li>
                                 </ol>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="fused-multi-head-att-fprop__fig19"><a name="fused-multi-head-att-fprop__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 23. <samp class="ph codeph">Mha-fprop</samp> cuDNN Operation Graph</span><br clear="none"></br><a name="fused-multi-head-att-fprop__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-fprop__image_am5_pxv_nhb" src="graphics/mha-fprop.png" alt="Mha-fprop cuDNN Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">g<sub class="ph sub">3</sub> can be an empty graph or a single scale operation with the scale being a
                                 scalar value (<samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp> with mode
                                 <samp class="ph codeph">CUDNN_POINTWISE_MUL</samp>). 
                              </p>
                              <p class="p">g<sub class="ph sub">4</sub> can be empty or the combination of the following DAGs of cuDNN operations.
                                 Each of these DAGs is optional, as shown by the dotted line.
                              </p>
                              <div class="p">
                                 <div class="fig fignone" id="fused-multi-head-att-fprop__dag1"><a name="fused-multi-head-att-fprop__dag1" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 24. DAGs of cuDNN operations</span><br clear="none"></br><a name="fused-multi-head-att-fprop__image_nhm_5rs_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-fprop__image_nhm_5rs_bxb" src="graphics/dag1.png" alt="DAGs of cuDNN operations"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">The combination has to obey the order in which we present them. For example, if you want
                                 to use the padding mask and softmax, the padding mask has to appear before softmax.
                              </p>
                              <p class="p">These operations are commonly used in attention. In the following diagram, we depict how
                                 to create a DAG for each of the operations. In later versions, we will be expanding the
                                 possible DAGs for g<sub class="ph sub">3</sub> and g<sub class="ph sub">4</sub>.
                              </p>
                              <div class="section" id="fused-multi-head-att-fprop__section_ymb_dss_bxb"><a name="fused-multi-head-att-fprop__section_ymb_dss_bxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Padding Mask</h5>
                                 <div class="p">
                                    <div class="fig fignone" id="fused-multi-head-att-fprop__fig_xd4_jss_bxb"><a name="fused-multi-head-att-fprop__fig_xd4_jss_bxb" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 25. cuDNN graph depicting <samp class="ph codeph">DAG:Padding Mask</samp></span><br clear="none"></br><a name="fused-multi-head-att-fprop__image_yd4_jss_bxb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-fprop__image_yd4_jss_bxb" src="graphics/padding-mask.png" alt="cuDNN graph depicting DAG:Padding Mask"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                              <div class="section" id="fused-multi-head-att-fprop__section_yrz_lss_bxb"><a name="fused-multi-head-att-fprop__section_yrz_lss_bxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Causal Mask</h5>
                                 <div class="p">
                                    <div class="fig fignone" id="fused-multi-head-att-fprop__fig_zrz_lss_bxb"><a name="fused-multi-head-att-fprop__fig_zrz_lss_bxb" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 26. cuDNN graph depicting <samp class="ph codeph">DAG:Causal Mask</samp></span><br clear="none"></br><a name="fused-multi-head-att-fprop__image_asz_lss_bxb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-fprop__image_asz_lss_bxb" src="graphics/dag-causal-mask.png" alt="cuDNN graph depicting DAG:Causal Mask"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                              <div class="section" id="fused-multi-head-att-fprop__section_t5d_tss_bxb"><a name="fused-multi-head-att-fprop__section_t5d_tss_bxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Softmax</h5>
                                 <div class="p">
                                    <div class="fig fignone" id="fused-multi-head-att-fprop__fig_u5d_tss_bxb"><a name="fused-multi-head-att-fprop__fig_u5d_tss_bxb" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 27. cuDNN graph depicting <samp class="ph codeph">DAG:Softmax</samp></span><br clear="none"></br><a name="fused-multi-head-att-fprop__image_v5d_tss_bxb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-fprop__image_v5d_tss_bxb" src="graphics/softmax.png" alt="cuDNN graph depicting DAG:Softmax"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                              <div class="section" id="fused-multi-head-att-fprop__section_tpg_wss_bxb"><a name="fused-multi-head-att-fprop__section_tpg_wss_bxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Dropout</h5>
                                 <div class="p">
                                    <div class="fig fignone" id="fused-multi-head-att-fprop__fig_upg_wss_bxb"><a name="fused-multi-head-att-fprop__fig_upg_wss_bxb" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 28. cuDNN graph depicting <samp class="ph codeph">DAG:Dropout</samp></span><br clear="none"></br><a name="fused-multi-head-att-fprop__image_vpg_wss_bxb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-fprop__image_vpg_wss_bxb" src="graphics/dropout.png" alt="cuDNN graph depicting DAG:Dropout"></img></div><br clear="none"></br></div>
                                 </div>
                                 <p class="p">g<sub class="ph sub">4</sub> is capable of storing an intermediate tensor to global memory marked as
                                    <samp class="ph codeph">S</samp>, which can be used for fused multi-head attention
                                    <samp class="ph codeph">bprop</samp>. Both <samp class="ph codeph">DAG:Softmax</samp> and
                                    <samp class="ph codeph">DAG:Dropout</samp> have this capability. Set <samp class="ph codeph">S</samp> as the
                                    output from the last DAG in the graph.
                                 </p>
                                 <p class="p">The tensor descriptor marked as <samp class="ph codeph">S</samp> must have the
                                    <samp class="ph codeph">CUDNN_ATTR_TENSOR_REORDERING_MODE</samp> set to
                                    <samp class="ph codeph">CUDNN_TENSOR_REORDERING_F16x16</samp>. This is because the tensor is
                                    stored in a special format and can only be consumed by fused attention
                                    <samp class="ph codeph">bprop</samp>. 
                                 </p>
                                 <p class="p">There is an additional option of generating the mask on the user end and passing it
                                    directly to the pointwise multiply. The mask needs to be of I/O data type FP16/BF16
                                    and <samp class="ph codeph">S</samp> will store the mask in the sign bit to communicate to
                                    <samp class="ph codeph">bprop</samp>.
                                 </p>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="fused-multi-head-att-fprop__table_tby_45s_bxb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="fused-multi-head-att-fprop__table_tby_45s_bxb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 22. Limitations Of <samp class="ph codeph">Mha-fprop</samp> Fusions</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e6875" rowspan="1" colspan="1">&nbsp;</th>
                                                <th class="entry" valign="top" width="50%" id="d54e6877" rowspan="1" colspan="1">Limitations Of <samp class="ph codeph">Mha-fprop</samp> Fusions
                                                </th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e6875" rowspan="1" colspan="1">MatMul</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e6877" rowspan="1" colspan="1"><a name="fused-multi-head-att-fprop__ul_bfd_t5s_bxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="fused-multi-head-att-fprop__ul_bfd_t5s_bxb">
                                                      <li class="li">Compute type for both MatMul ops must be float.</li>
                                                      <li class="li">Input tensors must have data type <samp class="ph codeph">FP16</samp>
                                                         or <samp class="ph codeph">BF16</samp>.
                                                      </li>
                                                      <li class="li">Output tensors must have data type
                                                         <samp class="ph codeph">FP16</samp>, <samp class="ph codeph">BF16</samp>, or
                                                         <samp class="ph codeph">FP32</samp> (<samp class="ph codeph">TF32</samp>).
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e6875" rowspan="1" colspan="1">Pointwise operations in g<sub class="ph sub">3</sub> and
                                                   g<sub class="ph sub">4</sub></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e6877" rowspan="1" colspan="1">Compute type must be <samp class="ph codeph">FP32</samp>
                                                   (<samp class="ph codeph">TF32</samp>).
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e6875" rowspan="1" colspan="1">Reduction operations in g<sub class="ph sub">3</sub> and
                                                   g<sub class="ph sub">4</sub></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e6877" rowspan="1" colspan="1">I/O types and compute types must be <samp class="ph codeph">FP32</samp>
                                                   (<samp class="ph codeph">TF32</samp>).
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e6875" rowspan="1" colspan="1">RNG operation in g<sub class="ph sub">3</sub> and g<sub class="ph sub">4</sub></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e6877" rowspan="1" colspan="1"><a name="fused-multi-head-att-fprop__ul_qds_55s_bxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="fused-multi-head-att-fprop__ul_qds_55s_bxb">
                                                      <li class="li">Data type of <samp class="ph codeph">yTensor</samp> must be
                                                         <samp class="ph codeph">FP32</samp> (<samp class="ph codeph">TF32</samp>).
                                                      </li>
                                                      <li class="li">The <samp class="ph codeph">CUDNN_TYPE_RNG_DISTRIBUTION</samp> must be
                                                         <samp class="ph codeph">CUDNN_RNG_DISTRIBUTION_BERNOULLI</samp>.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">Layout requirements of <samp class="ph codeph">Mha-fprop</samp> fusions include:<a name="fused-multi-head-att-fprop__ul_sc3_bvs_bxb" shape="rect">
                                       <!-- --></a><ul class="ul" id="fused-multi-head-att-fprop__ul_sc3_bvs_bxb">
                                       <li class="li liexpand">All I/O tensors must have 4 dimensions, with the first two denoting the
                                          batch dimensions. The usage of rank-4 tensors in MatMul ops can be read from
                                          the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnn-backend-api" target="_blank" shape="rect">NVIDIA cuDNN Backend API</a>
                                          documentation.
                                       </li>
                                       <li class="li liexpand">The contracting dimension (dimension <samp class="ph codeph">K</samp>) for the first
                                          MatMul must be 64.
                                       </li>
                                       <li class="li liexpand">The non-contracting dimension (dimensions <samp class="ph codeph">M</samp> and
                                          <samp class="ph codeph">N</samp>) for the first MatMul must be less than or equal to
                                          512. In inference mode, any sequence length is functional. For training,
                                          support exists only for multiples of 64.
                                       </li>
                                       <li class="li liexpand">The last dimension (corresponding to hidden dimensions) in
                                          <samp class="ph codeph">Q</samp>, <samp class="ph codeph">V</samp>, and <samp class="ph codeph">O</samp> is
                                          expected to have stride 1.
                                       </li>
                                       <li class="li liexpand">For the <samp class="ph codeph">K</samp> tensor, the stride is expected to be 1 for the
                                          2nd last dimension.
                                       </li>
                                       <li class="li liexpand">The <samp class="ph codeph">S</samp> tensor is expected to have
                                          <samp class="ph codeph">CUDNN_ATTR_TENSOR_REORDERING_MODE</samp> set to
                                          <samp class="ph codeph">CUDNN_TENSOR_REORDERING_F16x16</samp>.
                                       </li>
                                    </ul>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="fused-multi-head-att-bprop"><a name="fused-multi-head-att-bprop" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#fused-multi-head-att-bprop" name="fused-multi-head-att-bprop" shape="rect">3.3.3.4.&nbsp;Fused Attention <kbd class="ph userinput">bprop</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">Mha-Bprop</samp> fusions are executed in a fused pattern in a single
                                    kernel.</span></div>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mtext fontfamily="Times New Roman">dV</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mtext fontfamily="Times New Roman">matmul</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <msub>
                                             <mtext>g</mtext>
                                             <mtext>5</mtext>
                                          </msub>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>(</mo>
                                          <mrow>
                                             <mtext>S</mtext>
                                          </mrow>
                                          <mo>)</mo>
                                          <mtext>,</mtext>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mtext>dO</mtext>
                                       </mrow>
                                       <mo>)</mo>
                                    </mrow>
                                 </math>
                              </p>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mtext fontfamily="Times New Roman">dS</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mtext fontfamily="Times New Roman">matmul</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <mtext>dO</mtext>
                                          <mtext>,</mtext>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mrow>
                                             <msup>
                                                <mi>V</mi>
                                                <mi>T</mi>
                                             </msup>
                                          </mrow>
                                       </mrow>
                                       <mo>)</mo>
                                    </mrow>
                                 </math>
                              </p>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mtext fontfamily="Times New Roman">dQ</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mtext fontfamily="Times New Roman">matmul</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <msub>
                                             <mtext>g</mtext>
                                             <mtext>6</mtext>
                                          </msub>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>(</mo>
                                          <mrow>
                                             <mtext>dS</mtext>
                                          </mrow>
                                          <mo>)</mo>
                                          <mtext>,</mtext>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mtext>K</mtext>
                                       </mrow>
                                       <mo>)</mo>
                                    </mrow>
                                 </math>
                              </p>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mtext fontfamily="Times New Roman">dK</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mtext fontfamily="Times New Roman">matmul</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mtext>Q</mtext>
                                       <mtext>,</mtext>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mrow>
                                          <msub>
                                             <mtext>g</mtext>
                                             <mtext>7</mtext>
                                          </msub>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>(</mo>
                                          <mrow>
                                             <mtext>dS</mtext>
                                          </mrow>
                                          <mo>)</mo>
                                       </mrow>
                                       <mo>)</mo>
                                    </mrow>
                                 </math>
                              </p>
                              <p class="p">cuDNN supports the corresponding backpropagation graph for fused attention. This can be
                                 used together with the fused attention <samp class="ph codeph">fprop</samp> graph to perform training
                                 on models that have similar architectures to BERT and T5. This is not compatible with
                                 the flash fused attention <samp class="ph codeph">bprop</samp> operation graph.
                              </p>
                              <div class="p">
                                 <div class="fig fignone" id="fused-multi-head-att-bprop__fig19"><a name="fused-multi-head-att-bprop__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 29. <samp class="ph codeph">Mha-bprop</samp> cuDNN Operation Graph</span><br clear="none"></br><a name="fused-multi-head-att-bprop__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-bprop__image_am5_pxv_nhb" src="graphics/mha-bprop.png" alt="Mha-bprop cuDNN Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">g<sub class="ph sub">5</sub>, g<sub class="ph sub">6</sub>, and g<sub class="ph sub">7</sub> can only support a fixed DAG. We are
                                 working towards generalizing these graphs.
                              </p>
                              <div class="p">
                                 <div class="fig fignone" id="fused-multi-head-att-bprop__fig_mhm_5rs_bxb"><a name="fused-multi-head-att-bprop__fig_mhm_5rs_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 30. cuDNN Graph Depicting g<sub class="ph sub">5</sub></span><br clear="none"></br><a name="fused-multi-head-att-bprop__image_nhm_5rs_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-bprop__image_nhm_5rs_bxb" src="graphics/g5.png" alt="cuDNN Graph Depicting g5"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">g<sub class="ph sub">6</sub> represents the backward pass of softmax and masking, to get
                                 <samp class="ph codeph">dP</samp>.
                                 <div class="fig fignone" id="fused-multi-head-att-bprop__fig_xd4_jss_bxb"><a name="fused-multi-head-att-bprop__fig_xd4_jss_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 31. cuDNN Graph Depicting g<sub class="ph sub">6</sub></span><br clear="none"></br><a name="fused-multi-head-att-bprop__image_yd4_jss_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-bprop__image_yd4_jss_bxb" src="graphics/g6.png" alt="cuDNN Graph Depicting g6"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">There are options for the Mask DAG that you can opt-in. You can either use the
                                 padding/causal mask, general mask as an input, or not do any masking.
                                 <div class="fig fignone" id="fused-multi-head-att-bprop__fig_i2s_5tl_3xb"><a name="fused-multi-head-att-bprop__fig_i2s_5tl_3xb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 32. cuDNN Graph Depicting Mask DAG</span><br clear="none"></br><a name="fused-multi-head-att-bprop__image_j2s_5tl_3xb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-bprop__image_j2s_5tl_3xb" src="graphics/mask-dag.png" alt="cuDNN Graph Depicting Mask DAG"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p"><samp class="ph codeph">dBias</samp> DAG is useful to calculate the <samp class="ph codeph">bprop</samp> of the
                                 relative positional encoding and is optional and available for you to opt-in.
                                 <div class="fig fignone" id="fused-multi-head-att-bprop__fig_jwd_f5l_3xb"><a name="fused-multi-head-att-bprop__fig_jwd_f5l_3xb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 33. cuDNN Graph Depicting <samp class="ph codeph">dBias</samp> DAG</span><br clear="none"></br><a name="fused-multi-head-att-bprop__image_kwd_f5l_3xb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-bprop__image_kwd_f5l_3xb" src="graphics/dbias-dag.png" alt="cuDNN Graph Depicting dBias DAG"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">g<sub class="ph sub">7</sub> is the transpose of <samp class="ph codeph">dP</samp> the output of g<sub class="ph sub">6</sub>.
                                 <div class="fig fignone" id="fused-multi-head-att-bprop__fig_upg_yws_bxb"><a name="fused-multi-head-att-bprop__fig_upg_yws_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 34. cuDNN Graph Depicting g<sub class="ph sub">7</sub></span><br clear="none"></br><a name="fused-multi-head-att-bprop__image_vpg_yws_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="fused-multi-head-att-bprop__image_vpg_yws_bxb" src="graphics/g7.png" alt="cuDNN Graph Depicting g7"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="fused-multi-head-att-bprop__table_jhp_w3t_bxb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="fused-multi-head-att-bprop__table_jhp_w3t_bxb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 23. Limitations Of <samp class="ph codeph">Mha-bprop</samp> Fusions</span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e7534" rowspan="1" colspan="1">&nbsp;</th>
                                             <th class="entry" valign="top" width="50%" id="d54e7536" rowspan="1" colspan="1">Limitations Of <samp class="ph codeph">Mha-bprop</samp> Fusions
                                             </th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7534" rowspan="1" colspan="1">MatMul</td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7536" rowspan="1" colspan="1"><a name="fused-multi-head-att-bprop__ul_nnw_z3t_bxb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="fused-multi-head-att-bprop__ul_nnw_z3t_bxb">
                                                   <li class="li">Compute type for all MatMul ops must be float.</li>
                                                   <li class="li">Input tensors must have data type <samp class="ph codeph">FP16</samp> or
                                                      <samp class="ph codeph">BF16</samp>.
                                                   </li>
                                                   <li class="li">Output tensors must have data type <samp class="ph codeph">FP16</samp>,
                                                      <samp class="ph codeph">BF16</samp>, or <samp class="ph codeph">FP32</samp>
                                                      (<samp class="ph codeph">TF32</samp>).
                                                   </li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7534" rowspan="1" colspan="1">Pointwise operations in g<sub class="ph sub">5</sub>, g<sub class="ph sub">6</sub>, and
                                                g<sub class="ph sub">7</sub></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7536" rowspan="1" colspan="1">Compute type must be <samp class="ph codeph">FP32</samp>
                                                (<samp class="ph codeph">TF32</samp>).
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7534" rowspan="1" colspan="1">Reduction operations in g<sub class="ph sub">5</sub>, g<sub class="ph sub">6</sub>, and
                                                g<sub class="ph sub">7</sub></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7536" rowspan="1" colspan="1">I/O types and compute types must be <samp class="ph codeph">FP32</samp>
                                                (<samp class="ph codeph">TF32</samp>).
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">Layout requirements of <samp class="ph codeph">Mha-bprop</samp> fusions include:<a name="fused-multi-head-att-bprop__ul_x14_bjt_bxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="fused-multi-head-att-bprop__ul_x14_bjt_bxb">
                                    <li class="li liexpand">All I/O tensors must have 4 dimensions, with the first two denoting the batch
                                       dimensions. The usage of rank-4 tensors in MatMul ops can be read from the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnn-backend-api" target="_blank" shape="rect">NVIDIA cuDNN Backend API</a>
                                       documentation.
                                    </li>
                                    <li class="li liexpand">The contracting dimension (dimension <samp class="ph codeph">K</samp>) for the second MatMul
                                       must be 64.
                                    </li>
                                    <li class="li liexpand">The contracting dimension (dimension <samp class="ph codeph">K</samp>) for the 1st, 2nd, and
                                       3rd MatMul must be less than or equal to 512 and a multiple of 64.
                                    </li>
                                    <li class="li liexpand">The last dimension (corresponding to hidden dimensions) in <samp class="ph codeph">Q</samp>,
                                       <samp class="ph codeph">K</samp>, <samp class="ph codeph">V</samp>, <samp class="ph codeph">O</samp>, and
                                       <samp class="ph codeph">dO</samp> is expected to have stride 1.
                                    </li>
                                    <li class="li liexpand">The <samp class="ph codeph">S</samp> and <samp class="ph codeph">dP</samp> tensors are expected to have
                                       <samp class="ph codeph">CUDNN_ATTR_TENSOR_REORDERING_MODE</samp> set to
                                       <samp class="ph codeph">CUDNN_TENSOR_REORDERING_F16x16</samp>.
                                    </li>
                                 </ul>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="flash-fused-multi-head-att-fprop"><a name="flash-fused-multi-head-att-fprop" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#flash-fused-multi-head-att-fprop" name="flash-fused-multi-head-att-fprop" shape="rect">3.3.3.5.&nbsp;Fused Flash Attention <kbd class="ph userinput">fprop</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">cuDNN supports flash fused attention to perform scale dot product attention commonly
                                 used in models like GPT, BERT, and so on. The general pattern supported by this engine is
                                 BMM-Softmax-BMM with many other optional features that you can opt into. You can choose to
                                 create the graph by yourself or use the custom
                                 <samp class="ph codeph">scaled_dot_product_attention_node</samp> in <a class="xref" href="https://github.com/NVIDIA/cudnn-frontend/blob/1.0/pre_release_1/README.FE.1.0.md" target="_blank" shape="rect">cuDNN frontend</a>. Using the frontend node will make
                                 opting into the different options like causal mask, dropout, alibi masking, and so on, very
                                 easy. <span class="shortdesc">c</span></div>
                              <div class="p">
                                 <div class="fig fignone" id="flash-fused-multi-head-att-fprop__fig19"><a name="flash-fused-multi-head-att-fprop__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 35. Flash <samp class="ph codeph">fprop</samp> cuDNN Operation Graph</span><br clear="none"></br><a name="flash-fused-multi-head-att-fprop__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="flash-fused-multi-head-att-fprop__image_am5_pxv_nhb" src="graphics/flash-fprop.png" alt="Flash fprop cuDNN Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">Pre-softmax optional DAGs cover multiple options for the users to configure:<a name="flash-fused-multi-head-att-fprop__ul_rqh_s1r_ryb" shape="rect">
                                    <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fprop__ul_rqh_s1r_ryb">
                                    <li class="li">pointwise <samp class="ph codeph">Multiply</samp> node for attention scale after the first
                                       matmul
                                    </li>
                                    <li class="li">pointwise <samp class="ph codeph">Add</samp> node for the relative positional encoding to add
                                       a bias after the first matmul
                                    </li>
                                    <li class="li">Different masking options like causal masking, padding masking, and alibi
                                       masking. Users can choose multiple masking schemes together or no masking.
                                    </li>
                                    <li class="li">pointwise <samp class="ph codeph">Multiply</samp> node that accepts a full tensor that can be
                                       used as a custom mask generated by the user
                                    </li>
                                 </ul>
                              </div>
                              <div class="p">Post-softmax optional DAGs cover multiple options for the users to configure:<a name="flash-fused-multi-head-att-fprop__ul_sk4_y1r_ryb" shape="rect">
                                    <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fprop__ul_sk4_y1r_ryb">
                                    <li class="li">pointwise <samp class="ph codeph">Multiply</samp> node with a RNG node to signify dropout
                                    </li>
                                    <li class="li">pointwise <samp class="ph codeph">Multiply</samp> node with a user generated tensor acting as
                                       the dropout mask
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">All these DAGs are optional. A user can enable them depending on the cuDNN API they are
                                 targeting. If using the <samp class="ph codeph">scaled_dot_product_attention_node</samp> in cuDNN
                                 frontend, they can set the provided API options to <samp class="ph codeph">true</samp>, for example
                                 <samp class="ph codeph">set_causal_mask(True)</samp>and internally, the frontend will add the
                                 correct graph automatically. While using the graph API directly, users can add the
                                 corresponding graph of the operations they want into the cuDNN graph. 
                              </p>
                              <p class="p">The compound operations for example: Causal Mask, Softmax, and so on, can be represented
                                 using the following operation graphs in cuDNN.
                              </p>
                              <div class="p">
                                 <div class="fig fignone" id="flash-fused-multi-head-att-fprop__fig_ctw_fkk_bxb"><a name="flash-fused-multi-head-att-fprop__fig_ctw_fkk_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 36. Flash <samp class="ph codeph">fprop</samp> Causal Mask Operation Graph</span><br clear="none"></br><a name="flash-fused-multi-head-att-fprop__image_dtw_fkk_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="flash-fused-multi-head-att-fprop__image_dtw_fkk_bxb" src="graphics/fprop-causal-mask.png" alt="Flash fprop Causal Mask Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="flash-fused-multi-head-att-fprop__fig_hlm_gnk_bxb"><a name="flash-fused-multi-head-att-fprop__fig_hlm_gnk_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 37. Flash <samp class="ph codeph">fprop</samp> Softmax Operation Graph</span><br clear="none"></br><a name="flash-fused-multi-head-att-fprop__image_ilm_gnk_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="flash-fused-multi-head-att-fprop__image_ilm_gnk_bxb" src="graphics/fprop-softmax.png" alt="Flash fprop Softmax Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="flash-fused-multi-head-att-fprop__fig_r1t_knk_bxb"><a name="flash-fused-multi-head-att-fprop__fig_r1t_knk_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 38. Flash <samp class="ph codeph">fprop</samp> Dropout Operation Graph</span><br clear="none"></br><a name="flash-fused-multi-head-att-fprop__image_s1t_knk_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="flash-fused-multi-head-att-fprop__image_s1t_knk_bxb" src="graphics/fprop-dropout.png" alt="Flash fprop Dropout Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="flash-fused-multi-head-att-fprop__table_crl_4nk_bxb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-fprop__table_crl_4nk_bxb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 24. Limitations For The Input And The Output Non-Virtual Tensors</span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e7876" rowspan="1" colspan="1">Tensor</th>
                                             <th class="entry" valign="top" width="50%" id="d54e7879" rowspan="1" colspan="1">Requirements</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7876" rowspan="1" colspan="1"><samp class="ph codeph">Q</samp>, <samp class="ph codeph">K^T</samp>, and <samp class="ph codeph">V</samp>
                                                tensor
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7879" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fprop__ul_t1c_5nk_bxb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fprop__ul_t1c_5nk_bxb">
                                                   <li class="li">All tensors must be either <samp class="ph codeph">FP16</samp> or
                                                      <samp class="ph codeph">BF16</samp> data type.
                                                   </li>
                                                   <li class="li">Contracting dimension for <samp class="ph codeph">Q</samp> must be a
                                                      multiple of 8 with maximum value 128
                                                   </li>
                                                   <li class="li">Non-contracting dimension for <samp class="ph codeph">V</samp> must be a
                                                      multiple of 8 with maximum value 128.
                                                   </li>
                                                   <li class="li">Contracting dimension for <samp class="ph codeph">Q</samp> and
                                                      <samp class="ph codeph">K^T</samp> needs to have stride 1 in the
                                                      layout.
                                                   </li>
                                                   <li class="li">Non-contracting dimension for <samp class="ph codeph">V</samp> needs to
                                                      have stride 1 in the layout.
                                                   </li>
                                                   <li class="li">The second dimension in <samp class="ph codeph">K^T</samp> corresponding
                                                      to the number of heads can be a factor of the number of
                                                      heads of <samp class="ph codeph">Q</samp>.
                                                   </li>
                                                   <li class="li">The second dimension in <samp class="ph codeph">V</samp> corresponding to
                                                      the number of heads can be a factor of the number of heads
                                                      of <samp class="ph codeph">Q</samp>.
                                                   </li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7876" rowspan="1" colspan="1"><samp class="ph codeph">Softmax</samp> stats
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7879" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fprop__ul_qdd_l4k_bxb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fprop__ul_qdd_l4k_bxb">
                                                   <li class="li">Data type must be either <samp class="ph codeph">FP16</samp> or
                                                      <samp class="ph codeph">BF16</samp>.
                                                   </li>
                                                   <li class="li">Data must be be in row major format.</li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7876" rowspan="1" colspan="1"><samp class="ph codeph">O</samp> tensor
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7879" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fprop__ul_gp4_p4k_bxb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fprop__ul_gp4_p4k_bxb">
                                                   <li class="li">Data type must be either <samp class="ph codeph">FP16</samp> or
                                                      <samp class="ph codeph">BF16</samp>.
                                                   </li>
                                                   <li class="li">The stride for the last dimension corresponding to the
                                                      hidden dim per head should be 1.
                                                   </li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7876" rowspan="1" colspan="1"><samp class="ph codeph">Seed</samp> and <samp class="ph codeph">Offset</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7879" rowspan="1" colspan="1">INT32 or INT64 scalar in host or GPU</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e7876" rowspan="1" colspan="1"><samp class="ph codeph">Scale</samp> to <samp class="ph codeph">Pointwise</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e7879" rowspan="1" colspan="1">Attention scale can be FP16/BF16/FP32.</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <p class="p">Inference mode can be turned on by passing the <samp class="ph codeph">Softmax</samp> stats as a
                                 virtual tensor and setting the RNG node probability to <samp class="ph codeph">0.0f</samp>. The
                                 pattern is supported for GPUs with NVIDIA Ampere architecture and newer.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="flash-fused-multi-head-att-bprop"><a name="flash-fused-multi-head-att-bprop" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#flash-fused-multi-head-att-bprop" name="flash-fused-multi-head-att-bprop" shape="rect">3.3.3.6.&nbsp;Fused Flash Attention <kbd class="ph userinput">bprop</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">cuDNN supports the corresponding backpropagation graph for fused flash attention.
                                    This can be used together with the <samp class="ph codeph">fprop</samp> graph to perform training on
                                    Large Language Models (LLMs).</span></div>
                              <p class="p">All the options mentioned in <samp class="ph codeph">fprop</samp> are applicable in the
                                 <samp class="ph codeph">bprop</samp> graph as well. The corresponding <samp class="ph codeph">bprop</samp>
                                 frontend node contains the same options and can be configured to do the
                                 <samp class="ph codeph">bprop</samp>. Users opting in for the graph API, again need to add the
                                 graphs of the operations they want. The graph shown below is for a standard attention
                                 layer in GPT with causal masking and dropout. 
                              </p>
                              <p class="p">For Grouped Query Attention (GQA) and Multi Query Attention (MQA), you can configure an
                                 additional reduction node for <samp class="ph codeph">dK</samp> and <samp class="ph codeph">dV</samp>, which reduces
                                 the tensor from the full number of heads (<samp class="ph codeph">Q</samp> heads) to the actual
                                 <samp class="ph codeph">K</samp> and <samp class="ph codeph">V</samp> heads.
                              </p>
                              <div class="p">For the input and output tensors, the limitations from the <samp class="ph codeph">fprop</samp> graph
                                 are carried over. For the <samp class="ph codeph">bprop</samp> specific tensors, the limitations are
                                 as follows:
                                 
                                 
                                 <div class="tablenoborder"><a name="flash-fused-multi-head-att-bprop__table_omy_bqk_bxb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-bprop__table_omy_bqk_bxb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 25. Limitations For The <samp class="ph codeph">bprop</samp> Specific Tensors</span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e8131" rowspan="1" colspan="1">Tensor</th>
                                             <th class="entry" valign="top" width="50%" id="d54e8134" rowspan="1" colspan="1">Requirements</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e8131" rowspan="1" colspan="1"><samp class="ph codeph">dQ</samp>, <samp class="ph codeph">dK</samp>, and <samp class="ph codeph">dV</samp>
                                                tensor
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e8134" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-bprop__ul_evq_lsk_bxb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-bprop__ul_evq_lsk_bxb">
                                                   <li class="li">All tensors must be either <samp class="ph codeph">FP16</samp> or
                                                      <samp class="ph codeph">BF16</samp> data type.
                                                   </li>
                                                   <li class="li">The last dimension corresponding to the hidden dim per head
                                                      must be a multiple of 8 with maximum value 128.
                                                   </li>
                                                   <li class="li">The stride for the last dimension corresponding to the
                                                      hidden dim per head should be 1. 
                                                   </li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e8131" rowspan="1" colspan="1"><samp class="ph codeph">Softmax</samp> sum
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e8134" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-bprop__ul_mht_dtk_bxb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-bprop__ul_mht_dtk_bxb">
                                                   <li class="li">Data type must be <samp class="ph codeph">FP32</samp>.
                                                   </li>
                                                   <li class="li">Data must be in row major format.</li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e8131" rowspan="1" colspan="1"><samp class="ph codeph">dO</samp> tensor
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e8134" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-bprop__ul_rkc_q2r_ryb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-bprop__ul_rkc_q2r_ryb">
                                                   <li class="li">Data type must be either <samp class="ph codeph">FP16</samp> or
                                                      <samp class="ph codeph">BF16</samp>.
                                                   </li>
                                                   <li class="li">The last dimension corresponding to the hidden dim per head
                                                      must be a multiple of 8 with maximum value 128. 
                                                   </li>
                                                   <li class="li">The stride for the last dimension corresponding to the
                                                      hidden dim per head should be 1.
                                                   </li>
                                                   <li class="li">The layout of the tensor is required to be the same as the
                                                      <samp class="ph codeph">O</samp> tensor. 
                                                   </li>
                                                </ul>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e8131" rowspan="1" colspan="1"><samp class="ph codeph">dqAccum</samp> tensor
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e8134" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-bprop__ul_rpc_ftk_bxb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-bprop__ul_rpc_ftk_bxb">
                                                   <li class="li">Data type must be <samp class="ph codeph">FP32</samp>.
                                                   </li>
                                                   <li class="li">The tensor must be <samp class="ph codeph">memset</samp> to
                                                      <samp class="ph codeph">zero</samp> before passing to cuDNN.
                                                   </li>
                                                   <li class="li">Data must be in row major format.</li>
                                                </ul>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="flash-fused-multi-head-att-bprop__fig19"><a name="flash-fused-multi-head-att-bprop__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 39. Flash <samp class="ph codeph">bprop</samp> cuDNN Operation Graph</span><br clear="none"></br><a name="flash-fused-multi-head-att-bprop__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="flash-fused-multi-head-att-bprop__image_am5_pxv_nhb" src="graphics/bprop-op-graph.png" alt="Flash bprop cuDNN Operation Graph"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">The pattern is supported for GPUs with NVIDIA Ampere architecture and newer.</p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="compile-specialized-engine"><a name="compile-specialized-engine" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#compile-specialized-engine" name="compile-specialized-engine" shape="rect">3.3.4.&nbsp;Specialized Pre-Compiled Engines</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">The pre-compiled specialized engines target and optimize for a specialized graph
                                 pattern with a ragged support surface. Because of this targeting, these graphs do not
                                 require runtime compilation.</span></div>
                           <p class="p">In most cases, the specialized patterns are just special cases of the generic patterns
                              used in the runtime fusion engines, but there are some cases where the specialized
                              pattern does not fit any of the generic patterns. If your graph pattern matches a
                              specialized pattern, you will get at least a pattern matching engine, and you might also
                              get runtime fusion engines as another option.
                           </p>
                           <p class="p">Currently, the following patterns are supported by the pattern matching engines. Some
                              nodes are optional. Optional nodes are indicated by dashed outlines.
                           </p>
                        </div>
                        <div class="topic concept nested3" id="convbnfprop"><a name="convbnfprop" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convbnfprop" name="convbnfprop" shape="rect">3.3.4.1.&nbsp;<kbd class="ph userinput">ConvBNfprop</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">In <a class="xref" href="index.html#convbnfprop__fig19" shape="rect">Figure 40</a>, the <samp class="ph codeph">ConvBNfprop</samp> pattern is
                                 illustrated. Its restrictions and options include: <span class="shortdesc"></span></div>
                              <div class="p"><a name="convbnfprop__ul_qym_lhf_lwb" shape="rect">
                                    <!-- --></a><ul class="ul" id="convbnfprop__ul_qym_lhf_lwb">
                                    <li class="li liexpand">The three pointwise nodes scale, bias, and ReLU are optional.</li>
                                    <li class="li liexpand">X, Z, W, s<sub class="ph sub">1</sub>, b<sub class="ph sub">1</sub> must all be of FP16 data type.
                                    </li>
                                    <li class="li liexpand">Z needs to be of shape [N, C, H, W] with NHWC packed layout.</li>
                                    <li class="li liexpand">W needs to be of shape [K, C, R, S] with KRSC packed layout.</li>
                                    <li class="li liexpand">s<sub class="ph sub">1</sub>, b<sub class="ph sub">1</sub> need to be of shape [1, C, 1, 1] with NHWC packed
                                       layout.
                                    </li>
                                    <li class="li liexpand">Only ReLU activation is supported.</li>
                                    <li class="li liexpand">All of the intermediate tensors need to be virtual, except Y needs to be
                                       non-virtual.
                                    </li>
                                    <li class="li liexpand">I/O pointers should be 16 bytes aligned.</li>
                                    <li class="li liexpand">This pattern is only supported on devices with compute capability &gt;= 8.0 (with
                                       the exception of NVIDIA Ada Lovelace architecture, 8.9).
                                    </li>
                                    <li class="li liexpand">On devices with compute capability &gt;= 9.0, we only support two patterns:<a name="convbnfprop__ul_tpp_1cr_ywb" shape="rect">
                                          <!-- --></a><ul class="ul" id="convbnfprop__ul_tpp_1cr_ywb">
                                          <li class="li">the full pattern: scale + bias + ReLU + Conv + GenStats, and</li>
                                          <li class="li">the partial pattern: Conv + GenStats.</li>
                                       </ul>
                                    </li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="convbnfprop__fig19"><a name="convbnfprop__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 40. <samp class="ph codeph">ConvBNfprop</samp>, A Pre-Compiled Engine, Fuses
                                       <samp class="ph codeph">ConvolutionFwd</samp> and <samp class="ph codeph">GenStats</samp> With Several
                                       Pointwise Operations</span><br clear="none"></br><a name="convbnfprop__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convbnfprop__image_am5_pxv_nhb" src="graphics/ConvBNfprop.png" alt="ConvBNfprop, A Pre-Compiled Engine, Fuses ConvolutionFwd and GenStats With Several Pointwise Operations"></img></div><br clear="none"></br></div>
                              </div>
                              <div class="p">Skip connections are commonly observed in ResNet-like models. To support fusions in skip
                                 connections, we support a variant of the pattern above, the DBARCS pattern (short for
                                 Dual, Scale, Bias, Add, ReLU, Conv genStats). The limitations and options of the DBARCS
                                 pattern include:<a name="convbnfprop__ul_emg_3kt_bxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="convbnfprop__ul_emg_3kt_bxb">
                                    <li class="li liexpand">The pointwise dual scale and dual bias nodes are either both present or not.
                                       This is indicated by the dashed block encircling the dual scale and dual bias
                                       nodes. In case both the nodes are missing, the <samp class="ph codeph">dual_X</samp> tensor is
                                       directly fed as input to the add node.
                                    </li>
                                    <li class="li liexpand">The pointwise nodes scale, bias, add, and ReLU are required nodes.</li>
                                    <li class="li liexpand">Currently, only supported on Hopper GPUs.</li>
                                    <li class="li liexpand">For all the other data types, layout and virtualness restrictions of the
                                       <samp class="ph codeph">ConvBNfprop</samp> pattern apply to this pattern as well.
                                    </li>
                                    <li class="li liexpand"><samp class="ph codeph">dual_X</samp>, <samp class="ph codeph">dual_scale</samp>, and
                                       <samp class="ph codeph">dual_bias</samp> must all be of FP16 data type.
                                    </li>
                                    <li class="li liexpand"><samp class="ph codeph">dual_scale</samp> and <samp class="ph codeph">dual_bias</samp> must be of shape
                                       [1,C,1,1] with NHWC packed layout.
                                    </li>
                                    <li class="li liexpand">Intermediate outputs of the ReLU and Conv nodes: <samp class="ph codeph">Relu_Y</samp> and
                                       <samp class="ph codeph">Y</samp> are non-virtual. All the other intermediate outputs are
                                       virtual.
                                    </li>
                                    <li class="li liexpand">The weight tensor W for the convolution needs to be of shape [K,C,1,1]. Only 1x1
                                       filters with padding 0 are supported for the convolution in the DBARCS
                                       pattern.
                                    </li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="convbnfprop__fig_fp2_glt_bxb"><a name="convbnfprop__fig_fp2_glt_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 41. DBARCS In The <samp class="ph codeph">convBNfprop</samp> Series For Supporting Fusions
                                       Across Skip Connections</span><br clear="none"></br><a name="convbnfprop__image_gp2_glt_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convbnfprop__image_gp2_glt_bxb" src="graphics/new-pattern.png" alt="DBARCS In The convBNfprop Series For Supporting Fusions Across Skip Connections"></img></div><br clear="none"></br></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="convbnwgrad"><a name="convbnwgrad" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convbnwgrad" name="convbnwgrad" shape="rect">3.3.4.2.&nbsp;<kbd class="ph userinput">ConvBNwgrad</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">In <a class="xref" href="index.html#convbnwgrad__fig19" shape="rect">Figure 42</a>, the <samp class="ph codeph">ConvBNwgrad</samp> pattern is
                                 illustrated. Its restrictions and options include: <span class="shortdesc"></span></div>
                              <div class="p"><a name="convbnwgrad__ul_tsg_qhf_lwb" shape="rect">
                                    <!-- --></a><ul class="ul" id="convbnwgrad__ul_tsg_qhf_lwb">
                                    <li class="li liexpand">The three pointwise operations are all optional, as indicated by the dashed
                                       outlines.
                                    </li>
                                    <li class="li liexpand">Only ReLU activation is supported.</li>
                                    <li class="li liexpand">X, s<sub class="ph sub">1</sub>, b<sub class="ph sub">1</sub>, and <samp class="ph codeph">dy</samp> must all be of FP16
                                       datatype.
                                    </li>
                                    <li class="li liexpand">I/O pointers should be 16 bytes aligned.</li>
                                    <li class="li liexpand">X, s<sub class="ph sub">1</sub>, b<sub class="ph sub">1</sub>, and <samp class="ph codeph">dy</samp> must all have NHWC
                                       packed layouts.
                                    </li>
                                    <li class="li liexpand">All the intermediate tensors need to be virtual.</li>
                                    <li class="li liexpand">This pattern is only supported on devices with compute capability &gt;= 8.0 (with
                                       the exception of NVIDIA Ada Lovelace architecture, 8.9).
                                    </li>
                                    <li class="li liexpand">On devices with compute capability &gt;= 9.0, support is restricted to:<a name="convbnwgrad__ul_kcf_gcr_ywb" shape="rect">
                                          <!-- --></a><ul class="ul" id="convbnwgrad__ul_kcf_gcr_ywb">
                                          <li class="li">the full pattern: scale + bias + ReLU + wgrad.</li>
                                       </ul>
                                    </li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="convbnwgrad__fig19"><a name="convbnwgrad__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 42. <samp class="ph codeph">ConvBNwgrad</samp>, A Pre-Compiled Engine, Fuses
                                       <samp class="ph codeph">ConvolutionBwFilter</samp> With Several (Optional) Pointwise
                                       Operations</span><br clear="none"></br><a name="convbnwgrad__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convbnwgrad__image_am5_pxv_nhb" src="graphics/ConvBNwgrad.png" alt="ConvBNwgrad, A Pre-Compiled Engine, Fuses ConvolutionBwFilter With Several (Optional) Pointwise Operations"></img></div><br clear="none"></br></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="convbiasact"><a name="convbiasact" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convbiasact" name="convbiasact" shape="rect">3.3.4.3.&nbsp;<kbd class="ph userinput">ConvBiasAct</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">In the following figure, the <samp class="ph codeph">ConvBiasAct</samp> pattern is illustrated. Its
                                 restrictions and options include: <span class="shortdesc"></span></div>
                              <div class="p"><a name="convbiasact__ul_ejs_thf_lwb" shape="rect">
                                    <!-- --></a><ul class="ul" id="convbiasact__ul_ejs_thf_lwb">
                                    <li class="li liexpand">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>α</mi>
                                                <mtext>1</mtext>
                                             </msub>
                                          </mrow>
                                       </math>
                                       and 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>α</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                          </mrow>
                                       </math>
                                       need to be scalars.
                                    </li>
                                    <li class="li liexpand">The activation node is optional.</li>
                                    <li class="li liexpand">The size of the bias tensor should be [1, K, 1, 1].</li>
                                    <li class="li liexpand">Internal conversions are not supported. That is, the virtual output between
                                       nodes need to have the same data type as the node’s compute type, which should
                                       be the same as the epilog type of the convolution node.
                                    </li>
                                    <li class="li liexpand">There are some restrictions on the supported combination of data types, which
                                       can be found in the API Reference (refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionBiasActivationForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBiasActivationForward()</samp></a>).
                                    </li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="convbiasact__fig19"><a name="convbiasact__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 43. <samp class="ph codeph">ConvBiasAct</samp>, A Pre-Compiled Engine, Fuses
                                       <samp class="ph codeph">ConvolutionFwd</samp> With Several Pointwise Operations</span><br clear="none"></br><a name="convbiasact__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convbiasact__image_am5_pxv_nhb" src="graphics/ConvBiasAct.png" alt="ConvBiasAct, A Pre-Compiled Engine, Fuses ConvolutionFwd With Several Pointwise Operations"></img></div><br clear="none"></br></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="convscalebiasact"><a name="convscalebiasact" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#convscalebiasact" name="convscalebiasact" shape="rect">3.3.4.4.&nbsp;<kbd class="ph userinput">ConvScaleBiasAct</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">In the following figure, the <samp class="ph codeph">ConvScaleBiasAct</samp> pattern is illustrated.
                                 Its restrictions and options include: <span class="shortdesc"></span></div>
                              <div class="p"><a name="convscalebiasact__ul_bfr_xhf_lwb" shape="rect">
                                    <!-- --></a><ul class="ul" id="convscalebiasact__ul_bfr_xhf_lwb">
                                    <li class="li liexpand">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>α</mi>
                                                <mtext>1</mtext>
                                             </msub>
                                          </mrow>
                                       </math>
                                       and 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>α</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                          </mrow>
                                       </math>
                                       and 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>b</mi>
                                                <mtext>2</mtext>
                                             </msub>
                                          </mrow>
                                       </math>
                                       should have the same data type/layout and can only be FP32.
                                    </li>
                                    <li class="li liexpand">X, W, and Z can only be INT8x4 or INT8x32.</li>
                                    <li class="li liexpand">The size of the bias tensor should be [1, K, 1, 1].</li>
                                    <li class="li liexpand">Internal conversions are not supported. Meaning, "virtual output" between nodes
                                       needs to be the same as their compute type.
                                    </li>
                                    <li class="li liexpand">Currently, <samp class="ph codeph">Pointwise:ReLU</samp> is the only optional pointwise
                                       node.
                                    </li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="fig fignone" id="convscalebiasact__fig19"><a name="convscalebiasact__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 44. <samp class="ph codeph">ConvScaleBiasAct</samp>, A Pre-Compiled Engine</span><br clear="none"></br><a name="convscalebiasact__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="convscalebiasact__image_am5_pxv_nhb" src="graphics/ConvScaleBiasAct.png" alt="ConvScaleBiasAct, A Pre-Compiled Engine"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">This pattern is very similar as <samp class="ph codeph">ConvBiasAct</samp>. The difference is that
                                 here, the scales 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi>α</mi>
                                          <mtext>1</mtext>
                                       </msub>
                                    </mrow>
                                 </math>
                                 and 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi>α</mi>
                                          <mtext>2</mtext>
                                       </msub>
                                    </mrow>
                                 </math>
                                 are tensors, not scalars. If they are scalars, this pattern becomes a
                                 normal <samp class="ph codeph">ConvBiasAct</samp>.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="dgraddrelubnbwdweight"><a name="dgraddrelubnbwdweight" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#dgraddrelubnbwdweight" name="dgraddrelubnbwdweight" shape="rect">3.3.4.5.&nbsp;<kbd class="ph userinput">DgradDreluBNBwdWeight</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">In <a class="xref" href="index.html#dgraddrelubnbwdweight__fig19" shape="rect">Figure 45</a>, the
                                 <samp class="ph codeph">DgradDreluBNBwdWeight</samp> pattern is illustrated. Its restrictions and
                                 options include: <span class="shortdesc"></span></div>
                              <div class="p"><a name="dgraddrelubnbwdweight__ul_sq5_43f_lwb" shape="rect">
                                    <!-- --></a><ul class="ul" id="dgraddrelubnbwdweight__ul_sq5_43f_lwb">
                                    <li class="li liexpand"><samp class="ph codeph">Dgrad</samp> input <samp class="ph codeph">dy</samp> and W are of FP16
                                       datatypes.
                                    </li>
                                    <li class="li liexpand">Batch norm fwd inputs, <samp class="ph codeph">X_bn</samp> is of FP16 datatype while the other
                                       tensors <samp class="ph codeph">mean_bn</samp>, <samp class="ph codeph">invstd_dev_bn</samp>,
                                       <samp class="ph codeph">scale_bn</samp>, and <samp class="ph codeph">bias_bn</samp> are FP32.
                                    </li>
                                    <li class="li liexpand">Outputs: <samp class="ph codeph">dScale</samp>, <samp class="ph codeph">dBias</samp>, A,B,C are of FP32 data
                                       type.
                                    </li>
                                    <li class="li liexpand">All pointers are 16 byte aligned.</li>
                                    <li class="li liexpand">This pattern is only supported on devices with compute capability &gt;= 8.0 (with
                                       the exception of NVIDIA Ada Lovelace architecture, 8.9).
                                    </li>
                                 </ul>
                              </div>
                              <div class="p"><samp class="ph codeph">DgradDreluBNBwdWeight</samp> is a pre-compiled engine that can be used in
                                 conjunction with the <samp class="ph codeph">dBNApply</samp> pattern to compute the backwards path of
                                 batch norm.
                                 <div class="fig fignone" id="dgraddrelubnbwdweight__fig19"><a name="dgraddrelubnbwdweight__fig19" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 45. <samp class="ph codeph">DgradDreluBNBwdWeight</samp> Pattern For Fusions In The Backward
                                       Pass</span><br clear="none"></br><a name="dgraddrelubnbwdweight__image_am5_pxv_nhb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="dgraddrelubnbwdweight__image_am5_pxv_nhb" src="graphics/DgradDreluBnBwdWeight.png" alt="DgradDreluBNBwdWeight Pattern For Fusions In The Backward Pass"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">The <samp class="ph codeph">BNBwdWeight</samp> operation takes in five inputs: <samp class="ph codeph">X_bn</samp>,
                                 <samp class="ph codeph">mean_bn</samp>, <samp class="ph codeph">invstddev_bn</samp>, <samp class="ph codeph">scale_bn</samp>,
                                 and <samp class="ph codeph">dy_bn</samp> (that is, the output from the <samp class="ph codeph">ReLUBwd</samp>
                                 node).
                              </p>
                              <p class="p">It produces five outputs: gradients of the batch norm scale and bias params,
                                 <samp class="ph codeph">dScale</samp>, <samp class="ph codeph">dBias</samp>, and coefficients A,B,C. Note that
                                 for illustration purposes, the inputs are duplicated. The inputs on the left and right
                                 are however exactly the same.
                              </p>
                              <p class="p">This pattern is typically used in the computation of the <strong class="ph b">Batch Norm Backward
                                    Pass.</strong></p>
                              <p class="p">When computing the backward pass of batch norm, <samp class="ph codeph">dScale</samp>,
                                 <samp class="ph codeph">dBias</samp>, and <samp class="ph codeph">dX_bn</samp> are needed. The
                                 <samp class="ph codeph">DgradDreluBnBwdWeight</samp> pattern computes the former two. Using the
                                 generated A, B, and C we can use the following <samp class="ph codeph">dBNApply</samp> pattern to
                                 compute <samp class="ph codeph">dX</samp>, the input gradient, as follows <samp class="ph codeph">dx_bn = A*dy_bn +
                                    B*X_bn +C</samp>.
                              </p>
                              <div class="p">
                                 <div class="fig fignone" id="dgraddrelubnbwdweight__fig_uwj_xlt_bxb"><a name="dgraddrelubnbwdweight__fig_uwj_xlt_bxb" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 46. <samp class="ph codeph">dBNApply</samp> Pattern For Final Gradient Computation</span><br clear="none"></br><a name="dgraddrelubnbwdweight__image_vwj_xlt_bxb" shape="rect">
                                       <!-- --></a><div class="imageleft"><img class="image imageleft" id="dgraddrelubnbwdweight__image_vwj_xlt_bxb" src="graphics/pointwise-options.png" alt="dBNApply Pattern For Final Gradient Computation"></img></div><br clear="none"></br></div>
                              </div>
                              <p class="p">The <samp class="ph codeph">dBNApply</samp> pattern was initially supported by a pre-compiled static
                                 engine but is now supported by the generic runtime fusion engine.
                              </p>
                              <p class="p">Note that the <samp class="ph codeph">DgradDreluBNBwdWeight</samp> pattern is used in combination with
                                 the forward pass pattern <samp class="ph codeph">ConvBNfprop</samp>. Because of performance reasons,
                                 the output of batch norm <samp class="ph codeph">Y_bn</samp>, which was calculated in
                                 <samp class="ph codeph">ConvBNfprop</samp> (output of scale-bias), needs to be recalculated by
                                 <samp class="ph codeph">DgradDreluBnBwdWeight</samp>. The pointwise add node subtracts
                                 <samp class="ph codeph">mean_bn</samp> from <samp class="ph codeph">X_bn</samp>, hence the
                                 <samp class="ph codeph">alpha2</samp> parameter for that node should be set to
                                 <samp class="ph codeph">-1</samp>.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="flash-fused-multi-head-att-fp8"><a name="flash-fused-multi-head-att-fp8" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#flash-fused-multi-head-att-fp8" name="flash-fused-multi-head-att-fp8" shape="rect">3.3.4.6.&nbsp;FP8 Fused Flash Attention</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">cuDNN supports fused flash attention with input and output data types being in
                                    FP8 format. This FP8-specific graph pattern is supported only on Hopper (H100)
                                    GPUs.</span></div>
                              <p class="p">Support exists for both training (forward and backward pass) and inference in FP8 format.
                                 The training forward pass is slightly different from the inference forward pass
                                 regarding whether some intermediate tensors are output or not.
                              </p>
                              <p class="p">Within the <a class="xref" href="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/" target="_blank" shape="rect">NVIDIA Hopper architecture</a>, there are two new
                                 FP8 formats: E4M3 and E5M2. Currently, for forward pass, only when all the inputs and
                                 outputs are in E4M3 format is supported. For the backward pass, the support is only when
                                 some of the inputs and outputs are in E4M3 and some in E5M2. More general support for
                                 the FP8 formats will be added in future releases.
                              </p>
                              <p class="p">Due to the limited numerical precision of FP8 data type, for practical use cases, you
                                 must scale values computed in FP32 format before storing them in FP8 format, and descale
                                 the values stored in FP8 format before performing computations on them. For more
                                 information, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/examples/fp8_primer.html" target="_blank" shape="rect">Transformer Engine FP8 Primer</a>.
                              </p>
                              <div class="p">The following notation is used in this section.<a name="flash-fused-multi-head-att-fp8__ul_jhr_tjn_cxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_jhr_tjn_cxb">
                                    <li class="li">b - number of batches</li>
                                    <li class="li">h - number of heads</li>
                                    <li class="li">s - maximum length of sequences in a batch</li>
                                    <li class="li">d - embedding dimension size of a word in a sequence</li>
                                 </ul>
                              </div>
                              <div class="section" id="flash-fused-multi-head-att-fp8__section_p4p_vjn_cxb"><a name="flash-fused-multi-head-att-fp8__section_p4p_vjn_cxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Scaling and Descaling</h5>
                                 <p class="p">In the context of FP8, scaling refers to multiplying each element of a FP32 tensor by
                                    a quantization factor.
                                 </p>
                                 <p class="p">The quantization factor is computed as: <em class="ph i">(Max representable value in the fp8
                                       format) / (Max absolute value seen in the tensor)</em>.
                                 </p>
                                 <p class="p">For the E4M3 format, the quantization factor is <samp class="ph codeph">448.f/ tensor_amax</samp>
                                    (rounded to the nearest lower power of two).
                                 </p>
                                 <p class="p">For the E5M2 format, the quantization factor is <samp class="ph codeph">57344.f /
                                       tensor_amax</samp> (rounded to the nearest lower power of two).
                                 </p>
                                 <p class="p">The meaning behind scaling is to spawn the full range of the FP8 format when
                                    computing on FP8 values and storing FP8 values, thereby, minimizing the precision
                                    loss. True values in FP32 format are multiplied by the quantization factor before
                                    storing them as scaled values in FP8 format. Computations on scaled values in FP8
                                    format are descaled by multiplying with the dequantization factor to convert them
                                    back to their true values in FP32 format.
                                 </p>
                                 <p class="p">Scaling and descaling are critical for convergence with the FP8 data type, hence
                                    cuDNN only supports graph patterns for FP8 fused attention with the scaling and
                                    descaling nodes present.
                                 </p>
                              </div>
                              <div class="section" id="flash-fused-multi-head-att-fp8__section_p1g_kkn_cxb"><a name="flash-fused-multi-head-att-fp8__section_p1g_kkn_cxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Unpadded Tensors</h5>
                                 <p class="p">In fused flash attention, the length of different sequences in a batch can be
                                    different. The cuDNN operation graph supports an unpadded layout where all the
                                    sequences of different lengths in a batch are tightly packed. All the word
                                    embeddings after the useful length of the sequence are pushed towards the end of all
                                    sequences in the layout.
                                 </p>
                              </div>
                              <div class="section" id="flash-fused-multi-head-att-fp8__section_jfc_lkn_cxb"><a name="flash-fused-multi-head-att-fp8__section_jfc_lkn_cxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Forward Pass</h5>
                                 <p class="p">The following figure shows the cuDNN operation graph for the fused attention forward
                                    pass. The same graph supports forward pass for both training and inference. The
                                    operation graph pattern is identified as training when <samp class="ph codeph">M</samp> and
                                    <samp class="ph codeph">Zinv</samp> tensors are non-virtual. When <samp class="ph codeph">M</samp> and
                                    <samp class="ph codeph">Zinv</samp> tensors are virtual, the operation graph pattern is
                                    identified as inference.
                                 </p>
                                 <p class="p">The FP8 tensors are expected to be scaled and the matrix multiplication computation
                                    is performed on the FP8 tensors in the scaled format. All non matrix multiplication
                                    computations are performed in FP32 precision. The output of the FP8 matrix
                                    multiplication is converted to real values in FP32 by format multiplying with the
                                    descale values.
                                 </p>
                                 <div class="p">
                                    <div class="fig fignone" id="flash-fused-multi-head-att-fp8__fig19"><a name="flash-fused-multi-head-att-fp8__fig19" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 47. FP8 Fused Attention Forward Pass Operation Graph</span><br clear="none"></br><a name="flash-fused-multi-head-att-fp8__image_am5_pxv_nhb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="flash-fused-multi-head-att-fp8__image_am5_pxv_nhb" src="graphics/fmha-forward-pass.png" alt="FP8 Fused Attention Forward Pass Operation Graph"></img></div><br clear="none"></br></div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="flash-fused-multi-head-att-fp8__table_s3c_lmn_cxb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-fp8__table_s3c_lmn_cxb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 26. FP8 Fused Attention Forward Pass Input Tensors</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9217" rowspan="1" colspan="1">Tensor Name</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9220" rowspan="1" colspan="1">Data Type</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9223" rowspan="1" colspan="1">Dimensions</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1"><samp class="ph codeph">Q</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1"><samp class="ph codeph">K</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1"><samp class="ph codeph">V</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Attention Scale</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32 (by value)</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Descale <samp class="ph codeph">Q</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Descale <samp class="ph codeph">K</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Descale <samp class="ph codeph">V</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Scale <samp class="ph codeph">S</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Descale <samp class="ph codeph">S</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Scale <samp class="ph codeph">O</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">RNG Seed</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">INT64</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">RNG Offset</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">INT64</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9217" rowspan="1" colspan="1">Dropout Probability (p) or Keep Probability (1 - p)</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9220" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9223" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="flash-fused-multi-head-att-fp8__table_pg4_zmn_cxb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-fp8__table_pg4_zmn_cxb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 27. FP8 Fused Attention Forward Pass Output Tensors</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9427" rowspan="1" colspan="1">Tensor Name</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9430" rowspan="1" colspan="1">Data Type</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9433" rowspan="1" colspan="1">Dimensions</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9427" rowspan="1" colspan="1"><samp class="ph codeph">O</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9430" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9433" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9427" rowspan="1" colspan="1"><samp class="ph codeph">Amax_O</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9430" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9433" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9427" rowspan="1" colspan="1"><samp class="ph codeph">M</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9430" rowspan="1" colspan="1">FP32 (training only)</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9433" rowspan="1" colspan="1">[b, h, s, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9427" rowspan="1" colspan="1"><samp class="ph codeph">Zinv</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9430" rowspan="1" colspan="1">FP32 (training only)</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9433" rowspan="1" colspan="1">[b, h, s, 1]</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="flash-fused-multi-head-att-fp8__table_nrk_2nn_cxb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-fp8__table_nrk_2nn_cxb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 28. FP8 Fused Attention Forward Pass Limitations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e9513" rowspan="1" colspan="1">Item</th>
                                                <th class="entry" valign="top" width="50%" id="d54e9516" rowspan="1" colspan="1">Requirements</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1"><samp class="ph codeph">Q</samp>, <samp class="ph codeph">K</samp>, and
                                                   <samp class="ph codeph">V</samp> tensors
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fp8__ul_hxk_j4n_cxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_hxk_j4n_cxb">
                                                      <li class="li">Required to be interleaved.</li>
                                                      <li class="li">Packing layout is (b,s,3,h,d).</li>
                                                      <li class="li">Must be in the E4M3 FP8 data type.</li>
                                                      <li class="li">Can be in an unpadded tightly packed layout.</li>
                                                      <li class="li">Either <samp class="ph codeph">Q</samp>, <samp class="ph codeph">K</samp>,
                                                         <samp class="ph codeph">V</samp>, and <samp class="ph codeph">O</samp> can all
                                                         be unpadded or none.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1"><samp class="ph codeph">O</samp> tensor
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fp8__ul_zbl_l4n_cxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_zbl_l4n_cxb">
                                                      <li class="li">Must be in (b,s,h,d) layout.</li>
                                                      <li class="li">Must be in the E4M3 format.</li>
                                                      <li class="li">Can be in an unpadded tightly packed layout.</li>
                                                      <li class="li">Either <samp class="ph codeph">Q</samp>, <samp class="ph codeph">K</samp>,
                                                         <samp class="ph codeph">V</samp>, and <samp class="ph codeph">O</samp> can all
                                                         be unpadded or none.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1">All virtual tensors</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1">All virtual tensors must be in FP32 format.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1">Compute precision</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1">The compute precision of all operations must be FP32.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1"><samp class="ph codeph">M</samp>, <samp class="ph codeph">Zinv</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fp8__ul_myq_44n_cxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_myq_44n_cxb">
                                                      <li class="li">Must be in FP32 format.</li>
                                                      <li class="li">Should not be in an unpadded tightly packed layout.</li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1">Attention Scale, Quantization (scale) and Dequantization
                                                   (descale) tensors
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1">Must be in FP32 format.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1">Match between cuDNN API specifications and passed in device
                                                   tensors
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1">There is an implicit dependency between specifications done
                                                   through cuDNN API and device tensors passed in runtime. The
                                                   execution of the operation graph is undefined when the passed in
                                                   device tensors do not conform with the API
                                                   specifications.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1">Dropout probability for inference (p)</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1">The dropout probability for forward pass inference must be
                                                   zero.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1">Embedding dimension size (d)</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1">Embedding dimension size of only 64 is supported.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e9513" rowspan="1" colspan="1">Maximum sequence length (s)</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e9516" rowspan="1" colspan="1">Maximum sequence length sizes must be a multiple of 64. In
                                                   addition, maximum sequence lengths sizes up-to only 512 are
                                                   supported.
                                                </td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                              <div class="section" id="flash-fused-multi-head-att-fp8__section_ayt_s4n_cxb"><a name="flash-fused-multi-head-att-fp8__section_ayt_s4n_cxb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Backward Pass</h5>
                                 <div class="p">
                                    <div class="fig fignone" id="flash-fused-multi-head-att-fp8__fig_bsj_v4n_cxb"><a name="flash-fused-multi-head-att-fp8__fig_bsj_v4n_cxb" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 48. FP8 Fused Attention Backward Pass Operation Graph</span><br clear="none"></br><a name="flash-fused-multi-head-att-fp8__image_csj_v4n_cxb" shape="rect">
                                          <!-- --></a><div class="imageleft"><img class="image imageleft" id="flash-fused-multi-head-att-fp8__image_csj_v4n_cxb" src="graphics/fmha-backward-pass.png" alt="FP8 Fused Attention Backward Pass Operation Graph"></img></div><br clear="none"></br></div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="flash-fused-multi-head-att-fp8__table_pgz_z4n_cxb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-fp8__table_pgz_z4n_cxb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 29. FP8 Fused Attention Backward Pass Input Tensors</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9738" rowspan="1" colspan="1">Tensor Name</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9741" rowspan="1" colspan="1">Data Type</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e9744" rowspan="1" colspan="1">Dimensions</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1"><samp class="ph codeph">Q</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1"><samp class="ph codeph">K</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1"><samp class="ph codeph">V</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1"><samp class="ph codeph">O</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">E4M3</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1"><samp class="ph codeph">dO</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">E5M2</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1"><samp class="ph codeph">M</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[b, h, s, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1"><samp class="ph codeph">Zinv</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[b, h, s, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Attention Scale</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32 (by value)</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Descale <samp class="ph codeph">Q</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Descale <samp class="ph codeph">K</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Descale <samp class="ph codeph">V</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Scale <samp class="ph codeph">S</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Descale <samp class="ph codeph">S</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Descale <samp class="ph codeph">O</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Descale <samp class="ph codeph">dO</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Scale <samp class="ph codeph">dS</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Descale <samp class="ph codeph">dS</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Scale <samp class="ph codeph">dQ</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Scale <samp class="ph codeph">dK</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Scale <samp class="ph codeph">dV</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">RNG Seed</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">INT64</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">RNG Offset</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">INT64</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9738" rowspan="1" colspan="1">Dropout Probability (p) or Keep Probability (1 - p)</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9741" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e9744" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="flash-fused-multi-head-att-fp8__table_wgg_sqn_cxb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-fp8__table_wgg_sqn_cxb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 30. FP8 Fused Attention Backward Pass Output Tensors</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e10084" rowspan="1" colspan="1">Tensor Name</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e10087" rowspan="1" colspan="1">Data Type</th>
                                                <th class="entry" valign="top" width="33.33333333333333%" id="d54e10090" rowspan="1" colspan="1">Dimensions</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10084" rowspan="1" colspan="1"><samp class="ph codeph">dQ</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10087" rowspan="1" colspan="1">E5M2</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10090" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10084" rowspan="1" colspan="1"><samp class="ph codeph">dK</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10087" rowspan="1" colspan="1">E5M2</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10090" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10084" rowspan="1" colspan="1"><samp class="ph codeph">dV</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10087" rowspan="1" colspan="1">E5M2</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10090" rowspan="1" colspan="1">[b, h, s, d]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10084" rowspan="1" colspan="1"><samp class="ph codeph">Amax_dQ</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10087" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10090" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10084" rowspan="1" colspan="1"><samp class="ph codeph">Amax_dK</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10087" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10090" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10084" rowspan="1" colspan="1"><samp class="ph codeph">Amax_dV</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10087" rowspan="1" colspan="1">FP32</td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10090" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10084" rowspan="1" colspan="1"><samp class="ph codeph">Amax_dS</samp></td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10087" rowspan="1" colspan="1">FP32 (virtual tensor <samp class="ph codeph">dS</samp> is of E5M2
                                                   type)
                                                </td>
                                                <td class="entry" valign="top" width="33.33333333333333%" headers="d54e10090" rowspan="1" colspan="1">[1, 1, 1, 1]</td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                                 <div class="p">
                                    <div class="tablenoborder"><a name="flash-fused-multi-head-att-fp8__table_pml_1sn_cxb" shape="rect">
                                          <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="flash-fused-multi-head-att-fp8__table_pml_1sn_cxb" class="table" frame="border" border="1" rules="all">
                                          <caption><span class="tablecap">Table 31. FP8 Fused Attention Backward Pass Limitations</span></caption>
                                          <thead class="thead" align="left">
                                             <tr class="row">
                                                <th class="entry" valign="top" width="50%" id="d54e10213" rowspan="1" colspan="1">Item</th>
                                                <th class="entry" valign="top" width="50%" id="d54e10216" rowspan="1" colspan="1">Requirements</th>
                                             </tr>
                                          </thead>
                                          <tbody class="tbody">
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1"><samp class="ph codeph">Q</samp>, <samp class="ph codeph">K</samp>, and
                                                   <samp class="ph codeph">V</samp> tensors
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fp8__ul_qml_1sn_cxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_qml_1sn_cxb">
                                                      <li class="li">Required to be interleaved.</li>
                                                      <li class="li">The packing layout is (b,s,3,h,d).</li>
                                                      <li class="li">Must be in the E4M3 FP8 format.</li>
                                                      <li class="li">Can be in an unpadded tightly packed layout.</li>
                                                      <li class="li">Either <samp class="ph codeph">Q</samp>, <samp class="ph codeph">K</samp>,
                                                         <samp class="ph codeph">V</samp>, <samp class="ph codeph">O</samp>,
                                                         <samp class="ph codeph">dO</samp>, <samp class="ph codeph">dQ</samp>,
                                                         <samp class="ph codeph">dK</samp>, and <samp class="ph codeph">dV</samp> can all
                                                         be unpadded or none.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1"><samp class="ph codeph">dQ</samp>, <samp class="ph codeph">dK</samp>, and
                                                   <samp class="ph codeph">dV</samp> tensors
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fp8__ul_rml_1sn_cxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_rml_1sn_cxb">
                                                      <li class="li">Required to be interleaved.</li>
                                                      <li class="li">The packing layout is (b,s,3,h,d).</li>
                                                      <li class="li">Must be in the E5M2 FP8 format.</li>
                                                      <li class="li">Can be in an unpadded tightly packed layout.</li>
                                                      <li class="li">Either <samp class="ph codeph">Q</samp>, <samp class="ph codeph">K</samp>,
                                                         <samp class="ph codeph">V</samp>, <samp class="ph codeph">O</samp>,
                                                         <samp class="ph codeph">dO</samp>, <samp class="ph codeph">dQ</samp>,
                                                         <samp class="ph codeph">dK</samp>, and <samp class="ph codeph">dV</samp> can all
                                                         be unpadded or none.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1"><samp class="ph codeph">O</samp> and <samp class="ph codeph">dO</samp> tensor
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fp8__ul_l12_gsn_cxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_l12_gsn_cxb">
                                                      <li class="li">Must be in (b,s,h,d) layout.</li>
                                                      <li class="li">Must be in the E4M3 format.</li>
                                                      <li class="li">Can be in an unpadded tightly packed layout.</li>
                                                      <li class="li">Either <samp class="ph codeph">Q</samp>, <samp class="ph codeph">K</samp>,
                                                         <samp class="ph codeph">V</samp>, <samp class="ph codeph">O</samp>,
                                                         <samp class="ph codeph">dO</samp>, <samp class="ph codeph">dQ</samp>,
                                                         <samp class="ph codeph">dK</samp>, and <samp class="ph codeph">dV</samp> can all
                                                         be unpadded or none.
                                                      </li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1">All virtual tensors</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1">All virtual tensors must be in FP32 format.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1">Compute precision</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1">The compute precision of all operations must be FP32.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1"><samp class="ph codeph">M</samp>, <samp class="ph codeph">Zinv</samp></td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1"><a name="flash-fused-multi-head-att-fp8__ul_r2q_msn_cxb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="flash-fused-multi-head-att-fp8__ul_r2q_msn_cxb">
                                                      <li class="li">Must be in FP32 format.</li>
                                                      <li class="li">Should not be in an unpadded tightly packed layout.</li>
                                                   </ul>
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1">Attention Scale, Quantization (scale) and Dequantization
                                                   (descale) tensors
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1">Must be in FP32 format.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1">Match between cuDNN API specifications and passed in device
                                                   tensors
                                                </td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1">There is an implicit dependency between specifications done
                                                   through cuDNN API and device tensors passed in runtime. The
                                                   execution of the operation graph is undefined when the passed in
                                                   device tensors do not conform with the API
                                                   specifications.
                                                </td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1">Embedding dimension size (d)</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1">Embedding dimension size of only 64 is supported.</td>
                                             </tr>
                                             <tr class="row">
                                                <td class="entry" valign="top" width="50%" headers="d54e10213" rowspan="1" colspan="1">Maximum sequence length (s)</td>
                                                <td class="entry" valign="top" width="50%" headers="d54e10216" rowspan="1" colspan="1">Maximum sequence length sizes must be a multiple of 64. In
                                                   addition, maximum sequence lengths sizes up-to only 512 are
                                                   supported.
                                                </td>
                                             </tr>
                                          </tbody>
                                       </table>
                                    </div>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="mapping-backend-desc"><a name="mapping-backend-desc" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#mapping-backend-desc" name="mapping-backend-desc" shape="rect">3.3.5.&nbsp;Mapping with Backend Descriptors</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">For readability, the operations used in this section are abbreviated. The mapping
                                 with the actual backend descriptors can be found in this table:</span></div>
                           <div class="p">
                              <div class="tablenoborder"><a name="mapping-backend-desc__table_q2s_gz3_rtb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="mapping-backend-desc__table_q2s_gz3_rtb" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 32. Notations and Backend Descriptors</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="50%" id="d54e10511" rowspan="1" colspan="1">Notation used in this section</th>
                                          <th class="entry" valign="top" width="50%" id="d54e10514" rowspan="1" colspan="1"><strong class="ph b">Backend descriptor</strong></th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:scale</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_MUL </samp>and with
                                             operand B broadcasting into operand X
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:bias</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_ADD </samp>and with
                                             operand B broadcasting into operand X
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:add</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_ADD </samp>and with
                                             operand B with same dimensions as X
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:mul</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_MUL </samp>and with
                                             operand B with same dimensions as X
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:ReLU</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_RELU_FWD</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:ReLUBwd</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_RELU_BWD</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:tanh</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_TANH_FWD</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:sigmoid</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode
                                             <samp class="ph codeph">CUDNN_POINTWISE_SIGMOID_FWD</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:ELU</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR
                                                </samp>with mode <samp class="ph codeph">CUDNN_POINTWISE_ELU_FWD</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Pointwise:{ReLU,tanh,sigmoid,ELU}</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp>
                                             with one of the following modes:
                                             <pre xml:space="preserve">CUDNN_POINTWISE_RELU_FWD, CUDNN_POINTWISE_TANH_FWD, CUDNN_POINTWISE_SIGMOID_FWD,
        CUDNN_POINTWISE_ELU_FWD</pre></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">MatMul</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionFwd</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwFilter</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">ConvolutionBwData</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">GenStats</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">ResampleFwd</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">GenStats</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">Reduction</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">BnBwdWeight</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_BN_BWD_WEIGHTS_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">NormForward</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">NormBackward</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">BOOLEAN/packed-BOOLEAN</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_DATA_BOOLEAN: </samp>As described in the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnn-ops-infer-so-library" target="_blank" shape="rect">NVIDIA cuDNN API
                                                   Reference</a>, this type implies that eight boolean
                                                values are packed in a single byte, with the lowest index on the
                                                right (that is, least significant bit).
                                             </p>
                                             <p class="p"><samp class="ph codeph">packed-BOOLEAN</samp> and <samp class="ph codeph">BOOLEAN</samp> are
                                                used interchangeably, where the former is used to emphasize and
                                                remind the user about the semantics.
                                             </p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">FP8</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp> or
                                             <samp class="ph codeph">CUDNN_DATA_FP8_E5M2</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">FP16</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">BF16</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">FP32</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e10511" rowspan="1" colspan="1"><samp class="ph codeph">TF32</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e10514" rowspan="1" colspan="1">A tensor core operation mode used to accelerate floating point
                                             convolutions or matmuls. This can be used for an operation with
                                             compute type <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>, on NVIDIA Ampere
                                             architecture or later and be disabled with
                                             <samp class="ph codeph">NVIDIA_TF32_OVERRIDE=1</samp>.
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="legacy-api"><a name="legacy-api" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#legacy-api" name="legacy-api" shape="rect">4.&nbsp;Legacy API</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc"></span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="tensor-ops-conv-functions"><a name="tensor-ops-conv-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions" name="tensor-ops-conv-functions" shape="rect">4.1.&nbsp;Convolution Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-conv-functions-pre-req"><a name="tensor-ops-conv-functions-pre-req" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions-pre-req" name="tensor-ops-conv-functions-pre-req" shape="rect">4.1.1.&nbsp;Prerequisites</a></h3>
                        <div class="body conbody">
                           <div class="abstract">For the supported GPUs, the Tensor Core operations will be triggered for convolution
                              		functions only when <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnSetConvolutionMathType" target="_blank" shape="rect"><samp class="ph codeph">cudnnSetConvolutionMathType()</samp></a> is
                              		called on the appropriate convolution descriptor by setting the <samp class="ph codeph">mathType</samp> to
                              			<samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                              			<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>. <span class="shortdesc"></span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-conv-functions-supported-algos"><a name="tensor-ops-conv-functions-supported-algos" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions-supported-algos" name="tensor-ops-conv-functions-supported-algos" shape="rect">4.1.2.&nbsp;Supported Algorithms</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">When the prerequisite is met, the below convolution functions can be run as
                                 			Tensor Core operations: </span></div>
                           <div class="p"><a name="tensor-ops-conv-functions-supported-algos__ul_f5w_rl1_3jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-conv-functions-supported-algos__ul_f5w_rl1_3jb">
                                 <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionForward()</samp></a></li>
                                 <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionBackwardData" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardData()</samp></a></li>
                                 <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionBackwardFilter" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp></a></li>
                              </ul>
                           </div>
                           <div class="p">Refer to the following table for a list of supported algorithms:
                              
                              
                              <div class="tablenoborder"><a name="tensor-ops-conv-functions-supported-algos__table_kw4_w41_3jb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="tensor-ops-conv-functions-supported-algos__table_kw4_w41_3jb" class="table" frame="border" border="1" rules="all">
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="50%" id="d54e11005" rowspan="1" colspan="1">Supported Convolution Function</th>
                                          <th class="entry" valign="top" width="50%" id="d54e11008" rowspan="1" colspan="1">Supported Algos</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e11005" rowspan="1" colspan="1"><samp class="ph codeph">cudnnConvolutionForward</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e11008" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM</samp></p>
                                             <p class="p"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED</samp></p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e11005" rowspan="1" colspan="1"><samp class="ph codeph">cudnnConvolutionBackwardData</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e11008" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_1</samp></p>
                                             <p class="p"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED</samp></p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e11005" rowspan="1" colspan="1"><samp class="ph codeph">cudnnConvolutionBackwardFilter</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e11008" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1</samp></p>
                                             <p class="p"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED</samp></p>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-conv-functions-data-filter-formats"><a name="tensor-ops-conv-functions-data-filter-formats" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions-data-filter-formats" name="tensor-ops-conv-functions-data-filter-formats" shape="rect">4.1.3.&nbsp;Data and Filter Formats</a></h3>
                        <div class="body conbody">
                           <div class="abstract">The cuDNN library may use padding, folding, and NCHW-to-NHWC transformations to call
                              		the Tensor Core operations. For more information, refer to <a class="xref" href="index.html#tensor-ops-tensor-transformations" title="A few functions in the cuDNN library will perform transformations such as folding, padding, and NCHW-to-NHWC conversion while performing the actual function operation." shape="rect">Tensor Transformations</a>. <span class="shortdesc"></span></div>
                           <div class="p">For algorithms other than <samp class="ph codeph">*_ALGO_WINOGRAD_NONFUSED</samp>, when the following
                              			requirements are met, the cuDNN library will trigger the Tensor Core operations:<a name="tensor-ops-conv-functions-data-filter-formats__ul_ybq_hm1_3jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-conv-functions-data-filter-formats__ul_ybq_hm1_3jb">
                                 <li class="li liexpand">Input, filter, and output descriptors (<samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                    						<samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dxDesc</samp>, <samp class="ph codeph">dyDesc</samp> and
                                    						<samp class="ph codeph">dwDesc</samp> as applicable) are of the <samp class="ph codeph">dataType =
                                       						CUDNN_DATA_HALF</samp> (that is, FP16). For FP32
                                    					<samp class="ph codeph">dataType</samp>, refer to <a class="xref" href="index.html#tensor-ops-tensor-transformations-fp32-to-fp16" shape="rect">Conversion Between FP32 and FP16</a>.
                                 </li>
                                 <li class="li liexpand">The number of input and output feature maps (that is, channel dimension <samp class="ph codeph">C</samp>)
                                    					is a multiple of 8. When the channel dimension is not a multiple of 8, refer to
                                    						<a class="xref" href="index.html#tensor-ops-tensor-transformations-padding" title="For packed NCHW data, when the channel dimension is not a multiple of 8, then the cuDNN library will pad the tensors as needed to enable Tensor Core operations. This padding is automatic for packed NCHW data in both the CUDNN_TENSOR_OP_MATH and the CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION cases." shape="rect">Padding</a>.
                                 </li>
                                 <li class="li liexpand">The filter is of type <samp class="ph codeph">CUDNN_TENSOR_NCHW</samp> or
                                    						<samp class="ph codeph">CUDNN_TENSOR_NHWC</samp>.
                                 </li>
                                 <li class="li liexpand">If using a filter of type <samp class="ph codeph">CUDNN_TENSOR_NHWC</samp>, then the input, filter, and
                                    					output data pointers (<samp class="ph codeph">X</samp>, <samp class="ph codeph">Y</samp>,
                                    					<samp class="ph codeph">W</samp>, <samp class="ph codeph">dX</samp>, <samp class="ph codeph">dY</samp>, and
                                    						<samp class="ph codeph">dW</samp> as applicable) are aligned to 128-bit boundaries.
                                 </li>
                              </ul>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="tensor-ops-rnn-functions"><a name="tensor-ops-rnn-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions" name="tensor-ops-rnn-functions" shape="rect">4.2.&nbsp;RNN Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-rnn-functions-pre-req"><a name="tensor-ops-rnn-functions-pre-req" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions-pre-req" name="tensor-ops-rnn-functions-pre-req" shape="rect">4.2.1.&nbsp;Prerequisites</a></h3>
                        <div class="body conbody">
                           <div class="abstract">Tensor Core operations are triggered for these RNN functions only when <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnSetRNNMatrixMathType" target="_blank" shape="rect"><samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp></a> is
                              		called on the appropriate RNN descriptor setting <samp class="ph codeph">mathType</samp> to
                              			<samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                              			<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>. <span class="shortdesc"></span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-rnn-functions-supported-algos"><a name="tensor-ops-rnn-functions-supported-algos" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions-supported-algos" name="tensor-ops-rnn-functions-supported-algos" shape="rect">4.2.2.&nbsp;Supported Algorithms</a></h3>
                        <div class="body conbody">
                           <div class="abstract">When the above prerequisites are met, the RNN functions below can be run as Tensor
                              		Core operations: <span class="shortdesc"></span></div>
                           <div class="p"><a name="tensor-ops-rnn-functions-supported-algos__ul_yzd_bn1_3jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-supported-algos__ul_yzd_bn1_3jb">
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNForwardInference" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNForwardInference()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNForwardTraining" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNForwardTraining()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNBackwardData" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNBackwardData()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNBackwardWeights" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNBackwardWeights()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNForwardInferenceEx" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNForwardInferenceEx()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNForwardTrainingEx" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNForwardTrainingEx()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNBackwardDataEx" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNBackwardDataEx()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNBackwardWeightsEx" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNBackwardWeightsEx()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNForward()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNBackwardData_v8" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNBackwardData_v8()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnRNNBackwardWeights_v8" target="_blank" shape="rect"><samp class="ph codeph">cudnnRNNBackwardWeights_v8()</samp></a></li>
                              </ul>
                           </div>
                           <div class="p">Refer to the following table for a list of supported algorithms:
                              
                              
                              <div class="tablenoborder"><a name="tensor-ops-rnn-functions-supported-algos__table_dvm_qn1_3jb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="tensor-ops-rnn-functions-supported-algos__table_dvm_qn1_3jb" class="table" frame="border" border="1" rules="all">
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="50%" id="d54e11320" rowspan="1" colspan="1">RNN Function</th>
                                          <th class="entry" valign="top" width="50%" id="d54e11323" rowspan="1" colspan="1">Support Algos</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e11320" rowspan="1" colspan="1">All RNN functions that support Tensor Core operations.</td>
                                          <td class="entry" valign="top" width="50%" headers="d54e11323" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp></p>
                                             <p class="p"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp></p>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-rnn-functions-data-filter-formats"><a name="tensor-ops-rnn-functions-data-filter-formats" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions-data-filter-formats" name="tensor-ops-rnn-functions-data-filter-formats" shape="rect">4.2.3.&nbsp;Data and Filter Formats</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">When the following requirements are met, then the cuDNN library triggers the
                                 			Tensor Core operations:</span></div>
                           <div class="p"><a name="tensor-ops-rnn-functions-data-filter-formats__ul_dbb_dp1_3jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-data-filter-formats__ul_dbb_dp1_3jb">
                                 <li class="li liexpand">For <samp class="ph codeph">algo = CUDNN_RNN_ALGO_STANDARD</samp>:<a name="tensor-ops-rnn-functions-data-filter-formats__ul_llx_dp1_3jb" shape="rect">
                                       <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-data-filter-formats__ul_llx_dp1_3jb">
                                       <li class="li liexpand">The hidden state size, input size, and the batch size is a multiple of
                                          							8.
                                       </li>
                                       <li class="li liexpand">All user-provided tensors, workspace, and reserve space are aligned to
                                          							128-bit boundaries.
                                       </li>
                                       <li class="li liexpand">For FP16 input/output, the <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                                          								<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> is
                                          							selected.
                                       </li>
                                       <li class="li liexpand">For FP32 input/output,
                                          								<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> is
                                          							selected.
                                       </li>
                                    </ul>
                                 </li>
                                 <li class="li liexpand">For <samp class="ph codeph">algo = CUDNN_RNN_ALGO_PERSIST_STATIC</samp>:<a name="tensor-ops-rnn-functions-data-filter-formats__ul_kh2_hp1_3jb" shape="rect">
                                       <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-data-filter-formats__ul_kh2_hp1_3jb">
                                       <li class="li liexpand">The hidden state size and the input size is a multiple of 32.</li>
                                       <li class="li liexpand">The batch size is a multiple of 8.</li>
                                       <li class="li liexpand">If the batch size exceeds 96 (for forward training or inference) or 32
                                          							(for backward data), then the batch size constraints may be stricter,
                                          							and large power-of-two batch sizes may be needed. 
                                       </li>
                                       <li class="li liexpand">All user-provided tensors, workspace, and reserve space are aligned to
                                          							128-bit boundaries.
                                       </li>
                                       <li class="li liexpand">For FP16 input/output, <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                                          								<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> is
                                          							selected.
                                       </li>
                                       <li class="li liexpand">For FP32 input/output,
                                          								<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> is
                                          							selected.
                                       </li>
                                    </ul>
                                 </li>
                              </ul>
                           </div>
                           <p class="p">For more information, refer to <a class="xref" href="index.html#features-of-rnn-functions" title="Refer to the following table for a list of features supported by each RNN function." shape="rect">Features of RNN Functions</a>.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="features-of-rnn-functions"><a name="features-of-rnn-functions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#features-of-rnn-functions" name="features-of-rnn-functions" shape="rect">4.2.4.&nbsp;Features of RNN Functions</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Refer to the following table for a list of features supported by each RNN
                                 function.</span></div>
                           <div class="p">
                              <div class="note note"><span class="notetitle">Note:</span><p class="p">For each of these terms, the short-form versions shown in the parenthesis are
                                    used in the tables below for brevity: <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>
                                    (<samp class="ph codeph">_ALGO_STANDARD</samp>),
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>
                                    (<samp class="ph codeph">_ALGO_PERSIST_STATIC</samp>),
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>
                                    (<samp class="ph codeph">_ALGO_PERSIST_DYNAMIC</samp>), and
                                    <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>
                                    (<samp class="ph codeph">_ALLOW_CONVERSION</samp>).
                                 </p>
                              </div>
                              <div class="tablenoborder"><a name="features-of-rnn-functions__table_ihj_4cb_3jb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="features-of-rnn-functions__table_ihj_4cb_3jb" class="table" frame="border" border="1" rules="all">
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="25%" id="d54e11510" rowspan="1" colspan="1">Functions</th>
                                          <th class="entry" valign="top" width="25%" id="d54e11513" rowspan="1" colspan="1">I/O layout supported</th>
                                          <th class="entry" valign="top" width="25%" id="d54e11516" rowspan="1" colspan="1">Supports variable sequence length in batch</th>
                                          <th class="entry" valign="top" width="25%" id="d54e11519" rowspan="1" colspan="1">Commonly supported</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNForwardInference()</samp></td>
                                          <td class="entry" rowspan="4" valign="top" width="25%" headers="d54e11513" colspan="1">Only Sequence major, packed (non-padded)</td>
                                          <td class="entry" rowspan="4" valign="top" width="25%" headers="d54e11516" colspan="1">
                                             <p class="p">Only with <samp class="ph codeph">_ALGO_STANDARD</samp></p>
                                             <p class="p">Require input sequences descending sorted according to
                                                length.
                                             </p>
                                          </td>
                                          <td class="entry" rowspan="8" valign="top" width="25%" headers="d54e11519" colspan="1">
                                             <p class="p">Mode (cell type) supported:<samp class="ph codeph">CUDNN_RNN_RELU,
                                                   CUDNN_RNN_TANH, CUDNN_LSTM, CUDNN_GRU</samp></p>
                                             <p class="p">Algo supported<a name="fnsrc_1" href="#fntarg_1" shape="rect"><sup>1</sup></a>
                                                (refer to the table for for information on these
                                                algorithms):<samp class="ph codeph">_ALGO_STANDARD, _ALGO_PERSIST_STATIC,
                                                   _ALGO_PERSIST_DYNAMIC </samp></p>
                                             <p class="p">Math mode supported:
                                                <samp class="ph codeph">CUDNN_DEFAULT_MATH,CUDNN_TENSOR_OP_MATH</samp></p>
                                             <p class="p">(will automatically fall back if run on pre-Volta or if algo
                                                doesn’t support Tensor Cores)
                                             </p>
                                             <p class="p"><samp class="ph codeph">_ALLOW_CONVERSION</samp> (may perform down conversion
                                                to utilize Tensor Cores)
                                             </p>
                                             <p class="p">Direction mode supported: <samp class="ph codeph">CUDNN_UNIDIRECTIONAL,
                                                   CUDNN_BIDIRECTIONAL</samp></p>
                                             <p class="p"> RNN input mode: <samp class="ph codeph">CUDNN_LINEAR_INPUT,
                                                   CUDNN_SKIP_INPUT</samp></p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNForwardTraining()</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNBackwardData()</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNBackwardWeights()</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNForwardInferenceEx()</samp></td>
                                          <td class="entry" rowspan="4" valign="top" width="25%" headers="d54e11513" colspan="1">
                                             <p class="p">Sequence major unpacked</p>
                                             <p class="p">Batch major unpacked<a name="fnsrc_2" href="#fntarg_2" shape="rect"><sup>2</sup></a></p>
                                             <p class="p">Sequence major packed<a name="fnsrc_3" href="#fntarg_3" shape="rect"><sup>3</sup></a></p>
                                          </td>
                                          <td class="entry" rowspan="4" valign="top" width="25%" headers="d54e11516" colspan="1">
                                             <p class="p">Only with <samp class="ph codeph">_ALGO_STANDARD</samp></p>
                                             <p class="p"></p>
                                             <p class="p">For unpacked layout, no input sorting required. <a name="fnsrc_4" href="#fntarg_4" shape="rect"><sup>4</sup></a></p>
                                             <p class="p">For packed layout, require input sequences descending sorted
                                                according to length.
                                             </p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNForwardTrainingEx()</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNBackwardDataEx()</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e11510" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNBackwardWeightsEx()</samp></td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="p">The following table provides the features supported by the algorithms referred in the
                              above table: <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>,
                              <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>, and
                              <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>.
                              
                              
                              <div class="tablenoborder"><a name="features-of-rnn-functions__table_px4_ldb_3jb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="features-of-rnn-functions__table_px4_ldb_3jb" class="table" frame="border" border="1" rules="all">
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="20%" id="d54e11726" rowspan="1" colspan="1">Features</th>
                                          <th class="entry" valign="top" width="20%" id="d54e11729" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_STANDARD</samp></th>
                                          <th class="entry" valign="top" width="20%" id="d54e11733" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_PERSIST_STATIC</samp></th>
                                          <th class="entry" valign="top" width="20%" id="d54e11737" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC_SMALL_H</samp></th>
                                          <th class="entry" valign="top" width="20%" id="d54e11741" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_PERSIST_DYNAMIC</samp></th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">Half input
                                             <p class="p">Single accumulation</p>
                                             <p class="p">Half output</p>
                                          </td>
                                          <td class="entry" colspan="4" valign="top" headers="d54e11729 d54e11733 d54e11737 d54e11741" rowspan="1">Supported
                                             <p class="p">Half intermediate
                                                storage
                                             </p>
                                             <p class="p">Single accumulation</p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">Single input
                                             <p class="p">Single accumulation</p>
                                             <p class="p">Single
                                                output
                                             </p>
                                          </td>
                                          <td class="entry" colspan="4" valign="top" headers="d54e11729 d54e11733 d54e11737 d54e11741" rowspan="1">Supported
                                             <p class="p">If running on Volta, with
                                                <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp><a name="fnsrc_5" href="#fntarg_5" shape="rect"><sup>5</sup></a>, will
                                                down-convert and use half intermediate storage.
                                             </p>
                                             <p class="p">Otherwise:
                                                Single intermediate storage
                                             </p>
                                             <p class="p">Single
                                                accumulation
                                             </p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">Double input
                                             <p class="p">Double accumulation</p>
                                             <p class="p">Double
                                                output
                                             </p>
                                          </td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11729" rowspan="1" colspan="1">Supported
                                             <p class="p">Double intermediate storage</p>
                                             <p class="p">Double
                                                accumulation
                                             </p>
                                          </td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11733" rowspan="1" colspan="1">Not Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11737" rowspan="1" colspan="1">Not Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11741" rowspan="1" colspan="1">Supported
                                             <p class="p">Double intermediate storage</p>
                                             <p class="p">Double
                                                accumulation
                                             </p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">LSTM recurrent projection</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11729" rowspan="1" colspan="1">Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11733" rowspan="1" colspan="1">Not Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11737" rowspan="1" colspan="1">Not Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11741" rowspan="1" colspan="1">Not Supported</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">LSTM cell clipping</td>
                                          <td class="entry" colspan="4" valign="top" headers="d54e11729 d54e11733 d54e11737 d54e11741" rowspan="1">Supported</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">Variable sequence length in batch</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11729" rowspan="1" colspan="1">Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11733" rowspan="1" colspan="1">Not Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11737" rowspan="1" colspan="1">Not Supported</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11741" rowspan="1" colspan="1">Not Supported</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">Tensor Cores</td>
                                          <td class="entry" colspan="3" valign="top" headers="d54e11729 d54e11733 d54e11737" rowspan="1">
                                             <p class="p">Supported</p>
                                             <p class="p">For half input/output, acceleration requires setting</p>
                                             <p class="p"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp><a name="fnsrc_6" href="#fntarg_6" shape="rect"><sup>6</sup></a> or
                                                <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION
                                                   </samp><a name="fnsrc_7" href="#fntarg_7" shape="rect"><sup>7</sup></a></p>
                                             <p class="p">Acceleration requires <samp class="ph codeph">inputSize</samp> and
                                                <samp class="ph codeph">hiddenSize</samp> to be a multiple of 8
                                             </p>
                                             <p class="p">For single input/output on NVIDIA Volta, NVIDIA Xavier, and
                                                NVIDIA Turing, acceleration requires setting
                                             </p>
                                             <p class="p"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp><a name="fnsrc_8" href="#fntarg_8" shape="rect"><sup>8</sup></a></p>
                                             <p class="p">Acceleration requires <samp class="ph codeph">inputSize</samp> and
                                                <samp class="ph codeph">hiddenSize</samp> to be a multiple of 8
                                             </p>
                                             <p class="p">For single input/output on NVIDIA Ampere architecture,
                                                acceleration requires setting 
                                             </p>
                                             <p class="p"><samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>,
                                                <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>,  or <samp class="ph codeph">
                                                   CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp><a name="fnsrc_9" href="#fntarg_9" shape="rect"><sup>9</sup></a></p>
                                             <p class="p">Acceleration requires <samp class="ph codeph">inputSize</samp> and
                                                <samp class="ph codeph">hiddenSize</samp> to be a multiple of 4.
                                             </p>
                                          </td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11741" rowspan="1" colspan="1">Not Supported, will execute normally ignoring
                                             <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp><a name="fnsrc_10" href="#fntarg_10" shape="rect"><sup>10</sup></a>
                                             or
                                             <samp class="ph codeph">_ALLOW_CONVERSION</samp><a name="fnsrc_11" href="#fntarg_11" shape="rect"><sup>11</sup></a></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e11726" rowspan="1" colspan="1">Other limitations</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11729" rowspan="1" colspan="1">&nbsp;</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11733" rowspan="1" colspan="1">Max problem size is limited by GPU specifications.</td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11737" rowspan="1" colspan="1">
                                             <div class="p">Forward RNN:<a name="features-of-rnn-functions__ul_mjy_m5h_rsb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="features-of-rnn-functions__ul_mjy_m5h_rsb">
                                                   <li class="li">RELU and TANH RNN: <samp class="ph codeph">hidden_size &lt;=
                                                         384</samp></li>
                                                   <li class="li">LSTM and GRU: <samp class="ph codeph">hidden_size &lt;=
                                                         192</samp></li>
                                                </ul>
                                             </div>
                                             <div class="p">BackwardData RNN:<a name="features-of-rnn-functions__ul_f2q_q5h_rsb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="features-of-rnn-functions__ul_f2q_q5h_rsb">
                                                   <li class="li">RELU and TANH RNN: <samp class="ph codeph">hidden_size &lt;=
                                                         256</samp></li>
                                                   <li class="li">LSTM and GRU: <samp class="ph codeph">hidden_size &lt;=
                                                         128</samp></li>
                                                </ul>
                                             </div>
                                          </td>
                                          <td class="entry" valign="top" width="20%" headers="d54e11741" rowspan="1" colspan="1">Requires real time compilation through NVRTC</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="tensor-ops-tensor-transformations"><a name="tensor-ops-tensor-transformations" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations" name="tensor-ops-tensor-transformations" shape="rect">4.3.&nbsp;Tensor Transformations </a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">A few functions in the cuDNN library will perform transformations such as
                              folding, padding, and NCHW-to-NHWC conversion while performing the actual function
                              operation. </span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-tensor-transformations-fp32-to-fp16"><a name="tensor-ops-tensor-transformations-fp32-to-fp16" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-fp32-to-fp16" name="tensor-ops-tensor-transformations-fp32-to-fp16" shape="rect">4.3.1.&nbsp;Conversion Between FP32 and FP16 </a></h3>
                        <div class="body conbody">
                           <div class="abstract">The cuDNN API Reference allows you to specify that FP32 input data may be copied and
                              		converted to FP16 data internally to use Tensor Core operations for potentially improved
                              		performance. This can be achieved by selecting
                              			<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> enum for <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnMathType_t" target="_blank" shape="rect"><samp class="ph codeph">cudnnMathType_t</samp></a>. In this mode,
                              		the FP32 tensors are internally down-converted to FP16, the Tensor Op math is performed, and
                              		finally up-converted to FP32 as outputs. For more information, refer to <a class="xref" href="index.html#tensor-ops-tensor-transformations-fp32-to-fp16__fig-tensor-op-fp32-to-fp16" shape="rect">Figure 49</a>. <span class="shortdesc"></span></div>
                           <div class="p">
                              <div class="fig fignone" id="tensor-ops-tensor-transformations-fp32-to-fp16__fig-tensor-op-fp32-to-fp16"><a name="tensor-ops-tensor-transformations-fp32-to-fp16__fig-tensor-op-fp32-to-fp16" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 49. Tensor Operation with FP32 Inputs</span><br clear="none"></br><a name="tensor-ops-tensor-transformations-fp32-to-fp16__image_fcc_hhn_mpb" shape="rect">
                                    <!-- --></a><div class="imageleft">
                                    <embed class="image imageleft" id="tensor-ops-tensor-transformations-fp32-to-fp16__image_fcc_hhn_mpb" src="graphics/tensor-op-fp32-to-fp16.svg"></embed>
                                 </div><br clear="none"></br></div>
                           </div>
                           <div class="section" id="tensor-ops-tensor-transformations-fp32-to-fp16__section_wfz_rx1_3jb"><a name="tensor-ops-tensor-transformations-fp32-to-fp16__section_wfz_rx1_3jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">For Convolutions</h4>
                              <div class="p">For convolutions, the FP32-to-FP16 conversion can be achieved by passing the
                                 					<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> enum value to the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnSetConvolutionMathType" target="_blank" shape="rect"><samp class="ph codeph">cudnnSetConvolutionMathType()</samp></a> call.
                                 				<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">// Set the math type to allow cuDNN to use Tensor Cores:
checkCudnnErr(cudnnSetConvolutionMathType(cudnnConvDesc, CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION));
</kbd></pre></div>
                           </div>
                           <div class="section" id="tensor-ops-tensor-transformations-fp32-to-fp16__section_rnp_wx1_3jb"><a name="tensor-ops-tensor-transformations-fp32-to-fp16__section_rnp_wx1_3jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">For RNNs</h4>
                              <div class="p">For RNNs, the FP32-to-FP16 conversion can be achieved by passing the
                                 					<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> enum value to the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnSetRNNMatrixMathType" target="_blank" shape="rect"><samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp></a> call to allow FP32 data to
                                 				be converted for use in
                                 				RNNs.<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">// Set the math type to allow cuDNN to use Tensor Cores:
checkCudnnErr(cudnnSetRNNMatrixMathType(cudnnRnnDesc, CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION));
</kbd></pre></div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-tensor-transformations-padding"><a name="tensor-ops-tensor-transformations-padding" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-padding" name="tensor-ops-tensor-transformations-padding" shape="rect">4.3.2.&nbsp;Padding </a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">For packed NCHW data, when the channel dimension is not a multiple of 8, then the
                                 cuDNN library will pad the tensors as needed to enable Tensor Core operations. This
                                 padding is automatic for packed NCHW data in both the
                                 <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> and the
                                 <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> cases.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-tensor-transformations-folding"><a name="tensor-ops-tensor-transformations-folding" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-folding" name="tensor-ops-tensor-transformations-folding" shape="rect">4.3.3.&nbsp;Folding </a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">In the folding operation, the cuDNN library implicitly performs the formatting of
                                 			input tensors and saves the input tensors in an internal workspace. This can lead to an
                                 			acceleration of the call to Tensor Cores.</span></div>
                           <p class="p">With folding or channel-folding, cuDNN can implicitly format the input tensors within an
                              			internal workspace to accelerate the overall calculation. Performing this transformation
                              			for the user often allows cuDNN to use kernels with restrictions on convolution stride
                              			to support a strided convolution problem.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-tensor-transformations-conversion"><a name="tensor-ops-tensor-transformations-conversion" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-conversion" name="tensor-ops-tensor-transformations-conversion" shape="rect">4.3.4.&nbsp;Conversion Between NCHW And NHWC </a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Tensor Cores require that the tensors be in the NHWC data layout. Conversion
                                 			between NCHW and NHWC is performed when the user requests Tensor Op math. However, a
                                 			request to use Tensor Cores is just that, a request and Tensor Cores may not be used in
                                 			some cases. The cuDNN library converts between NCHW and NHWC if and only if Tensor Cores
                                 			are requested and are actually used.</span></div>
                           <p class="p">If your input (and output) are NCHW, then expect a layout change. </p>
                           <p class="p">Non-Tensor Op convolutions will not perform conversions between NCHW and NHWC.</p>
                           <p class="p">In very rare and difficult-to-qualify cases that are a complex function of padding and filter
                              			sizes, it is possible that Tensor Ops is not enabled. In such cases, users can pre-pad
                              			to enable the Tensor Ops path.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="mixed-precision-numerical-accuracy"><a name="mixed-precision-numerical-accuracy" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#mixed-precision-numerical-accuracy" name="mixed-precision-numerical-accuracy" shape="rect">4.4.&nbsp;Mixed Precision Numerical Accuracy</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">When the computation precision and the output precision are not the same, it is
                              possible that the numerical accuracy will vary from one algorithm to the
                              other.</span></div>
                        <p class="p">For example, when the computation is performed in FP32 and the output is in FP16, the
                           <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0</samp> (<samp class="ph codeph">ALGO_0</samp>) has
                           lower accuracy compared to the <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1</samp>
                           (<samp class="ph codeph">ALGO_1</samp>). This is because <samp class="ph codeph">ALGO_0</samp> does not use
                           extra workspace, and is forced to accumulate the intermediate results in FP16, that is,
                           half precision float, and this reduces the accuracy. The <samp class="ph codeph">ALGO_1</samp>, on the
                           other hand, uses additional workspace to accumulate the intermediate values in FP32,
                           that is, full precision float. 
                        </p>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="misc"><a name="misc" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#misc" name="misc" shape="rect">5.&nbsp;Odds and Ends</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">This section includes a random set of topics and concepts. </span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="thread-safety"><a name="thread-safety" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#thread-safety" name="thread-safety" shape="rect">5.1.&nbsp;Thread Safety</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The cuDNN library is thread-safe. Its functions can be called from multiple host
                              threads, so long as the threads do not share the same cuDNN handle
                              simultaneously.</span></div>
                        <p class="p">When creating a per-thread cuDNN handle, it is recommended that a single synchronous call
                           of <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnCreate" target="_blank" shape="rect"><samp class="ph codeph">cudnnCreate()</samp></a> be made first
                           before each thread creates its own handle asynchronously.
                        </p>
                        <p class="p">Per <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnCreate" target="_blank" shape="rect"><samp class="ph codeph">cudnnCreate()</samp></a>, for
                           multi-threaded applications that use the same device from different threads, the
                           recommended programming model is to create one (or a few, as is convenient) cuDNN
                           handles per thread and use that cuDNN handle for the entire life of the thread.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="reproducibility"><a name="reproducibility" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#reproducibility" name="reproducibility" shape="rect">5.2.&nbsp;Reproducibility (Determinism)</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">By design, most of cuDNN's routines from a given version generate the same
                              bit-wise results across runs when executed on GPUs with the same architecture. There are
                              some exceptions. For example, the following routines do not guarantee reproducibility
                              across runs, even on the same architecture, because they use atomic operations in a way
                              that introduces truly random floating point rounding errors:</span></div>
                        <div class="p"><a name="reproducibility__ul_pzy_xby_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="reproducibility__ul_pzy_xby_r1b">
                              <li class="li liexpand"><samp class="ph codeph">cudnnConvolutionBackwardFilter</samp> when
                                 <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0</samp> or
                                 <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3</samp> is used
                              </li>
                              <li class="li liexpand"><samp class="ph codeph">cudnnConvolutionBackwardData</samp> when
                                 <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_0 </samp> is used
                              </li>
                              <li class="li liexpand"><samp class="ph codeph">cudnnPoolingBackward</samp> when <samp class="ph codeph">CUDNN_POOLING_MAX </samp>
                                 is used
                              </li>
                              <li class="li liexpand"><samp class="ph codeph">cudnnSpatialTfSamplerBackward</samp></li>
                              <li class="li liexpand"><samp class="ph codeph">cudnnCTCLoss</samp> and <samp class="ph codeph">cudnnCTCLoss_v8</samp> when
                                 <samp class="ph codeph">CUDNN_CTC_LOSS_ALGO_NON_DETERMINSTIC</samp> is used
                              </li>
                           </ul>
                        </div>
                        <p class="p">Across different architectures, no cuDNN routines guarantee bit-wise reproducibility. For
                           example, there is no guarantee of bit-wise reproducibility when comparing the same
                           routine run on NVIDIA Volta™ and NVIDIA Turing™, NVIDIA
                           Turing, and NVIDIA Ampere architecture.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="scaling-parameters"><a name="scaling-parameters" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#scaling-parameters" name="scaling-parameters" shape="rect">5.3.&nbsp;Scaling Parameters</a></h3>
                     <div class="body conbody">
                        <div class="abstract">Many cuDNN routines like <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionForward()</samp></a> accept
                           		pointers in host memory to scaling factors <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp>.
                           		These scaling factors are used to blend the computed values with the prior values in the
                           		destination tensor as follows (refer to <a class="xref" href="index.html#scaling-parameters__fig-scaling-params-conv" shape="rect">Figure 50</a>):  <span class="shortdesc"></span></div>
                        <div class="p"><pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">dstValue = alpha*computedValue + beta*priorDstValue</kbd></pre><div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">dstValue</samp> is written to after being read. 
                           </div>
                        </div>
                        <div class="p">
                           <div class="fig fignone" id="scaling-parameters__fig-scaling-params-conv"><a name="scaling-parameters__fig-scaling-params-conv" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 50. Scaling Parameters for Convolution</span><br clear="none"></br><div class="imageleft"><img class="image imageleft" src="graphics/alpha-beta-dstValue.png" alt="Scaling Parameters for Convolution"></img></div><br clear="none"></br></div>
                        </div>
                        <p class="p">When <samp class="ph codeph">beta</samp> is zero, the output is not read and may contain uninitialized data
                           			(including NaN). 
                        </p>
                        <div class="p">These parameters are passed using a host memory pointer. The storage data types for
                           				<samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> are:<a name="scaling-parameters__ul_qs4_qk1_3jb" shape="rect">
                              <!-- --></a><ul class="ul" id="scaling-parameters__ul_qs4_qk1_3jb">
                              <li class="li"><samp class="ph codeph">float</samp> for HALF and FLOAT tensors, and
                              </li>
                              <li class="li"><samp class="ph codeph">double</samp> for DOUBLE tensors. 
                              </li>
                           </ul>
                           <div class="note note"><span class="notetitle">Note:</span> For improved performance use <samp class="ph codeph">beta = 0.0</samp>. Use a non-zero
                              				value for beta only when you need to blend the current output tensor values with the
                              				prior values of the output tensor.
                           </div>
                        </div>
                        <div class="section" id="scaling-parameters__section_n5g_nn2_cgb"><a name="scaling-parameters__section_n5g_nn2_cgb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Type Conversion</h3>
                           <p class="p">When the data input <samp class="ph codeph">x</samp>, the filter input <samp class="ph codeph">w</samp> and the output
                              					<samp class="ph codeph">y</samp> are all in INT8 data type, the function <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionBiasActivationForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBiasActivationForward()</samp></a> will
                              				perform the type conversion as shown in <a class="xref" href="index.html#scaling-parameters__fig-conv-bias-activation-forward" shape="rect">Figure 51</a>:
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> Accumulators are 32-bit integers that wrap on overflow. 
                           </div>
                           <div class="fig fignone" id="scaling-parameters__fig-conv-bias-activation-forward"><a name="scaling-parameters__fig-conv-bias-activation-forward" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 51. INT8 for <samp class="ph codeph">cudnnConvolutionBiasActivationForward</samp></span><br clear="none"></br><div class="imageleft"><img class="image imageleft" src="graphics/cudnnConvolutionBiasActivationForward.png" alt="INT8 for cudnnConvolutionBiasActivationForward"></img></div><br clear="none"></br></div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="api-compat"><a name="api-compat" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#api-compat" name="api-compat" shape="rect">5.4.&nbsp;cuDNN API Compatibility</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">Beginning in cuDNN 7, the binary compatibility of a patch and minor releases is
                              maintained as follows:</span></div>
                        <div class="p"><a name="api-compat__ul_kcs_24q_kwb" shape="rect">
                              <!-- --></a><ul class="ul" id="api-compat__ul_kcs_24q_kwb">
                              <li class="li liexpand">Any patch release x.y.z is forward or backward-compatible with applications
                                 built against another cuDNN patch release x.y.w (meaning, of the same major and
                                 minor version number, but having w!=z).
                              </li>
                              <li class="li liexpand">cuDNN minor releases are binary backward-compatible with applications built
                                 against the same or earlier minor release (meaning, cuDNN x.y is binary
                                 compatible with an app built against cuDNN x.z, where z&lt;=y).
                              </li>
                              <li class="li liexpand">Applications compiled with a cuDNN version x.z are not guaranteed to work with
                                 x.y release when z&gt;y.
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="backward-compatibility"><a name="backward-compatibility" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#backward-compatibility" name="backward-compatibility" shape="rect">5.5.&nbsp;Deprecation Policy</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">cuDNN uses a streamlined, two-step, deprecation policy for all API and enum
                              changes to enable a fast pace of innovation:</span></div>
                        <div class="p"><a name="backward-compatibility__ul_cgx_j2b_mxb" shape="rect">
                              <!-- --></a><ul class="ul" id="backward-compatibility__ul_cgx_j2b_mxb">
                              <li class="li liexpand">Step 1: Label for deprecation<a name="backward-compatibility__ul_dnb_k2b_mxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="backward-compatibility__ul_dnb_k2b_mxb">
                                    <li class="li">The current major version marks an API function or enum as deprecated
                                       without changing its behavior.
                                    </li>
                                    <li class="li">A deprecated enum value is marked with the
                                       <samp class="ph codeph">CUDNN_DEPRECATED_ENUM</samp> macro.<a name="backward-compatibility__ul_y4s_k2b_mxb" shape="rect">
                                          <!-- --></a><ul class="ul" id="backward-compatibility__ul_y4s_k2b_mxb">
                                          <li class="li">If it is simply renamed, the old name will map to the new name,
                                             and the old name will be marked with the
                                             <samp class="ph codeph">CUDNN_DEPRECATED_ENUM</samp> macro.
                                          </li>
                                       </ul>
                                    </li>
                                    <li class="li">A deprecated API function is marked with the
                                       <samp class="ph codeph">CUDNN_DEPRECATED</samp> macro.
                                    </li>
                                 </ul>
                              </li>
                              <li class="li liexpand">Step 2: Removal<a name="backward-compatibility__ul_bxd_m2b_mxb" shape="rect">
                                    <!-- --></a><ul class="ul" id="backward-compatibility__ul_bxd_m2b_mxb">
                                    <li class="li">The next major version removes the deprecated API function or enum value
                                       and its name is never reused.
                                    </li>
                                 </ul>
                              </li>
                           </ul>
                        </div>
                        <p class="p">This depreciation scheme allows us to retire the deprecated API in just one major
                           release. Functionality that is deprecated in the current major release can be compiled
                           without any changes.The backward compatibility ends when another major cuDNN release is
                           introduced.
                        </p>
                        <div class="p">Prototypes of deprecated functions will be prepended in cuDNN’s headers using the
                           <samp class="ph codeph">CUDNN_DEPRECATED</samp> macro. When the
                           <samp class="ph codeph">-DCUDNN_WARN_DEPRECATED</samp> switch is passed to the compiler, any
                           deprecated function call in your code will emit a compiler warning, for
                           example:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">warning: ‘cudnnStatus_t cudnnSetRNNMatrixMathType(cudnnRNNDescriptor_t, cudnnMathType_t)’ is deprecated [-Wdeprecated-declarations]</kbd></pre>
                           
                           
                           or
                           <pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">warning C4996: 'cudnnSetRNNMatrixMathType': was declared deprecated</kbd></pre></div>
                        <p class="p">The above warnings are disabled by default to avoid potential build breaks in software
                           setups where compiler warnings are treated as errors.
                        </p>
                        <div class="p">Similarly, for deprecated enum values, the compiler emits a warning when attempting to
                           use a deprecated
                           value:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">warning: ‘EXAMPLE_VAL’ is deprecated: value not allowed [-Wdeprecated-declarations]</kbd></pre>
                           
                           or<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">warning  C4996: ‘EXAMPLE_VAL’: was declared deprecated</kbd></pre></div>
                        <div class="section" id="backward-compatibility__section_lp4_x2b_mxb"><a name="backward-compatibility__section_lp4_x2b_mxb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Special Case: API Behavior Change</h3>
                           <p class="p">To help ease the transition and avoid any surprises to developers, a behavior change
                              between two major versions of a specific API function is accommodated by suffixing
                              the function with a <samp class="ph codeph">_v</samp> tag followed by the current, major cuDNN
                              version. In the next major release, the deprecated function is removed, and its name
                              is never reused. (Brand-new API’s are first introduced without the
                              <samp class="ph codeph">_v</samp> tag).
                           </p>
                           <p class="p">Updating a function’s behavior in this way uses the API’s name to embed the cuDNN
                              version where the API call was modified. As a result, the API changes will be easier
                              to track and document.
                           </p>
                           <div class="p">Let us explain this process through an example using two subsequent, major cuDNN
                              releases, version 8 and 9. In this example, an API function <samp class="ph codeph">foo()</samp>
                              changes its behavior from cuDNN v7 to cuDNN v8.
                              <dl class="dl">
                                 <dt class="dt dlterm">Major release 8</dt>
                                 <dd class="dd">The updated API is introduced as <samp class="ph codeph">foo_v8()</samp>. The
                                    deprecated API <samp class="ph codeph">foo()</samp> is kept unchanged to maintain
                                    backward compatibility until the next major release.
                                 </dd>
                                 <dt class="dt dlterm">Major release 9</dt>
                                 <dd class="dd">The deprecated API <samp class="ph codeph">foo()</samp> is permanently removed and its
                                    name is not reused. The <samp class="ph codeph">foo_v8()</samp> function supersedes
                                    the retired call <samp class="ph codeph">foo()</samp>.
                                 </dd>
                              </dl>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="requirements"><a name="requirements" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#requirements" name="requirements" shape="rect">5.6.&nbsp;GPU And Driver Requirements</a></h3>
                     <div class="body conbody">
                        <div class="abstract">For the latest compatibility software versions of the OS, CUDA, the CUDA driver, and
                           the NVIDIA hardware, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-support-matrix/index.html" target="_blank" shape="rect">NVIDIA cuDNN Support
                              Matrix</a>. <span class="shortdesc"></span></div>
                        <p class="p"></p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="convolutions"><a name="convolutions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#convolutions" name="convolutions" shape="rect">5.7.&nbsp;Convolutions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The convolution functions are:</span></div>
                        <div class="p"><a name="convolutions__ul_ztt_1xb_rsb" shape="rect">
                              <!-- --></a><ul class="ul" id="convolutions__ul_ztt_1xb_rsb">
                              <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionBackwardData" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardData()</samp></a></li>
                              <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionBiasActivationForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBiasActivationForward()</samp></a></li>
                              <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionForward()</samp></a></li>
                              <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionBackwardBias" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardBias()</samp></a></li>
                              <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionBackwardFilter" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp></a></li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="convolution-formulas"><a name="convolution-formulas" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#convolution-formulas" name="convolution-formulas" shape="rect">5.7.1.&nbsp;Convolution Formulas</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This section describes the various convolution formulas implemented in cuDNN
                                 			convolution functions for the <samp class="ph codeph">cudnnConvolutionForward()</samp>
                                 			path.</span></div>
                           <div class="p">The convolution terms described in the table below apply to all the convolution formulas that
                              				follow.
                              
                              
                              <div class="tablenoborder"><a name="convolution-formulas__table_ztl_dly_cfb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="convolution-formulas__table_ztl_dly_cfb" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 33. Convolution terms</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="24.509803921568626%" id="d54e12779" rowspan="1" colspan="1">Term</th>
                                          <th class="entry" valign="top" width="75.49019607843137%" id="d54e12782" rowspan="1" colspan="1">Description</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>x</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Input (image) Tensor</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>w</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Weight Tensor</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>y</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Output Tensor</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>n</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Current Batch Size</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>c</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Current Input Channel</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>C</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Total Input Channels</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>H</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Input Image Height</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>W</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Input Image Width</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>k</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Current Output Channel </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>K</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Total Output Channels</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>p</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Current Output Height Position</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>q</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Current Output Width Position</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>G</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Group Count</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi mathvariant="italic">pad</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Padding Value</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>u</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Vertical Subsample Stride (along Height)</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi mathvariant="italic">v</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Horizontal Subsample Stride (along Width)</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi mathvariant="italic">dil</mi>
                                                      <mi mathvariant="italic">h</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Vertical Dilation (along Height)</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi mathvariant="italic">dil</mi>
                                                      <mi mathvariant="italic">w</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Horizontal Dilation (along Width)</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>r</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Current Filter Height </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>R</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Total Filter Height</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>s</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Current Filter Width </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>S</mi>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">Total Filter Width</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>C</mi>
                                                      <mi>g</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mfrac>
                                                      <mi>C</mi>
                                                      <mi>G</mi>
                                                   </mfrac>
                                                </mrow>
                                             </math>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="24.509803921568626%" headers="d54e12779" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>K</mi>
                                                      <mi>g</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                          </td>
                                          <td class="entry" valign="top" width="75.49019607843137%" headers="d54e12782" rowspan="1" colspan="1">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mfrac>
                                                      <mi>K</mi>
                                                      <mi>G</mi>
                                                   </mfrac>
                                                </mrow>
                                             </math>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Convolution (convolution mode set to <samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp>)
                              </h4>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>y</mi>
                                       <mi mathvariant="italic">n, k, p, q</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>c</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>C</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>r</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>R</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>s</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>S</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="10px"></mspace>
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic">n, c, p+r, q+s </mi>
                                    </msub>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <mi>×</mi>
                                    </mrow>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <msub>
                                          <mi>w</mi>
                                          <mi mathvariant="italic">k,c,r,s</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Convolution with Padding</h4>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic"> &lt;0, &lt;0 </mi>
                                    </msub>
                                    <mspace width="5px"></mspace>
                                    <mo>=</mo>
                                    <mrow>
                                       <mi>0</mi>
                                    </mrow>
                                 </math>
                              </p>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic"> &gt;H, &gt;W </mi>
                                    </msub>
                                    <mspace width="5px"></mspace>
                                    <mo>=</mo>
                                    <mrow>
                                       <mi>0</mi>
                                    </mrow>
                                 </math>
                              </p>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>y</mi>
                                       <mi mathvariant="italic">n, k, p, q</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>c</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>C</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>r</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>R</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>s</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>S</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="10px"></mspace>
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic">n, c, p+r-pad, q+s-pad </mi>
                                    </msub>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <mi>×</mi>
                                    </mrow>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <msub>
                                          <mi>w</mi>
                                          <mi mathvariant="italic">k,c,r,s</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Convolution with Subsample-Striding</h4>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>y</mi>
                                       <mi mathvariant="italic">n, k, p, q</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>c</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>C</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>r</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>R</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>s</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>S</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="10px"></mspace>
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic">n, c, (p*u) + r, (q*v) + s </mi>
                                    </msub>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <mi>×</mi>
                                    </mrow>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <msub>
                                          <mi>w</mi>
                                          <mi mathvariant="italic">k,c,r,s</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Convolution with Dilation</h4>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>y</mi>
                                       <mi mathvariant="italic">n, k, p, q</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>c</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>C</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>r</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>R</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>s</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>S</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="10px"></mspace>
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic">n, c, p + (r*dilh), q + (s*dilw) </mi>
                                    </msub>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <mi>×</mi>
                                    </mrow>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <msub>
                                          <mi>w</mi>
                                          <mi mathvariant="italic">k,c,r,s</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Convolution (convolution mode set to <samp class="ph codeph">CUDNN_CONVOLUTION</samp>)
                              </h4>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>y</mi>
                                       <mi mathvariant="italic">n, k, p, q</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>c</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>C</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>r</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>R</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>s</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>S</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="10px"></mspace>
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic">n, c, p + r, q + s </mi>
                                    </msub>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <mi>×</mi>
                                    </mrow>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <msub>
                                          <mi>w</mi>
                                          <mi mathvariant="italic">k, c, R-r-1, S-s-1</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Convolution using Grouped Convolution</h4>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi>C</mi>
                                          <mi>g</mi>
                                       </msub>
                                    </mrow>
                                    <mo>=</mo>
                                    <mrow>
                                       <mfrac>
                                          <mi>C</mi>
                                          <mi>G</mi>
                                       </mfrac>
                                    </mrow>
                                 </math>
                              </p>
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi>K</mi>
                                          <mi>g</mi>
                                       </msub>
                                    </mrow>
                                    <mo>=</mo>
                                    <mrow>
                                       <mfrac>
                                          <mi>K</mi>
                                          <mi>G</mi>
                                       </mfrac>
                                    </mrow>
                                 </math>
                              </p>
                           </div>
                           <div class="section">
                              <p class="p">
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <msub>
                                       <mi>y</mi>
                                       <mi mathvariant="italic">n, k, p, q</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>c</mi>
                                       </mrow>
                                       <mrow>
                                          <msub>
                                             <mi>C</mi>
                                             <mi>g</mi>
                                          </msub>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>r</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>R</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="5px"></mspace>
                                    <munderover>
                                       <mo>∑</mo>
                                       <mrow>
                                          <mi>s</mi>
                                       </mrow>
                                       <mrow>
                                          <mi>S</mi>
                                       </mrow>
                                    </munderover>
                                    <mspace width="10px"></mspace>
                                    <msub>
                                       <mi>x</mi>
                                       <mi mathvariant="italic">n, Cg*floor(k/Kg)+c, p+r, q+s </mi>
                                    </msub>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <mi>×</mi>
                                    </mrow>
                                    <mspace width="15px"></mspace>
                                    <mrow>
                                       <msub>
                                          <mi>w</mi>
                                          <mi mathvariant="italic">k,c,r,s</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="grouped-convolutions"><a name="grouped-convolutions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#grouped-convolutions" name="grouped-convolutions" shape="rect">5.7.2.&nbsp;Grouped Convolutions</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">cuDNN supports grouped convolutions by setting <samp class="ph codeph">groupCount</samp> &gt; 1
                                 			for the convolution descriptor <samp class="ph codeph">convDesc</samp>, using
                                 				<samp class="ph codeph">cudnnSetConvolutionGroupCount()</samp>. </span></div>
                           <div class="note note"><span class="notetitle">Note:</span> By default, the convolution descriptor <samp class="ph codeph">convDesc</samp> is set to
                              				<samp class="ph codeph">groupCount</samp> of 1. 
                           </div>
                           <div class="section" id="grouped-convolutions__section_uvw_dz1_3jb"><a name="grouped-convolutions__section_uvw_dz1_3jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Basic Idea</h4>
                              <p class="p">Conceptually, in grouped convolutions, the input channels and the filter channels are split
                                 				into a <samp class="ph codeph">groupCount</samp> number of independent groups, with each group
                                 				having a reduced number of channels. The convolution operation is then performed
                                 				separately on these input and filter groups.
                              </p>
                              <p class="p">For example, consider the following: if the number of input channels is 4, and the
                                 				number of filter channels of 12. For a normal, ungrouped convolution, the number of
                                 				computation operations performed are 12*4. 
                              </p>
                              <p class="p">If the <samp class="ph codeph">groupCount</samp> is set to 2, then there are now two input channel
                                 				groups of two input channels each, and two filter channel groups of six filter
                                 				channels each. 
                              </p>
                              <p class="p">As a result, each grouped convolution will now perform 2*6 computation operations, and two
                                 				such grouped convolutions are performed. Hence the computation savings are 2x:
                                 					<samp class="ph codeph">(12*4)/(2*(2*6)) </samp>.
                              </p>
                           </div>
                           <div class="section" id="grouped-convolutions__section_fln_fz1_3jb"><a name="grouped-convolutions__section_fln_fz1_3jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">cuDNN Grouped Convolution</h4>
                              <div class="p"><a name="grouped-convolutions__ul_m1c_pn1_bfb" shape="rect">
                                    <!-- --></a><ul class="ul" id="grouped-convolutions__ul_m1c_pn1_bfb">
                                    <li class="li liexpand">When using <samp class="ph codeph">groupCount</samp> for grouped convolutions, you must
                                       						still define all tensor descriptors so that they describe the size of the
                                       						entire convolution, instead of specifying the sizes per group. 
                                    </li>
                                    <li class="li liexpand">Grouped convolutions are supported for all formats that are currently
                                       						supported by the functions <samp class="ph codeph">cudnnConvolutionForward()</samp>,
                                       							<samp class="ph codeph">cudnnConvolutionBackwardData()</samp> and
                                       							<samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp>. 
                                    </li>
                                    <li class="li liexpand">The tensor stridings that are set for <samp class="ph codeph">groupCount</samp> of 1 are
                                       						also valid for any group count. 
                                    </li>
                                    <li class="li liexpand">By default, the convolution descriptor <samp class="ph codeph">convDesc</samp> is set to
                                       							<samp class="ph codeph">groupCount</samp> of 1. 
                                    </li>
                                 </ul>
                                 <div class="note note"><span class="notetitle">Note:</span> Refer to <a class="xref" href="index.html#convolution-formulas" title="This section describes the various convolution formulas implemented in cuDNN convolution functions for the cudnnConvolutionForward() path." shape="rect">Convolution Formulas</a> for the math
                                    					behind the cuDNN grouped convolution. 
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="grouped-convolutions__section_m1p_gz1_3jb"><a name="grouped-convolutions__section_m1p_gz1_3jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Example</h4>
                              <div class="p">Below is an example showing the dimensions and strides for grouped convolutions for NCHW
                                 				format, for 2D convolution. 
                                 <div class="note note"><span class="notetitle">Note:</span> The symbols <samp class="ph codeph">*</samp> and
                                    						<samp class="ph codeph">/</samp> are used to indicate multiplication and division. 
                                 </div>
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><a name="grouped-convolutions__ul_xrx_5r1_bfb" shape="rect">
                                          <!-- --></a><ul class="ul" id="grouped-convolutions__ul_xrx_5r1_bfb">
                                          <li class="li liexpand"><strong class="ph b">Dimensions</strong>: <samp class="ph codeph">[batch_size, input_channel, x_height,
                                                										x_width]</samp></li>
                                          <li class="li liexpand"><strong class="ph b">Strides</strong>: <samp class="ph codeph">[input_channels*x_height*x_width,
                                                										x_height*x_width, x_width, 1]</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">wDesc</samp> or <samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><a name="grouped-convolutions__ul_gqb_xr1_bfb" shape="rect">
                                          <!-- --></a><ul class="ul" id="grouped-convolutions__ul_gqb_xr1_bfb">
                                          <li class="li liexpand"><strong class="ph b">Dimensions</strong>: <samp class="ph codeph">[output_channels,
                                                										input_channels/groupCount, w_height, w_width]</samp></li>
                                          <li class="li liexpand"><strong class="ph b">Format</strong>: <samp class="ph codeph">NCHW</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><a name="grouped-convolutions__ul_i4s_yr1_bfb" shape="rect">
                                          <!-- --></a><ul class="ul" id="grouped-convolutions__ul_i4s_yr1_bfb">
                                          <li class="li"><strong class="ph b">Group Count</strong>: <samp class="ph codeph">groupCount</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><a name="grouped-convolutions__ul_elf_zr1_bfb" shape="rect">
                                          <!-- --></a><ul class="ul" id="grouped-convolutions__ul_elf_zr1_bfb">
                                          <li class="li liexpand"><strong class="ph b">Dimensions</strong>: <samp class="ph codeph">[batch_size, output_channels,
                                                										y_height, y_width]</samp></li>
                                          <li class="li liexpand"><strong class="ph b">Strides</strong>: <samp class="ph codeph">[output_channels*y_height*y_width,
                                                										y_height*y_width, y_width, 1]</samp></li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="best-practices-convolutions"><a name="best-practices-convolutions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#best-practices-convolutions" name="best-practices-convolutions" shape="rect">5.7.3.&nbsp;Best Practices for 3D Convolutions</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <div class="p">
                              <div class="note attention"><span class="attentiontitle">Attention:</span> These guidelines are applicable to 3D convolution and
                                 deconvolution functions starting in cuDNN v7.6.3.
                              </div>
                           </div>
                           <p class="p">The following guidelines are for setting the cuDNN library parameters to enhance the
                              performance of 3D convolutions. Specifically, these guidelines are focused on settings
                              such as filter sizes, padding and dilation settings. Additionally, an
                              application-specific use-case, namely, medical imaging, is presented to demonstrate the
                              performance enhancement of 3D convolutions with these recommended settings.
                           </p>
                           <div class="p">Specifically, these guidelines are applicable to the following functions and their
                              associated data types:<a name="best-practices-convolutions__ul_t3y_pbs_cjb" shape="rect">
                                 <!-- --></a><ul class="ul" id="best-practices-convolutions__ul_t3y_pbs_cjb">
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionForward" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionForward()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionBackwardData" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardData()</samp></a></li>
                                 <li class="li liexpand"><a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnConvolutionBackwardFilter" target="_blank" shape="rect"><samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp></a></li>
                              </ul>
                           </div>
                           <p class="p">For more information, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html" target="_blank" shape="rect">NVIDIA cuDNN API Reference</a>.
                           </p>
                        </div>
                        <div class="topic concept nested3" id="rec-settings-3d-conv"><a name="rec-settings-3d-conv" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#rec-settings-3d-conv" name="rec-settings-3d-conv" shape="rect">5.7.3.1.&nbsp;Recommended Settings</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">The following table shows the recommended settings while performing 3D
                                    convolutions for cuDNN.</span></div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="rec-settings-3d-conv__table_lsl_5qx_5lb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="rec-settings-3d-conv__table_lsl_5qx_5lb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 34. Recommended settings while performing 3D convolutions for cuDNN</span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="2" valign="top" id="d54e14482" rowspan="1">&nbsp;</th>
                                             <th class="entry" valign="top" width="33.33333333333333%" id="d54e14484" rowspan="1" colspan="1">&nbsp;</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Platform</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">
                                                <p class="p">NVIDIA Hopper architecture</p>
                                                <p class="p">NVIDIA Ampere architecture</p>
                                                <p class="p">NVIDIA Turing architecture</p>
                                                <p class="p">NVIDIA Volta architecture</p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Convolution (3D or 2D)</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">3D and 2D</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Convolution or deconvolution
                                                (<samp class="ph codeph">fprop</samp>, <samp class="ph codeph">dgrad</samp>, or
                                                <samp class="ph codeph">wgrad</samp>)
                                             </td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">fprop</samp></p>
                                                <p class="p"><samp class="ph codeph">dgrad</samp></p>
                                                <p class="p"><samp class="ph codeph">wgrad</samp></p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Grouped convolution size</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">C_per_group == K_per_group ==
                                                      {1,4,8,16,32,64,128,256}</samp></p>
                                                <p class="p">Not supported for INT8</p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Data layout format
                                                (<samp class="ph codeph">NHWC</samp>/<samp class="ph codeph">NCHW</samp>)<a name="fnsrc_12" href="#fntarg_12" shape="rect"><sup>12</sup></a></td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">NDHWC</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Input/output precision (FP16, FP32,
                                                INT8, or FP64)
                                             </td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">FP16, FP32<a name="fnsrc_13" href="#fntarg_13" shape="rect"><sup>13</sup></a>, INT8<a name="fnsrc_14" href="#fntarg_14" shape="rect"><sup>14</sup></a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Accumulator (compute) precision (FP16,
                                                FP32, INT32 or FP64)
                                             </td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">FP32, INT32</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Filter (kernel) sizes</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">No limitation</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Padding</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">No limitation</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Image sizes</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">2 GB limitation for a tensor</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" rowspan="2" valign="top" width="33.33333333333333%" headers="d54e14482" colspan="1">Number of channels</td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e14482" rowspan="1" colspan="1">C</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">0 mod 8</samp></p>
                                                <p class="p"><samp class="ph codeph">0 mod 16</samp> (for INT8)
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e14482" rowspan="1" colspan="1">K</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">0 mod 8</samp></p>
                                                <p class="p"><samp class="ph codeph">0 mod 16</samp> (for INT8)
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Convolution mode</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">Cross-correlation and convolution</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Strides</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">No limitation</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Dilation</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">No limitation</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" colspan="2" valign="top" headers="d54e14482" rowspan="1">Data pointer alignment</td>
                                             <td class="entry" align="center" valign="top" width="33.33333333333333%" headers="d54e14484" rowspan="1" colspan="1">All data pointers are 16-bytes aligned.</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="conv-limits"><a name="conv-limits" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#conv-limits" name="conv-limits" shape="rect">5.7.3.2.&nbsp;Limitations</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">Your application will be functional but could be less performant if the model has
                                    channel counts lower than 32 (gets worse the lower it is).</span></div>
                              <p class="p">If the above is in the network, use <samp class="ph codeph">cuDNNFind</samp> to get the best
                                 option.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="environ-variables"><a name="environ-variables" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#environ-variables" name="environ-variables" shape="rect">5.8.&nbsp;Environment Variables</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">cuDNN’s behavior can be influenced through a set of environment variables. The
                              following environment variables are officially supported by cuDNN:</span></div>
                        <div class="p"><a name="environ-variables__ul_kcs_24q_kwb" shape="rect">
                              <!-- --></a><ul class="ul" id="environ-variables__ul_kcs_24q_kwb">
                              <li class="li liexpand"><samp class="ph codeph">NVIDIA_TF32_OVERRIDE</samp></li>
                              <li class="li liexpand"><samp class="ph codeph">NVIDIA_LICENSE_FILE</samp></li>
                              <li class="li liexpand"><samp class="ph codeph">CUDNN_LOGDEST_DBG</samp></li>
                              <li class="li liexpand"><samp class="ph codeph">CUDNN_LOGINFO_DBG</samp></li>
                              <li class="li liexpand"><samp class="ph codeph">CUDNN_LOGWARN_DBG</samp></li>
                              <li class="li liexpand"><samp class="ph codeph">CUDNN_LOGERR_DBG</samp></li>
                           </ul>
                        </div>
                        <div class="p">For more information about these variables, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html" target="_blank" shape="rect">NVIDIA cuDNN API Reference</a>.
                           <div class="note note"><span class="notetitle">Note:</span> Except for the environment
                              variables listed above, we provide no support or guarantee on the use of any other
                              environment variables prefixed by <samp class="ph codeph">CUDNN_</samp>.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="sm-carveout"><a name="sm-carveout" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#sm-carveout" name="sm-carveout" shape="rect">5.9.&nbsp;SM Carveout</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">Starting in cuDNN 8.9.5, SM carveout is supported on NVIDIA Hopper GPUs, allowing
                              expert users to reserve SMs for concurrent execution on a separate CUDA stream. Users
                              can set a target SM count to cuDNN heuristics, and get a list of engine configs that
                              will use that number of SMs during execution. For advanced use cases without cuDNN
                              heuristics, users can also create the engine config from scratch with the SM carveout
                              configured (the engines that support this feature are listed in the table
                              below).</span></div>
                        <div class="p">The following code snippet is a sample for heuristics use
                           cases.<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">// Create heuristics descriptor
cudnnBackendDescriptor_t engHeur;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR, &amp;engHeur);
cudnnBackendSetAttribute(engHeur, CUDNN_ATTR_ENGINEHEUR_OPERATION_GRAPH, CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;opGraph);
cudnnBackendSetAttribute(engHeur, CUDNN_ATTR_ENGINEHEUR_MODE, CUDNN_TYPE_HEUR_MODE, 1, &amp;heurMode);
// SM carveout
int32_t targetSMCount = 66;
cudnnBackendSetAttribute(engHeur, CUDNN_ATTR_ENGINEHEUR_SM_COUNT_TARGET, CUDNN_TYPE_INT32, 1, &amp;targetSMCount);
cudnnBackendFinalize(engHeur);
// Create engine config descriptor
cudnnBackendDescriptor_t engConfig;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINECFG_DESCRIPTOR, &amp;engConfig);
// Retrieve optimal engine config(s) from heuristics
cudnnBackendGetAttribute(engHeur, CUDNN_ATTR_ENGINEHEUR_RESULTS, CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;returnedCount, engConfig);
// "engConfig" should now be ready with target SM count as 66
</kbd></pre></div>
                        <div class="p">This feature is currently supported by normal convolutions (<samp class="ph codeph">Fprop</samp>,
                           <samp class="ph codeph">Dgrad</samp>, and <samp class="ph codeph">Wgrad</samp>) as well as the Conv-Bias-Act
                           fusions.
                           
                           
                           <div class="tablenoborder"><a name="sm-carveout__table_zzn_xnq_ryb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="sm-carveout__table_zzn_xnq_ryb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 35. cuDNN backend engines that support SM carveout</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="20%" id="d54e14872" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_ATTR_ENGINE_GLOBAL_INDEX</samp></th>
                                       <th class="entry" valign="top" width="20%" id="d54e14876" rowspan="1" colspan="1">Convolution Forward</th>
                                       <th class="entry" valign="top" width="20%" id="d54e14879" rowspan="1" colspan="1">Convolution Backward Data</th>
                                       <th class="entry" valign="top" width="20%" id="d54e14882" rowspan="1" colspan="1">Convolution Backward Filter</th>
                                       <th class="entry" valign="top" width="20%" id="d54e14885" rowspan="1" colspan="1"><samp class="ph codeph">cudnnConvolutionBiasActivationForward</samp></th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="20%" headers="d54e14872" rowspan="1" colspan="1">&nbsp;</td>
                                       <td class="entry" valign="top" width="20%" headers="d54e14876" rowspan="1" colspan="1">
                                          <p class="p">6</p>
                                          <p class="p">58</p>
                                          <p class="p">61</p>
                                          <p class="p">62</p>
                                          <p class="p">64</p>
                                          <p class="p">65</p>
                                          <p class="p">66</p>
                                          <p class="p">67</p>
                                          <p class="p">68</p>
                                          <p class="p">69</p>
                                       </td>
                                       <td class="entry" valign="top" width="20%" headers="d54e14879" rowspan="1" colspan="1">
                                          <p class="p">7</p>
                                          <p class="p">63</p>
                                          <p class="p">66</p>
                                          <p class="p">67</p>
                                          <p class="p">68</p>
                                          <p class="p">69</p>
                                          <p class="p">70</p>
                                          <p class="p">71</p>
                                          <p class="p">72</p>
                                          <p class="p">73</p>
                                          <p class="p">75</p>
                                          <p class="p">76</p>
                                       </td>
                                       <td class="entry" valign="top" width="20%" headers="d54e14882" rowspan="1" colspan="1">
                                          <p class="p">17</p>
                                          <p class="p">62</p>
                                          <p class="p">64</p>
                                          <p class="p">65</p>
                                          <p class="p">66</p>
                                          <p class="p">68</p>
                                       </td>
                                       <td class="entry" valign="top" width="20%" headers="d54e14885" rowspan="1" colspan="1">
                                          <p class="p">14</p>
                                          <p class="p">39</p>
                                          <p class="p">40</p>
                                          <p class="p">41</p>
                                          <p class="p">42</p>
                                          <p class="p">43</p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="troubleshooting"><a name="troubleshooting" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#troubleshooting" name="troubleshooting" shape="rect">6.&nbsp;Troubleshooting</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">The following sections help answer the most commonly asked questions regarding
                           typical use cases.</span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="api-logging"><a name="api-logging" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#api-logging" name="api-logging" shape="rect">6.1.&nbsp;Error Reporting And API Logging</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The cuDNN error reporting and API logging is a utility for recording the cuDNN
                              API execution and error information. For each cuDNN API function call, all input
                              parameters are reported in the API logging. If errors occur during the execution of the
                              cuDNN API, a traceback of the error conditions can also be reported to help
                              troubleshooting. This functionality is disabled by default, and can be enabled using the
                              methods described in the later part of this section through three logging severity
                              levels: <samp class="ph codeph">CUDNN_LOGINFO_DBG</samp>, <samp class="ph codeph">CUDNN_LOGWARN_DBG</samp> and
                              <samp class="ph codeph">CUDNN_LOGERR_DBG</samp>.</span></div>
                        <p class="p">The log output contains variable names, data types, parameter values, device pointers,
                           process ID, thread ID, cuDNN handle, CUDA stream ID, and metadata such as time of the
                           function call in microseconds.
                        </p>
                        <p class="p">For example, when the severity level <samp class="ph codeph">CUDNN_LOGINFO_DBG</samp> is enabled, the
                           user will receive the API loggings, such as:
                        </p><pre xml:space="preserve">cuDNN (v8300) function cudnnSetActivationDescriptor() called:
    mode: type=cudnnActivationMode_t; val=CUDNN_ACTIVATION_RELU (1);
    reluNanOpt: type=cudnnNanPropagation_t; val=CUDNN_NOT_PROPAGATE_NAN (0);
    coef: type=<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>; val=1000.000000;
Time: 2017-11-21T14:14:21.366171 (0d+0h+1m+5s since start)
Process: 21264, Thread: 21264, cudnn_handle: NULL, cudnn_stream: NULL.
</pre><div class="p">Starting in cuDNN 8.3.0, when the severity level <samp class="ph codeph">CUDNN_LOGWARN_DBG</samp> or
                           <samp class="ph codeph">CUDNN_LOGERR_DBG</samp> are enabled, the log output additionally reports
                           an error traceback such as the example below (currently only cuDNN version 8 graph APIs
                           and legacy convolution APIs are using this error reporting feature). This traceback
                           reports the relevant error/warning conditions, aiming to provide the user hints for
                           troubleshooting purposes. Within the traceback, each message may have their own severity
                           and will only be reported when the respective severity level is enabled. The traceback
                           messages are printed in the reverse order of the execution so the messages at the top
                           will be the root cause and tend to be more helpful for
                           debugging.<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">cuDNN (v8300) function cudnnBackendFinalize() called:
    Info: Traceback contains 5 message(s)
        Error: CUDNN_STATUS_BAD_PARAM; reason: out &lt;= 0
        Error: CUDNN_STATUS_BAD_PARAM; reason: is_valid_spacial_dim(xSpatialDimA[dim], wSpatialDimA[dim], ySpatialDimA[dim], cDesc.getPadLowerA()[dim], cDesc.getPadUpperA()[dim], cDesc.getStrideA()[dim], cDesc.getDilationA()[dim])
        Error: CUDNN_STATUS_BAD_PARAM; reason: is_valid_convolution(xDesc, wDesc, cDesc, yDesc)
        Error: CUDNN_STATUS_BAD_PARAM; reason: convolution.init(xDesc, wDesc, cDesc, yDesc)
        Error: CUDNN_STATUS_BAD_PARAM; reason: finalize_internal()
Time: 2021-10-05T17:11:07.935640 (0d+0h+0m+15s since start)
Process=87720; Thread=87720; GPU=NULL; Handle=NULL; StreamId=NULL.
</kbd></pre></div>
                        <p class="p">There are two methods, as described below, to enable the error/warning reporting and API
                           logging. For convenience, the log output can be handled by the built-in default callback
                           function, which will direct the output to a log file or the standard I/O as designated
                           by the user. The user may also write their own callback function to handle this
                           information programmably, and use the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnSetCallback" target="_blank" shape="rect"><u class="ph u"><samp class="ph codeph">cudnnSetCallback()</samp></u></a> to
                           pass in the function pointer of their own callback function.
                        </p>
                        <div class="section">
                           <h3 class="title sectiontitle">Method 1: Using Environment Variables</h3>
                           <div class="p">To enable API logging using environment variables, follow these steps:<a name="api-logging__ul_j41_ztr_mfb" shape="rect">
                                 <!-- --></a><ul class="ul" id="api-logging__ul_j41_ztr_mfb">
                                 <li class="li liexpand">Decide which logging severity levels to include from these three options:
                                    <samp class="ph codeph">CUDNN_LOGINFO_DBG</samp>, <samp class="ph codeph">CUDNN_LOGWARN_DBG</samp>,
                                    or <samp class="ph codeph">CUDNN_LOGERR_DBG</samp>. The logging severity levels are
                                    independent of each other. Any combination of them is valid.
                                 </li>
                                 <li class="li liexpand">Set the environment variables <samp class="ph codeph">CUDNN_LOGINFO_DBG</samp>,
                                    <samp class="ph codeph">CUDNN_LOGWARN_DBG</samp>, or <samp class="ph codeph">CUDNN_LOGERR_DBG</samp>
                                    to <samp class="ph codeph">1</samp>, and
                                 </li>
                                 <li class="li liexpand">Set the environment variable <samp class="ph codeph">CUDNN_LOGDEST_DBG</samp> to one of
                                    the following: <a name="api-logging__ul_czg_c5r_mfb" shape="rect">
                                       <!-- --></a><ul class="ul" id="api-logging__ul_czg_c5r_mfb">
                                       <li class="li"><samp class="ph codeph">stdout</samp>, <samp class="ph codeph">stderr</samp>, or a user-desired
                                          file path, for example, <samp class="ph codeph">/home/userName1/log.txt</samp>.
                                          
                                       </li>
                                    </ul>
                                 </li>
                                 <li class="li liexpand">Include the conversion specifiers in the file name. For example:<a name="api-logging__ul_xkw_dyr_mfb" shape="rect">
                                       <!-- --></a><ul class="ul" id="api-logging__ul_xkw_dyr_mfb">
                                       <li class="li">To include date and time in the file name, use the date and time
                                          conversion specifiers: <samp class="ph codeph">log_%Y_%m_%d_%H_%M_%S.txt</samp>.
                                          The conversion specifiers will be automatically replaced with the
                                          date and time when the program is initiated, resulting in
                                          <samp class="ph codeph">log_2017_11_21_09_41_00.txt</samp>. 
                                       </li>
                                       <li class="li">To include the process id in the file name, use the
                                          <samp class="ph codeph">%i</samp> conversion specifier:
                                          <samp class="ph codeph">log_%Y_%m_%d_%H_%M_%S_%i.txt</samp> for the result:
                                          <samp class="ph codeph">log_2017_11_21_09_41_00_21264.txt</samp> when the
                                          process id is <samp class="ph codeph">21264</samp>. When you have several
                                          processes running, using the process id conversion specifier will
                                          prevent these processes from writing to the same file at the same
                                          time. 
                                       </li>
                                    </ul>
                                    <div class="p">
                                       <div class="note note"><span class="notetitle">Note:</span> The supported conversion specifiers are similar to the
                                          <samp class="ph codeph">strftime</samp> function. 
                                       </div>
                                    </div>
                                    <p class="p">If the file already exists, the log will overwrite the existing
                                       file.
                                    </p>
                                    <div class="note note"><span class="notetitle">Note:</span> These environmental variables are only checked once at
                                       the initialization. Any subsequent changes in these environmental
                                       variables will not be effective in the current run. Also note that these
                                       environment settings can be overridden by Method 2 below.
                                    </div>
                                 </li>
                              </ul>
                           </div>
                           <p class="p">Refer to <a class="xref" href="index.html#api-logging__table_api_logging" shape="rect">Table 36</a> for the impact on the
                              performance of API logging using environment variables. The
                              <samp class="ph codeph">CUDNN_LOG{INFO,WARN,ERR}_DBG </samp>notation in the table header means
                              the conclusion is applicable to either one of the environment variables.
                           </p>
                           <div class="p">
                              <div class="tablenoborder"><a name="api-logging__table_api_logging" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="api-logging__table_api_logging" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 36. API Logging Using Environment Variables</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" id="d54e15218" rowspan="1" colspan="1"> Environment variables </th>
                                          <th class="entry" valign="top" id="d54e15221" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_LOG{INFO,WARN,ERR}_DBG=0</samp></th>
                                          <th class="entry" valign="top" id="d54e15225" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_LOG{INFO,WARN,ERR}_DBG=1</samp></th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e15218" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_LOGDEST_DBG</samp> not set
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15221" rowspan="1" colspan="1">
                                             <p class="p">No logging output</p>
                                             <p class="p">No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15225" rowspan="1" colspan="1">
                                             <p class="p">No logging output</p>
                                             <p class="p">No performance loss</p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e15218" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_LOGDEST_DBG=NULL</samp></p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15221" rowspan="1" colspan="1">
                                             <p class="p">No logging output</p>
                                             <p class="p">No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15225" rowspan="1" colspan="1">
                                             <p class="p">No logging output</p>
                                             <p class="p">No performance loss</p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e15218" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_LOGDEST_DBG=stdout</samp> or
                                                <samp class="ph codeph">stderr</samp></p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15221" rowspan="1" colspan="1">
                                             <p class="p">No logging output</p>
                                             <p class="p">No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15225" rowspan="1" colspan="1">
                                             <p class="p">Logging to <samp class="ph codeph">stdout</samp> or
                                                <samp class="ph codeph">stderr</samp></p>
                                             <p class="p">Some performance loss</p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e15218" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">CUDNN_LOGDEST_DBG=filename.txt</samp></p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15221" rowspan="1" colspan="1">
                                             <p class="p">No logging output</p>
                                             <p class="p">No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e15225" rowspan="1" colspan="1">
                                             <p class="p">Logging to <samp class="ph codeph">filename.txt</samp></p>
                                             <p class="p">Some performance loss</p>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Method 2: Using the API</h3>
                           <p class="p">To use API function calls to enable API logging, refer to the API description of
                              <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnSetCallback" target="_blank" shape="rect"><samp class="ph codeph">cudnnSetCallback()</samp></a> and
                              <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnGetCallback" target="_blank" shape="rect"><samp class="ph codeph">cudnnGetCallback()</samp></a>.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="faq"><a name="faq" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#faq" name="faq" shape="rect">6.2.&nbsp;FAQs</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <div class="section" id="faq__section_trb_z5j_lmb"><a name="faq__section_trb_z5j_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: I’m not sure if I should use cuDNN for inference or training. How does it
                              compare with TensorRT?
                           </h3>
                           <p class="p">A: cuDNN provides the building blocks for common routines such as convolution,
                              matmul, normalization, attention, pooling, activation and RNN/LSTMs. You can use
                              cuDNN for both training and inference. However, where it differs from TensorRT is
                              that the latter (TensorRT) is a programmable inference accelerator; just like a
                              framework. TensorRT sees the whole graph and optimizes the network by
                              fusing/combining layers and optimizing kernel selection for improved latency,
                              throughout, power efficiency and for reducing memory requirements.
                           </p>
                           <p class="p">A rule of thumb you can apply is to check out TensorRT, see if it meets your
                              inference needs, if it doesn't, then look at cuDNN for a closer, more in-depth
                              perspective.
                           </p>
                        </div>
                        <div class="section" id="faq__section_syd_mvj_lmb"><a name="faq__section_syd_mvj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: How does heuristics in cuDNN work? How does it know what is the optimal
                              solution for a given problem?
                           </h3>
                           <p class="p">A: NVIDIA actively monitors the Deep Learning space for important problem
                              specifications such as commonly used models. The heuristics are produced by sampling
                              a portion of these problem specifications with available computational choices. Over
                              time, more models are discovered and incorporated into the heuristics.
                           </p>
                        </div>
                        <div class="section" id="faq__section_bms_vvj_lmb"><a name="faq__section_bms_vvj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: Is cuDNN going to support running arbitrary graphs?</h3>
                           <p class="p">A: No, we don’t plan to become a framework and execute the whole graph one op at a
                              time. At this time, we are focused on a subgraph given by the user, where we try to
                              produce an optimized fusion kernel. We will document the rules regarding what can be
                              fused and what cannot. The goal is to support general and flexible fusion, however,
                              it will take time and there will be limits in what it can do in the cuDNN version
                              8.0.0 launch.
                           </p>
                        </div>
                        <div class="section" id="faq__section_wnr_wvj_lmb"><a name="faq__section_wnr_wvj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: What’s the difference between TensorRT, TensorFlow/XLA’s fusion, and cuDNN’s
                              fusion?
                           </h3>
                           <p class="p">A: TensorRT and TensorFlow are frameworks; they see the whole graph and can do global
                              optimization, however, they generally only fuse pointwise ops together or pattern
                              match to a limited set of pre-compiled fixed fusion patterns like conv-bias-relu. On
                              the other hand, cuDNN targets a subgraph, but can fuse convolutions with pointwise
                              ops, thus providing potentially better performance. CuDNN fusion kernels can be
                              utilized by TensorRT and TensorFlow/XLA as part of their global graph
                              optimization.
                           </p>
                        </div>
                        <div class="section" id="faq__section_f3t_xvj_lmb"><a name="faq__section_f3t_xvj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: Can I write an application calling cuDNN directly?</h3>
                           <p class="p">A: Yes, you can call the C/C++ API directly. Usually, data scientists would wait for
                              framework integration and use the Python API which is more convenient. However, if
                              your use case requires better performance, you can target the cuDNN API
                              directly.
                           </p>
                        </div>
                        <div class="section" id="faq__section_rzn_yvj_lmb"><a name="faq__section_rzn_yvj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: How does mixed precision training work?</h3>
                           <p class="p">A: Several components need to work together to make mixed precision training
                              possible. CuDNN needs to support the layers with the required datatype config and
                              have optimized kernels that run very fast. In addition, there is a module called
                              automatic mixed precision (AMP) in frameworks which intelligently decides which op
                              can run in a lower precision without affecting convergence and minimize the number
                              of type conversions/transposes in the entire graph. These work together to give you
                              speed up. For more information, refer to  <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#mixed-precision-numerical-accuracy" target="_blank" shape="rect">Mixed Precision Numerical Accuracy</a>.
                           </p>
                        </div>
                        <div class="section" id="faq__section_xz3_zvj_lmb"><a name="faq__section_xz3_zvj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: How can I pick the fastest convolution kernels with cuDNN version
                              8.0.0?
                           </h3>
                           <p class="p">A: In the API introduced in cuDNN v8, convolution kernels are grouped by similar
                              computation and numerical properties into engines. Every engine has a queryable set
                              of performance tuning knobs. A computation case such as a convolution operation
                              graph can be computed using different valid combinations of engines and their knobs,
                              known as an engine configuration. Users can query an array of engine configurations
                              for any given computation case ordered by performance, from fastest to slowest
                              according to cuDNN’s own heuristics. Alternately, users can generate all possible
                              engine configurations by querying the engine count and available knobs for each
                              engine. This generated list could be used for auto-tuning or the user could create
                              their own heuristics.
                           </p>
                        </div>
                        <div class="section" id="faq__section_qpy_3dd_cnb"><a name="faq__section_qpy_3dd_cnb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: Why is cuDNN version 8.0 convolution API call much slower on the first call
                              than subsequent calls?
                           </h3>
                           <p class="p">A: Due to the library split, cuDNN version 8.0 API will only load the necessary
                              kernels on the first API call that requires it. In previous versions, this load
                              would have been observed in the first cuDNN API call that triggers CUDA context
                              initialization, typically <samp class="ph codeph">cudnnCreate()</samp>. In version 8.0, this is
                              delayed until the first sub-library call that triggers CUDA context initialization.
                              Users who desire to have CUDA context preloaded can call the new
                              <samp class="ph codeph">cudnnCnnInferVersionCheck()</samp> API (or its related cousins), which
                              has the side effect of initializing a CUDA context. This will reduce the run time
                              for all subsequent API calls.
                           </p>
                        </div>
                        <div class="section" id="faq__section_xc4_1wj_lmb"><a name="faq__section_xc4_1wj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: How do I build the cuDNN version 8.0.0 split library?</h3>
                           <p class="p">A: cuDNN v8.0 library is split into multiple sub-libraries. Each library contains a
                              subset of the API. Users can link directly against the individual libraries or link
                              with a <samp class="ph codeph">dlopen</samp> layer which follows a plugin architecture.
                           </p>
                           <p class="p">To link against an individual library, users can directly specify it and its
                              dependencies on the linker command line. For example, for infer libraries:
                              <samp class="ph codeph">-lcudnn_adv_infer</samp>, <samp class="ph codeph">-lcudnn_cnn_infer</samp>, or
                              <samp class="ph codeph">-lcudnn_ops_infer</samp>.
                           </p>
                           <p class="p">For all libraries, <samp class="ph codeph">-lcudnn_adv_train</samp>,
                              <samp class="ph codeph">-lcudnn_cnn_train</samp>, <samp class="ph codeph">-lcudnn_ops_train</samp>,
                              <samp class="ph codeph">-lcudnn_adv_infer</samp>, <samp class="ph codeph">-lcudnn_cnn_infer</samp>, and
                              <samp class="ph codeph">-lcudnn_ops_infer</samp>.
                           </p>
                           <p class="p">The dependency order is documented in the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_8.html#rel-800-Preview" target="_blank" shape="rect">NVIDIA cuDNN 8.0.0 Preview Release Notes</a>
                              and the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html" target="_blank" shape="rect">NVIDIA cuDNN API Reference</a>.
                           </p>
                           <p class="p">Alternatively, the user can continue to link against a shim layer
                              (<samp class="ph codeph">-libcudnn</samp>) which can <samp class="ph codeph">dlopen</samp> the correct
                              library that provides the implementation of the function. When the function is
                              called for the first time, the dynamic loading of the library takes place.
                           </p>
                           <div class="p">Linker argument:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">-lcudnn</kbd></pre></div>
                        </div>
                        <div class="section" id="faq__section_c5z_dwj_lmb"><a name="faq__section_c5z_dwj_lmb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Q: What are the new APIs in cuDNN version 8.0.0?</h3>
                           <p class="p">A: The new cuDNN APIs are listed in the cuDNN 8.0.0 Release Notes as well as in the
                              <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#release-800-preview" target="_blank" shape="rect">API changes for cuDNN 8.0.0</a>.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="support"><a name="support" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#support" name="support" shape="rect">6.3.&nbsp;Support</a></h3>
                     <div class="body conbody">
                        <div class="abstract">Support, resources, and information about cuDNN can be found online at <a class="xref" href="https://developer.nvidia.com/cudnn" target="_blank" shape="rect">https://developer.nvidia.com/cudnn</a>. This
                           includes downloads, webinars, <a class="xref" href="http://devtalk.nvidia.com/" target="_blank" shape="rect">NVIDIA Developer Forums</a>, and more. <span class="shortdesc"></span></div>
                        <p class="p">We appreciate all types of feedback. Consider posting on the forums with questions,
                           comments, feature requests, and suspected bugs that are appropriate to discuss publicly.
                           cuDNN-related posts are reviewed by the cuDNN engineering team, and internally we will
                           file bugs where appropriate. It’s helpful if you can paste or attach an <a class="xref" href="index.html#api-logging" title="The cuDNN error reporting and API logging is a utility for recording the cuDNN API execution and error information. For each cuDNN API function call, all input parameters are reported in the API logging. If errors occur during the execution of the cuDNN API, a traceback of the error conditions can also be reported to help troubleshooting. This functionality is disabled by default, and can be enabled using the methods described in the later part of this section through three logging severity levels: CUDNN_LOGINFO_DBG, CUDNN_LOGWARN_DBG and CUDNN_LOGERR_DBG." shape="rect">API log</a> to help us reproduce.
                        </p>
                        <div class="p">External users can also file bugs directly by following these steps:<a name="support__ol_xv2_fvl_vlb" shape="rect">
                              <!-- --></a><ol class="ol" id="support__ol_xv2_fvl_vlb">
                              <li class="li">Register for the <a class="xref" href="https://developer.nvidia.com/" target="_blank" shape="rect">NVIDIA Developer website</a>.
                              </li>
                              <li class="li">Log in to the developer site.</li>
                              <li class="li">Click on your name in the upper right corner.</li>
                              <li class="li">Click <strong class="ph b">My account</strong> &gt; <strong class="ph b">My Bugs</strong> and select <strong class="ph b">Submit a New
                                    Bug</strong>.
                              </li>
                              <li class="li">Fill out the bug reporting page. Be descriptive and if possible, provide the
                                 steps that you are following to help reproduce the problem. If possible, paste
                                 or attach an <a class="xref" href="index.html#api-logging" title="The cuDNN error reporting and API logging is a utility for recording the cuDNN API execution and error information. For each cuDNN API function call, all input parameters are reported in the API logging. If errors occur during the execution of the cuDNN API, a traceback of the error conditions can also be reported to help troubleshooting. This functionality is disabled by default, and can be enabled using the methods described in the later part of this section through three logging severity levels: CUDNN_LOGINFO_DBG, CUDNN_LOGWARN_DBG and CUDNN_LOGERR_DBG." shape="rect">API log</a>.
                              </li>
                              <li class="li">Click <strong class="ph b">Submit a bug</strong>.
                              </li>
                           </ol>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="acknowledgments"><a name="acknowledgments" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#acknowledgments" name="acknowledgments" shape="rect">7.&nbsp;Acknowledgments</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">Some of the cuDNN library routines were derived from code developed by others and
                           are subject to the following:</span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="university-of-tennessee"><a name="university-of-tennessee" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#university-of-tennessee" name="university-of-tennessee" shape="rect">7.1.&nbsp;University of Tennessee</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <div class="p"><pre xml:space="preserve">Copyright (c) 2010 The University of Tennessee.

All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:
    * Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
    * Redistributions in binary form must reproduce the above
      copyright notice, this list of conditions and the following
      disclaimer listed in this license in the documentation and/or
      other materials provided with the distribution.
    * Neither the name of the copyright holders nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</pre></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="university-of-california-berkeley"><a name="university-of-california-berkeley" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#university-of-california-berkeley" name="university-of-california-berkeley" shape="rect">7.2.&nbsp;University of California, Berkeley</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <div class="p"><pre xml:space="preserve">COPYRIGHT

All contributions by the University of California:
Copyright (c) 2014, The Regents of the University of California (Regents)
All rights reserved.

All other contributions:
Copyright (c) 2014, the respective contributors
All rights reserved.

Caffe uses a shared copyright model: each contributor holds copyright over
their contributions to Caffe. The project versioning records all such
contribution and copyright details. If a contributor wants to further mark
their specific copyright on a particular contribution, they should indicate
their copyright solely in the commit message of the change when it is
committed.

LICENSE

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met: 

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer. 
2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution. 

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

CONTRIBUTION AGREEMENT

By contributing to the BVLC/caffe repository through pull-request, comment,
or otherwise, the contributor releases their content to the
license and copyright terms herein.</pre></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="facebook-ai-research"><a name="facebook-ai-research" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#facebook-ai-research" name="facebook-ai-research" shape="rect">7.3.&nbsp;Facebook AI Research, New York</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <div class="p"><pre xml:space="preserve">Copyright (c) 2014, Facebook, Inc. All rights reserved.

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

 * Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

 * Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

 * Neither the name Facebook nor the names of its contributors may be used to
   endorse or promote products derived from this software without specific
   prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</pre></div>
                        <div class="p"><pre xml:space="preserve">Additional Grant of Patent Rights

"Software" means fbcunn software distributed by Facebook, Inc.

Facebook hereby grants you a perpetual, worldwide, royalty-free, non-exclusive,
irrevocable (subject to the termination provision below) license under any
rights in any patent claims owned by Facebook, to make, have made, use, sell,
offer to sell, import, and otherwise transfer the Software. For avoidance of
doubt, no license is granted under Facebook’s rights in any patent claims that
are infringed by (i) modifications to the Software made by you or a third party,
or (ii) the Software in combination with any software or other technology
provided by you or a third party.

The license granted hereunder will terminate, automatically and without notice,
for anyone that makes any claim (including by filing any lawsuit, assertion or
other action) alleging (a) direct, indirect, or contributory infringement or
inducement to infringe any patent: (i) by Facebook or any of its subsidiaries or
affiliates, whether or not such claim is related to the Software, (ii) by any
party if such claim arises in whole or in part from any software, product or
service of Facebook or any of its subsidiaries or affiliates, whether or not
such claim is related to the Software, or (iii) by any party relating to the
Software; or (b) that any right in any patent claim of Facebook is invalid or
unenforceable.</pre></div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="notices-header"><a name="notices-header" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#notices-header" name="notices-header" shape="rect">Notices</a></h2>
                  <div class="topic reference nested1" id="notice"><a name="notice" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#notice" name="notice" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices" id="notice__section_kbg_pmm_flb"><a name="notice__section_kbg_pmm_flb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle notices">Notice</h3>
                           <p class="p" id="notice__notice-para-1"><a name="notice__notice-para-1" shape="rect">
                                 <!-- --></a>This document is provided for information purposes
                              only and shall not be regarded as a warranty of a certain
                              functionality, condition, or quality of a product. NVIDIA
                              Corporation (“NVIDIA”) makes no representations or warranties,
                              expressed or implied, as to the accuracy or completeness of the
                              information contained in this document and assumes no responsibility
                              for any errors contained herein. NVIDIA shall have no liability for
                              the consequences or use of such information or for any infringement
                              of patents or other rights of third parties that may result from its
                              use. This document is not a commitment to develop, release, or
                              deliver any Material (defined below), code, or functionality.
                           </p>
                           <p class="p" id="notice__notice-para-2"><a name="notice__notice-para-2" shape="rect">
                                 <!-- --></a>NVIDIA reserves the right to make corrections,
                              modifications, enhancements, improvements, and any other changes to
                              this document, at any time without notice.
                           </p>
                           <p class="p" id="notice__notice-para-3"><a name="notice__notice-para-3" shape="rect">
                                 <!-- --></a>Customer should obtain the latest relevant information
                              before placing orders and should verify that such information is
                              current and complete.
                           </p>
                           <p class="p" id="notice__notice-para-4"><a name="notice__notice-para-4" shape="rect">
                                 <!-- --></a>NVIDIA products are sold subject to the NVIDIA
                              standard terms and conditions of sale supplied at the time of order
                              acknowledgement, unless otherwise agreed in an individual sales
                              agreement signed by authorized representatives of NVIDIA and
                              customer (“Terms of Sale”). NVIDIA hereby expressly objects to
                              applying any customer general terms and conditions with regards to
                              the purchase of the NVIDIA product referenced in this document. No
                              contractual obligations are formed either directly or indirectly by
                              this document.
                           </p>
                           <p class="p" id="notice__notice-para-5"><a name="notice__notice-para-5" shape="rect">
                                 <!-- --></a>NVIDIA products are not designed, authorized, or
                              warranted to be suitable for use in medical, military, aircraft,
                              space, or life support equipment, nor in applications where failure
                              or malfunction of the NVIDIA product can reasonably be expected to
                              result in personal injury, death, or property or environmental
                              damage. NVIDIA accepts no liability for inclusion and/or use of
                              NVIDIA products in such equipment or applications and therefore such
                              inclusion and/or use is at customer’s own risk.
                           </p>
                           <p class="p" id="notice__notice-para-6"><a name="notice__notice-para-6" shape="rect">
                                 <!-- --></a>NVIDIA makes no representation or warranty that
                              products based on this document will be suitable for any specified
                              use. Testing of all parameters of each product is not necessarily
                              performed by NVIDIA. It is customer’s sole responsibility to
                              evaluate and determine the applicability of any information
                              contained in this document, ensure the product is suitable and fit
                              for the application planned by customer, and perform the necessary
                              testing for the application in order to avoid a default of the
                              application or the product. Weaknesses in customer’s product designs
                              may affect the quality and reliability of the NVIDIA product and may
                              result in additional or different conditions and/or requirements
                              beyond those contained in this document. NVIDIA accepts no liability
                              related to any default, damage, costs, or problem which may be based
                              on or attributable to: (i) the use of the NVIDIA product in any
                              manner that is contrary to this document or (ii) customer product
                              designs.
                           </p>
                           <p class="p" id="notice__notice-para-7"><a name="notice__notice-para-7" shape="rect">
                                 <!-- --></a>No license, either expressed or implied, is granted
                              under any NVIDIA patent right, copyright, or other NVIDIA
                              intellectual property right under this document. Information
                              published by NVIDIA regarding third-party products or services does
                              not constitute a license from NVIDIA to use such products or
                              services or a warranty or endorsement thereof. Use of such
                              information may require a license from a third party under the
                              patents or other intellectual property rights of the third party, or
                              a license from NVIDIA under the patents or other intellectual
                              property rights of NVIDIA.
                           </p>
                           <p class="p" id="notice__notice-para-8"><a name="notice__notice-para-8" shape="rect">
                                 <!-- --></a>Reproduction of information in this document is
                              permissible only if approved in advance by NVIDIA in writing,
                              reproduced without alteration and in full compliance with all
                              applicable export laws and regulations, and accompanied by all
                              associated conditions, limitations, and notices.
                           </p>
                           <p class="p" id="notice__notice-para-9"><a name="notice__notice-para-9" shape="rect">
                                 <!-- --></a>THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS,
                              REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER
                              DOCUMENTS (TOGETHER AND SEPARATELY, “MATERIALS”) ARE BEING PROVIDED
                              “AS IS.” NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY,
                              OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS
                              ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND
                              FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY
                              LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING
                              WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL,
                              PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF
                              THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT,
                              EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.
                              Notwithstanding any damages that customer might incur for any reason
                              whatsoever, NVIDIA’s aggregate and cumulative liability towards
                              customer for the products described herein shall be limited in
                              accordance with the Terms of Sale for the product.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="arm"><a name="arm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#arm" name="arm" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices" id="arm__section_n3n_kf2_qtb"><a name="arm__section_n3n_kf2_qtb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle notices">Arm</h3>
                           <p class="p">Arm, AMBA and Arm Powered are registered trademarks of Arm Limited. Cortex, MPCore
                              and Mali are trademarks of Arm Limited. "Arm" is used to represent Arm Holdings plc;
                              its operating company Arm Limited; and the regional subsidiaries Arm Inc.; Arm KK;
                              Arm Korea Limited.; Arm Taiwan Limited; Arm France SAS; Arm Consulting (Shanghai)
                              Co. Ltd.; Arm Germany GmbH; Arm Embedded Technologies Pvt. Ltd.; Arm Norway, AS and
                              Arm Sweden AB.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="hdmi"><a name="hdmi" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#hdmi" name="hdmi" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">HDMI</h3>
                           <p class="p">HDMI, the HDMI logo, and High-Definition Multimedia Interface are trademarks or
                              registered trademarks of HDMI Licensing LLC.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="blackberry"><a name="blackberry" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#blackberry" name="blackberry" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Blackberry/QNX</h3>
                           <p class="p">Copyright © 2020 BlackBerry Limited. All rights reserved.</p>
                           <p class="p">Trademarks, including but not limited to BLACKBERRY, EMBLEM Design, QNX, AVIAGE,
                              MOMENTICS, NEUTRINO and QNX CAR are the trademarks or registered trademarks of
                              BlackBerry Limited, used under license, and the exclusive rights to such trademarks
                              are expressly reserved. 
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="google"><a name="google" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#google" name="google" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Google</h3>
                           <p class="p">Android, Android TV, Google Play and the Google Play logo are trademarks of Google,
                              Inc.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="trademarks"><a name="trademarks" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#trademarks" name="trademarks" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Trademarks</h3>
                           <p class="p">NVIDIA, the NVIDIA logo, and BlueField, CUDA, DALI, DRIVE, Hopper, JetPack, Jetson
                              AGX Xavier, Jetson Nano, Maxwell, NGC, Nsight, Orin, Pascal, Quadro, Tegra,
                              TensorRT, Triton, Turing and Volta are trademarks and/or registered trademarks of
                              NVIDIA Corporation in the United States and other countries. Other company and
                              product names may be trademarks of the respective companies with which they are
                              associated.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="copyright-past-to-present"><a name="copyright-past-to-present" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#copyright-past-to-present" name="copyright-past-to-present" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Copyright</h3>
                           <p class="p">© <span class="ph">2014</span>-<span class="ph">2024</span> NVIDIA Corporation &amp;
                              affiliates. All rights reserved.
                           </p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="fn"><a name="fntarg_1" href="#fnsrc_1" shape="rect"><sup>1</sup></a>  Do not mix different algos for different steps
                  of training. It’s also not recommended to mix non-extended
                  and extended API for different steps of training.
               </div>
               <div class="fn"><a name="fntarg_2" href="#fnsrc_2" shape="rect"><sup>2</sup></a>  To use an unpacked layout, users need to
                  set <samp class="ph codeph">CUDNN_RNN_PADDED_IO_ENABLED</samp> through
                  <samp class="ph codeph">cudnnSetRNNPaddingMode()</samp>.
               </div>
               <div class="fn"><a name="fntarg_3" href="#fnsrc_3" shape="rect"><sup>3</sup></a>  To use an unpacked layout, users need to
                  set <samp class="ph codeph">CUDNN_RNN_PADDED_IO_ENABLED</samp> through
                  <samp class="ph codeph">cudnnSetRNNPaddingMode()</samp>.
               </div>
               <div class="fn"><a name="fntarg_4" href="#fnsrc_4" shape="rect"><sup>4</sup></a>  To use an
                  unpacked layout, set
                  <samp class="ph codeph">CUDNN_RNN_PADDED_IO_ENABLED</samp> through
                  <samp class="ph codeph">cudnnSetRNNPaddingMode()</samp>.
               </div>
               <div class="fn"><a name="fntarg_5" href="#fnsrc_5" shape="rect"><sup>5</sup></a><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>
                  or <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>
                  can be set through
                  <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>.
               </div>
               <div class="fn"><a name="fntarg_6" href="#fnsrc_6" shape="rect"><sup>6</sup></a><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>
                  or <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>
                  can be set through
                  <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>.
               </div>
               <div class="fn"><a name="fntarg_7" href="#fnsrc_7" shape="rect"><sup>7</sup></a><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                  <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>
                  can be set through
                  <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>.
               </div>
               <div class="fn"><a name="fntarg_8" href="#fnsrc_8" shape="rect"><sup>8</sup></a><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>
                  or <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>
                  can be set through
                  <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>.
               </div>
               <div class="fn"><a name="fntarg_9" href="#fnsrc_9" shape="rect"><sup>9</sup></a><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>
                  or <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>
                  can be set through
                  <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>.
               </div>
               <div class="fn"><a name="fntarg_10" href="#fnsrc_10" shape="rect"><sup>10</sup></a><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>
                  or <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> can be
                  set through <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>.
               </div>
               <div class="fn"><a name="fntarg_11" href="#fnsrc_11" shape="rect"><sup>11</sup></a><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>
                  or <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> can be
                  set through
                  <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>.
               </div>
               <div class="fn"><a name="fntarg_12" href="#fnsrc_12" shape="rect"><sup>12</sup></a><samp class="ph codeph">NHWC</samp>/<samp class="ph codeph">NCHW</samp>
                  corresponds to <samp class="ph codeph">NDHWC</samp>/<samp class="ph codeph">NCDHW</samp> in
                  3D convolution.
               </div>
               <div class="fn"><a name="fntarg_13" href="#fnsrc_13" shape="rect"><sup>13</sup></a>   With
                  <samp class="ph codeph">CUDNN_TENSOROP_MATH_ALLOW_CONVERSION</samp>
                  pre-Ampere. Default TF32 math in NVIDIA Ampere
                  architecture.
               </div>
               <div class="fn"><a name="fntarg_14" href="#fnsrc_14" shape="rect"><sup>14</sup></a>  INT8 does not support
                  <samp class="ph codeph">dgrad</samp> and <samp class="ph codeph">wgrad</samp>. INT8 3D
                  convolutions are only supported in the backend API. Refer to the
                  tables in <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionForward" target="_blank" shape="rect"><u class="ph u"><samp class="ph codeph">cudnnConvolutionForward()</samp></u></a>
                  for more information.
               </div>
               
               
            </article>
            <footer id="footer"><img src="../common/formatting/NVIDIA-LogoBlack.svg"></img><div><a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a> |
                  <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">Manage My Privacy</a> |
                  <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">Do Not Sell or Share My Data</a> |
                  <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a> |
                  <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a> |
                  <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a> |
                  <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a> |
                  <a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a></div>
               <div class="copyright">Copyright © 2024 NVIDIA Corporation</div>
            </footer>
         </div>
      </div>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/formatting/common.min.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
      <script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>
      <script type="text/javascript">_satellite.pageBottom();</script></body>

<!-- Mirrored from docs.nvidia.com/deeplearning/cudnn/archives/cudnn-897/developer-guide/index.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 06 Aug 2024 07:09:41 GMT -->
</html>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-us" xml:lang="en-us">
   
<!-- Mirrored from docs.nvidia.com/deeplearning/cudnn/archives/cudnn-897/api/index.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 06 Aug 2024 07:09:01 GMT -->
<head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>
      <meta name="copyright" content="(C) Copyright 2005"></meta>
      <meta name="DC.rights.owner" content="(C) Copyright 2005"></meta>
      <meta name="DC.Type" content="concept"></meta>
      <meta name="DC.Title" content="Abstract"></meta>
      <meta name="abstract" content="This is the API Reference documentation for the NVIDIA cuDNN version 8.9.7 library. This API Reference lists the datatyes and functions per library. Specifically, this reference consists of a cuDNN datatype reference section that describes the types of enums and a cuDNN API reference section that describes all routines in the cuDNN library API. The cuDNN API is a context-based API that allows for easy multithreading and (optional) interoperability with CUDA streams."></meta>
      <meta name="description" content="This is the API Reference documentation for the NVIDIA cuDNN version 8.9.7 library. This API Reference lists the datatyes and functions per library. Specifically, this reference consists of a cuDNN datatype reference section that describes the types of enums and a cuDNN API reference section that describes all routines in the cuDNN library API. The cuDNN API is a context-based API that allows for easy multithreading and (optional) interoperability with CUDA streams."></meta>
      <meta name="DC.Coverage" content="API Reference"></meta>
      <meta name="DC.subject" content="cuDNN API Reference"></meta>
      <meta name="keywords" content="cuDNN API Reference"></meta>
      <meta name="DC.Format" content="XHTML"></meta>
      <meta name="DC.Identifier" content="abstract"></meta>
      <link rel="stylesheet" type="text/css" href="../common/formatting/commonltr.css"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/site.css"></link>
      <title>API Reference :: NVIDIA cuDNN Documentation</title>
      <!--[if lt IE 9]>
      <script src="../common/formatting/html5shiv-printshiv.min.js"></script>
      <![endif]-->
      <script src="../../../../../../assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
      <script type="text/javascript" src="../../../../../../cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-svg.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.ba-hashchange.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.scrollintoview.min.js"></script>
      <script type="text/javascript" src="../search/htmlFileList.js"></script>
      <script type="text/javascript" src="../search/htmlFileInfoList.js"></script>
      <script type="text/javascript" src="../search/nwSearchFnt.min.js"></script>
      <script type="text/javascript" src="../search/stemmers/en_stemmer.min.js"></script>
      <script type="text/javascript" src="../search/index-1.js"></script>
      <script type="text/javascript" src="../search/index-2.js"></script>
      <script type="text/javascript" src="../search/index-3.js"></script>
      <link rel="canonical" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/qwcode.highlight.css"></link>
   </head>
   <body>
      
      <header id="header"><span id="company">NVIDIA</span><span id="site-title">NVIDIA cuDNN Documentation</span><form id="search" method="get" action="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-897/api/search">
            <input type="text" name="search-text"></input><fieldset id="search-location">
               <legend>Search In:</legend>
               <label><input type="radio" name="search-type" value="site"></input>Entire Site</label>
               <label><input type="radio" name="search-type" value="document"></input>Just This Document</label></fieldset>
            <button type="reset">clear search</button>
            <button id="submit" type="submit">search</button></form>
      </header>
      <div id="site-content">
         <nav id="site-nav">
            <div class="category closed"><a href="../index.html" title="The root of the site.">Getting Started</a></div>
            <div class="category"><a href="index.html" title="API Reference">API Reference</a></div>
            <ul>
               <li>
                  <div class="section-link"><a href="#overview">1.&nbsp;Introduction</a></div>
               </li>
               <li>
                  <div class="section-link"><a href="#api-changes">2.&nbsp;Added, Deprecated, and Removed API Functions</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#release-870">2.1.&nbsp;API Changes for cuDNN 8.7.0</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-850">2.2.&nbsp;API Changes for cuDNN 8.5.0</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-840">2.3.&nbsp;API Changes for cuDNN 8.4.0</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-830">2.4.&nbsp;API Changes for cuDNN 8.3.0</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-820">2.5.&nbsp;API Changes for cuDNN 8.2.0</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-810">2.6.&nbsp;API Changes for cuDNN 8.1.0</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-803">2.7.&nbsp;API Changes for cuDNN 8.0.3</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-802">2.8.&nbsp;API Changes for cuDNN 8.0.2</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#release-800-preview">2.9.&nbsp;API Changes for cuDNN 8.0.0 Preview</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cudnn-ops-infer-so-library">3.&nbsp;cudnn_ops_infer.so Library</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnn-ops-infer-so-data-type">3.1.&nbsp;Data Type References</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnn-ops-infer-so-opaque">3.1.1.&nbsp;Pointer To Opaque Struct Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnActivationDescriptor_t">3.1.1.1.&nbsp;cudnnActivationDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnCTCLossDescriptor_t">3.1.1.2.&nbsp;cudnnCTCLossDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnDropoutDescriptor_t">3.1.1.3.&nbsp;cudnnDropoutDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFilterDescriptor_t">3.1.1.4.&nbsp;cudnnFilterDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnHandle_t">3.1.1.5.&nbsp;cudnnHandle_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnLRNDescriptor_t">3.1.1.6.&nbsp;cudnnLRNDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnOpTensorDescriptor_t">3.1.1.7.&nbsp;cudnnOpTensorDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnPoolingDescriptor_t">3.1.1.8.&nbsp;cudnnPoolingDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnReduceTensorDescriptor_t">3.1.1.9.&nbsp;cudnnReduceTensorDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSpatialTransformerDescriptor_t">3.1.1.10.&nbsp;cudnnSpatialTransformerDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnTensorDescriptor_t">3.1.1.11.&nbsp;cudnnTensorDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnTensorTransformDescriptor_t">3.1.1.12.&nbsp;cudnnTensorTransformDescriptor_t</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnn-ops-infer-so-enum-types">3.1.2.&nbsp;Enumeration Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnActivationMode_t">3.1.2.1.&nbsp;cudnnActivationMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnAlgorithm_t">3.1.2.2.&nbsp;cudnnAlgorithm_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBatchNormMode_t">3.1.2.3.&nbsp;cudnnBatchNormMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBatchNormOps_t">3.1.2.4.&nbsp;cudnnBatchNormOps_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnCTCLossAlgo_t">3.1.2.5.&nbsp;cudnnCTCLossAlgo_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnDataType_t">3.1.2.6.&nbsp;cudnnDataType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnDeterminism_t">3.1.2.7.&nbsp;cudnnDeterminism_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnDivNormMode_t">3.1.2.8.&nbsp;cudnnDivNormMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnErrQueryMode_t">3.1.2.9.&nbsp;cudnnErrQueryMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFoldingDirection_t">3.1.2.10.&nbsp;cudnnFoldingDirection_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnIndicesType_t">3.1.2.11.&nbsp;cudnnIndicesType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnLRNMode_t">3.1.2.12.&nbsp;cudnnLRNMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnMathType_t">3.1.2.13.&nbsp;cudnnMathType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnNanPropagation_t">3.1.2.14.&nbsp;cudnnNanPropagation_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnNormAlgo_t">3.1.2.15.&nbsp;cudnnNormAlgo_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnNormMode_t">3.1.2.16.&nbsp;cudnnNormMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnNormOps_t">3.1.2.17.&nbsp;cudnnNormOps_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnOpTensorOp_t">3.1.2.18.&nbsp;cudnnOpTensorOp_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnPoolingMode_t">3.1.2.19.&nbsp;cudnnPoolingMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnReduceTensorIndices_t">3.1.2.20.&nbsp;cudnnReduceTensorIndices_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnReduceTensorOp_t">3.1.2.21.&nbsp;cudnnReduceTensorOp_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNAlgo_t">3.1.2.22.&nbsp;cudnnRNNAlgo_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSamplerType_t">3.1.2.23.&nbsp;cudnnSamplerType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSeverity_t">3.1.2.24.&nbsp;cudnnSeverity_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSoftmaxAlgorithm_t">3.1.2.25.&nbsp;cudnnSoftmaxAlgorithm_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSoftmaxMode_t">3.1.2.26.&nbsp;cudnnSoftmaxMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnStatus_t">3.1.2.27.&nbsp;cudnnStatus_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnTensorFormat_t">3.1.2.28.&nbsp;cudnnTensorFormat_t</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnn-ops-infer-so-api">3.2.&nbsp;API Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnnActivationForward">3.2.1.&nbsp;cudnnActivationForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnAddTensor">3.2.2.&nbsp;cudnnAddTensor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBatchNormalizationForwardInference">3.2.3.&nbsp;cudnnBatchNormalizationForwardInference()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCopyAlgorithmDescriptor">3.2.4.&nbsp;cudnnCopyAlgorithmDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreate">3.2.5.&nbsp;cudnnCreate()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateActivationDescriptor">3.2.6.&nbsp;cudnnCreateActivationDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateAlgorithmDescriptor">3.2.7.&nbsp;cudnnCreateAlgorithmDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateAlgorithmPerformance">3.2.8.&nbsp;cudnnCreateAlgorithmPerformance()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateDropoutDescriptor">3.2.9.&nbsp;cudnnCreateDropoutDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateFilterDescriptor">3.2.10.&nbsp;cudnnCreateFilterDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateLRNDescriptor">3.2.11.&nbsp;cudnnCreateLRNDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateOpTensorDescriptors">3.2.12.&nbsp;cudnnCreateOpTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreatePoolingDescriptor">3.2.13.&nbsp;cudnnCreatePoolingDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateReduceTensorDescriptor">3.2.14.&nbsp;cudnnCreateReduceTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateSpatialTransformerDescriptor">3.2.15.&nbsp;cudnnCreateSpatialTransformerDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateTensorDescriptor">3.2.16.&nbsp;cudnnCreateTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateTensorTransformDescriptor">3.2.17.&nbsp;cudnnCreateTensorTransformDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDeriveBNTensorDescriptor">3.2.18.&nbsp;cudnnDeriveBNTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDeriveNormTensorDescriptor">3.2.19.&nbsp;cudnnDeriveNormTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroy">3.2.20.&nbsp;cudnnDestroy()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyActivationDescriptor">3.2.21.&nbsp;cudnnDestroyActivationDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyAlgorithmDescriptor">3.2.22.&nbsp;cudnnDestroyAlgorithmDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyAlgorithmPerformance">3.2.23.&nbsp;cudnnDestroyAlgorithmPerformance()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyDropoutDescriptor">3.2.24.&nbsp;cudnnDestroyDropoutDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyFilterDescriptor">3.2.25.&nbsp;cudnnDestroyFilterDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyLRNDescriptor">3.2.26.&nbsp;cudnnDestroyLRNDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyOpTensorDescriptor">3.2.27.&nbsp;cudnnDestroyOpTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyPoolingDescriptor">3.2.28.&nbsp;cudnnDestroyPoolingDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyReduceTensorDescriptor">3.2.29.&nbsp;cudnnDestroyReduceTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroySpatialTransformerDescriptor">3.2.30.&nbsp;cudnnDestroySpatialTransformerDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyTensorDescriptor">3.2.31.&nbsp;cudnnDestroyTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyTensorTransformDescriptor">3.2.32.&nbsp;cudnnDestroyTensorTransformDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDivisiveNormalizationForward">3.2.33.&nbsp;cudnnDivisiveNormalizationForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDropoutForward">3.2.34.&nbsp;cudnnDropoutForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDropoutGetReserveSpaceSize">3.2.35.&nbsp;cudnnDropoutGetReserveSpaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDropoutGetStatesSize">3.2.36.&nbsp;cudnnDropoutGetStatesSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetActivationDescriptor">3.2.37.&nbsp;cudnnGetActivationDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetActivationDescriptorSwishBeta">3.2.38.&nbsp;cudnnGetActivationDescriptorSwishBeta()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetAlgorithmDescriptor">3.2.39.&nbsp;cudnnGetAlgorithmDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetAlgorithmPerformance">3.2.40.&nbsp;cudnnGetAlgorithmPerformance()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetAlgorithmSpaceSize">3.2.41.&nbsp;cudnnGetAlgorithmSpaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetCallback">3.2.42.&nbsp;cudnnGetCallback()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetCudartVersion">3.2.43.&nbsp;cudnnGetCudartVersion()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetDropoutDescriptor">3.2.44.&nbsp;cudnnGetDropoutDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetErrorString">3.2.45.&nbsp;cudnnGetErrorString()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetFilter4dDescriptor">3.2.46.&nbsp;cudnnGetFilter4dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetFilterNdDescriptor">3.2.47.&nbsp;cudnnGetFilterNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetFilterSizeInBytes">3.2.48.&nbsp;cudnnGetFilterSizeInBytes()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetLRNDescriptor">3.2.49.&nbsp;cudnnGetLRNDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetOpTensorDescriptor">3.2.50.&nbsp;cudnnGetOpTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetPooling2dDescriptor">3.2.51.&nbsp;cudnnGetPooling2dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetPooling2dForwardOutputDim">3.2.52.&nbsp;cudnnGetPooling2dForwardOutputDim()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetPoolingNdDescriptor">3.2.53.&nbsp;cudnnGetPoolingNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetPoolingNdForwardOutputDim">3.2.54.&nbsp;cudnnGetPoolingNdForwardOutputDim()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetProperty">3.2.55.&nbsp;cudnnGetProperty()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetReduceTensorDescriptor">3.2.56.&nbsp;cudnnGetReduceTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetReductionIndicesSize">3.2.57.&nbsp;cudnnGetReductionIndicesSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetReductionWorkspaceSize">3.2.58.&nbsp;cudnnGetReductionWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetStream">3.2.59.&nbsp;cudnnGetStream()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetTensor4dDescriptor">3.2.60.&nbsp;cudnnGetTensor4dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetTensorNdDescriptor">3.2.61.&nbsp;cudnnGetTensorNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetTensorSizeInBytes">3.2.62.&nbsp;cudnnGetTensorSizeInBytes()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetTensorTransformDescriptor">3.2.63.&nbsp;cudnnGetTensorTransformDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetVersion">3.2.64.&nbsp;cudnnGetVersion()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnInitTransformDest">3.2.65.&nbsp;cudnnInitTransformDest()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnLRNCrossChannelForward">3.2.66.&nbsp;cudnnLRNCrossChannelForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnNormalizationForwardInference">3.2.67.&nbsp;cudnnNormalizationForwardInference()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnOpsInferVersionCheck">3.2.68.&nbsp;cudnnOpsInferVersionCheck()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnOpTensor">3.2.69.&nbsp;cudnnOpTensor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnPoolingForward">3.2.70.&nbsp;cudnnPoolingForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnQueryRuntimeError">3.2.71.&nbsp;cudnnQueryRuntimeError()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnReduceTensor">3.2.72.&nbsp;cudnnReduceTensor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRestoreAlgorithm">3.2.73.&nbsp;cudnnRestoreAlgorithm()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRestoreDropoutDescriptor">3.2.74.&nbsp;cudnnRestoreDropoutDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSaveAlgorithm">3.2.75.&nbsp;cudnnSaveAlgorithm()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnScaleTensor">3.2.76.&nbsp;cudnnScaleTensor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetActivationDescriptor">3.2.77.&nbsp;cudnnSetActivationDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetActivationDescriptorSwishBeta">3.2.78.&nbsp;cudnnSetActivationDescriptorSwishBeta()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetAlgorithmDescriptor">3.2.79.&nbsp;cudnnSetAlgorithmDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetAlgorithmPerformance">3.2.80.&nbsp;cudnnSetAlgorithmPerformance()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetCallback">3.2.81.&nbsp;cudnnSetCallback()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetDropoutDescriptor">3.2.82.&nbsp;cudnnSetDropoutDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetFilter4dDescriptor">3.2.83.&nbsp;cudnnSetFilter4dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetFilterNdDescriptor">3.2.84.&nbsp;cudnnSetFilterNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetLRNDescriptor">3.2.85.&nbsp;cudnnSetLRNDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetOpTensorDescriptor">3.2.86.&nbsp;cudnnSetOpTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetPooling2dDescriptor">3.2.87.&nbsp;cudnnSetPooling2dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetPoolingNdDescriptor">3.2.88.&nbsp;cudnnSetPoolingNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetReduceTensorDescriptor">3.2.89.&nbsp;cudnnSetReduceTensorDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetSpatialTransformerNdDescriptor">3.2.90.&nbsp;cudnnSetSpatialTransformerNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetStream">3.2.91.&nbsp;cudnnSetStream()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetTensor">3.2.92.&nbsp;cudnnSetTensor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetTensor4dDescriptor">3.2.93.&nbsp;cudnnSetTensor4dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetTensor4dDescriptorEx">3.2.94.&nbsp;cudnnSetTensor4dDescriptorEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetTensorNdDescriptor">3.2.95.&nbsp;cudnnSetTensorNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetTensorNdDescriptorEx">3.2.96.&nbsp;cudnnSetTensorNdDescriptorEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetTensorTransformDescriptor">3.2.97.&nbsp;cudnnSetTensorTransformDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSoftmaxForward">3.2.98.&nbsp;cudnnSoftmaxForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSpatialTfGridGeneratorForward">3.2.99.&nbsp;cudnnSpatialTfGridGeneratorForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSpatialTfSamplerForward">3.2.100.&nbsp;cudnnSpatialTfSamplerForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnTransformFilter">3.2.101.&nbsp;cudnnTransformFilter()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnTransformTensor">3.2.102.&nbsp;cudnnTransformTensor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnTransformTensorEx">3.2.103.&nbsp;cudnnTransformTensorEx()</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cudnn-ops-train-so-library">4.&nbsp;cudnn_ops_train.so Library</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnn-ops-train-so-api">4.1.&nbsp;API Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnnActivationBackward">4.1.1.&nbsp;cudnnActivationBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBatchNormalizationBackward">4.1.2.&nbsp;cudnnBatchNormalizationBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBatchNormalizationBackwardEx">4.1.3.&nbsp;cudnnBatchNormalizationBackwardEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBatchNormalizationForwardTraining">4.1.4.&nbsp;cudnnBatchNormalizationForwardTraining()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBatchNormalizationForwardTrainingEx">4.1.5.&nbsp;cudnnBatchNormalizationForwardTrainingEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDivisiveNormalizationBackward">4.1.6.&nbsp;cudnnDivisiveNormalizationBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDropoutBackward">4.1.7.&nbsp;cudnnDropoutBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetBatchNormalizationBackwardExWorkspaceSize">4.1.8.&nbsp;cudnnGetBatchNormalizationBackwardExWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize">4.1.9.&nbsp;cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetBatchNormalizationTrainingExReserveSpaceSize">4.1.10.&nbsp;cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetNormalizationBackwardWorkspaceSize">4.1.11.&nbsp;cudnnGetNormalizationBackwardWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetNormalizationForwardTrainingWorkspaceSize">4.1.12.&nbsp;cudnnGetNormalizationForwardTrainingWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetNormalizationTrainingReserveSpaceSize">4.1.13.&nbsp;cudnnGetNormalizationTrainingReserveSpaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnLRNCrossChannelBackward">4.1.14.&nbsp;cudnnLRNCrossChannelBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnNormalizationBackward">4.1.15.&nbsp;cudnnNormalizationBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnNormalizationForwardTraining">4.1.16.&nbsp;cudnnNormalizationForwardTraining()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnOpsTrainVersionCheck">4.1.17.&nbsp;cudnnOpsTrainVersionCheck()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnPoolingBackward">4.1.18.&nbsp;cudnnPoolingBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSoftmaxBackward">4.1.19.&nbsp;cudnnSoftmaxBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSpatialTfGridGeneratorBackward">4.1.20.&nbsp;cudnnSpatialTfGridGeneratorBackward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSpatialTfSamplerBackward">4.1.21.&nbsp;cudnnSpatialTfSamplerBackward()</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cudnn-cnn-infer-so-library">5.&nbsp;cudnn_cnn_infer.so Library</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnn-cnn-infer-so-data-types">5.1.&nbsp;Data Type References</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnn-cnn-infer-so-opaque">5.1.1.&nbsp;Pointer To Opaque Struct Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionDescriptor_t">5.1.1.1.&nbsp;cudnnConvolutionDescriptor_t</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnn-cnn-infer-so-struct">5.1.2.&nbsp;Struct Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionBwdDataAlgoPerf_t">5.1.2.1.&nbsp;cudnnConvolutionBwdDataAlgoPerf_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionFwdAlgoPerf_t">5.1.2.2.&nbsp;cudnnConvolutionFwdAlgoPerf_t</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnn-cnn-infer-so-enum-types">5.1.3.&nbsp;Enumeration Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionBwdDataAlgo_t">5.1.3.1.&nbsp;cudnnConvolutionBwdDataAlgo_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionBwdFilterAlgo_t">5.1.3.2.&nbsp;cudnnConvolutionBwdFilterAlgo_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionFwdAlgo_t">5.1.3.3.&nbsp;cudnnConvolutionFwdAlgo_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionMode_t">5.1.3.4.&nbsp;cudnnConvolutionMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnReorderType_t">5.1.3.5.&nbsp;cudnnReorderType_t</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnn-cnn-infer-so-api">5.2.&nbsp;API Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnnCnnInferVersionCheck">5.2.1.&nbsp;cudnnCnnInferVersionCheck()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnConvolutionBackwardData">5.2.2.&nbsp;cudnnConvolutionBackwardData()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnConvolutionBiasActivationForward">5.2.3.&nbsp;cudnnConvolutionBiasActivationForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnConvolutionForward">5.2.4.&nbsp;cudnnConvolutionForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateConvolutionDescriptor">5.2.5.&nbsp;cudnnCreateConvolutionDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyConvolutionDescriptor">5.2.6.&nbsp;cudnnDestroyConvolutionDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindConvolutionBackwardDataAlgorithm">5.2.7.&nbsp;cudnnFindConvolutionBackwardDataAlgorithm()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindConvolutionBackwardDataAlgorithmEx">5.2.8.&nbsp;cudnnFindConvolutionBackwardDataAlgorithmEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindConvolutionForwardAlgorithm">5.2.9.&nbsp;cudnnFindConvolutionForwardAlgorithm()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindConvolutionForwardAlgorithmEx">5.2.10.&nbsp;cudnnFindConvolutionForwardAlgorithmEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolution2dDescriptor">5.2.11.&nbsp;cudnnGetConvolution2dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolution2dForwardOutputDim">5.2.12.&nbsp;cudnnGetConvolution2dForwardOutputDim()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionBackwardDataAlgorithmMaxCount">5.2.13.&nbsp;cudnnGetConvolutionBackwardDataAlgorithmMaxCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionBackwardDataAlgorithm_v7">5.2.14.&nbsp;cudnnGetConvolutionBackwardDataAlgorithm_v7()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionBackwardDataWorkspaceSize">5.2.15.&nbsp;cudnnGetConvolutionBackwardDataWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionForwardAlgorithmMaxCount">5.2.16.&nbsp;cudnnGetConvolutionForwardAlgorithmMaxCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionForwardAlgorithm_v7">5.2.17.&nbsp;cudnnGetConvolutionForwardAlgorithm_v7()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionForwardWorkspaceSize">5.2.18.&nbsp;cudnnGetConvolutionForwardWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionGroupCount">5.2.19.&nbsp;cudnnGetConvolutionGroupCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionMathType">5.2.20.&nbsp;cudnnGetConvolutionMathType()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionNdDescriptor">5.2.21.&nbsp;cudnnGetConvolutionNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionNdForwardOutputDim">5.2.22.&nbsp;cudnnGetConvolutionNdForwardOutputDim()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionReorderType">5.2.23.&nbsp;cudnnGetConvolutionReorderType()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetFoldedConvBackwardDataDescriptors">5.2.24.&nbsp;cudnnGetFoldedConvBackwardDataDescriptors()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnIm2Col">5.2.25.&nbsp;cudnnIm2Col()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnReorderFilterAndBias">5.2.26.&nbsp;cudnnReorderFilterAndBias()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetConvolution2dDescriptor">5.2.27.&nbsp;cudnnSetConvolution2dDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetConvolutionGroupCount">5.2.28.&nbsp;cudnnSetConvolutionGroupCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetConvolutionMathType">5.2.29.&nbsp;cudnnSetConvolutionMathType()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetConvolutionNdDescriptor">5.2.30.&nbsp;cudnnSetConvolutionNdDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetConvolutionReorderType">5.2.31.&nbsp;cudnnSetConvolutionReorderType()</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cudnn-cnn-train-so-library">6.&nbsp;cudnn_cnn_train.so Library</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnn-cnn-train-so-data-types">6.1.&nbsp;Data Type References</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnn-cnn-train-so-opaque">6.1.1.&nbsp;Pointer To Opaque Struct Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFusedOpsConstParamPack_t">6.1.1.1.&nbsp;cudnnFusedOpsConstParamPack_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFusedOpsPlan_t">6.1.1.2.&nbsp;cudnnFusedOpsPlan_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFusedOpsVariantParamPack_t">6.1.1.3.&nbsp;cudnnFusedOpsVariantParamPack_t</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnn-cnn-train-so-struct-types">6.1.2.&nbsp;Struct Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnConvolutionBwdFilterAlgoPerf_t">6.1.2.1.&nbsp;cudnnConvolutionBwdFilterAlgoPerf_t</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnn-cnn-train-so-enum-types">6.1.3.&nbsp;Enumeration Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFusedOps_t">6.1.3.1.&nbsp;cudnnFusedOps_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFusedOpsConstParamLabel_t">6.1.3.2.&nbsp;cudnnFusedOpsConstParamLabel_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFusedOpsPointerPlaceHolder_t">6.1.3.3.&nbsp;cudnnFusedOpsPointerPlaceHolder_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFusedOpsVariantParamLabel_t">6.1.3.4.&nbsp;cudnnFusedOpsVariantParamLabel_t</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnn-cnn-train-so-api">6.2.&nbsp;API Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnnCnnTrainVersionCheck">6.2.1.&nbsp;cudnnCnnTrainVersionCheck()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnConvolutionBackwardBias">6.2.2.&nbsp;cudnnConvolutionBackwardBias()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnConvolutionBackwardFilter">6.2.3.&nbsp;cudnnConvolutionBackwardFilter()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateFusedOpsConstParamPack">6.2.4.&nbsp;cudnnCreateFusedOpsConstParamPack()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateFusedOpsPlan">6.2.5.&nbsp;cudnnCreateFusedOpsPlan()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateFusedOpsVariantParamPack">6.2.6.&nbsp;cudnnCreateFusedOpsVariantParamPack()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyFusedOpsConstParamPack">6.2.7.&nbsp;cudnnDestroyFusedOpsConstParamPack()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyFusedOpsPlan">6.2.8.&nbsp;cudnnDestroyFusedOpsPlan()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyFusedOpsVariantParamPack">6.2.9.&nbsp;cudnnDestroyFusedOpsVariantParamPack()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindConvolutionBackwardFilterAlgorithm">6.2.10.&nbsp;cudnnFindConvolutionBackwardFilterAlgorithm()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindConvolutionBackwardFilterAlgorithmEx">6.2.11.&nbsp;cudnnFindConvolutionBackwardFilterAlgorithmEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFusedOpsExecute">6.2.12.&nbsp;cudnnFusedOpsExecute()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount">6.2.13.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithmMaxCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionBackwardFilterAlgorithm_v7">6.2.14.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithm_v7()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetConvolutionBackwardFilterWorkspaceSize">6.2.15.&nbsp;cudnnGetConvolutionBackwardFilterWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetFusedOpsConstParamPackAttribute">6.2.16.&nbsp;cudnnGetFusedOpsConstParamPackAttribute()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetFusedOpsVariantParamPackAttribute">6.2.17.&nbsp;cudnnGetFusedOpsVariantParamPackAttribute()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnMakeFusedOpsPlan">6.2.18.&nbsp;cudnnMakeFusedOpsPlan()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetFusedOpsConstParamPackAttribute">6.2.19.&nbsp;cudnnSetFusedOpsConstParamPackAttribute()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetFusedOpsVariantParamPackAttribute">6.2.20.&nbsp;cudnnSetFusedOpsVariantParamPackAttribute()</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cudnn-adv-infer-so-library">7.&nbsp;cudnn_adv_infer.so Library</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnn-adv-infer-so-data-types">7.1.&nbsp;Data Type References</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnn-adv-infer-so-opaque">7.1.1.&nbsp;Pointer To Opaque Struct Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnAttnDescriptor_t">7.1.1.1.&nbsp;cudnnAttnDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnPersistentRNNPlan_t">7.1.1.2.&nbsp;cudnnPersistentRNNPlan_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNDataDescriptor_t">7.1.1.3.&nbsp;cudnnRNNDataDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNDescriptor_t">7.1.1.4.&nbsp;cudnnRNNDescriptor_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSeqDataDescriptor_t">7.1.1.5.&nbsp;cudnnSeqDataDescriptor_t</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnn-adv-infer-so-enum-types">7.1.2.&nbsp;Enumeration Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnDirectionMode_t">7.1.2.1.&nbsp;cudnnDirectionMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnForwardMode_t">7.1.2.2.&nbsp;cudnnForwardMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnMultiHeadAttnWeightKind_t">7.1.2.3.&nbsp;cudnnMultiHeadAttnWeightKind_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNBiasMode_t">7.1.2.4.&nbsp;cudnnRNNBiasMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNClipMode_t">7.1.2.5.&nbsp;cudnnRNNClipMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNDataLayout_t">7.1.2.6.&nbsp;cudnnRNNDataLayout_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNInputMode_t">7.1.2.7.&nbsp;cudnnRNNInputMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNMode_t">7.1.2.8.&nbsp;cudnnRNNMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRNNPaddingMode_t">7.1.2.9.&nbsp;cudnnRNNPaddingMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSeqDataAxis_t">7.1.2.10.&nbsp;cudnnSeqDataAxis_t</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnn-adv-infer-so-api">7.2.&nbsp;API Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnnAdvInferVersionCheck">7.2.1.&nbsp;cudnnAdvInferVersionCheck()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBuildRNNDynamic">7.2.2.&nbsp;cudnnBuildRNNDynamic()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateAttnDescriptor">7.2.3.&nbsp;cudnnCreateAttnDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreatePersistentRNNPlan">7.2.4.&nbsp;cudnnCreatePersistentRNNPlan()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateRNNDataDescriptor">7.2.5.&nbsp;cudnnCreateRNNDataDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateRNNDescriptor">7.2.6.&nbsp;cudnnCreateRNNDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateSeqDataDescriptor">7.2.7.&nbsp;cudnnCreateSeqDataDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyAttnDescriptor">7.2.8.&nbsp;cudnnDestroyAttnDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyPersistentRNNPlan">7.2.9.&nbsp;cudnnDestroyPersistentRNNPlan()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyRNNDataDescriptor">7.2.10.&nbsp;cudnnDestroyRNNDataDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyRNNDescriptor">7.2.11.&nbsp;cudnnDestroyRNNDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroySeqDataDescriptor">7.2.12.&nbsp;cudnnDestroySeqDataDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindRNNForwardInferenceAlgorithmEx">7.2.13.&nbsp;cudnnFindRNNForwardInferenceAlgorithmEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetAttnDescriptor">7.2.14.&nbsp;cudnnGetAttnDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetMultiHeadAttnBuffers">7.2.15.&nbsp;cudnnGetMultiHeadAttnBuffers()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetMultiHeadAttnWeights">7.2.16.&nbsp;cudnnGetMultiHeadAttnWeights()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNBackwardWeightsAlgorithmMaxCount">7.2.17.&nbsp;cudnnGetRNNBackwardWeightsAlgorithmMaxCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNBiasMode">7.2.18.&nbsp;cudnnGetRNNBiasMode()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNDataDescriptor">7.2.19.&nbsp;cudnnGetRNNDataDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNDescriptor_v6">7.2.20.&nbsp;cudnnGetRNNDescriptor_v6()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNDescriptor_v8">7.2.21.&nbsp;cudnnGetRNNDescriptor_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNForwardInferenceAlgorithmMaxCount">7.2.22.&nbsp;cudnnGetRNNForwardInferenceAlgorithmMaxCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNLinLayerBiasParams">7.2.23.&nbsp;cudnnGetRNNLinLayerBiasParams()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNLinLayerMatrixParams">7.2.24.&nbsp;cudnnGetRNNLinLayerMatrixParams()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNMatrixMathType">7.2.25.&nbsp;cudnnGetRNNMatrixMathType()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNPaddingMode">7.2.26.&nbsp;cudnnGetRNNPaddingMode()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNParamsSize">7.2.27.&nbsp;cudnnGetRNNParamsSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNProjectionLayers">7.2.28.&nbsp;cudnnGetRNNProjectionLayers()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNTempSpaceSizes">7.2.29.&nbsp;cudnnGetRNNTempSpaceSizes()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNTrainingReserveSize">7.2.30.&nbsp;cudnnGetRNNTrainingReserveSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNWeightParams">7.2.31.&nbsp;cudnnGetRNNWeightParams()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNWeightSpaceSize">7.2.32.&nbsp;cudnnGetRNNWeightSpaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNWorkspaceSize">7.2.33.&nbsp;cudnnGetRNNWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetSeqDataDescriptor">7.2.34.&nbsp;cudnnGetSeqDataDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnMultiHeadAttnForward">7.2.35.&nbsp;cudnnMultiHeadAttnForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNForward">7.2.36.&nbsp;cudnnRNNForward()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNForwardInference">7.2.37.&nbsp;cudnnRNNForwardInference()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNForwardInferenceEx">7.2.38.&nbsp;cudnnRNNForwardInferenceEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNGetClip">7.2.39.&nbsp;cudnnRNNGetClip()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNGetClip_v8">7.2.40.&nbsp;cudnnRNNGetClip_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNSetClip">7.2.41.&nbsp;cudnnRNNSetClip()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNSetClip_v8">7.2.42.&nbsp;cudnnRNNSetClip_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetAttnDescriptor">7.2.43.&nbsp;cudnnSetAttnDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetPersistentRNNPlan">7.2.44.&nbsp;cudnnSetPersistentRNNPlan()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNAlgorithmDescriptor">7.2.45.&nbsp;cudnnSetRNNAlgorithmDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNBiasMode">7.2.46.&nbsp;cudnnSetRNNBiasMode()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNDataDescriptor">7.2.47.&nbsp;cudnnSetRNNDataDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNDescriptor_v6">7.2.48.&nbsp;cudnnSetRNNDescriptor_v6()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNDescriptor_v8">7.2.49.&nbsp;cudnnSetRNNDescriptor_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNMatrixMathType">7.2.50.&nbsp;cudnnSetRNNMatrixMathType()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNPaddingMode">7.2.51.&nbsp;cudnnSetRNNPaddingMode()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetRNNProjectionLayers">7.2.52.&nbsp;cudnnSetRNNProjectionLayers()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetSeqDataDescriptor">7.2.53.&nbsp;cudnnSetSeqDataDescriptor()</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cudnn-adv-train-so-library">8.&nbsp;cudnn_adv_train.so Library</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnn-adv-train-so-data-types">8.1.&nbsp;Data Type References</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnn-adv-train-so-enum-types">8.1.1.&nbsp;Enumeration Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnLossNormalizationMode_t">8.1.1.1.&nbsp;cudnnLossNormalizationMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnWgradMode_t">8.1.1.2.&nbsp;cudnnWgradMode_t</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnn-adv-train-so-api">8.2.&nbsp;API Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnnAdvTrainVersionCheck">8.2.1.&nbsp;cudnnAdvTrainVersionCheck()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCreateCTCLossDescriptor">8.2.2.&nbsp;cudnnCreateCTCLossDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCTCLoss">8.2.3.&nbsp;cudnnCTCLoss()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnCTCLoss_v8">8.2.4.&nbsp;cudnnCTCLoss_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnDestroyCTCLossDescriptor">8.2.5.&nbsp;cudnnDestroyCTCLossDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindRNNBackwardDataAlgorithmEx">8.2.6.&nbsp;cudnnFindRNNBackwardDataAlgorithmEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindRNNBackwardWeightsAlgorithmEx">8.2.7.&nbsp;cudnnFindRNNBackwardWeightsAlgorithmEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnFindRNNForwardTrainingAlgorithmEx">8.2.8.&nbsp;cudnnFindRNNForwardTrainingAlgorithmEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetCTCLossDescriptor">8.2.9.&nbsp;cudnnGetCTCLossDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetCTCLossDescriptorEx">8.2.10.&nbsp;cudnnGetCTCLossDescriptorEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetCTCLossDescriptor_v8">8.2.11.&nbsp;cudnnGetCTCLossDescriptor_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetCTCLossWorkspaceSize">8.2.12.&nbsp;cudnnGetCTCLossWorkspaceSize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetCTCLossWorkspaceSize_v8">8.2.13.&nbsp;cudnnGetCTCLossWorkspaceSize_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNBackwardDataAlgorithmMaxCount">8.2.14.&nbsp;cudnnGetRNNBackwardDataAlgorithmMaxCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnGetRNNForwardTrainingAlgorithmMaxCount">8.2.15.&nbsp;cudnnGetRNNForwardTrainingAlgorithmMaxCount()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnMultiHeadAttnBackwardData">8.2.16.&nbsp;cudnnMultiHeadAttnBackwardData()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnMultiHeadAttnBackwardWeights">8.2.17.&nbsp;cudnnMultiHeadAttnBackwardWeights()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNBackwardData">8.2.18.&nbsp;cudnnRNNBackwardData()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNBackwardData_v8">8.2.19.&nbsp;cudnnRNNBackwardData_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNBackwardDataEx">8.2.20.&nbsp;cudnnRNNBackwardDataEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNBackwardWeights">8.2.21.&nbsp;cudnnRNNBackwardWeights()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNBackwardWeights_v8">8.2.22.&nbsp;cudnnRNNBackwardWeights_v8()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNBackwardWeightsEx">8.2.23.&nbsp;cudnnRNNBackwardWeightsEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNForwardTraining">8.2.24.&nbsp;cudnnRNNForwardTraining()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnRNNForwardTrainingEx">8.2.25.&nbsp;cudnnRNNForwardTrainingEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetCTCLossDescriptor">8.2.26.&nbsp;cudnnSetCTCLossDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetCTCLossDescriptorEx">8.2.27.&nbsp;cudnnSetCTCLossDescriptorEx()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnSetCTCLossDescriptor_v8">8.2.28.&nbsp;cudnnSetCTCLossDescriptor_v8()</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cudnn-backend-api">9.&nbsp;cuDNN Backend API</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#backend-data-type">9.1.&nbsp;Data Type References</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#backend-enumeration-types">9.1.1.&nbsp;Enumeration Types</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendAttributeName_t">9.1.1.1.&nbsp;cudnnBackendAttributeName_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendAttributeType_t">9.1.1.2.&nbsp;cudnnBackendAttributeType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendBehaviorNote_t">9.1.1.3.&nbsp;cudnnBackendBehaviorNote_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendDescriptorType_t">9.1.1.4.&nbsp;cudnnBackendDescriptorType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendHeurMode_t">9.1.1.5.&nbsp;cudnnBackendHeurMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendKnobType_t">9.1.1.6.&nbsp;cudnnBackendKnobType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendLayoutType_t">9.1.1.7.&nbsp;cudnnBackendLayoutType_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendNormFwdPhase_t">9.1.1.8.&nbsp;cudnnBackendNormFwdPhase_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendNormMode_t">9.1.1.9.&nbsp;cudnnBackendNormMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendNumericalNote_t">9.1.1.10.&nbsp;cudnnBackendNumericalNote_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendTensorReordering_t">9.1.1.11.&nbsp;cudnnBackendTensorReordering_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBnFinalizeStatsMode_t">9.1.1.12.&nbsp;cudnnBnFinalizeStatsMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnFraction_t">9.1.1.13.&nbsp;cudnnFraction_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnGenStatsMode_t">9.1.1.14.&nbsp;cudnnGenStatsMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnPaddingMode_t">9.1.1.15.&nbsp;cudnnPaddingMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnPointwiseMode_t">9.1.1.16.&nbsp;cudnnPointwiseMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnResampleMode_t">9.1.1.17.&nbsp;cudnnResampleMode_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnRngDistribution_t">9.1.1.18.&nbsp;cudnnRngDistribution_t</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cudnnSignalMode_t">9.1.1.19.&nbsp;cudnnSignalMode_t</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnn-cnn-infer-so-found">9.1.2.&nbsp;Data Types Found In cudnn_backend.h</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cudnnBackendDescriptor_t">9.1.2.1.&nbsp;cudnnBackendDescriptor_t</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#backend-api-functions">9.2.&nbsp;API Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cudnnBackendCreateDescriptor">9.2.1.&nbsp;cudnnBackendCreateDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBackendDestroyDescriptor">9.2.2.&nbsp;cudnnBackendDestroyDescriptor()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBackendExecute">9.2.3.&nbsp;cudnnBackendExecute()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBackendFinalize">9.2.4.&nbsp;cudnnBackendFinalize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBackendGetAttribute">9.2.5.&nbsp;cudnnBackendGetAttribute()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBackendInitialize">9.2.6.&nbsp;cudnnBackendInitialize()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cudnnBackendSetAttribute">9.2.7.&nbsp;cudnnBackendSetAttribute()</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#backend-descriptor-type">9.3.&nbsp;Backend Descriptor Types</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR">9.3.1.&nbsp;CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_ENGINE_DESCRIPTOR">9.3.2.&nbsp;CUDNN_BACKEND_ENGINE_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_ENGINECFG_DESCRIPTOR">9.3.3.&nbsp;CUDNN_BACKEND_ENGINECFG_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR">9.3.4.&nbsp;CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR">9.3.5.&nbsp;CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR">9.3.6.&nbsp;CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR">9.3.7.&nbsp;CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR">9.3.8.&nbsp;CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR">9.3.9.&nbsp;CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_MATMUL_DESCRIPTOR">9.3.10.&nbsp;CUDNN_BACKEND_MATMUL_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR">9.3.11.&nbsp;CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR">9.3.12.&nbsp;CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR">9.3.13.&nbsp;CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR">9.3.14.&nbsp;CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR">9.3.15.&nbsp;CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR">9.3.16.&nbsp;CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR">9.3.17.&nbsp;CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR">9.3.18.&nbsp;CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR">9.3.19.&nbsp;CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR">9.3.20.&nbsp;CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR">9.3.21.&nbsp;CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR">9.3.22.&nbsp;CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR">9.3.23.&nbsp;CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR">9.3.24.&nbsp;CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR">9.3.25.&nbsp;CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_POINTWISE_DESCRIPTOR">9.3.26.&nbsp;CUDNN_BACKEND_POINTWISE_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_REDUCTION_DESCRIPTOR">9.3.27.&nbsp;CUDNN_BACKEND_REDUCTION_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_RESAMPLE_DESCRIPTOR">9.3.28.&nbsp;CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_RNG_DESCRIPTOR">9.3.29.&nbsp;CUDNN_BACKEND_RNG_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_TENSOR_DESCRIPTOR">9.3.30.&nbsp;CUDNN_BACKEND_TENSOR_DESCRIPTOR</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR">9.3.31.&nbsp;CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#use-cases">9.4.&nbsp;Use Cases</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#use-case-op-graph-group-convo">9.4.1.&nbsp;Setting Up An Operation Graph For A Grouped Convolution</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#use-case-engine-config">9.4.2.&nbsp;Setting Up An Engine Configuration</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#use-case-execute-plan">9.4.3.&nbsp;Setting Up And Executing A Plan</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
            </ul>
         </nav>
         <div id="resize-nav"></div>
         <nav id="search-results">
            <h2>Search Results</h2>
            <ol></ol>
         </nav>
         
         <div id="contents-container">
            <div id="breadcrumbs-container">
               <div id="release-info">API Reference (<a href="../pdf/cuDNN-API.pdf">PDF</a>)
                  -
                  
                  
                  
                  -
                  
                  Last updated April 20, 2024
               </div>
            </div>
            <article id="contents">
               <div class="topic nested0" id="abstract"><a name="abstract" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#abstract" name="abstract" shape="rect">Abstract</a></h2>
                  <div class="body conbody">
                     <p class="shortdesc">This is the API Reference documentation for the NVIDIA cuDNN version 8.9.7 library.
                        This API Reference lists the datatyes and functions per library. Specifically, this
                        reference consists of a cuDNN datatype reference section that describes the types of enums
                        and a cuDNN API reference section that describes all routines in the cuDNN library API. The
                        cuDNN API is a context-based API that allows for easy multithreading and (optional)
                        interoperability with CUDA streams.
                     </p>
                  </div>
               </div>
               <div class="topic concept nested0" id="overview"><a name="overview" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#overview" name="overview" shape="rect">1.&nbsp;Introduction</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">NVIDIA<sup></sup> CUDA<sup></sup> Deep Neural Network (cuDNN)
                           library offers a context-based API that allows for easy multithreading and (optional)
                           interoperability with CUDA streams. This API Reference lists the datatyes and functions
                           per library. Specifically, this reference consists of a cuDNN datatype reference section
                           that describes the types of enums and a cuDNN API reference section that describes all
                           routines in the cuDNN library API.</span></div>
                     <div class="p">
                        <div class="fig fignone" id="overview__fig1"><a name="overview__fig1" shape="rect">
                              <!-- --></a><span class="figcap">Figure 1. Dynamic library dependency structure of cuDNN v8.x on Linux</span><br clear="none"></br><a name="overview__image_csc_1yv_nhb" shape="rect">
                              <!-- --></a><div class="imageleft"><img class="image imageleft" id="overview__image_csc_1yv_nhb" src="graphics/library-ovr.png" alt="Dynamic library dependency structure of cuDNN v8.x on Linux"></img></div><br clear="none"></br></div>
                     </div>
                     <div class="p">As illustrated in <a class="xref" href="index.html#overview__fig1" shape="rect">Figure 1</a>, the cuDNN library as well as this API
                        document has been split into the following libraries:
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">cudnn_ops_infer</samp></dt>
                           <dd class="dd">This entity contains the routines related to cuDNN context creation and
                              destruction, tensor descriptor management, tensor utility routines, and the
                              inference portion of common machine learning algorithms such as batch
                              normalization, softmax, dropout, and so on.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnn_ops_train</samp></dt>
                           <dd class="dd">This entity contains common training routines and algorithms, such as batch
                              normalization, softmax, dropout, and so on. The
                              <samp class="ph codeph">cudnn_ops_train</samp> library depends on
                              <samp class="ph codeph">cudnn_ops_infer</samp>.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnn_cnn_infer</samp></dt>
                           <dd class="dd">This entity contains all routines related to convolutional neural networks
                              needed at inference time. The <samp class="ph codeph">cudnn_cnn_infer</samp> library
                              depends on <samp class="ph codeph">cudnn_ops_infer</samp>.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnn_cnn_train</samp></dt>
                           <dd class="dd">This entity contains all routines related to convolutional neural networks
                              needed during training time. The <samp class="ph codeph">cudnn_cnn_train</samp> library
                              depends on <samp class="ph codeph">cudnn_ops_infer</samp>,
                              <samp class="ph codeph">cudnn_ops_train</samp>, and
                              <samp class="ph codeph">cudnn_cnn_infer</samp>.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnn_adv_infer</samp></dt>
                           <dd class="dd">This entity contains all other features and algorithms. This includes RNNs,
                              CTC loss, and multi-head attention. The <samp class="ph codeph">cudnn_adv_infer</samp>
                              library depends on <samp class="ph codeph">cudnn_ops_infer</samp>.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnn_adv_train</samp></dt>
                           <dd class="dd">This entity contains all the training counterparts of
                              <samp class="ph codeph">cudnn_adv_infer</samp>. The <samp class="ph codeph">cudnn_adv_train</samp>
                              library depends on <samp class="ph codeph">cudnn_ops_infer</samp>,
                              <samp class="ph codeph">cudnn_ops_train</samp>, and
                              <samp class="ph codeph">cudnn_adv_infer</samp>.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnBackend*</samp></dt>
                           <dd class="dd">Introduced in cuDNN version 8.x, this entity contains a list of valid cuDNN
                              backend descriptor types, a list of valid attributes, a subset of valid
                              attribute values, and a full description of each backend descriptor type and
                              their attributes.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnn</samp></dt>
                           <dd class="dd">This is an optional shim layer between the application layer and the cuDNN
                              code. This layer opportunistically opens the correct library for the API at
                              runtime.
                           </dd>
                        </dl>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="api-changes"><a name="api-changes" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#api-changes" name="api-changes" shape="rect">2.&nbsp;Added, Deprecated, and Removed API Functions</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc"></span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="release-870"><a name="release-870" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-870" name="release-870" shape="rect">2.1.&nbsp;API Changes for cuDNN 8.7.0</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.7.0.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-870__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-870__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 1. API functions and data types that were added in cuDNN 8.7.0</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e253" rowspan="1" colspan="1">Backend descriptor types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e253" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRngDistribution_t" title="cudnnRngDistribution_t is an enumerated type to indicate the distribution to be used in the backend Rng (random number generator) operation." shape="rect">cudnnRngDistribution_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e253" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR, &amp;desc); the cuDNN backend Rng operation descriptor specifies an operation node for generating a tensor with random numbers based on the probability distribution specified in the Rng descriptor." shape="rect">CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e253" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_RNG_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_RNG_DESCRIPTOR, &amp;desc); the cuDNN backend Rng descriptor specifies any metadata, including the probability distribution that will be used to generate the tensor and the distributions corresponding parameters." shape="rect">CUDNN_BACKEND_RNG_DESCRIPTOR</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-850"><a name="release-850" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-850" name="release-850" shape="rect">2.2.&nbsp;API Changes for cuDNN 8.5.0</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.5.0.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-850__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-850__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 2. API functions and data types that were added in cuDNN 8.5.0</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e347" rowspan="1" colspan="1">Backend descriptor types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendNormFwdPhase_t" title="cudnnBackendNormFwdPhase_t is an enumerated type used to distinguish the inference and training phase of the normalization forward operation." shape="rect">cudnnBackendNormFwdPhase_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendNormMode_t" title="cudnnBackendNormMode_t is an enumerated type to indicate the normalization mode in the backend normalization forward and normalization backward operations." shape="rect">cudnnBackendNormMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR, &amp;desc); the cuDNN backend concatenation operation descriptor specifies an operation node for concatenating a given vector of tensors along a given concatenation axis." shape="rect">CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR, &amp;desc), the cuDNN backend normalization backward operation specifies a node for a backward normalization that takes as input the gradient tensor dY and outputs the gradient tensor dX and weight gradients dScale and dBias. The normalization mode is set using the CUDNN_ATTR_OPERATION_NORM_BWD_MODE attribute." shape="rect">CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR, &amp;desc), the cuDNN backend normalization forward operation specifies a node for a forward normalization that takes as input a tensor X and produces a normalized output Y with the normalization mode set by the CUDNN_ATTR_OPERATION_NORM_FWD_MODE attribute. The operation supports optional running stats computation and allows for storing the computed means and variances for reuse in the backwards calculation depending on the setting of the CUDNN_ATTR_OPERATION_NORM_FWD_PHASE attribute." shape="rect">CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR, &amp;desc); the cuDNN backend signal operation descriptor specifies an operation node for updating or waiting on a flag variable. Signaling operations can be used to communicate between cuDNN operation graphs, even with operation graphs in another GPU." shape="rect">CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnFraction_t" title="cudnnFraction_t is a structure that allows a user to define int64_t fractions." shape="rect">cudnnFraction_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e347" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSignalMode_t" title="cudnnSignalMode_t is an enumerated type to indicate the signaling mode in the backend signal operation." shape="rect">cudnnSignalMode_t</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-840"><a name="release-840" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-840" name="release-840" shape="rect">2.3.&nbsp;API Changes for cuDNN 8.4.0</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.4.0.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-840__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-840__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 3. API functions and data types that were added in cuDNN 8.4.0</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e523" rowspan="1" colspan="1">Backend descriptor types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendBehaviorNote_t" shape="rect">cudnnBackendBehaviorNote_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR" title="The cuDNN backend reduction operation descriptor represents an operation node that implements reducing values of an input tensor X in one or more dimensions to get an output tensor Y. The math operation and compute data type used for reducing tensor values is specified via CUDNN_ATTR_OPERATION_REDUCTION_DESC." shape="rect">CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_POINTWISE_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_POINTWISE_DESCRIPTOR, &amp;desc); the cuDNN backend pointwise descriptor specifies the parameters for a pointwise operator like mode, math precision, nan propagation and so on." shape="rect">CUDNN_BACKEND_POINTWISE_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_REDUCTION_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_REDUCTION_DESCRIPTOR, &amp;desc); the cuDNN backend reduction descriptor specifies any metadata, including the math operation and compute data type, needed for the reduction operation." shape="rect">CUDNN_BACKEND_REDUCTION_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendTensorReordering_t" shape="rect">cudnnBackendTensorReordering_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBnFinalizeStatsMode_t" title="cudnnBnFinalizeStatsMode_t is an enumerated type that exposes the different mathematical operation modes that converts batchnorm statistics and the trained scale and bias to the equivalent scale and bias to be applied in the next normalization stage for inference and training use cases." shape="rect">cudnnBnFinalizeStatsMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnPaddingMode_t" title="cudnnPaddingMode_t is an enumerated type to indicate the padding mode in the backend resample operations." shape="rect">cudnnPaddingMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e523" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnResampleMode_t" title="cudnnResampleMode_t is an enumerated type to indicate the resample mode in the backend resample operations." shape="rect">cudnnResampleMode_t</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-830"><a name="release-830" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-830" name="release-830" shape="rect">2.4.&nbsp;API Changes for cuDNN 8.3.0</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.3.0.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-830__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-830__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 4. API functions and data types that were added in cuDNN 8.3.0</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e681" rowspan="1" colspan="1">Backend descriptor types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e681" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR, &amp;desc); the cuDNN backend resample backward operation descriptor specifies an operation node for backward resampling. It computes the input tensor gradient from output tensor gradient with backward resampling done according to CUDNN_ATTR_RESAMPLE_MODE with output scaling  and residual add with  scaling." shape="rect">CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e681" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR, &amp;desc); the cuDNN backend resample forward operation descriptor specifies an operation node for forward resampling. It computes the output tensor of image tensor resampled according to CUDNN_ATTR_RESAMPLE_MODE, with output scaling  and residual add with  scaling." shape="rect">CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e681" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_RESAMPLE_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_RESAMPLE_DESCRIPTOR, &amp;desc); the cuDNN backend resample descriptor specifies the parameters for a resample operation (upsampling or downsampling) in both forward and backward propagation." shape="rect">CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-820"><a name="release-820" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-820" name="release-820" shape="rect">2.5.&nbsp;API Changes for cuDNN 8.2.0</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.2.0.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-820__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-820__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 5. API functions and data types that were added in cuDNN 8.2.0</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e818" rowspan="1" colspan="1">New functions</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e818" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetActivationDescriptorSwishBeta" title="This function queries the current beta parameter set for SWISH activation." shape="rect">cudnnGetActivationDescriptorSwishBeta()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e818" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetActivationDescriptorSwishBeta" title="This function sets the beta parameter of the SWISH activation function to swish_beta." shape="rect">cudnnSetActivationDescriptorSwishBeta()</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-810"><a name="release-810" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-810" name="release-810" shape="rect">2.6.&nbsp;API Changes for cuDNN 8.1.0</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.1.0.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-810__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-810__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 6. API functions and data types that were added in cuDNN 8.1.0</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e884" rowspan="1" colspan="1">Backend descriptor types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e884" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_MATMUL_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_MATMUL_DESCRIPTOR, &amp;desc); the cuDNN backend matmul descriptor specifies any metadata needed for the matmul operation." shape="rect">CUDNN_BACKEND_MATMUL_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e884" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR" shape="rect">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-803"><a name="release-803" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-803" name="release-803" shape="rect">2.7.&nbsp;API Changes for cuDNN 8.0.3</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.0.3.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-803__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-803__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 7. API functions and data types that were added in cuDNN 8.0.3</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e955" rowspan="1" colspan="1">Backend descriptor types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR, &amp;desc); the cuDNN backend convolution descriptor specifies the parameters for a convolution operator for both forward and backward propagation: compute data type, convolution mode, filter dilation and stride, and padding on both sides." shape="rect">CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_ENGINE_DESCRIPTOR" title="Created with descriptor type value CUDNN_BACKEND_ENGINE_DESCRIPTOR, cuDNN backend engine descriptor describes an engine to compute an operation graph. An engine is a grouping of kernels with similar compute and numerical attributes." shape="rect">CUDNN_BACKEND_ENGINE_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_ENGINECFG_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINECFG_DESCRIPTOR, &amp;desc); the cuDNN backend engine configuration descriptor consists of an engine descriptor and an array of knob choice descriptors. Users can query from engine config information about intermediates: computational intermediate results that can be reused between executions." shape="rect">CUDNN_BACKEND_ENGINECFG_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR, &amp;desc); the cuDNN backend engine heuristics descriptor allows users to obtain for an operation graph engine configuration descriptors ranked by performance according to cuDNNs heuristics." shape="rect">CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR, &amp;desc); the cuDNN backend execution plan descriptor allows the user to specify an execution plan, consists of a cuDNN handle, an engine configuration, and optionally an array of intermediates to compute." shape="rect">CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR, &amp;desc); the cuDNN backend intermediate descriptor is a read-only descriptor that contains information about an execution intermediate. An execution intermediate is some intermediate computation for an engine config in device memory that can be reused between plan execution to amortize the kernel. Each intermediate is identified by a unique ID. Users can query for the device memory size of the intermediate. An intermediate can depend on the data of one or more tensors identified by the tensor UIDs or one more attribute of the operation graph." shape="rect">CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR, &amp;desc); the cuDNN backend knob choice descriptor consists of the type of knobs to be set and the value to which the knob is set." shape="rect">CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_INFO_DESCRIPTOR, &amp;desc); the cuDNN backend knob info descriptor consists of the type and valid value range of an engine performance knob. Valid value range is given in terms of minimum, maximum, and stride of valid values. This is a purely informative descriptor type. Setting descriptor attributes is not supported. User obtains an array of finalized descriptors, one for each knob type, from a finalized backend descriptor." shape="rect">CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR" title="Created with descriptor type value CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR, cuDNN backend layout info descriptor provides information on the preferred layout for a tensor." shape="rect">CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR, &amp;desc); the cuDNN backend convolution backward data operation descriptor specifies an operation node for convolution backward data to compute the gradient of input data with filter tensor and gradient of response with output  scaling and residue add with  scaling. That is, the equation , where denotes the convolution backward data operator." shape="rect">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR, &amp;desc); the cuDNN backend convolution backward filter operation descriptor specifies an operation node for convolution backward filter to compute the gradient of filter with image tensor and gradient of response with output  scaling and residue add with  scaling. That is, the equation: , where denotes the convolution backward filter operator." shape="rect">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR, &amp;desc); the cuDNN backend convolution forward operation descriptor specifies an operation node for forward convolution to compute the response tensor of image tensor convoluted with filter tensor with output scaling  and residual add with  scaling. That is, the equation , where * is the convolution operator in the forward direction." shape="rect">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR" title="Represents an operation that will generate per-channel statistics. The specific statistics that will be generated depends on the CUDNN_ATTR_OPERATION_GENSTATS_MODE attribute in the descriptor. Currently, only CUDNN_GENSTATS_SUM_SQSUMis supported for the CUDNN_ATTR_OPERATION_GENSTATS_MODE. It will generate the sum and quadratic sum of per-channel elements of the input tensor x. The output dimension should be all 1 except the C dimension. Also, the C dimension of outputs should equal the C dimension of the input. This opaque struct can be created with cudnnBackendCreateDescriptor() (CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR)." shape="rect">CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR" title="Represents a pointwise operation that implements the equation depending on the operation type. The actual type of operation represented by op() above depends on the CUDNN_ATTR_OPERATION_POINTWISE_PW_DESCRIPTOR attribute in the descriptor. This operation descriptor supports operations with single-input single-output." shape="rect">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR" title="Created with descriptor type value CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR, cuDNN backend operation graph descriptor describes an operation graph, a small network of one or more operations connected by virtual tensors. Operation graph defines users computation case or mathematical expression that they wish to compute." shape="rect">CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_TENSOR_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_TENSOR_DESCRIPTOR, &amp;desc); the cuDNN backend tensor allows users to specify the memory storage of a generic tensor. A tensor is identified by a unique identifier and described by its data type, its data byte-alignment requirements, and the extents and strides of its dimensions. Optionally, a tensor element can be vector in one of its dimensions. A tensor can also be set to be virtual when it is an intermediate variable in a computation graph and not mapped to physical global memory storage." shape="rect">CUDNN_BACKEND_TENSOR_DESCRIPTOR</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e955" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR, &amp;desc); the cuDNN backend variant pack plan allows users to set up pointers to device buffers to various non-virtual tensors, identified by unique identifiers, of the operation graph, workspace, and computation intermediates." shape="rect">CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-802"><a name="release-802" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-802" name="release-802" shape="rect">2.8.&nbsp;API Changes for cuDNN 8.0.2</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.0.2.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-802__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-802__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 8. API functions and data types that were added in cuDNN 8.0.2</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e1730" rowspan="1" colspan="1">New functions and data types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e1730" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e1730" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to all trainable parameters: weights and biases. If o = [y, hy, cy] = F(w) is a vector-valued function that represents the multi-layer RNN model and it takes some vector of &#34;flatten&#34; weights or biases as input (with all other data inputs constant), and outputs vector , then cudnnRNNBackwardWeights_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(w). The input is supplied via the dy, dhy, and dcy arguments in the cudnnRNNBackwardData_v8() function." shape="rect">cudnnRNNBackwardWeights_v8()</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="release-800-preview"><a name="release-800-preview" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#release-800-preview" name="release-800-preview" shape="rect">2.9.&nbsp;API Changes for cuDNN 8.0.0 Preview</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">The following tables show which API functions were added, deprecated, and removed
                              for the cuDNN 8.0.0 Preview Release.</span></div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-800-preview__table_sbt_p1j_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-800-preview__table_sbt_p1j_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 9. API functions and data types that were added in cuDNN 8.0.0 Preview</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e2435" rowspan="1" colspan="1">New functions and data types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnAdvInferVersionCheck" title="This function checks to see whether the version of the AdvInfer subset of the library is consistent with the other sub-libraries." shape="rect">cudnnAdvInferVersionCheck()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnAdvTrainVersionCheck" title="This function checks whether the version of the AdvTrain subset of the library is consistent with the other sub-libraries." shape="rect">cudnnAdvTrainVersionCheck()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeType_t" shape="rect">cudnnBackendAttributeType_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendCreateDescriptor" title="This function allocates memory in the descriptor for a given descriptor type and at the location pointed by the descriptor." shape="rect">cudnnBackendCreateDescriptor()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptorType_t" shape="rect">cudnnBackendDescriptorType_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDestroyDescriptor" shape="rect">cudnnBackendDestroyDescriptor()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendExecute" title="This function executes the given Engine Configuration Plan on the VariantPack and the finalized ExecutionPlan on the data. The data and the working space are encapsulated in the VariantPack." shape="rect">cudnnBackendExecute()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendHeurMode_t" title="cudnnBackendHeurMode_t is an enumerated type that indicates the operation mode of a CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR." shape="rect">cudnnBackendHeurMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendInitialize" title="This function repurposes a pre-allocated memory pointed to by a descriptor of size sizeInByte to a backend descriptor of type descriptorType. The finalized state of the descriptor is set to false." shape="rect">cudnnBackendInitialize()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendKnobType_t" shape="rect">cudnnBackendKnobType_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendLayoutType_t" shape="rect">cudnnBackendLayoutType_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendNumericalNote_t" shape="rect">cudnnBackendNumericalNote_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBuildRNNDynamic" title="This function compiles the RNN persistent code using CUDA runtime compilation library (NVRTC) when the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo is selected. The code is tailored to the current GPU and specific hyperparameters (miniBatch). This call is expected to be expensive in terms of runtime and should be invoked infrequently. Note that the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo does not support variable length sequences within the batch." shape="rect">cudnnBuildRNNDynamic()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLoss_v8" shape="rect">cudnnCTCLoss_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveNormTensorDescriptor" title="This function derives tensor descriptors for the normalization mean, invariance, normBias, and normScale subtensors from the layer's x data descriptor and norm mode. normalization, mean, and invariance share the same descriptor while bias and scale share the same descriptor." shape="rect">cudnnDeriveNormTensorDescriptor()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnForwardMode_t" title="cudnnForwardMode_t is an enumerated type to specify inference or training mode in RNN API. This parameter allows the cuDNN library to tune more precisely the size of the workspace buffer that could be different in inference and training regimens." shape="rect">cudnnForwardMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGenStatsMode_t" title="cudnnGenStatsMode_t is an enumerated type to indicate the statistics mode in the backend statistics generation operation." shape="rect">cudnnGenStatsMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetCTCLossDescriptor_v8" title="This function returns the configuration of the passed CTC loss function descriptor." shape="rect">cudnnGetCTCLossDescriptor_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetCTCLossDescriptorEx" title="This function returns the configuration of the passed CTC loss function descriptor." shape="rect">cudnnGetCTCLossDescriptorEx()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetCTCLossWorkspaceSize_v8" shape="rect">cudnnGetCTCLossWorkspaceSize_v8</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFilterSizeInBytes" title="This function returns the size of the filter tensor in memory with respect to the given descriptor. It can be used to know the amount of GPU memory to be allocated to hold that filter tensor." shape="rect">cudnnGetFilterSizeInBytes()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFoldedConvBackwardDataDescriptors" title="This function calculates folding descriptors for backward data gradients. It takes as input the data descriptors along with the convolution descriptor and computes the folded data descriptors and the folding transform descriptors. These can then be used to do the actual folding transform." shape="rect">cudnnGetFoldedConvBackwardDataDescriptors()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationBackwardWorkspaceSize" shape="rect">cudnnGetNormalizationBackwardWorkspaceSize()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">cudnnGetNormalizationForwardTrainingWorkspaceSize()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationTrainingReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetNormalizationTrainingReserveSpaceSize()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDescriptor_v8" shape="rect">cudnnGetRNNDescriptor_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNMatrixMathType" shape="rect">cudnnGetRNNMatrixMathType()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNTempSpaceSizes" title="This function computes the work and reserve space buffer sizes based on the RNN network geometry stored in rnnDesc, designated usage (inference or training) defined by the fMode argument, and the current RNN data dimensions (maxSeqLength, batchSize) retrieved from xDesc. When RNN data dimensions change, the cudnnGetRNNTempSpaceSizes() must be called again because RNN temporary buffer sizes are not monotonic." shape="rect">cudnnGetRNNTempSpaceSizes()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWeightParams" title="This function is used to obtain the start address and shape of every RNN weight matrix and bias vector in each pseudo-layer within the recurrent network." shape="rect">cudnnGetRNNWeightParams()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWeightSpaceSize" title="This function reports the required size of the weight space buffer in bytes. The weight space buffer holds all RNN weight matrices and bias vectors." shape="rect">cudnnGetRNNWeightSpaceSize()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnLRNDescriptor_t" shape="rect">cudnnLRNDescriptor_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnNormAlgo_t" shape="rect">cudnnNormAlgo_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationBackward" shape="rect">cudnnNormalizationBackward()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardInference" shape="rect">cudnnNormalizationForwardInference()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnNormMode_t" shape="rect">cudnnNormMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnNormOps_t" shape="rect">cudnnNormOps_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnOpsInferVersionCheck" title="This function is the first of a series of corresponding functions that check for consistent library versions among DLL files for different modules." shape="rect">cudnnOpsInferVersionCheck()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnOpsTrainVersionCheck" title="This function checks whether the version of the OpsTrain subset of the library is consistent with the other sub-libraries." shape="rect">cudnnOpsTrainVersionCheck()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnPointwiseMode_t" title="cudnnPointwiseMode_t is an enumerated type to indicate the intended pointwise math operation in the backend pointwise operation descriptor." shape="rect">cudnnPointwiseMode_t</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNGetClip_v8" title="Retrieves the current LSTM cell clipping parameters, and stores them in the arguments provided. The user can assign NULL to any pointer except rnnDesc when the retrieved value is not needed. The function does not check the validity of retrieved parameters." shape="rect">cudnnRNNGetClip_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNSetClip_v8" shape="rect">cudnnRNNSetClip_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptor_v8" title="Many CTC API functions are updated in cuDNN version 8.0.0 to support CUDA graphs. In order to do so, a new parameter is needed, maxLabelLength. Now that label and input data are assumed to be in GPU memory, this information is not otherwise readily available." shape="rect">cudnnSetCTCLossDescriptor_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e2435" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSeverity_t" title="cudnnSeverity_t is an enumerated type passed to the customized callback function for logging that users may set. This enumerate describes the severity level of the item, so the customized logging call back may react differently." shape="rect">cudnnSeverity_t</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <p class="p">For our deprecation policy, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#backward-compatibility" target="_blank" shape="rect">Backward Compatibility And Deprecation
                              Policy</a>.
                        </p>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-800-preview__table_vtn_4z3_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-800-preview__table_vtn_4z3_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 10. API functions and data types that were deprecated in cuDNN 8.0.0
                                       Preview</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="50%" id="d54e3190" rowspan="1" colspan="1">Deprecated functions and data types</th>
                                       <th class="entry" valign="top" width="50%" id="d54e3193" rowspan="1" colspan="1">Replaced with</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnCopyAlgorithmDescriptor()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnCreateAlgorithmDescriptor()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnCreatePersistentRNNPlan()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBuildRNNDynamic" title="This function compiles the RNN persistent code using CUDA runtime compilation library (NVRTC) when the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo is selected. The code is tailored to the current GPU and specific hyperparameters (miniBatch). This call is expected to be expensive in terms of runtime and should be invoked infrequently. Note that the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo does not support variable length sequences within the batch." shape="rect">cudnnBuildRNNDynamic()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnDestroyAlgorithmDescriptor()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnDestroyPersistentRNNPlan()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnFindRNNBackwardDataAlgorithmEx()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnFindRNNBackwardWeightsAlgorithmEx()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnFindRNNForwardInferenceAlgorithmEx()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnFindRNNForwardTrainingAlgorithmEx()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetAlgorithmDescriptor()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetAlgorithmPerformance()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetAlgorithmSpaceSize()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetRNNBackwardDataAlgorithmMaxCount()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetRNNBackwardWeightsAlgorithmMaxCount()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><a name="release-800-preview__ul_jcq_tz3_skb" shape="rect">
                                             <!-- --></a><ul class="ul" id="release-800-preview__ul_jcq_tz3_skb">
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNDescriptor_v6()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNMatrixMathType()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNBiasMode()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNPaddingMode()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNProjectionLayers()</samp></li>
                                          </ul>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDescriptor_v8" shape="rect">cudnnGetRNNDescriptor_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetRNNForwardInferenceAlgorithmMaxCount()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetRNNForwardTrainingAlgorithmMaxCount()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><a name="release-800-preview__ul_kcv_c1j_skb" shape="rect">
                                             <!-- --></a><ul class="ul" id="release-800-preview__ul_kcv_c1j_skb">
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNLinLayerBiasParams()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNLinLayerMatrixParams()</samp></li>
                                          </ul>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWeightParams" title="This function is used to obtain the start address and shape of every RNN weight matrix and bias vector in each pseudo-layer within the recurrent network." shape="rect">cudnnGetRNNWeightParams()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetRNNParamsSize()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWeightSpaceSize" title="This function reports the required size of the weight space buffer in bytes. The weight space buffer holds all RNN weight matrices and bias vectors." shape="rect">cudnnGetRNNWeightSpaceSize()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><a name="release-800-preview__ul_gp4_23n_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="release-800-preview__ul_gp4_23n_wlb">
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNWorkspaceSize()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnGetRNNTrainingReserveSize()</samp></li>
                                          </ul>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNTempSpaceSizes" title="This function computes the work and reserve space buffer sizes based on the RNN network geometry stored in rnnDesc, designated usage (inference or training) defined by the fMode argument, and the current RNN data dimensions (maxSeqLength, batchSize) retrieved from xDesc. When RNN data dimensions change, the cudnnGetRNNTempSpaceSizes() must be called again because RNN temporary buffer sizes are not monotonic." shape="rect">cudnnGetRNNTempSpaceSizes()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnPersistentRNNPlan_t</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRestoreAlgorithm()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><a name="release-800-preview__ul_rbc_m1j_skb" shape="rect">
                                             <!-- --></a><ul class="ul" id="release-800-preview__ul_rbc_m1j_skb">
                                             <li class="li"><samp class="ph codeph">cudnnRNNBackwardData()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnRNNBackwardDataEx()</samp></li>
                                          </ul>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><a name="release-800-preview__ul_ptn_21j_skb" shape="rect">
                                             <!-- --></a><ul class="ul" id="release-800-preview__ul_ptn_21j_skb">
                                             <li class="li"><samp class="ph codeph">cudnnRNNBackwardWeights()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnRNNBackwardWeightsEx()</samp></li>
                                          </ul>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to all trainable parameters: weights and biases. If o = [y, hy, cy] = F(w) is a vector-valued function that represents the multi-layer RNN model and it takes some vector of &#34;flatten&#34; weights or biases as input (with all other data inputs constant), and outputs vector , then cudnnRNNBackwardWeights_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(w). The input is supplied via the dy, dhy, and dcy arguments in the cudnnRNNBackwardData_v8() function." shape="rect">cudnnRNNBackwardWeights_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><a name="release-800-preview__ul_r22_g1j_skb" shape="rect">
                                             <!-- --></a><ul class="ul" id="release-800-preview__ul_r22_g1j_skb">
                                             <li class="li"><samp class="ph codeph">cudnnRNNForwardInference()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnRNNForwardInferenceEx()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnRNNForwardTraining()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnRNNForwardTrainingEx()</samp></li>
                                          </ul>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNGetClip()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNGetClip_v8" title="Retrieves the current LSTM cell clipping parameters, and stores them in the arguments provided. The user can assign NULL to any pointer except rnnDesc when the retrieved value is not needed. The function does not check the validity of retrieved parameters." shape="rect">cudnnRNNGetClip_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnRNNSetClip()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNSetClip_v8" shape="rect">cudnnRNNSetClip_v8()</a></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnSaveAlgorithm()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnSetAlgorithmDescriptor()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnSetAlgorithmPerformance()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnSetPersistentRNNPlan()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><samp class="ph codeph">cudnnSetRNNAlgorithmDescriptor()</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e3190" rowspan="1" colspan="1"><a name="release-800-preview__ul_rpv_vz3_skb" shape="rect">
                                             <!-- --></a><ul class="ul" id="release-800-preview__ul_rpv_vz3_skb">
                                             <li class="li"><samp class="ph codeph">cudnnSetRNNBiasMode()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnSetRNNDescriptor_v6()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnSetRNNPaddingMode()</samp></li>
                                             <li class="li"><samp class="ph codeph">cudnnSetRNNProjectionLayers()</samp></li>
                                          </ul>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d54e3193" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="release-800-preview__table_v3m_kz3_skb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="release-800-preview__table_v3m_kz3_skb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 11. API functions and data types that were removed in cuDNN 8.0.0 Preview</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="100%" id="d54e4409" rowspan="1" colspan="1">Removed functions and data types</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnConvolutionBwdDataPreference_t</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnConvolutionBwdFilterPreference_t</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnConvolutionFwdPreference_t</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetConvolutionBackwardDataAlgorithm()</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetConvolutionBackwardFilterAlgorithm()</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetConvolutionForwardAlgorithm()</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnGetRNNDescriptor()</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="100%" headers="d54e4409" rowspan="1" colspan="1"><samp class="ph codeph">cudnnSetRNNDescriptor()</samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="cudnn-ops-infer-so-library"><a name="cudnn-ops-infer-so-library" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cudnn-ops-infer-so-library" name="cudnn-ops-infer-so-library" shape="rect">3.&nbsp;<kbd class="ph userinput">cudnn_ops_infer.so</kbd> Library</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">This entity contains the routines related to cuDNN context creation and
                           destruction, tensor descriptor management, tensor utility routines, and the inference
                           portion of common machine learning algorithms such as batch normalization, softmax,
                           dropout, and so on.</span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="cudnn-ops-infer-so-data-type"><a name="cudnn-ops-infer-so-data-type" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-ops-infer-so-data-type" name="cudnn-ops-infer-so-data-type" shape="rect">3.1.&nbsp;Data Type References</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the data type references in the <samp class="ph codeph">cudnn_ops_infer.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnn-ops-infer-so-opaque"><a name="cudnn-ops-infer-so-opaque" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-ops-infer-so-opaque" name="cudnn-ops-infer-so-opaque" shape="rect">3.1.1.&nbsp;Pointer To Opaque Struct Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the pointers to the opaque struct types in the
                                 <samp class="ph codeph">cudnn_ops_infer.so</samp> library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnActivationDescriptor_t"><a name="cudnnActivationDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationDescriptor_t" name="cudnnActivationDescriptor_t" shape="rect">3.1.1.1.&nbsp;<kbd class="ph userinput">cudnnActivationDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnActivationDescriptor_t</samp> is a pointer to an opaque structure
                                 holding the description of an activation operation. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateActivationDescriptor" shape="rect">cudnnCreateActivationDescriptor()</a></samp> is used to create one instance,
                                 and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetActivationDescriptor" title="This function initializes a previously created generic activation descriptor object." shape="rect">cudnnSetActivationDescriptor()</a></samp> must be used to
                                 initialize this instance.  <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnCTCLossDescriptor_t"><a name="cudnnCTCLossDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCTCLossDescriptor_t" name="cudnnCTCLossDescriptor_t" shape="rect">3.1.1.2.&nbsp;<kbd class="ph userinput">cudnnCTCLossDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnCTCLossDescriptor_t</samp> is a pointer to an opaque structure holding
                                 the description of a CTC loss operation. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateCTCLossDescriptor" title="This function creates a CTC loss function descriptor." shape="rect">cudnnCreateCTCLossDescriptor()</a></samp> is used to create one instance, <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptor" shape="rect">cudnnSetCTCLossDescriptor()</a></samp> is used to initialize this instance,
                                 and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyCTCLossDescriptor" title="This function destroys a CTC loss function descriptor object." shape="rect">cudnnDestroyCTCLossDescriptor()</a></samp> is used to destroy this
                                 instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnDropoutDescriptor_t"><a name="cudnnDropoutDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutDescriptor_t" name="cudnnDropoutDescriptor_t" shape="rect">3.1.1.3.&nbsp;<kbd class="ph userinput">cudnnDropoutDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnDropoutDescriptor_t</samp> is a pointer to an opaque structure holding
                                 the description of a dropout operation. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateDropoutDescriptor" shape="rect">cudnnCreateDropoutDescriptor()</a></samp> is used to create one instance, <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetDropoutDescriptor" title="This function initializes a previously created dropout descriptor object. If the states argument is equal to NULL, then the random number generator states won't be initialized, and only the dropout value will be set. The user is expected not to change the memory pointed at by states for the duration of the computation." shape="rect">cudnnSetDropoutDescriptor()</a></samp> is used to initialize this instance,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyDropoutDescriptor" title="This function destroys a previously created dropout descriptor object." shape="rect">cudnnDestroyDropoutDescriptor()</a></samp> is used to destroy
                                 this instance, <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetDropoutDescriptor" title="This function queries the fields of a previously initialized dropout descriptor." shape="rect">cudnnGetDropoutDescriptor()</a></samp> is used to query
                                 fields of a previously initialized instance, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRestoreDropoutDescriptor" title="This function restores a dropout descriptor to a previously saved-off state." shape="rect">cudnnRestoreDropoutDescriptor()</a></samp> is used to restore an instance to
                                 a previously saved off state. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFilterDescriptor_t"><a name="cudnnFilterDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFilterDescriptor_t" name="cudnnFilterDescriptor_t" shape="rect">3.1.1.4.&nbsp;<kbd class="ph userinput">cudnnFilterDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnFilterDescriptor_t</samp> is a pointer to an opaque structure holding
                                 the description of a filter dataset. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateFilterDescriptor" shape="rect">cudnnCreateFilterDescriptor()</a></samp> is used to create one instance, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetFilter4dDescriptor" title="This function initializes a previously created filter descriptor object into a 4D filter. The layout of the filters must be contiguous in memory." shape="rect">cudnnSetFilter4dDescriptor()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetFilterNdDescriptor" title="This function initializes a previously created filter descriptor object. The layout of the filters must be contiguous in memory." shape="rect">cudnnSetFilterNdDescriptor()</a></samp> must be used to initialize this
                                 instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnHandle_t"><a name="cudnnHandle_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnHandle_t" name="cudnnHandle_t" shape="rect">3.1.1.5.&nbsp;<kbd class="ph userinput">cudnnHandle_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnHandle_t</samp> is a pointer to an opaque structure holding the cuDNN
                                 library context. The cuDNN library context must be created using <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreate" title="This function initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls." shape="rect">cudnnCreate()</a></samp> and the returned handle must be passed to all
                                 subsequent library function calls. The context should be destroyed at the end using
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroy" shape="rect">cudnnDestroy()</a></samp>. The context is associated with only
                                 one GPU device, the current device at the time of the call to <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreate" title="This function initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls." shape="rect">cudnnCreate()</a></samp>. However, multiple contexts can be created on the
                                 same GPU device. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnLRNDescriptor_t"><a name="cudnnLRNDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLRNDescriptor_t" name="cudnnLRNDescriptor_t" shape="rect">3.1.1.6.&nbsp;<kbd class="ph userinput">cudnnLRNDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnLRNDescriptor_t</samp> is a pointer to an opaque structure holding the
                                 		parameters of a local response normalization. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateLRNDescriptor" title="This function allocates the memory needed to hold the data needed for LRN and DivisiveNormalization layers operation and returns a descriptor used with subsequent layer forward and backward calls." shape="rect">cudnnCreateLRNDescriptor()</a></samp> is used to create one instance, and the
                                 		routine <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetLRNDescriptor" title="This function initializes a previously created LRN descriptor object." shape="rect">cudnnSetLRNDescriptor()</a></samp> must be used to initialize
                                 		this instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnOpTensorDescriptor_t"><a name="cudnnOpTensorDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpTensorDescriptor_t" name="cudnnOpTensorDescriptor_t" shape="rect">3.1.1.7.&nbsp;<kbd class="ph userinput">cudnnOpTensorDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnOpTensorDescriptor_t</samp> is a pointer to an opaque structure holding
                                 the description of a Tensor Core operation, used as a parameter to <samp class="ph codeph"><a class="xref" href="index.html#cudnnOpTensor" shape="rect">cudnnOpTensor()</a></samp>. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateOpTensorDescriptors" shape="rect">cudnnCreateOpTensorDescriptor()</a></samp> is used to create one instance,
                                 and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetOpTensorDescriptor" title="This function initializes a tensor pointwise math descriptor." shape="rect">cudnnSetOpTensorDescriptor()</a></samp> must be used to initialize
                                 this instance.  <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnPoolingDescriptor_t"><a name="cudnnPoolingDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingDescriptor_t" name="cudnnPoolingDescriptor_t" shape="rect">3.1.1.8.&nbsp;<kbd class="ph userinput">cudnnPoolingDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnPoolingDescriptor_t</samp> is a pointer to an opaque structure holding
                                 the description of a pooling operation. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreatePoolingDescriptor" shape="rect">cudnnCreatePoolingDescriptor()</a></samp> is used to create one instance, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPoolingNdDescriptor" title="This function initializes a previously created generic pooling descriptor object." shape="rect">cudnnSetPoolingNdDescriptor()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPooling2dDescriptor" title="This function initializes a previously created generic pooling descriptor object into a 2D description." shape="rect">cudnnSetPooling2dDescriptor()</a></samp> must be used to initialize this
                                 instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnReduceTensorDescriptor_t"><a name="cudnnReduceTensorDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReduceTensorDescriptor_t" name="cudnnReduceTensorDescriptor_t" shape="rect">3.1.1.9.&nbsp;<kbd class="ph userinput">cudnnReduceTensorDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnReduceTensorDescriptor_t</samp> is a pointer to an opaque structure
                                 holding the description of a tensor reduction operation, used as a parameter to
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensor" shape="rect">cudnnReduceTensor()</a></samp>. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateReduceTensorDescriptor" title="This function creates a reduced tensor descriptor object by allocating the memory needed to hold its opaque structure." shape="rect">cudnnCreateReduceTensorDescriptor()</a></samp> is used to create one
                                 instance, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetReduceTensorDescriptor" title="This function initializes a previously created reduce tensor descriptor object." shape="rect">cudnnSetReduceTensorDescriptor()</a></samp> must be used
                                 to initialize this instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSpatialTransformerDescriptor_t"><a name="cudnnSpatialTransformerDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTransformerDescriptor_t" name="cudnnSpatialTransformerDescriptor_t" shape="rect">3.1.1.10.&nbsp;<kbd class="ph userinput">cudnnSpatialTransformerDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnSpatialTransformerDescriptor_t</samp> is a pointer to an opaque
                                 structure holding the description of a spatial transformation operation. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateSpatialTransformerDescriptor" title="This function creates a generic spatial transformer descriptor object by allocating the memory needed to hold its opaque structure." shape="rect">cudnnCreateSpatialTransformerDescriptor()</a></samp> is used to create one
                                 instance, <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSpatialTransformerNdDescriptor" title="This function initializes a previously created generic spatial transformer descriptor object." shape="rect">cudnnSetSpatialTransformerNdDescriptor()</a></samp> is used
                                 to initialize this instance, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroySpatialTransformerDescriptor" title="This function destroys a previously created spatial transformer descriptor object." shape="rect">cudnnDestroySpatialTransformerDescriptor()</a></samp> is used to destroy this
                                 instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnTensorDescriptor_t"><a name="cudnnTensorDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTensorDescriptor_t" name="cudnnTensorDescriptor_t" shape="rect">3.1.1.11.&nbsp;<kbd class="ph userinput">cudnnTensorDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnTensorDescriptor_t</samp> is a pointer to an opaque structure holding
                                 the description of a generic n-D dataset. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateTensorDescriptor" title="This function creates a generic tensor descriptor object by allocating the memory needed to hold its opaque structure. The data is initialized to all zeros." shape="rect">cudnnCreateTensorDescriptor()</a></samp> is used to create one instance, and one of the routines <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetTensorNdDescriptor" title="This function initializes a previously created generic tensor descriptor object." shape="rect">cudnnSetTensorNdDescriptor()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetTensor4dDescriptor" title="This function initializes a previously created generic tensor descriptor object into a 4D tensor. The strides of the four dimensions are inferred from the format parameter and set in such a way that the data is contiguous in memory with no padding between dimensions." shape="rect">cudnnSetTensor4dDescriptor()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetTensor4dDescriptorEx" title="This function initializes a previously created generic tensor descriptor object into a 4D tensor, similarly to cudnnSetTensor4dDescriptor() but with the strides explicitly passed as parameters. This can be used to lay out the 4D tensor in any order or simply to define gaps between dimensions." shape="rect">cudnnSetTensor4dDescriptorEx()</a></samp> must be used to initialize this
                                 instance.  <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnTensorTransformDescriptor_t"><a name="cudnnTensorTransformDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTensorTransformDescriptor_t" name="cudnnTensorTransformDescriptor_t" shape="rect">3.1.1.12.&nbsp;<kbd class="ph userinput">cudnnTensorTransformDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnTensorTransformDescriptor_t</samp> is an opaque structure containing
                                 		the description of the tensor transform. Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateTensorTransformDescriptor" shape="rect">cudnnCreateTensorTransformDescriptor()</a></samp> function to create an
                                 		instance of this descriptor, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyTensorTransformDescriptor" title="Destroys a previously created tensor transform descriptor." shape="rect">cudnnDestroyTensorTransformDescriptor()</a></samp> function to destroy a
                                 		previously created instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnn-ops-infer-so-enum-types"><a name="cudnn-ops-infer-so-enum-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-ops-infer-so-enum-types" name="cudnn-ops-infer-so-enum-types" shape="rect">3.1.2.&nbsp;Enumeration Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the enumeration types in the <samp class="ph codeph">cudnn_ops_infer.so</samp>
                                 library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnActivationMode_t"><a name="cudnnActivationMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationMode_t" name="cudnnActivationMode_t" shape="rect">3.1.2.1.&nbsp;<kbd class="ph userinput">cudnnActivationMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnActivationMode_t</samp> is an enumerated type used to select the neuron
                                 activation function used in <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationForward" title="This routine applies a specified neuron activation function element-wise over each input value." shape="rect">cudnnActivationForward()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationBackward" title="This routine computes the gradient of a neuron activation function." shape="rect">cudnnActivationBackward()</a></samp>, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBiasActivationForward" shape="rect">cudnnConvolutionBiasActivationForward()</a></samp>.  <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnActivationMode_t__section_pzn_ndr_2jb"><a name="cudnnActivationMode_t__section_pzn_ndr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ACTIVATION_SIGMOID</samp></dt>
                                       <dd class="dd">Selects the sigmoid function.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp></dt>
                                       <dd class="dd">Selects the rectified linear function.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ACTIVATION_TANH</samp></dt>
                                       <dd class="dd">Selects the hyperbolic tangent function.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ACTIVATION_CLIPPED_RELU</samp></dt>
                                       <dd class="dd">Selects the clipped rectified linear function.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ACTIVATION_ELU</samp></dt>
                                       <dd class="dd">Selects the exponential linear function.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp></dt>
                                       <dd class="dd">Selects the identity function, intended for bypassing the activation
                                          step in <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBiasActivationForward" shape="rect">cudnnConvolutionBiasActivationForward()</a></samp>. (The <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBiasActivationForward" shape="rect">cudnnConvolutionBiasActivationForward()</a></samp>
                                          function must use
                                          <samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM</samp>.)
                                          Does not work with <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationForward" title="This routine applies a specified neuron activation function element-wise over each input value." shape="rect">cudnnActivationForward()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationBackward" title="This routine computes the gradient of a neuron activation function." shape="rect">cudnnActivationBackward()</a></samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ACTIVATION_SWISH</samp></dt>
                                       <dd class="dd">Selects the swish function.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnAlgorithm_t"><a name="cudnnAlgorithm_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAlgorithm_t" name="cudnnAlgorithm_t" shape="rect">3.1.2.2.&nbsp;<kbd class="ph userinput">cudnnAlgorithm_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBatchNormMode_t"><a name="cudnnBatchNormMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormMode_t" name="cudnnBatchNormMode_t" shape="rect">3.1.2.3.&nbsp;<kbd class="ph userinput">cudnnBatchNormMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBatchNormMode_t</samp> is an enumerated type used to specify the mode
                                 of operation in <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardInference" shape="rect">cudnnBatchNormalizationForwardInference()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp> routines. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnBatchNormMode_t__section_frq_qdr_2jb"><a name="cudnnBatchNormMode_t__section_frq_qdr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_BATCHNORM_PER_ACTIVATION</samp></dt>
                                       <dd class="dd">Normalization is performed per-activation. This mode is intended to be
                                          used after the non-convolutional network layers. In this mode, the
                                          tensor dimensions of <samp class="ph codeph">bnBias</samp> and
                                          <samp class="ph codeph">bnScale</samp> and the parameters used in the
                                          <samp class="ph codeph">cudnnBatchNormalization*</samp> functions are 1xCxHxW.
                                          
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp></dt>
                                       <dd class="dd">Normalization is performed over N+spatial dimensions. This mode is
                                          intended for use after convolutional layers (where spatial invariance is
                                          desired). In this mode the <samp class="ph codeph">bnBias</samp> and
                                          <samp class="ph codeph">bnScale</samp> tensor dimensions are 1xCx1x1.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp></dt>
                                       <dd class="dd">
                                          <p class="p">This mode is similar to <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp> but
                                             it can be faster for some tasks. 
                                          </p>
                                          <p class="p">An optimized path may be selected for
                                             <samp class="ph codeph">CUDNN_DATA_FLOAT</samp> and
                                             <samp class="ph codeph">CUDNN_DATA_HALF</samp> types, compute capability 6.0
                                             or higher for the following two batch normalization API calls:
                                             <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp>
                                             and <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp>. In the case of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp>, the
                                             <samp class="ph codeph">savedMean</samp> and <samp class="ph codeph">savedInvVariance</samp>
                                             arguments should not be <samp class="ph codeph">NULL</samp>. 
                                          </p>
                                          <p class="p"><strong class="ph b">The rest of this section applies to <samp class="ph codeph">NCHW</samp> mode
                                                only</strong>: This mode may use a scaled atomic integer reduction
                                             that is deterministic but imposes more restrictions on the input
                                             data range. When a numerical overflow occurs, the algorithm may
                                             produce NaN-s or Inf-s (infinity) in output buffers. 
                                          </p>
                                          <p class="p">When Inf-s/NaN-s are present in the input data, the output in this
                                             mode is the same as from a pure floating-point implementation. 
                                          </p>
                                          <p class="p">For finite but very large input values, the algorithm may encounter
                                             overflows more frequently due to a lower dynamic range and emit
                                             Inf-s/NaN-s while <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp> will
                                             produce finite results. The user can invoke <samp class="ph codeph"><a class="xref" href="index.html#cudnnQueryRuntimeError" title="cuDNN library functions perform extensive input argument checking before launching GPU kernels. The last step is to verify that the GPU kernel actually started. When a kernel fails to start, CUDNN_STATUS_EXECUTION_FAILED is returned by the corresponding API call. Typically, after a GPU kernel starts, no runtime checks are performed by the kernel itself - numerical results are simply written to output buffers." shape="rect">cudnnQueryRuntimeError()</a></samp> to check if a
                                             numerical overflow occurred in this mode.
                                          </p>
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBatchNormOps_t"><a name="cudnnBatchNormOps_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormOps_t" name="cudnnBatchNormOps_t" shape="rect">3.1.2.4.&nbsp;<kbd class="ph userinput">cudnnBatchNormOps_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBatchNormOps_t</samp> is an enumerated type used to specify the mode of
                                 operation in <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize" title="This function returns the amount of GPU memory workspace the user should allocate to be able to call cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize() function for the specified bnOps input setting. The workspace allocated should then be passed by the user to the function cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()." shape="rect">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTrainingEx" shape="rect">cudnnBatchNormalizationForwardTrainingEx()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationBackwardExWorkspaceSize" title="This function returns the amount of GPU memory workspace the user should allocate to be able to call cudnnGetBatchNormalizationBackwardExWorkspaceSize() function for the specified bnOps input setting. The workspace allocated will then be passed to the function cudnnGetBatchNormalizationBackwardExWorkspaceSize()." shape="rect">cudnnGetBatchNormalizationBackwardExWorkspaceSize()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackwardEx" shape="rect">cudnnBatchNormalizationBackwardEx()</a></samp>, and
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationTrainingExReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the batch normalization operation, for the specified bnOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</a></samp> functions. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnBatchNormOps_t__section_oxq_sdr_2jb"><a name="cudnnBatchNormOps_t__section_oxq_sdr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN</samp></dt>
                                       <dd class="dd">Only batch normalization is performed, per-activation.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp></dt>
                                       <dd class="dd">First, the batch normalization is performed, and then the activation is
                                          performed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp></dt>
                                       <dd class="dd">Performs the batch normalization, then element-wise addition, followed
                                          by the activation operation.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnCTCLossAlgo_t"><a name="cudnnCTCLossAlgo_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCTCLossAlgo_t" name="cudnnCTCLossAlgo_t" shape="rect">3.1.2.5.&nbsp;<kbd class="ph userinput">cudnnCTCLossAlgo_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnCTCLossAlgo_t</samp> is an enumerated type that exposes the different
                                 algorithms available to execute the CTC loss operation. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnCTCLossAlgo_t__section_i52_h2r_2jb"><a name="cudnnCTCLossAlgo_t__section_i52_h2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CTC_LOSS_ALGO_DETERMINISTIC</samp></dt>
                                       <dd class="dd">Results are guaranteed to be reproducible.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CTC_LOSS_ALGO_NON_DETERMINISTIC</samp></dt>
                                       <dd class="dd">Results are not guaranteed to be reproducible.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnDataType_t"><a name="cudnnDataType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDataType_t" name="cudnnDataType_t" shape="rect">3.1.2.6.&nbsp;<kbd class="ph userinput">cudnnDataType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnDataType_t</samp> is an enumerated type indicating the data type to
                                 which a tensor descriptor or filter descriptor refers. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnDataType_t__section_qgv_32r_2jb"><a name="cudnnDataType_t__section_qgv_32r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></dt>
                                       <dd class="dd">The data is a 32-bit single-precision floating-point
                                          (<samp class="ph codeph">float</samp>).
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></dt>
                                       <dd class="dd">The data is a 64-bit double-precision floating-point
                                          (<samp class="ph codeph">double</samp>).
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_HALF</samp></dt>
                                       <dd class="dd">The data is a 16-bit floating-point.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_INT8</samp></dt>
                                       <dd class="dd">The data is an 8-bit signed integer.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_INT32</samp></dt>
                                       <dd class="dd">The data is a 32-bit signed integer.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_INT8x4</samp></dt>
                                       <dd class="dd">The data is 32-bit elements each composed of 4 8-bit signed integers.
                                          This data type is only supported with the tensor format
                                          <samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_UINT8</samp></dt>
                                       <dd class="dd">The data is an 8-bit unsigned integer.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_UINT8x4</samp></dt>
                                       <dd class="dd">The data is 32-bit elements each composed of 4 8-bit unsigned integers.
                                          This data type is only supported with the tensor format
                                          <samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_INT8x32</samp></dt>
                                       <dd class="dd">The data is 32-element vectors, each element being an 8-bit signed
                                          integer. This data type is only supported with the tensor format
                                          <samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp>. Moreover, this data type
                                          can only be used with <samp class="ph codeph">algo 1</samp>, meaning,
                                          <samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM</samp>.
                                          For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionFwdAlgo_t" title="cudnnConvolutionFwdAlgo_t is an enumerated type that exposes the different algorithms available to execute the forward convolution operation." shape="rect">cudnnConvolutionFwdAlgo_t</a></samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></dt>
                                       <dd class="dd">The data is a 16-bit quantity, with 7 mantissa bits, 8 exponent bits,
                                          and 1 sign bit.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_INT64</samp></dt>
                                       <dd class="dd">The data is a 64-bit signed integer.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_BOOLEAN</samp></dt>
                                       <dd class="dd">
                                          <p class="p">The data is a boolean (<samp class="ph codeph">bool</samp>).
                                          </p>
                                          <p class="p">Note that for type <samp class="ph codeph">CUDNN_TYPE_BOOLEAN</samp>, elements are
                                             expected to be "packed": that is, one byte contains 8 elements of
                                             type <samp class="ph codeph">CUDNN_TYPE_BOOLEAN</samp>. Further, within each byte,
                                             elements are indexed from the least significant bit to the most
                                             significant bit. For example, a 1 dimensional tensor of 8 elements
                                             containing 01001111 has value 1 for elements 0 through 3, 0 for
                                             elements 4 and 5, 1 for element 6 and 0 for element 7.
                                          </p>
                                          <p class="p">Tensors with more than 8 elements simply use more bytes, where the
                                             order is also from least significant to most significant byte. Note,
                                             CUDA is little-endian, meaning that the least significant byte has
                                             the lower memory address address. For example, in the case of 16
                                             elements, 01001111 11111100 has value 1 for elements 0 through 3, 0
                                             for elements 4 and 5, 1 for element 6 and 0 for element 7, value 0
                                             for elements 8 and 9, 1 for elements 10 through 15.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_FP8_E4M3</samp></dt>
                                       <dd class="dd">The data is an 8-bit quantity, with 3 mantissa bits, 4 exponent bits,
                                          and 1 sign bit.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_FP8_E5M2</samp></dt>
                                       <dd class="dd">The data is an 8-bit quantity, with 2 mantissa bits, 5 exponent bits,
                                          and 1 sign bit.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DATA_FAST_FLOAT_FOR_FP8</samp></dt>
                                       <dd class="dd">The data type is a higher throughput but lower precision compute type
                                          (compared to <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>) used for FP8 tensor core
                                          operations
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnDeterminism_t"><a name="cudnnDeterminism_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDeterminism_t" name="cudnnDeterminism_t" shape="rect">3.1.2.7.&nbsp;<kbd class="ph userinput">cudnnDeterminism_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnDeterminism_t</samp> is an enumerated type used to indicate if the
                                 computed results are deterministic (reproducible). For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#reproducibility" target="_blank" shape="rect">Reproducibility
                                    (Determinism)</a>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnDeterminism_t__section_iyc_k2r_2jb"><a name="cudnnDeterminism_t__section_iyc_k2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NON_DETERMINISTIC</samp></dt>
                                       <dd class="dd">Results are not guaranteed to be reproducible.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DETERMINISTIC</samp></dt>
                                       <dd class="dd">Results are guaranteed to be reproducible.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnDivNormMode_t"><a name="cudnnDivNormMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDivNormMode_t" name="cudnnDivNormMode_t" shape="rect">3.1.2.8.&nbsp;<kbd class="ph userinput">cudnnDivNormMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnDivNormMode_t</samp> is an enumerated type used to specify the mode of
                                 operation in <samp class="ph codeph"><a class="xref" href="index.html#cudnnDivisiveNormalizationForward" shape="rect">cudnnDivisiveNormalizationForward()</a></samp> and
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnDivisiveNormalizationBackward" title="This function performs the backward DivisiveNormalization layer computation." shape="rect">cudnnDivisiveNormalizationBackward()</a></samp>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnDivNormMode_t__section_sbh_m2r_2jb"><a name="cudnnDivNormMode_t__section_sbh_m2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DIVNORM_PRECOMPUTED_MEANS</samp></dt>
                                       <dd class="dd">The means tensor data pointer is expected to contain means or other
                                          kernel convolution values precomputed by the user. The means pointer can
                                          also be <samp class="ph codeph">NULL</samp>, in that case, it's considered to be
                                          filled with zeroes. This is equivalent to spatial LRN. 
                                          <div class="note note"><span class="notetitle">Note:</span> In the
                                             backward pass, the means are treated as independent inputs and the
                                             gradient over means is computed independently. In this mode, to
                                             yield a net gradient over the entire LCN computational graph, the
                                             <samp class="ph codeph">destDiffMeans</samp> result should be backpropagated
                                             through the user's means layer (which can be implemented using
                                             average pooling) and added to the <samp class="ph codeph">destDiffData</samp>
                                             tensor produced by <samp class="ph codeph"><a class="xref" href="index.html#cudnnDivisiveNormalizationBackward" title="This function performs the backward DivisiveNormalization layer computation." shape="rect">cudnnDivisiveNormalizationBackward()</a></samp>.
                                             
                                          </div>
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnErrQueryMode_t"><a name="cudnnErrQueryMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnErrQueryMode_t" name="cudnnErrQueryMode_t" shape="rect">3.1.2.9.&nbsp;<kbd class="ph userinput">cudnnErrQueryMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnErrQueryMode_t</samp> is an enumerated type passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnQueryRuntimeError" title="cuDNN library functions perform extensive input argument checking before launching GPU kernels. The last step is to verify that the GPU kernel actually started. When a kernel fails to start, CUDNN_STATUS_EXECUTION_FAILED is returned by the corresponding API call. Typically, after a GPU kernel starts, no runtime checks are performed by the kernel itself - numerical results are simply written to output buffers." shape="rect">cudnnQueryRuntimeError()</a></samp> to select the remote kernel error query
                                 mode. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnErrQueryMode_t__section_v1w_n2r_2jb"><a name="cudnnErrQueryMode_t__section_v1w_n2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ERRQUERY_RAWCODE</samp></dt>
                                       <dd class="dd">Read the error storage location regardless of the kernel completion
                                          status.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ERRQUERY_NONBLOCKING</samp></dt>
                                       <dd class="dd">Report if all tasks in the user stream of the cuDNN handle were
                                          completed. If that is the case, report the remote kernel error
                                          code.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ERRQUERY_BLOCKING</samp></dt>
                                       <dd class="dd">Wait for all tasks to complete in the user stream before reporting the
                                          remote kernel error code.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFoldingDirection_t"><a name="cudnnFoldingDirection_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFoldingDirection_t" name="cudnnFoldingDirection_t" shape="rect">3.1.2.10.&nbsp;<kbd class="ph userinput">cudnnFoldingDirection_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnFoldingDirection_t</samp> is an enumerated type used to select the
                                 		folding direction. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorTransformDescriptor_t" shape="rect">cudnnTensorTransformDescriptor_t</a></samp>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnFoldingDirection_t__section_fhb_t2r_2jb"><a name="cudnnFoldingDirection_t__section_fhb_t2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Data Member</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TRANSFORM_FOLD = 0U</samp></dt>
                                       <dd class="dd">Selects folding.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TRANSFORM_UNFOLD = 1U</samp></dt>
                                       <dd class="dd">Selects unfolding.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnIndicesType_t"><a name="cudnnIndicesType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnIndicesType_t" name="cudnnIndicesType_t" shape="rect">3.1.2.11.&nbsp;<kbd class="ph userinput">cudnnIndicesType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnIndicesType_t</samp> is an enumerated type used to indicate the data
                                 type for the indices to be computed by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensor" shape="rect">cudnnReduceTensor()</a></samp> routine. This enumerated type is used as a field for the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensorDescriptor_t" shape="rect">cudnnReduceTensorDescriptor_t</a></samp> descriptor. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnIndicesType_t__section_rzz_bfr_2jb"><a name="cudnnIndicesType_t__section_rzz_bfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_32BIT_INDICES</samp></dt>
                                       <dd class="dd">Compute unsigned int indices.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_64BIT_INDICES</samp></dt>
                                       <dd class="dd">Compute unsigned long indices.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_16BIT_INDICES</samp></dt>
                                       <dd class="dd">Compute unsigned short indices.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_8BIT_INDICES</samp></dt>
                                       <dd class="dd">Compute unsigned char indices.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnLRNMode_t"><a name="cudnnLRNMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLRNMode_t" name="cudnnLRNMode_t" shape="rect">3.1.2.12.&nbsp;<kbd class="ph userinput">cudnnLRNMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnLRNMode_t</samp> is an enumerated type used to specify the mode of
                                 operation in <samp class="ph codeph"><a class="xref" href="index.html#cudnnLRNCrossChannelForward" title="This function performs the forward LRN layer computation." shape="rect">cudnnLRNCrossChannelForward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnLRNCrossChannelBackward" title="This function performs the backward LRN layer computation." shape="rect">cudnnLRNCrossChannelBackward()</a></samp>.  <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnLRNMode_t__section_aml_2fr_2jb"><a name="cudnnLRNMode_t__section_aml_2fr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_LRN_CROSS_CHANNEL_DIM1</samp></dt>
                                       <dd class="dd">LRN computation is performed across the tensor's dimension
                                          <samp class="ph codeph">dimA[1]</samp>.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnMathType_t"><a name="cudnnMathType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMathType_t" name="cudnnMathType_t" shape="rect">3.1.2.13.&nbsp;<kbd class="ph userinput">cudnnMathType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnMathType_t</samp> is an enumerated type used to indicate if the use of
                                 Tensor Core operations is permitted in a given library routine. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnMathType_t__section_op4_ffr_2jb"><a name="cudnnMathType_t__section_op4_ffr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_DEFAULT_MATH</samp></dt>
                                       <dd class="dd">Tensor Core operations are not used on pre-NVIDIA A100 GPU devices. On
                                          A100 GPU architecture devices, Tensor Core TF32 operation is
                                          permitted.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp></dt>
                                       <dd class="dd">The use of Tensor Core operations is permitted but will not actively
                                          perform datatype down conversion on tensors in order to utilize Tensor
                                          Cores.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp></dt>
                                       <dd class="dd">The use of Tensor Core operations is permitted and will actively perform
                                          datatype down conversion on tensors in order to utilize Tensor
                                          Cores.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FMA_MATH</samp></dt>
                                       <dd class="dd">Restricted to only kernels that use FMA instructions.</dd>
                                    </dl>
                                 </div>
                                 <p class="p">On pre-NVIDIA A100 GPU devices, <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> and
                                    <samp class="ph codeph">CUDNN_FMA_MATH</samp> have the same behavior: Tensor Core kernels will
                                    not be selected. With NVIDIA Ampere architecture and CUDA toolkit 11,
                                    <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> permits TF32 Tensor Core operation and
                                    <samp class="ph codeph">CUDNN_FMA_MATH</samp> does not. The TF32 behavior for
                                    <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> and the other Tensor Core math types can be
                                    explicitly disabled by the environment variable
                                    <samp class="ph codeph">NVIDIA_TF32_OVERRIDE=0</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnNanPropagation_t"><a name="cudnnNanPropagation_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNanPropagation_t" name="cudnnNanPropagation_t" shape="rect">3.1.2.14.&nbsp;<kbd class="ph userinput">cudnnNanPropagation_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnNanPropagation_t</samp> is an enumerated type used to indicate if a
                                 given routine should propagate <samp class="ph codeph">Nan</samp> numbers. This enumerated type is used as
                                 a field for the <samp class="ph codeph">cudnnActivationDescriptor_t</samp> descriptor and
                                 <samp class="ph codeph">cudnnPoolingDescriptor_t</samp> descriptor. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnNanPropagation_t__section_hyd_3fr_2jb"><a name="cudnnNanPropagation_t__section_hyd_3fr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp></dt>
                                       <dd class="dd"><samp class="ph codeph">Nan</samp> numbers are not propagated.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_PROPAGATE_NAN</samp></dt>
                                       <dd class="dd"><samp class="ph codeph">Nan</samp> numbers are propagated.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnNormAlgo_t"><a name="cudnnNormAlgo_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNormAlgo_t" name="cudnnNormAlgo_t" shape="rect">3.1.2.15.&nbsp;<kbd class="ph userinput">cudnnNormAlgo_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnNormAlgo_t</samp> is an enumerated type used to specify the algorithm
                                 to execute the normalization operation. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnNormAlgo_t__section_qgv_32r_2jb"><a name="cudnnNormAlgo_t__section_qgv_32r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NORM_ALGO_STANDARD</samp></dt>
                                       <dd class="dd">Standard normalization is performed.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NORM_ALGO_PERSIST</samp></dt>
                                       <dd class="dd">
                                          <p class="p">This mode is similar to <samp class="ph codeph">CUDNN_NORM_ALGO_STANDARD</samp>,
                                             however it only supports <samp class="ph codeph">CUDNN_NORM_PER_CHANNEL</samp> and
                                             can be faster for some tasks.
                                          </p>
                                          <p class="p">An optimized path may be selected for
                                             <samp class="ph codeph">CUDNN_DATA_FLOAT</samp> and
                                             <samp class="ph codeph">CUDNN_DATA_HALF</samp> types, compute capability 6.0
                                             or higher for the following two normalization API calls:
                                             <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationBackward" shape="rect">cudnnNormalizationBackward()</a></samp>. In the case
                                             of <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationBackward" shape="rect">cudnnNormalizationBackward()</a></samp>, the
                                             <samp class="ph codeph">savedMean</samp> and <samp class="ph codeph">savedInvVariance</samp>
                                             arguments should not be <samp class="ph codeph">NULL</samp>.
                                          </p>
                                          <p class="p"><strong class="ph b">The rest of this section applies to NCHW mode only:</strong> This mode
                                             may use a scaled atomic integer reduction that is deterministic but
                                             imposes more restrictions on the input data range. When a numerical
                                             overflow occurs, the algorithm may produce NaN-s or Inf-s (infinity)
                                             in output buffers.
                                          </p>
                                          <p class="p">When Inf-s/NaN-s are present in the input data, the output in this
                                             mode is the same as from a pure floating-point implementation.
                                          </p>
                                          <p class="p">For finite but very large input values, the algorithm may encounter
                                             overflows more frequently due to a lower dynamic range and emit
                                             Inf-s/NaN-s while <samp class="ph codeph">CUDNN_NORM_ALGO_STANDARD</samp> will
                                             produce finite results. The user can invoke <samp class="ph codeph"><a class="xref" href="index.html#cudnnQueryRuntimeError" title="cuDNN library functions perform extensive input argument checking before launching GPU kernels. The last step is to verify that the GPU kernel actually started. When a kernel fails to start, CUDNN_STATUS_EXECUTION_FAILED is returned by the corresponding API call. Typically, after a GPU kernel starts, no runtime checks are performed by the kernel itself - numerical results are simply written to output buffers." shape="rect">cudnnQueryRuntimeError()</a></samp> to check if a
                                             numerical overflow occurred in this mode.
                                          </p>
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnNormMode_t"><a name="cudnnNormMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNormMode_t" name="cudnnNormMode_t" shape="rect">3.1.2.16.&nbsp;<kbd class="ph userinput">cudnnNormMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnNormMode_t</samp> is an enumerated type used to specify the mode of
                                 operation in <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardInference" shape="rect">cudnnNormalizationForwardInference()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">cudnnGetNormalizationForwardTrainingWorkspaceSize()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationBackwardWorkspaceSize" shape="rect">cudnnGetNormalizationBackwardWorkspaceSize()</a></samp>, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationTrainingReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetNormalizationTrainingReserveSpaceSize()</a></samp>
                                 routines. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnNormMode_t__section_i52_h2r_2jb"><a name="cudnnNormMode_t__section_i52_h2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NORM_PER_ACTIVATION</samp></dt>
                                       <dd class="dd">Normalization is performed per-activation. This mode is intended to be
                                          used after the non-convolutional network layers. In this mode, the
                                          tensor dimensions of <samp class="ph codeph">normBias</samp> and
                                          <samp class="ph codeph">normScale</samp> and the parameters used in the
                                          <samp class="ph codeph">cudnnNormalization*</samp> functions are 1xCxHxW.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NORM_PER_CHANNEL</samp></dt>
                                       <dd class="dd">Normalization is performed per-channel over N+spatial dimensions. This
                                          mode is intended for use after convolutional layers (where spatial
                                          invariance is desired). In this mode, the <samp class="ph codeph">normBias</samp> and
                                          <samp class="ph codeph">normScale</samp> tensor dimensions are 1xCx1x1.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnNormOps_t"><a name="cudnnNormOps_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNormOps_t" name="cudnnNormOps_t" shape="rect">3.1.2.17.&nbsp;<kbd class="ph userinput">cudnnNormOps_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnNormOps_t</samp> is an enumerated type used to specify the mode of
                                 operation in <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">cudnnGetNormalizationForwardTrainingWorkspaceSize()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationBackwardWorkspaceSize" shape="rect">cudnnGetNormalizationBackwardWorkspaceSize()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationBackward" shape="rect">cudnnNormalizationBackward()</a></samp>, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationTrainingReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetNormalizationTrainingReserveSpaceSize()</a></samp>
                                 functions. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnNormOps_t__section_i52_h2r_2jb"><a name="cudnnNormOps_t__section_i52_h2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NORM_OPS_NORM</samp></dt>
                                       <dd class="dd">Only normalization is performed.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp></dt>
                                       <dd class="dd">First, the normalization is performed, then the activation is
                                          performed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp></dt>
                                       <dd class="dd">Performs the normalization, then element-wise addition, followed by the
                                          activation operation.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnOpTensorOp_t"><a name="cudnnOpTensorOp_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpTensorOp_t" name="cudnnOpTensorOp_t" shape="rect">3.1.2.18.&nbsp;<kbd class="ph userinput">cudnnOpTensorOp_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnOpTensorOp_t</samp> is an enumerated type used to indicate the Tensor
                                 Core operation to be used by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnOpTensor" shape="rect">cudnnOpTensor()</a></samp> routine.
                                 This enumerated type is used as a field for the <samp class="ph codeph"><a class="xref" href="index.html#cudnnOpTensorDescriptor_t" shape="rect">cudnnOpTensorDescriptor_t</a></samp> descriptor. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnOpTensorOp_t__section_eg5_jfr_2jb"><a name="cudnnOpTensorOp_t__section_eg5_jfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_OP_TENSOR_ADD</samp></dt>
                                       <dd class="dd">The operation to be performed is addition.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_OP_TENSOR_MUL</samp></dt>
                                       <dd class="dd">The operation to be performed is multiplication.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_OP_TENSOR_MIN</samp></dt>
                                       <dd class="dd">The operation to be performed is a minimum comparison.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_OP_TENSOR_MAX</samp></dt>
                                       <dd class="dd">The operation to be performed is a maximum comparison.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_OP_TENSOR_SQRT</samp></dt>
                                       <dd class="dd">The operation to be performed is square root, performed on only the
                                          <samp class="ph codeph">A</samp> tensor.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_OP_TENSOR_NOT</samp></dt>
                                       <dd class="dd">The operation to be performed is negation, performed on only the
                                          <samp class="ph codeph">A</samp> tensor.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnPoolingMode_t"><a name="cudnnPoolingMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingMode_t" name="cudnnPoolingMode_t" shape="rect">3.1.2.19.&nbsp;<kbd class="ph userinput">cudnnPoolingMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnPoolingMode_t</samp> is an enumerated type passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPooling2dDescriptor" title="This function initializes a previously created generic pooling descriptor object into a 2D description." shape="rect">cudnnSetPooling2dDescriptor()</a></samp> to select the pooling method to be
                                 used by <samp class="ph codeph"><a class="xref" href="index.html#cudnnPoolingForward" title="This function computes pooling of input values (meaning, the maximum or average of several adjacent values) to produce an output with smaller height and/or width." shape="rect">cudnnPoolingForward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnPoolingBackward" title="This function computes the gradient of a pooling operation." shape="rect">cudnnPoolingBackward()</a></samp>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnPoolingMode_t__section_cfq_lfr_2jb"><a name="cudnnPoolingMode_t__section_cfq_lfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POOLING_MAX</samp></dt>
                                       <dd class="dd">The maximum value inside the pooling window is used.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING</samp></dt>
                                       <dd class="dd">Values inside the pooling window are averaged. The number of elements
                                          used to calculate the average includes spatial locations falling in the
                                          padding region.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING</samp></dt>
                                       <dd class="dd">Values inside the pooling window are averaged. The number of elements
                                          used to calculate the average excludes spatial locations falling in the
                                          padding region.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POOLING_MAX_DETERMINISTIC</samp></dt>
                                       <dd class="dd">The maximum value inside the pooling window is used. The algorithm used
                                          is deterministic.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnReduceTensorIndices_t"><a name="cudnnReduceTensorIndices_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReduceTensorIndices_t" name="cudnnReduceTensorIndices_t" shape="rect">3.1.2.20.&nbsp;<kbd class="ph userinput">cudnnReduceTensorIndices_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnReduceTensorIndices_t</samp> is an enumerated type used to indicate
                                 whether indices are to be computed by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensor" shape="rect">cudnnReduceTensor()</a></samp> routine. This enumerated type is used as a field for the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensorDescriptor_t" shape="rect">cudnnReduceTensorDescriptor_t</a></samp> descriptor. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnReduceTensorIndices_t__section_sql_nfr_2jb"><a name="cudnnReduceTensorIndices_t__section_sql_nfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_NO_INDICES</samp></dt>
                                       <dd class="dd">Do not compute indices.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_FLATTENED_INDICES</samp></dt>
                                       <dd class="dd">Compute indices. The resulting indices are relative, and flattened.
                                          
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnReduceTensorOp_t"><a name="cudnnReduceTensorOp_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReduceTensorOp_t" name="cudnnReduceTensorOp_t" shape="rect">3.1.2.21.&nbsp;<kbd class="ph userinput">cudnnReduceTensorOp_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnReduceTensorOp_t</samp> is an enumerated type used to indicate the
                                 Tensor Core operation to be used by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensor" shape="rect">cudnnReduceTensor()</a></samp>
                                 routine. This enumerated type is used as a field for the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensorDescriptor_t" shape="rect">cudnnReduceTensorDescriptor_t</a></samp> descriptor. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnReduceTensorOp_t__section_hjp_4fr_2jb"><a name="cudnnReduceTensorOp_t__section_hjp_4fr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_ADD</samp></dt>
                                       <dd class="dd">The operation to be performed is addition.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MUL</samp></dt>
                                       <dd class="dd">The operation to be performed is multiplication.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MIN</samp></dt>
                                       <dd class="dd">The operation to be performed is a minimum comparison.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MAX</samp></dt>
                                       <dd class="dd">The operation to be performed is a maximum comparison. </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_AMAX</samp></dt>
                                       <dd class="dd">The operation to be performed is a maximum comparison of absolute
                                          values.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_AVG</samp></dt>
                                       <dd class="dd">The operation to be performed is averaging.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_NORM1</samp></dt>
                                       <dd class="dd">The operation to be performed is addition of absolute values.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_NORM2</samp></dt>
                                       <dd class="dd">The operation to be performed is a square root of the sum of
                                          squares.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MUL_NO_ZEROS</samp></dt>
                                       <dd class="dd">The operation to be performed is multiplication, not including elements
                                          of value zero.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNAlgo_t"><a name="cudnnRNNAlgo_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNAlgo_t" name="cudnnRNNAlgo_t" shape="rect">3.1.2.22.&nbsp;<kbd class="ph userinput">cudnnRNNAlgo_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNAlgo_t</samp> is an enumerated type used to specify the algorithm
                                 used in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp> routines. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnRNNAlgo_t__section_lmb_qfr_2jb"><a name="cudnnRNNAlgo_t__section_lmb_qfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp></dt>
                                       <dd class="dd">Each RNN layer is executed as a sequence of operations. This algorithm
                                          is expected to have robust performance across a wide range of network
                                          parameters.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp></dt>
                                       <dd class="dd">
                                          <p class="p">The recurrent parts of the network are executed using a <em class="ph i">persistent
                                                kernel</em> approach. This method is expected to be fast when the
                                             first dimension of the input tensor is small (meaning, a small
                                             minibatch). 
                                          </p>
                                          <p class="p"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> is only supported on
                                             devices with compute capability &gt;= 6.0. 
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp></dt>
                                       <dd class="dd">
                                          <p class="p">The recurrent parts of the network are executed using a <em class="ph i">persistent
                                                kernel</em> approach. This method is expected to be fast when the
                                             first dimension of the input tensor is small (meaning, a small
                                             minibatch). When using
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> persistent
                                             kernels are prepared at runtime and are able to optimize using the
                                             specific parameters of the network and active GPU. As such, when
                                             using <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> a one-time
                                             plan preparation stage must be executed. These plans can then be
                                             reused in repeated calls with the same model parameters. 
                                          </p>
                                          <p class="p">The limits on the maximum number of hidden units supported when using
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> are
                                             significantly higher than the limits when using
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>, however
                                             throughput is likely to significantly reduce when exceeding the
                                             maximums supported by
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>. In this regime, this
                                             method will still outperform
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp> for some cases. 
                                          </p>
                                          <p class="p"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is only supported on
                                             devices with compute capability &gt;= 6.0 on Linux machines. 
                                          </p>
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSamplerType_t"><a name="cudnnSamplerType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSamplerType_t" name="cudnnSamplerType_t" shape="rect">3.1.2.23.&nbsp;<kbd class="ph userinput">cudnnSamplerType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnSamplerType_t</samp> is an enumerated type passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSpatialTransformerNdDescriptor" title="This function initializes a previously created generic spatial transformer descriptor object." shape="rect">cudnnSetSpatialTransformerNdDescriptor()</a></samp> to select the sampler
                                 type to be used by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSpatialTfSamplerForward" title="This function performs a sampler operation and generates the output tensor using the grid given by the grid generator." shape="rect">cudnnSpatialTfSamplerForward()</a></samp> and
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnSpatialTfSamplerBackward" title="This function computes the gradient of a sampling operation." shape="rect">cudnnSpatialTfSamplerBackward()</a></samp>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnSamplerType_t__section_ct2_yfr_2jb"><a name="cudnnSamplerType_t__section_ct2_yfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SAMPLER_BILINEAR</samp></dt>
                                       <dd class="dd">Selects the bilinear sampler.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSeverity_t"><a name="cudnnSeverity_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSeverity_t" name="cudnnSeverity_t" shape="rect">3.1.2.24.&nbsp;<kbd class="ph userinput">cudnnSeverity_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnSeverity_t</samp> is an enumerated type passed to the customized
                                    callback function for logging that users may set. This enumerate describes the severity
                                    level of the item, so the customized logging call back may react
                                    differently.</span></div>
                              <div class="section" id="cudnnSeverity_t__section_i52_h2r_2jb"><a name="cudnnSeverity_t__section_i52_h2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEV_FATAL</samp></dt>
                                       <dd class="dd">This value indicates a fatal error emitted by cuDNN.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEV_ERROR</samp></dt>
                                       <dd class="dd">This value indicates a normal error emitted by cuDNN.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEV_WARNING</samp></dt>
                                       <dd class="dd">This value indicates a warning emitted by cuDNN.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEV_INFO</samp></dt>
                                       <dd class="dd">This value indicates a piece of information (for example, API log)
                                          emitted by cuDNN.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSoftmaxAlgorithm_t"><a name="cudnnSoftmaxAlgorithm_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxAlgorithm_t" name="cudnnSoftmaxAlgorithm_t" shape="rect">3.1.2.25.&nbsp;<kbd class="ph userinput">cudnnSoftmaxAlgorithm_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnSoftmaxAlgorithm_t</samp> is used to select an implementation of the
                                 softmax function used in <samp class="ph codeph"><a class="xref" href="index.html#cudnnSoftmaxForward" title="This routine computes the softmax function." shape="rect">cudnnSoftmaxForward()</a></samp> and
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnSoftmaxBackward" title="This routine computes the gradient of the softmax function." shape="rect">cudnnSoftmaxBackward()</a></samp>.  <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnSoftmaxAlgorithm_t__section_hfz_1gr_2jb"><a name="cudnnSoftmaxAlgorithm_t__section_hfz_1gr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SOFTMAX_FAST</samp></dt>
                                       <dd class="dd">This implementation applies the straightforward softmax operation.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SOFTMAX_ACCURATE</samp></dt>
                                       <dd class="dd">This implementation scales each point of the softmax input domain by its
                                          maximum value to avoid potential floating point overflows in the softmax
                                          evaluation.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SOFTMAX_LOG</samp></dt>
                                       <dd class="dd">This entry performs the log softmax operation, avoiding overflows by
                                          scaling each point in the input domain as in
                                          <samp class="ph codeph">CUDNN_SOFTMAX_ACCURATE</samp>.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSoftmaxMode_t"><a name="cudnnSoftmaxMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxMode_t" name="cudnnSoftmaxMode_t" shape="rect">3.1.2.26.&nbsp;<kbd class="ph userinput">cudnnSoftmaxMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnSoftmaxMode_t</samp> is used to select over which data the
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnSoftmaxForward" title="This routine computes the softmax function." shape="rect">cudnnSoftmaxForward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSoftmaxBackward" title="This routine computes the gradient of the softmax function." shape="rect">cudnnSoftmaxBackward()</a></samp> are computing their results.
                                 <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnSoftmaxMode_t__section_z1y_bgr_2jb"><a name="cudnnSoftmaxMode_t__section_z1y_bgr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SOFTMAX_MODE_INSTANCE</samp></dt>
                                       <dd class="dd">The softmax operation is computed per image (<samp class="ph codeph">N</samp>) across
                                          the dimensions <samp class="ph codeph">C,H,W</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SOFTMAX_MODE_CHANNEL</samp></dt>
                                       <dd class="dd">The softmax operation is computed per spatial location
                                          (<samp class="ph codeph">H,W</samp>) per image (<samp class="ph codeph">N</samp>) across
                                          dimension <samp class="ph codeph">C</samp>.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnStatus_t"><a name="cudnnStatus_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnStatus_t" name="cudnnStatus_t" shape="rect">3.1.2.27.&nbsp;<kbd class="ph userinput">cudnnStatus_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnStatus_t</samp> is an enumerated type used for function status
                                    returns. All cuDNN library functions return their status, which can be one of the
                                    following values:</span></div>
                              <div class="section" id="cudnnStatus_t__section_lmp_dgr_2jb"><a name="cudnnStatus_t__section_lmp_dgr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                       <dd class="dd">The operation was completed successfully.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                                       <dd class="dd">The cuDNN library was not initialized properly. This error is usually
                                          returned when a call to <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreate" title="This function initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls." shape="rect">cudnnCreate()</a></samp>
                                          fails or when <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreate" title="This function initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls." shape="rect">cudnnCreate()</a></samp> has not been
                                          called prior to calling another cuDNN routine. In the former case, it is
                                          usually due to an error in the CUDA Runtime API called by <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreate" title="This function initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls." shape="rect">cudnnCreate()</a></samp> or by an error in the hardware
                                          setup.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                       <dd class="dd">
                                          <p class="p">Resource allocation failed inside the cuDNN library. This is usually
                                             caused by an internal <samp class="ph codeph">cudaMalloc()</samp> failure.
                                          </p>
                                          <p class="p">To correct, prior to the function call, deallocate previously
                                             allocated memory as much as possible.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                       <dd class="dd">
                                          <p class="p">An incorrect value or parameter was passed to the function.</p>
                                          <p class="p">To correct, ensure that all the parameters being passed have valid
                                             values.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ARCH_MISMATCH</samp></dt>
                                       <dd class="dd">
                                          <p class="p">The function requires a feature absent from the current GPU device.
                                             Note that cuDNN only supports devices with compute capabilities
                                             greater than or equal to 3.0.
                                          </p>
                                          <p class="p">To correct, compile and run the application on a device with
                                             appropriate compute capability.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                       <dd class="dd">
                                          <p class="p">An access to GPU memory space failed, which is usually caused by a
                                             failure to bind a texture.
                                          </p>
                                          <p class="p">To correct, prior to the function call, unbind any previously bound
                                             textures.
                                          </p>
                                          <p class="p">Otherwise, this may indicate an internal error/bug in the
                                             library.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                       <dd class="dd">
                                          <p class="p">The GPU program failed to execute. This is usually caused by a
                                             failure to launch some cuDNN kernel on the GPU, which can occur for
                                             multiple reasons.
                                          </p>
                                          <p class="p">To correct, check that the hardware, an appropriate version of the
                                             driver, and the cuDNN library are correctly installed.
                                          </p>
                                          <p class="p">Otherwise, this may indicate an internal error/bug in the
                                             library.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                       <dd class="dd">An internal cuDNN operation failed.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                       <dd class="dd">The functionality requested is not presently supported by cuDNN.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_LICENSE_ERROR</samp></dt>
                                       <dd class="dd">The functionality requested requires some license and an error was
                                          detected when trying to check the current licensing. This error can
                                          happen if the license is not present or is expired or if the environment
                                          variable <samp class="ph codeph">NVIDIA_LICENSE_FILE</samp> is not set properly. 
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING</samp></dt>
                                       <dd class="dd">A runtime library required by cuDNN cannot be found in the predefined
                                          search paths. These libraries are <samp class="ph codeph">libcuda.so</samp>
                                          (<samp class="ph codeph">nvcuda.dll</samp>) and <samp class="ph codeph">libnvrtc.so</samp>
                                          (<samp class="ph codeph">nvrtc64_&lt;Major Release Version&gt;&lt;Minor Release
                                             Version&gt;_0.dll</samp> and <samp class="ph codeph">nvrtc-builtins64_&lt;Major
                                             Release Version&gt;&lt;Minor Release Version&gt;.dll</samp>).
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_IN_PROGRESS</samp></dt>
                                       <dd class="dd">Some tasks in the user stream are not completed. </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_FP_OVERFLOW</samp></dt>
                                       <dd class="dd">Numerical overflow occurred during the GPU kernel execution. </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnTensorFormat_t"><a name="cudnnTensorFormat_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTensorFormat_t" name="cudnnTensorFormat_t" shape="rect">3.1.2.28.&nbsp;<kbd class="ph userinput">cudnnTensorFormat_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnTensorFormat_t</samp> is an enumerated type used by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetTensor4dDescriptor" title="This function initializes a previously created generic tensor descriptor object into a 4D tensor. The strides of the four dimensions are inferred from the format parameter and set in such a way that the data is contiguous in memory with no padding between dimensions." shape="rect">cudnnSetTensor4dDescriptor()</a></samp> to create a tensor with a pre-defined
                                 layout. For a detailed explanation of how these tensors are arranged in memory, refer to
                                 <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#data-layout-formats" target="_blank" shape="rect">Data Layout Formats</a>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnTensorFormat_t__section_mt1_fgr_2jb"><a name="cudnnTensorFormat_t__section_mt1_fgr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TENSOR_NCHW</samp></dt>
                                       <dd class="dd">This tensor format specifies that the data is laid out in the following
                                          order: batch size, feature maps, rows, columns. The strides are
                                          implicitly defined in such a way that the data are contiguous in memory
                                          with no padding between images, feature maps, rows, and columns; the
                                          columns are the inner dimension and the images are the outermost
                                          dimension.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TENSOR_NHWC</samp></dt>
                                       <dd class="dd">This tensor format specifies that the data is laid out in the following
                                          order: batch size, rows, columns, feature maps. The strides are
                                          implicitly defined in such a way that the data are contiguous in memory
                                          with no padding between images, rows, columns, and feature maps; the
                                          feature maps are the inner dimension and the images are the outermost
                                          dimension.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp></dt>
                                       <dd class="dd">
                                          <p class="p">This tensor format specifies that the data is laid out in the
                                             following order: batch size, feature maps, rows, columns. However,
                                             each element of the tensor is a vector of multiple feature maps. The
                                             length of the vector is carried by the data type of the tensor. The
                                             strides are implicitly defined in such a way that the data are
                                             contiguous in memory with no padding between images, feature maps,
                                             rows, and columns; the columns are the inner dimension and the
                                             images are the outermost dimension. This format is only supported
                                             with tensor data types <samp class="ph codeph">CUDNN_DATA_INT8x4</samp>,
                                             <samp class="ph codeph">CUDNN_DATA_INT8x32</samp>, and
                                             <samp class="ph codeph">CUDNN_DATA_UINT8x4</samp>. 
                                          </p>
                                          <p class="p">The <samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp> can also be interpreted
                                             in the following way: The NCHW INT8x32 format is really N x (C/32) x
                                             H x W x 32 (32 Cs for every W), just as the NCHW INT8x4 format is N
                                             x (C/4) x H x W x 4 (4 Cs for every W). Hence, the
                                             <samp class="ph codeph">VECT_C</samp> name - each W is a vector (4 or 32) of
                                             Cs. 
                                          </p>
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnn-ops-infer-so-api"><a name="cudnn-ops-infer-so-api" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-ops-infer-so-api" name="cudnn-ops-infer-so-api" shape="rect">3.2.&nbsp;API Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the API functions in the <samp class="ph codeph">cudnn_ops_infer.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnnActivationForward"><a name="cudnnActivationForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationForward" name="cudnnActivationForward" shape="rect">3.2.1.&nbsp;<kbd class="ph userinput">cudnnActivationForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This routine applies a specified neuron activation function element-wise over
                                 each input value.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnActivationForward(
    cudnnHandle_t handle,
    cudnnActivationDescriptor_t     activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y)</pre><p class="p">In-place operation is allowed for this routine; meaning, <samp class="ph codeph">xData</samp> and
                              <samp class="ph codeph">yData</samp> pointers may be equal. However, this requires
                              <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> descriptors to be identical
                              (particularly, the strides of the input and output must match for an in-place operation
                              to be allowed).
                           </p>
                           <p class="p">All tensor formats are supported for 4 and 5 dimensions, however, the best performance is
                              obtained when the strides of <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> are equal
                              and <samp class="ph codeph">HW-packed</samp>. For more than 5 dimensions the tensors must have their
                              spatial dimensions packed.
                           </p>
                           <div class="section" id="cudnnActivationForward__section_drx_rln_y3b"><a name="cudnnActivationForward__section_drx_rln_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Activation descriptor. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*result + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnActivationForward__section_bhm_sln_y3b"><a name="cudnnActivationForward__section_bhm_sln_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnActivationForward__ul_j53_2zh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnActivationForward__ul_j53_2zh_s1b">
                                          <li class="li">The parameter <samp class="ph codeph">mode</samp> has an invalid enumerant
                                             value.
                                          </li>
                                          <li class="li">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                             <samp class="ph codeph">h</samp>, and <samp class="ph codeph">w</samp> of the input
                                             tensor and output tensor differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output
                                             tensor differs.
                                          </li>
                                          <li class="li">The strides <samp class="ph codeph">nStride</samp>, <samp class="ph codeph">cStride</samp>,
                                             <samp class="ph codeph">hStride</samp>, and <samp class="ph codeph">wStride</samp> of
                                             the input tensor and output tensor differ and in-place operation
                                             is used (meaning, <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>
                                             pointers are equal).
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnAddTensor"><a name="cudnnAddTensor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAddTensor" name="cudnnAddTensor" shape="rect">3.2.2.&nbsp;<kbd class="ph userinput">cudnnAddTensor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function adds the scaled values of a bias tensor to another tensor. Each
                                 dimension of the bias tensor <samp class="ph codeph">A</samp> must match the corresponding dimension
                                 of the destination tensor <samp class="ph codeph">C</samp> or must be equal to 1. In the latter case,
                                 the same value from the bias tensor for those dimensions will be used to blend into the
                                 <samp class="ph codeph">C</samp> tensor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnAddTensor(
    cudnnHandle_t                     handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *A,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *C)</pre><p class="p">Only 4D and 5D tensors are supported. Beyond these dimensions, this routine is not
                              supported.
                           </p>
                           <div class="section" id="cudnnAddTensor__section_l1g_xmn_y3b"><a name="cudnnAddTensor__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the source value with the prior value in the destination
                                          tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*srcValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">aDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">A</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">aDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">C</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">cDesc</samp> descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnAddTensor__section_zgs_xmn_y3b"><a name="cudnnAddTensor__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function executed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The dimensions of the bias tensor refer to an amount of data that is
                                       incompatible with the output tensor dimensions or the
                                       <samp class="ph codeph">dataType</samp> of the two tensor descriptors are
                                       different.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBatchNormalizationForwardInference"><a name="cudnnBatchNormalizationForwardInference" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationForwardInference" name="cudnnBatchNormalizationForwardInference" shape="rect">3.2.3.&nbsp;<kbd class="ph userinput">cudnnBatchNormalizationForwardInference()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs the forward batch normalization layer computation for the
                              inference phase. This layer is based on the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network Training
                                 by Reducing Internal Covariate Shift</a> paper. <span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnBatchNormalizationForwardInference(
      cudnnHandle_t                    handle,
      cudnnBatchNormMode_t             mode,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    bnScaleBiasMeanVarDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnScale,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnBias,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *estimatedMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *estimatedVariance,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           epsilon)</pre><p class="p">Only 4D and 5D tensors are supported.</p>
                           <div class="p">The input transformation performed by this function is defined
                              as:<pre xml:space="preserve">y = beta*y + alpha *[bnBias + (bnScale * (x-estimatedMean)/sqrt(epsilon + estimatedVariance)]</pre></div>
                           <p class="p">For the training phase, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp>.
                           </p>
                           <p class="p">Higher performance can be obtained when HW-packed tensors are used for all of
                              <samp class="ph codeph">x</samp> and <samp class="ph codeph">dx</samp>.
                           </p>
                           <p class="p">For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp> for the secondary tensor descriptor generation for the parameters used
                              in this function.
                           </p>
                           <div class="section" id="cudnnBatchNormalizationForwardInference__section_drr_4g4_y3b"><a name="cudnnBatchNormalizationForwardInference__section_drr_4g4_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as follows:
                                          <pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</kbd></pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handles to the previously initialized tensor
                                       descriptors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>, for the layers <samp class="ph codeph">x</samp>
                                       input data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>, for the
                                       <samp class="ph codeph">y</samp>output of the batch normalization layer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp>, <samp class="ph codeph">bnScale</samp>,
                                       <samp class="ph codeph">bnBias</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Tensor descriptors and pointers in device memory for the
                                       batch normalization scale and bias parameters (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network
                                          Training by Reducing Internal Covariate Shift</a> paper, bias is
                                       referred to as beta and scale as gamma).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">estimatedMean</samp>, <samp class="ph codeph">estimatedVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Mean and variance tensors (these have the same descriptor
                                       as the bias and scale). The <samp class="ph codeph">resultRunningMean</samp> and
                                       <samp class="ph codeph">resultRunningVariance</samp>, accumulated during the
                                       training phase from the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp> call,
                                       should be passed as inputs here.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in the batch normalization formula. Its
                                       value should be equal to or greater than the value defined for
                                       <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp> in <samp class="ph codeph">cudnn.h</samp>.
                                       
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationForwardInference__section_kfq_4r2_vlb"><a name="cudnnBatchNormalizationForwardInference__section_kfq_4r2_vlb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <p class="p">This function supports the following combinations of data types for various
                                 descriptors.
                              </p>
                              <div class="tablenoborder"><a name="cudnnBatchNormalizationForwardInference__table_t3s_rr2_vlb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnBatchNormalizationForwardInference__table_t3s_rr2_vlb" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 12. Supported Configurations for
                                          <samp class="ph codeph">cudnnBatchNormalizationForwardInference()</samp></span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="20%" id="d54e8589" rowspan="1" colspan="1">Data Type Configurations</th>
                                          <th class="entry" valign="top" width="20%" id="d54e8592" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                          <th class="entry" valign="top" width="20%" id="d54e8596" rowspan="1" colspan="1"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></th>
                                          <th class="entry" valign="top" width="20%" id="d54e8600" rowspan="1" colspan="1"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></th>
                                          <th class="entry" valign="top" width="20%" id="d54e8607" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e8589" rowspan="1" colspan="1"><samp class="ph codeph">INT8_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8592" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8596" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8600" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8607" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e8589" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8592" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8596" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8600" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8607" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e8589" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8592" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8596" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8600" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8607" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e8589" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8592" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8596" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8600" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8607" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="20%" headers="d54e8589" rowspan="1" colspan="1"><samp class="ph codeph">BFLOAT16_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8592" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8596" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8600" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="20%" headers="d54e8607" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationForwardInference__section_xqr_pg4_y3b"><a name="cudnnBatchNormalizationForwardInference__section_xqr_pg4_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnBatchNormalizationForwardInference__ul_wv1_blg_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardInference__ul_wv1_blg_jt">
                                          <li class="li">One of the pointers <samp class="ph codeph">alpha</samp>,
                                             <samp class="ph codeph">beta</samp>, <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp>, <samp class="ph codeph">bnScale</samp>,
                                             <samp class="ph codeph">bnBias</samp>, <samp class="ph codeph">estimatedMean</samp>, and
                                             <samp class="ph codeph">estimatedInvVariance</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                             tensor descriptor dimensions is not within the range of
                                             <samp class="ph codeph">[4,5]</samp> (only 4D and 5D tensors are
                                             supported.)
                                          </li>
                                          <li class="li"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> dimensions are not
                                             1xCx1x1 for 4D and 1xCx1x1x1 for 5D for spatial, and are not
                                             1xCxHxW for 4D and 1xCxDxHxW for 5D for per-activation
                                             mode.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than
                                             <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp>.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCopyAlgorithmDescriptor"><a name="cudnnCopyAlgorithmDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCopyAlgorithmDescriptor" name="cudnnCopyAlgorithmDescriptor" shape="rect">3.2.4.&nbsp;<kbd class="ph userinput">cudnnCopyAlgorithmDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreate"><a name="cudnnCreate" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreate" name="cudnnCreate" shape="rect">3.2.5.&nbsp;<kbd class="ph userinput">cudnnCreate()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes the cuDNN library and creates a handle to an opaque
                                 structure holding the cuDNN library context. It allocates hardware resources on the host
                                 and device and must be called prior to making any other cuDNN library calls.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreate(cudnnHandle_t *handle)</pre><p class="p">The cuDNN library handle is tied to the current CUDA device (context). To use the library
                              on multiple devices, one cuDNN handle needs to be created for each device. 
                           </p>
                           <p class="p">For a given device, multiple cuDNN handles with different configurations (for example,
                              different current CUDA streams) may be created. Because <samp class="ph codeph">cudnnCreate()</samp>
                              allocates some internal resources, the release of those resources by calling
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroy" shape="rect">cudnnDestroy()</a></samp> will implicitly call
                              <samp class="ph codeph"><a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" target="_blank" shape="rect">cudaDeviceSynchronize()</a></samp>;
                              therefore, the recommended best practice is to call
                              <samp class="ph codeph">cudnnCreate/cudnnDestroy</samp> outside of performance-critical code
                              paths. 
                           </p>
                           <p class="p">For multithreaded applications that use the same device from different threads, the
                              recommended programming model is to create one (or a few, as is convenient) cuDNN
                              handle(s) per thread and use that cuDNN handle for the entire life of the thread. 
                           </p>
                           <div class="section" id="cudnnCreate__section_bdj_mvb_z3b"><a name="cudnnCreate__section_bdj_mvb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to pointer where to store the address to the
                                       allocated cuDNN handle. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreate__section_uj5_mvb_z3b"><a name="cudnnCreate__section_uj5_mvb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid (<samp class="ph codeph">NULL</samp>) input pointer supplied.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                                    <dd class="dd">No compatible GPU found, CUDA driver not installed or disabled, CUDA
                                       runtime API initialization failed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ARCH_MISMATCH</samp></dt>
                                    <dd class="dd">NVIDIA GPU architecture is too old.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">Host memory allocation failed.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">CUDA resource allocation failed.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_LICENSE_ERROR</samp></dt>
                                    <dd class="dd">cuDNN license validation failed (only when the feature is enabled).</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">cuDNN handle was created successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateActivationDescriptor"><a name="cudnnCreateActivationDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateActivationDescriptor" name="cudnnCreateActivationDescriptor" shape="rect">3.2.6.&nbsp;<kbd class="ph userinput">cudnnCreateActivationDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function creates an activation descriptor object by allocating the memory needed
                              to hold its opaque structure. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a></samp>.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateActivationDescriptor(
        cudnnActivationDescriptor_t   *activationDesc)</pre><div class="section" id="cudnnCreateActivationDescriptor__section_htk_bwb_z3b"><a name="cudnnCreateActivationDescriptor__section_htk_bwb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateAlgorithmDescriptor"><a name="cudnnCreateAlgorithmDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateAlgorithmDescriptor" name="cudnnCreateAlgorithmDescriptor" shape="rect">3.2.7.&nbsp;<kbd class="ph userinput">cudnnCreateAlgorithmDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function creates an algorithm descriptor object by allocating the memory needed to
                              hold its opaque structure.
                           </p><pre xml:space="preserve">cudnnStatus_t cudnnCreateAlgorithmDescriptor(
    cudnnAlgorithmDescriptor_t *algoDesc)</pre><div class="section" id="cudnnCreateAlgorithmDescriptor__section_fxg_cwb_z3b"><a name="cudnnCreateAlgorithmDescriptor__section_fxg_cwb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateAlgorithmPerformance"><a name="cudnnCreateAlgorithmPerformance" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateAlgorithmPerformance" name="cudnnCreateAlgorithmPerformance" shape="rect">3.2.8.&nbsp;<kbd class="ph userinput">cudnnCreateAlgorithmPerformance()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates multiple algorithm performance objects by allocating the
                                 memory needed to hold their opaque structures.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateAlgorithmPerformance(
    cudnnAlgorithmPerformance_t *algoPerf,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         numberToCreate)</pre><div class="section" id="cudnnCreateAlgorithmPerformance__section_ekq_fwb_z3b"><a name="cudnnCreateAlgorithmPerformance__section_ekq_fwb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateDropoutDescriptor"><a name="cudnnCreateDropoutDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateDropoutDescriptor" name="cudnnCreateDropoutDescriptor" shape="rect">3.2.9.&nbsp;<kbd class="ph userinput">cudnnCreateDropoutDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function creates a generic dropout descriptor object by allocating the memory
                              needed to hold its opaque structure. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutDescriptor_t" shape="rect">cudnnDropoutDescriptor_t</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateDropoutDescriptor(
    cudnnDropoutDescriptor_t    *dropoutDesc)</pre><div class="section" id="cudnnCreateDropoutDescriptor__section_sjj_mxb_z3b"><a name="cudnnCreateDropoutDescriptor__section_sjj_mxb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateFilterDescriptor"><a name="cudnnCreateFilterDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFilterDescriptor" name="cudnnCreateFilterDescriptor" shape="rect">3.2.10.&nbsp;<kbd class="ph userinput">cudnnCreateFilterDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function creates a filter descriptor object by allocating the memory needed to
                              hold its opaque structure. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a></samp>.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFilterDescriptor(
    cudnnFilterDescriptor_t *filterDesc)</pre><div class="section" id="cudnnCreateFilterDescriptor__section_zqs_qxb_z3b"><a name="cudnnCreateFilterDescriptor__section_zqs_qxb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateLRNDescriptor"><a name="cudnnCreateLRNDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateLRNDescriptor" name="cudnnCreateLRNDescriptor" shape="rect">3.2.11.&nbsp;<kbd class="ph userinput">cudnnCreateLRNDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function allocates the memory needed to hold the data needed for LRN and
                                 <samp class="ph codeph">DivisiveNormalization</samp> layers operation and returns a descriptor
                                 used with subsequent layer forward and backward calls. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateLRNDescriptor(
            cudnnLRNDescriptor_t    *poolingDesc)</pre><div class="section" id="cudnnCreateLRNDescriptor__section_lyc_tjc_z3b"><a name="cudnnCreateLRNDescriptor__section_lyc_tjc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateOpTensorDescriptors"><a name="cudnnCreateOpTensorDescriptors" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateOpTensorDescriptors" name="cudnnCreateOpTensorDescriptors" shape="rect"><kbd class="ph userinput">cudnnCreateOpTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function creates a tensor pointwise math descriptor. For more information, refer
                              to <samp class="ph codeph"><a class="xref" href="index.html#cudnnOpTensorDescriptor_t" shape="rect">cudnnOpTensorDescriptor_t</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateOpTensorDescriptor(
    cudnnOpTensorDescriptor_t* 	opTensorDesc)</pre><div class="section" id="cudnnCreateOpTensorDescriptors__section_jlb_1kc_z3b"><a name="cudnnCreateOpTensorDescriptors__section_jlb_1kc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the structure holding the description of the
                                       tensor pointwise math such as add, multiply, and more.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateOpTensorDescriptors__section_n4g_dkc_z3b"><a name="cudnnCreateOpTensorDescriptors__section_n4g_dkc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Tensor pointwise math descriptor passed to the function is invalid.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">Memory allocation for this tensor pointwise math descriptor failed.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreatePoolingDescriptor"><a name="cudnnCreatePoolingDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreatePoolingDescriptor" name="cudnnCreatePoolingDescriptor" shape="rect">3.2.13.&nbsp;<kbd class="ph userinput">cudnnCreatePoolingDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function creates a pooling descriptor object by allocating the memory needed to
                              hold its opaque structure. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreatePoolingDescriptor(
    cudnnPoolingDescriptor_t    *poolingDesc)</pre><div class="section" id="cudnnCreatePoolingDescriptor__section_r43_pkc_z3b"><a name="cudnnCreatePoolingDescriptor__section_r43_pkc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateReduceTensorDescriptor"><a name="cudnnCreateReduceTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateReduceTensorDescriptor" name="cudnnCreateReduceTensorDescriptor" shape="rect">3.2.14.&nbsp;<kbd class="ph userinput">cudnnCreateReduceTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates a reduced tensor descriptor object by allocating the memory
                                 needed to hold its opaque structure.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateReduceTensorDescriptor(
	cudnnReduceTensorDescriptor_t*	reduceTensorDesc)</pre><div class="section" id="cudnnCreateReduceTensorDescriptor__section_rgm_tkc_z3b"><a name="cudnnCreateReduceTensorDescriptor__section_rgm_tkc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">reduceTensorDesc</samp> is a <samp class="ph codeph">NULL</samp>
                                       pointer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateSpatialTransformerDescriptor"><a name="cudnnCreateSpatialTransformerDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateSpatialTransformerDescriptor" name="cudnnCreateSpatialTransformerDescriptor" shape="rect">3.2.15.&nbsp;<kbd class="ph userinput">cudnnCreateSpatialTransformerDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates a generic spatial transformer descriptor object by
                                 allocating the memory needed to hold its opaque structure.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateSpatialTransformerDescriptor(
    cudnnSpatialTransformerDescriptor_t *stDesc)</pre><div class="section" id="cudnnCreateSpatialTransformerDescriptor__section_eys_rlc_z3b"><a name="cudnnCreateSpatialTransformerDescriptor__section_eys_rlc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateTensorDescriptor"><a name="cudnnCreateTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateTensorDescriptor" name="cudnnCreateTensorDescriptor" shape="rect">3.2.16.&nbsp;<kbd class="ph userinput">cudnnCreateTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates a generic tensor descriptor object by allocating the memory
                                 needed to hold its opaque structure. The data is initialized to all zeros.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateTensorDescriptor(
    cudnnTensorDescriptor_t *tensorDesc)</pre><div class="section" id="cudnnCreateTensorDescriptor__section_fjp_wlc_z3b"><a name="cudnnCreateTensorDescriptor__section_fjp_wlc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to pointer where the address to the allocated
                                       tensor descriptor object should be stored.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateTensorDescriptor__section_k31_xlc_z3b"><a name="cudnnCreateTensorDescriptor__section_k31_xlc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid input argument.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateTensorTransformDescriptor"><a name="cudnnCreateTensorTransformDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateTensorTransformDescriptor" name="cudnnCreateTensorTransformDescriptor" shape="rect">3.2.17.&nbsp;<kbd class="ph userinput">cudnnCreateTensorTransformDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function creates a tensor transform descriptor object by allocating the memory
                              		needed to hold its opaque structure. The tensor data is initialized to be all zero. Use the
                              				<samp class="ph codeph"><a class="xref" href="index.html#cudnnSetTensorTransformDescriptor" shape="rect">cudnnSetTensorTransformDescriptor()</a></samp> function to
                              		initialize the descriptor created by this function. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t *transformDesc);
</pre><div class="section" id="cudnnCreateTensorTransformDescriptor__section_rgb_2mc_z3b"><a name="cudnnCreateTensorTransformDescriptor__section_rgb_2mc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transformDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A pointer to an uninitialized tensor transform
                                       							descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateTensorTransformDescriptor__section_km3_nmc_z3b"><a name="cudnnCreateTensorTransformDescriptor__section_km3_nmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">transformDesc</samp> is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The memory allocation failed.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDeriveBNTensorDescriptor"><a name="cudnnDeriveBNTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDeriveBNTensorDescriptor" name="cudnnDeriveBNTensorDescriptor" shape="rect">3.2.18.&nbsp;<kbd class="ph userinput">cudnnDeriveBNTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function derives a secondary tensor descriptor for the batch normalization
                                 <samp class="ph codeph">scale</samp>, <samp class="ph codeph">invVariance</samp>, <samp class="ph codeph">bnBias</samp>, and
                                 <samp class="ph codeph">bnScale</samp> subtensors from the layer's <samp class="ph codeph">x</samp> data
                                 descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDeriveBNTensorDescriptor(
    cudnnTensorDescriptor_t         derivedBnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    cudnnBatchNormMode_t            mode)</pre><p class="p">Use the tensor descriptor produced by this function as the
                              <samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> parameter for the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardInference" shape="rect">cudnnBatchNormalizationForwardInference()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp> functions, and as the
                              <samp class="ph codeph">bnScaleBiasDiffDesc</samp> parameter in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> function. 
                           </p>
                           <div class="p">The resulting dimensions will be:<a name="cudnnDeriveBNTensorDescriptor__ul_dxq_gzc_z3b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDeriveBNTensorDescriptor__ul_dxq_gzc_z3b">
                                 <li class="li">1xCx1x1 for 4D and 1xCx1x1x1 for 5D for
                                    <samp class="ph codeph">BATCHNORM_MODE_SPATIAL</samp></li>
                                 <li class="li">1xCxHxW for 4D and 1xCxDxHxW for 5D for
                                    <samp class="ph codeph">BATCHNORM_MODE_PER_ACTIVATION</samp> mode
                                 </li>
                              </ul>
                           </div>
                           <div class="p">For <samp class="ph codeph">HALF</samp> input data type the resulting tensor descriptor will have a
                              <samp class="ph codeph">FLOAT</samp> type. For other data types, it will have the same type as the
                              input data.
                              <div class="note note"><span class="notetitle">Note:</span><a name="cudnnDeriveBNTensorDescriptor__ul_kbz_mzc_z3b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnDeriveBNTensorDescriptor__ul_kbz_mzc_z3b">
                                    <li class="li">Only 4D and 5D tensors are supported.</li>
                                    <li class="li">The <samp class="ph codeph">derivedBnDesc</samp> should be first created using
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateTensorDescriptor" title="This function creates a generic tensor descriptor object by allocating the memory needed to hold its opaque structure. The data is initialized to all zeros." shape="rect">cudnnCreateTensorDescriptor()</a></samp>.
                                    </li>
                                    <li class="li"><samp class="ph codeph">xDesc</samp> is the descriptor for the layer's <samp class="ph codeph">x</samp>
                                       data and has to be set up with proper dimensions prior to calling this
                                       function.
                                    </li>
                                 </ul>
                              </div>
                           </div>
                           <div class="section" id="cudnnDeriveBNTensorDescriptor__section_j3r_pzc_z3b"><a name="cudnnDeriveBNTensorDescriptor__section_j3r_pzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">derivedBnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created and initialized layer's
                                       <samp class="ph codeph">x</samp> data descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Batch normalization layer mode of operation. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDeriveBNTensorDescriptor__section_nqb_qzc_z3b"><a name="cudnnDeriveBNTensorDescriptor__section_nqb_qzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid batch normalization mode.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDeriveNormTensorDescriptor"><a name="cudnnDeriveNormTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDeriveNormTensorDescriptor" name="cudnnDeriveNormTensorDescriptor" shape="rect">3.2.19.&nbsp;<kbd class="ph userinput">cudnnDeriveNormTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function derives tensor descriptors for the normalization
                                 <samp class="ph codeph">mean</samp>, <samp class="ph codeph">invariance</samp>, <samp class="ph codeph">normBias</samp>, and
                                 <samp class="ph codeph">normScale</samp> subtensors from the layer's <samp class="ph codeph">x</samp> data
                                 descriptor and norm mode. <samp class="ph codeph">normalization</samp>, <samp class="ph codeph">mean</samp>, and
                                 <samp class="ph codeph">invariance</samp> share the same descriptor while <samp class="ph codeph">bias</samp>
                                 and <samp class="ph codeph">scale</samp> share the same descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t CUDNNWINAPI
cudnnDeriveNormTensorDescriptor(cudnnTensorDescriptor_t derivedNormScaleBiasDesc,
                                cudnnTensorDescriptor_t derivedNormMeanVarDesc,
                                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t xDesc,
   	                         cudnnNormMode_t mode,
                                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> groupCnt)
</pre><p class="p">Use the tensor descriptor produced by this function as the
                              <samp class="ph codeph">normScaleBiasDesc</samp> or <samp class="ph codeph">normMeanVarDesc</samp> parameter for
                              the <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardInference" shape="rect">cudnnNormalizationForwardInference()</a></samp> and
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp> functions,
                              and as the <samp class="ph codeph">dNormScaleBiasDesc</samp> and <samp class="ph codeph">normMeanVarDesc</samp>
                              parameters in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationBackward" shape="rect">cudnnNormalizationBackward()</a></samp>
                              function.
                           </p>
                           <div class="p">The resulting dimensions will be:<a name="cudnnDeriveNormTensorDescriptor__ul_pmm_js2_vlb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDeriveNormTensorDescriptor__ul_pmm_js2_vlb">
                                 <li class="li">1xCx1x1 for 4D and 1xCx1x1x1 for 5D for
                                    <samp class="ph codeph">CUDNN_NORM_PER_ACTIVATION</samp></li>
                                 <li class="li">1xCxHxW for 4D and 1xCxDxHxW for 5D for <samp class="ph codeph">CUDNN_NORM_PER_CHANNEL</samp>
                                    mode
                                 </li>
                              </ul>
                           </div>
                           <div class="p">For <samp class="ph codeph">HALF</samp> input data type the resulting tensor descriptor will have a
                              <samp class="ph codeph">FLOAT</samp> type. For other data types, it will have the same type as the
                              input data.<a name="cudnnDeriveNormTensorDescriptor__ul_ims_ls2_vlb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDeriveNormTensorDescriptor__ul_ims_ls2_vlb">
                                 <li class="li">Only 4D and 5D tensors are supported.</li>
                                 <li class="li">The <samp class="ph codeph">derivedNormScaleBiasDesc</samp> and
                                    <samp class="ph codeph">derivedNormMeanVarDesc</samp> should be created first using
                                    <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateTensorDescriptor" title="This function creates a generic tensor descriptor object by allocating the memory needed to hold its opaque structure. The data is initialized to all zeros." shape="rect">cudnnCreateTensorDescriptor()</a></samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> is the descriptor for the layer's <samp class="ph codeph">x</samp> data
                                    and has to be set up with proper dimensions prior to calling this function.
                                 </li>
                              </ul>
                           </div>
                           <div class="section" id="cudnnDeriveNormTensorDescriptor__section_kz3_xmc_z3b"><a name="cudnnDeriveNormTensorDescriptor__section_kz3_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">derivedNormScaleBiasDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">derivedNormMeanVarDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created and initialized layer's
                                       <samp class="ph codeph">x</samp> data descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The normalization layer mode of operation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">groupCnt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of grouped convolutions. Currently, only
                                       <samp class="ph codeph">1</samp> is supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDeriveNormTensorDescriptor__section_xs5_xmc_z3b"><a name="cudnnDeriveNormTensorDescriptor__section_xs5_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid batch normalization mode.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroy"><a name="cudnnDestroy" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroy" name="cudnnDestroy" shape="rect">3.2.20.&nbsp;<kbd class="ph userinput">cudnnDestroy()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function releases the resources used by the cuDNN handle. Because <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreate" title="This function initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls." shape="rect">cudnnCreate()</a></samp> allocates some internal resources, the release of
                              those resources by calling <samp class="ph codeph">cudnnDestroy()</samp> will implicitly call
                              <samp class="ph codeph"><a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" target="_blank" shape="rect">cudaDeviceSynchronize()</a></samp>; therefore,
                              the recommended best practice is to call <samp class="ph codeph">cudnnCreate/cudnnDestroy</samp> outside
                              of performance-critical code paths and before any CUDA context destroy
                              operation. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroy(cudnnHandle_t handle)</pre><div class="section" id="cudnnDestroy__section_ckg_xzc_z3b"><a name="cudnnDestroy__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The cuDNN handle to be destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroy__section_zpy_xzc_z3b"><a name="cudnnDestroy__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The cuDNN context destruction was successful.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyActivationDescriptor"><a name="cudnnDestroyActivationDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyActivationDescriptor" name="cudnnDestroyActivationDescriptor" shape="rect">3.2.21.&nbsp;<kbd class="ph userinput">cudnnDestroyActivationDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created activation descriptor object. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyActivationDescriptor(
        cudnnActivationDescriptor_t activationDesc)</pre><div class="section" id="cudnnDestroyActivationDescriptor__section_yzs_11d_z3b"><a name="cudnnDestroyActivationDescriptor__section_yzs_11d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyAlgorithmDescriptor"><a name="cudnnDestroyAlgorithmDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyAlgorithmDescriptor" name="cudnnDestroyAlgorithmDescriptor" shape="rect">3.2.22.&nbsp;<kbd class="ph userinput">cudnnDestroyAlgorithmDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function destroys a previously created algorithm descriptor object.</p><pre xml:space="preserve">cudnnStatus_t cudnnDestroyAlgorithmDescriptor(
        cudnnActivationDescriptor_t algorithmDesc)</pre><div class="section" id="cudnnDestroyAlgorithmDescriptor__section_jns_21d_z3b"><a name="cudnnDestroyAlgorithmDescriptor__section_jns_21d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyAlgorithmPerformance"><a name="cudnnDestroyAlgorithmPerformance" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyAlgorithmPerformance" name="cudnnDestroyAlgorithmPerformance" shape="rect">3.2.23.&nbsp;<kbd class="ph userinput">cudnnDestroyAlgorithmPerformance()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created algorithm descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyAlgorithmPerformance(
        cudnnAlgorithmPerformance_t     algoPerf)</pre><div class="section" id="cudnnDestroyAlgorithmPerformance__section_qys_g1d_z3b"><a name="cudnnDestroyAlgorithmPerformance__section_qys_g1d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyDropoutDescriptor"><a name="cudnnDestroyDropoutDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyDropoutDescriptor" name="cudnnDestroyDropoutDescriptor" shape="rect">3.2.24.&nbsp;<kbd class="ph userinput">cudnnDestroyDropoutDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created dropout descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyDropoutDescriptor(
    cudnnDropoutDescriptor_t dropoutDesc)</pre><div class="section" id="cudnnDestroyDropoutDescriptor__section_k2q_fbd_z3b"><a name="cudnnDestroyDropoutDescriptor__section_k2q_fbd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyFilterDescriptor"><a name="cudnnDestroyFilterDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFilterDescriptor" name="cudnnDestroyFilterDescriptor" shape="rect">3.2.25.&nbsp;<kbd class="ph userinput">cudnnDestroyFilterDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a filter object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFilterDescriptor(
    cudnnFilterDescriptor_t filterDesc)</pre><div class="section" id="cudnnDestroyFilterDescriptor__section_rz5_hbd_z3b"><a name="cudnnDestroyFilterDescriptor__section_rz5_hbd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyLRNDescriptor"><a name="cudnnDestroyLRNDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyLRNDescriptor" name="cudnnDestroyLRNDescriptor" shape="rect">3.2.26.&nbsp;<kbd class="ph userinput">cudnnDestroyLRNDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created LRN descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyLRNDescriptor(
    cudnnLRNDescriptor_t lrnDesc)</pre><div class="section" id="cudnnDestroyLRNDescriptor__section_ihf_5cd_z3b"><a name="cudnnDestroyLRNDescriptor__section_ihf_5cd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyOpTensorDescriptor"><a name="cudnnDestroyOpTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyOpTensorDescriptor" name="cudnnDestroyOpTensorDescriptor" shape="rect">3.2.27.&nbsp;<kbd class="ph userinput">cudnnDestroyOpTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function deletes a tensor pointwise math descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyOpTensorDescriptor(
    cudnnOpTensorDescriptor_t   opTensorDesc)</pre><div class="section" id="cudnnDestroyOpTensorDescriptor__section_zlt_wcd_z3b"><a name="cudnnDestroyOpTensorDescriptor__section_zlt_wcd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the structure holding the description of the
                                       tensor pointwise math to be deleted.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyOpTensorDescriptor__section_dpn_xcd_z3b"><a name="cudnnDestroyOpTensorDescriptor__section_dpn_xcd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyPoolingDescriptor"><a name="cudnnDestroyPoolingDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyPoolingDescriptor" name="cudnnDestroyPoolingDescriptor" shape="rect">3.2.28.&nbsp;<kbd class="ph userinput">cudnnDestroyPoolingDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created pooling descriptor object. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyPoolingDescriptor(
    cudnnPoolingDescriptor_t poolingDesc)</pre><div class="section" id="cudnnDestroyPoolingDescriptor__section_stn_cdd_z3b"><a name="cudnnDestroyPoolingDescriptor__section_stn_cdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyReduceTensorDescriptor"><a name="cudnnDestroyReduceTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyReduceTensorDescriptor" name="cudnnDestroyReduceTensorDescriptor" shape="rect">3.2.29.&nbsp;<kbd class="ph userinput">cudnnDestroyReduceTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created reduce tensor descriptor object. When
                                 the input pointer is <samp class="ph codeph">NULL</samp>, this function performs no destroy
                                 operation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyReduceTensorDescriptor(
    cudnnReduceTensorDescriptor_t   tensorDesc)</pre><div class="section" id="cudnnDestroyReduceTensorDescriptor__section_lqb_hdd_z3b"><a name="cudnnDestroyReduceTensorDescriptor__section_lqb_hdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the reduce tensor descriptor object to be
                                       destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyReduceTensorDescriptor__section_ngm_hdd_z3b"><a name="cudnnDestroyReduceTensorDescriptor__section_ngm_hdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroySpatialTransformerDescriptor"><a name="cudnnDestroySpatialTransformerDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroySpatialTransformerDescriptor" name="cudnnDestroySpatialTransformerDescriptor" shape="rect">3.2.30.&nbsp;<kbd class="ph userinput">cudnnDestroySpatialTransformerDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created spatial transformer descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroySpatialTransformerDescriptor(
    cudnnSpatialTransformerDescriptor_t stDesc)</pre><div class="section" id="cudnnDestroySpatialTransformerDescriptor__section_krk_xdd_z3b"><a name="cudnnDestroySpatialTransformerDescriptor__section_krk_xdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyTensorDescriptor"><a name="cudnnDestroyTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyTensorDescriptor" name="cudnnDestroyTensorDescriptor" shape="rect">3.2.31.&nbsp;<kbd class="ph userinput">cudnnDestroyTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created tensor descriptor object. When the
                                 input pointer is <samp class="ph codeph">NULL</samp>, this function performs no destroy
                                 operation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyTensorDescriptor(cudnnTensorDescriptor_t tensorDesc)</pre><div class="section" id="cudnnDestroyTensorDescriptor__section_ft2_zdd_z3b"><a name="cudnnDestroyTensorDescriptor__section_ft2_zdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the tensor descriptor object to be
                                       destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyTensorDescriptor__section_z45_12d_z3b"><a name="cudnnDestroyTensorDescriptor__section_z45_12d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyTensorTransformDescriptor"><a name="cudnnDestroyTensorTransformDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyTensorTransformDescriptor" name="cudnnDestroyTensorTransformDescriptor" shape="rect">3.2.32.&nbsp;<kbd class="ph userinput">cudnnDestroyTensorTransformDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Destroys a previously created tensor transform descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t transformDesc);
</pre><div class="section" id="cudnnDestroyTensorTransformDescriptor__section_utt_f2d_z3b"><a name="cudnnDestroyTensorTransformDescriptor__section_utt_f2d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transformDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The tensor transform descriptor to be destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyTensorTransformDescriptor__section_tr2_g2d_z3b"><a name="cudnnDestroyTensorTransformDescriptor__section_tr2_g2d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDivisiveNormalizationForward"><a name="cudnnDivisiveNormalizationForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDivisiveNormalizationForward" name="cudnnDivisiveNormalizationForward" shape="rect">3.2.33.&nbsp;<kbd class="ph userinput">cudnnDivisiveNormalizationForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs the forward spatial <samp class="ph codeph">DivisiveNormalization</samp>
                              layer computation. It divides every value in a layer by the standard deviation of its
                              spatial neighbors as described in the  <a class="xref" href="http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf" target="_blank" shape="rect">What
                                 is the Best Multi-Stage Architecture for Object Recognition</a> paper. Note that
                              <samp class="ph codeph">DivisiveNormalization</samp> only implements the <samp class="ph codeph">x/max(c,
                                 sigma_x)</samp> portion of the computation, where <samp class="ph codeph">sigma_x</samp> is the
                              variance over the spatial neighborhood of <samp class="ph codeph">x</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnDivisiveNormalizationForward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnDivNormMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *means,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><div class="p">The full LCN (Local Contrastive Normalization) computation can be implemented as a
                              two-step
                              process:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">x_m = x-mean(x);
y = x_m/max(c, sigma(x_m));
</kbd></pre></div>
                           <div class="p">The <samp class="ph codeph">x-mean(x)</samp> which is often referred to as "subtractive normalization"
                              portion of the computation can be implemented using cuDNN average pooling layer followed
                              by a call to <samp class="ph codeph">addTensor</samp>.
                              <div class="note note"><span class="notetitle">Note:</span> Supported tensor formats are NCHW for 4D
                                 and NCDHW for 5D with any non-overlapping non-negative strides. Only 4D and 5D
                                 tensors are supported. 
                              </div>
                           </div>
                           <div class="section" id="cudnnDivisiveNormalizationForward__section_xk2_rch_z3b"><a name="cudnnDivisiveNormalizationForward__section_xk2_rch_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized LRN parameter
                                       descriptor. This descriptor is used for both LRN and
                                       <samp class="ph codeph">DivisiveNormalization</samp> layers.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">divNormMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. <samp class="ph codeph">DivisiveNormalization</samp> layer mode of
                                       operation. Currently only
                                       <samp class="ph codeph">CUDNN_DIVNORM_PRECOMPUTED_MEANS</samp> is implemented.
                                       Normalization is performed using the means input tensor that is expected
                                       to be precomputed by the user.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor objects for the input and output
                                       tensors. Note that <samp class="ph codeph">xDesc</samp> is shared between
                                       <samp class="ph codeph">x</samp>, <samp class="ph codeph">means</samp>, <samp class="ph codeph">temp</samp>,
                                       and <samp class="ph codeph">temp2</samp> tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Input tensor data pointer in device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">means</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Input means tensor data pointer in device memory. Note
                                       that this tensor can be <samp class="ph codeph">NULL</samp> (in that case its values
                                       are assumed to be zero during the computation). This tensor also doesn't
                                       have to contain <samp class="ph codeph">means</samp>, these can be any values, a
                                       frequently used variation is a result of convolution with a normalized
                                       positive kernel (such as Gaussian).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">temp</samp>, <samp class="ph codeph">temp2</samp></dt>
                                    <dd class="dd"><em class="ph i">Workspace</em>. Temporary tensors in device memory. These are used for
                                       computing intermediate values during the forward pass. These tensors do
                                       not have to be preserved as inputs from forward to the backward pass.
                                       Both use <samp class="ph codeph">xDesc</samp> as their descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer in device memory to a tensor for the result of
                                       the forward <samp class="ph codeph">DivisiveNormalization</samp> computation.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDivisiveNormalizationForward__section_onp_rch_z3b"><a name="cudnnDivisiveNormalizationForward__section_onp_rch_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnDivisiveNormalizationForward__ul_oh5_bb3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnDivisiveNormalizationForward__ul_oh5_bb3_s1b">
                                          <li class="li">One of the tensor pointers <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp>, <samp class="ph codeph">temp</samp>, and
                                             <samp class="ph codeph">temp2</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Number of input tensor or output tensor dimensions is outside of
                                             <samp class="ph codeph">[4,5]</samp> range.
                                          </li>
                                          <li class="li">A mismatch in dimensions between any two of the input or output
                                             tensors.
                                          </li>
                                          <li class="li">For in-place computation when pointers <samp class="ph codeph">x == y</samp>,
                                             a mismatch in strides between the input data and output data
                                             tensors.
                                          </li>
                                          <li class="li">Alpha or beta pointer is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">LRN descriptor parameters are outside of their valid
                                             ranges.
                                          </li>
                                          <li class="li">Any of the tensor strides are negative.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_UNSUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration, for example,
                                       any of the input and output tensor strides mismatch (for the same
                                       dimension) is a non-supported configuration.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDropoutForward"><a name="cudnnDropoutForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutForward" name="cudnnDropoutForward" shape="rect">3.2.34.&nbsp;<kbd class="ph userinput">cudnnDropoutForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs forward dropout operation over <samp class="ph codeph">x</samp> returning
                              results in <samp class="ph codeph">y</samp>. If <samp class="ph codeph">dropout</samp> was used as a parameter to
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetDropoutDescriptor" title="This function initializes a previously created dropout descriptor object. If the states argument is equal to NULL, then the random number generator states won't be initialized, and only the dropout value will be set. The user is expected not to change the memory pointed at by states for the duration of the computation." shape="rect">cudnnSetDropoutDescriptor()</a></samp>, the approximate
                              <samp class="ph codeph">dropout</samp> fraction of <samp class="ph codeph">x</samp> values will be replaced by a
                              <samp class="ph codeph">0</samp>, and the rest will be scaled by <samp class="ph codeph">1/(1-dropout)</samp>. This
                              function should not be running concurrently with another
                              <samp class="ph codeph">cudnnDropoutForward()</samp> function using the same
                              <samp class="ph codeph">states</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutForward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnDropoutDescriptor_t      dropoutDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xdesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       ydesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *reserveSpace,
    size_t                              reserveSpaceSizeInBytes)</pre><div class="note note"><span class="notetitle">Note:</span><a name="cudnnDropoutForward__ul_tnl_p2h_z3b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDropoutForward__ul_tnl_p2h_z3b">
                                 <li class="li">Better performance is obtained for fully packed tensors.</li>
                                 <li class="li">This function should not be called during inference.</li>
                              </ul>
                           </div>
                           <div class="section" id="cudnnDropoutForward__section_zh3_t2h_z3b"><a name="cudnnDropoutForward__section_zh3_t2h_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously created dropout descriptor object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">xDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">yDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to user-allocated GPU memory used by this
                                       function. It is expected that the contents of
                                       <samp class="ph codeph">reserveSpace</samp> does not change between
                                       <samp class="ph codeph">cudnnDropoutForward()</samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutBackward" title="This function performs backward dropout operation over dy returning results in dx. If during forward dropout operation value from x was propagated to y then during backward operation value from dy will be propagated to dx, otherwise, dx value will be set to 0." shape="rect">cudnnDropoutBackward()</a></samp> calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided memory for the
                                       reserve space.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDropoutForward__section_kst_t2h_z3b"><a name="cudnnDropoutForward__section_kst_t2h_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnDropoutForward__ul_gwh_ph3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnDropoutForward__ul_gwh_ph3_s1b">
                                          <li class="li">The number of elements of input tensor and output tensors
                                             differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output
                                             tensors differs.
                                          </li>
                                          <li class="li">The strides of the input tensor and output tensors differ and
                                             in-place operation is used (meaning, <samp class="ph codeph">x</samp> and
                                             <samp class="ph codeph">y</samp> pointers are equal).
                                          </li>
                                          <li class="li">The provided <samp class="ph codeph">reserveSpaceSizeInBytes</samp> is less
                                             than the value returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutGetReserveSpaceSize" shape="rect">cudnnDropoutGetReserveSpaceSize()</a></samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetDropoutDescriptor" title="This function initializes a previously created dropout descriptor object. If the states argument is equal to NULL, then the random number generator states won't be initialized, and only the dropout value will be set. The user is expected not to change the memory pointed at by states for the duration of the computation." shape="rect">cudnnSetDropoutDescriptor()</a></samp> has
                                             not been called on <samp class="ph codeph">dropoutDesc</samp> with the
                                             non-<samp class="ph codeph">NULL</samp><samp class="ph codeph">states</samp> argument.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDropoutGetReserveSpaceSize"><a name="cudnnDropoutGetReserveSpaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutGetReserveSpaceSize" name="cudnnDropoutGetReserveSpaceSize" shape="rect">3.2.35.&nbsp;<kbd class="ph userinput">cudnnDropoutGetReserveSpaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function is used to query the amount of reserve needed to run dropout with the
                              input dimensions given by <samp class="ph codeph">xDesc</samp>. The same reserve space is expected to be
                              passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutForward" shape="rect">cudnnDropoutForward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutBackward" title="This function performs backward dropout operation over dy returning results in dx. If during forward dropout operation value from x was propagated to y then during backward operation value from dy will be propagated to dx, otherwise, dx value will be set to 0." shape="rect">cudnnDropoutBackward()</a></samp>, and its contents is expected to remain
                              unchanged between <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutForward" shape="rect">cudnnDropoutForward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutBackward" title="This function performs backward dropout operation over dy returning results in dx. If during forward dropout operation value from x was propagated to y then during backward operation value from dy will be propagated to dx, otherwise, dx value will be set to 0." shape="rect">cudnnDropoutBackward()</a></samp> calls. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutGetReserveSpaceSize(
    cudnnTensorDescriptor_t     xDesc,
    size_t                     *sizeInBytes)</pre><div class="section" id="cudnnDropoutGetReserveSpaceSize__section_jpl_mfh_z3b"><a name="cudnnDropoutGetReserveSpaceSize__section_jpl_mfh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor,
                                       describing input to a dropout operation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory needed as reserve space to be able
                                       to run dropout with an input tensor descriptor specified by
                                       <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDropoutGetReserveSpaceSize__section_prw_mfh_z3b"><a name="cudnnDropoutGetReserveSpaceSize__section_prw_mfh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDropoutGetStatesSize"><a name="cudnnDropoutGetStatesSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutGetStatesSize" name="cudnnDropoutGetStatesSize" shape="rect">3.2.36.&nbsp;<kbd class="ph userinput">cudnnDropoutGetStatesSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function is used to query the amount of space required to store the states of the
                              random number generators used by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutForward" shape="rect">cudnnDropoutForward()</a></samp>
                              function. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutGetStatesSize(
    cudnnHandle_t       handle,
    size_t             *sizeInBytes)</pre><div class="section" id="cudnnDropoutGetStatesSize__section_agw_sfh_z3b"><a name="cudnnDropoutGetStatesSize__section_agw_sfh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory needed to store random generator
                                       states.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDropoutGetStatesSize__section_sdh_tfh_z3b"><a name="cudnnDropoutGetStatesSize__section_sdh_tfh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetActivationDescriptor"><a name="cudnnGetActivationDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetActivationDescriptor" name="cudnnGetActivationDescriptor" shape="rect">3.2.37.&nbsp;<kbd class="ph userinput">cudnnGetActivationDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries a previously initialized generic activation descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetActivationDescriptor(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc,
        cudnnActivationMode_t              *mode,
        cudnnNanPropagation_t              *reluNanOpt,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                             *coef)</pre><div class="section" id="cudnnGetActivationDescriptor__section_mlq_dy3_z3b"><a name="cudnnGetActivationDescriptor__section_mlq_dy3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created activation descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the activation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reluNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the <samp class="ph codeph">Nan</samp> propagation
                                       mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">coef</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Floating point number to specify the clipping threshold
                                       when the activation mode is set to
                                       <samp class="ph codeph">CUDNN_ACTIVATION_CLIPPED_RELU</samp> or to specify the
                                       alpha coefficient when the activation mode is set to
                                       <samp class="ph codeph">CUDNN_ACTIVATION_ELU</samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetActivationDescriptor__section_tyg_2y3_z3b"><a name="cudnnGetActivationDescriptor__section_tyg_2y3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was queried successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetActivationDescriptorSwishBeta"><a name="cudnnGetActivationDescriptorSwishBeta" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetActivationDescriptorSwishBeta" name="cudnnGetActivationDescriptorSwishBeta" shape="rect">3.2.38.&nbsp;<kbd class="ph userinput">cudnnGetActivationDescriptorSwishBeta()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries the current beta parameter set for SWISH
                                 activation.</span></div><pre xml:space="preserve">cudnnStatus_t
cudnnGetActivationDescriptorSwishBeta(cudnnActivationDescriptor_t
activationDesc, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>* swish_beta)
</pre><div class="section" id="cudnnGetActivationDescriptorSwishBeta__section_mlq_dy3_z3b"><a name="cudnnGetActivationDescriptorSwishBeta__section_mlq_dy3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created activation descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">swish_beta</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to a double value that will receive the currently
                                       configured SWISH beta parameter.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetActivationDescriptorSwishBeta__section_tyg_2y3_z3b"><a name="cudnnGetActivationDescriptorSwishBeta__section_tyg_2y3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The beta parameter was queried successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of <samp class="ph codeph">activationDesc</samp> or
                                       <samp class="ph codeph">swish_beta</samp> were <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetAlgorithmDescriptor"><a name="cudnnGetAlgorithmDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAlgorithmDescriptor" name="cudnnGetAlgorithmDescriptor" shape="rect">3.2.39.&nbsp;<kbd class="ph userinput">cudnnGetAlgorithmDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function queries a previously initialized generic algorithm descriptor object.</p><pre xml:space="preserve">cudnnStatus_t cudnnGetAlgorithmDescriptor(        
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAlgorithmDescriptor_t    algoDesc,
        cudnnAlgorithm_t                    *algorithm)</pre><div class="section" id="cudnnGetAlgorithmDescriptor__section_chl_ly3_z3b"><a name="cudnnGetAlgorithmDescriptor__section_chl_ly3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algorithmDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created algorithm descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algorithm</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Struct to specify the algorithm.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetAlgorithmDescriptor__section_vqg_my3_z3b"><a name="cudnnGetAlgorithmDescriptor__section_vqg_my3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was queried successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetAlgorithmPerformance"><a name="cudnnGetAlgorithmPerformance" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAlgorithmPerformance" name="cudnnGetAlgorithmPerformance" shape="rect">3.2.40.&nbsp;<kbd class="ph userinput">cudnnGetAlgorithmPerformance()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function queries a previously initialized generic algorithm performance object.</p><pre xml:space="preserve">cudnnStatus_t cudnnGetAlgorithmPerformance(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAlgorithmPerformance_t   algoPerf,
        cudnnAlgorithmDescriptor_t*         algoDesc,
        cudnnStatus_t*                      status,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*                              time,
        size_t*                             memory)</pre><div class="section" id="cudnnGetAlgorithmPerformance__section_f3y_sy3_z3b"><a name="cudnnGetAlgorithmPerformance__section_f3y_sy3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoPerf</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created algorithm
                                       performance object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The algorithm descriptor which the performance results
                                       describe.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">status</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The cuDNN status returned from running the
                                       <samp class="ph codeph">algoDesc</samp> algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">timecoef</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The GPU time spent running the <samp class="ph codeph">algoDesc</samp>
                                       algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">memory</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The GPU memory needed to run the
                                       <samp class="ph codeph">algoDesc</samp> algorithm.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetAlgorithmPerformance__section_aby_ty3_z3b"><a name="cudnnGetAlgorithmPerformance__section_aby_ty3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was queried successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetAlgorithmSpaceSize"><a name="cudnnGetAlgorithmSpaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAlgorithmSpaceSize" name="cudnnGetAlgorithmSpaceSize" shape="rect">3.2.41.&nbsp;<kbd class="ph userinput">cudnnGetAlgorithmSpaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function queries for the amount of host memory needed to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnSaveAlgorithm" title="This function has been deprecated in cuDNN 8.0." shape="rect">cudnnSaveAlgorithm()</a></samp>, much like the <em class="ph i">get workspace size</em>
                              function query for the amount of device memory needed.
                           </p><pre xml:space="preserve">cudnnStatus_t cudnnGetAlgorithmSpaceSize(    
    cudnnHandle_t               handle,
    cudnnAlgorithmDescriptor_t  algoDesc,
    size_t*                     algoSpaceSizeInBytes)</pre><div class="section" id="cudnnGetAlgorithmSpaceSize__section_vc2_vqj_z3b"><a name="cudnnGetAlgorithmSpaceSize__section_vc2_vqj_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created algorithm descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of host memory needed as a workspace to be able to
                                       save the metadata from the specified <samp class="ph codeph">algoDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetAlgorithmSpaceSize__section_hrq_vqj_z3b"><a name="cudnnGetAlgorithmSpaceSize__section_hrq_vqj_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the arguments is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetCallback"><a name="cudnnGetCallback" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCallback" name="cudnnGetCallback" shape="rect">3.2.42.&nbsp;<kbd class="ph userinput">cudnnGetCallback()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries the internal states of cuDNN error reporting
                                 functionality.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCallback(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>            mask,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                **udata,
        cudnnCallback_t     fptr)</pre><div class="section" id="cudnnGetCallback__section_zjp_mrd_1jb"><a name="cudnnGetCallback__section_zjp_mrd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mask</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the address where the current internal error
                                       reporting message bit mask will be outputted.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">udata</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the address where the current internally
                                       stored <samp class="ph codeph">udata</samp> address will be stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">fptr</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the address where the current internally
                                       stored <samp class="ph codeph">callback</samp> function pointer will be stored. When
                                       the built-in default callback function is used, <samp class="ph codeph">NULL</samp>
                                       will be outputted.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetCallback__section_zzz_mrd_1jb"><a name="cudnnGetCallback__section_zzz_mrd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If any of the input parameters are <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetCudartVersion"><a name="cudnnGetCudartVersion" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCudartVersion" name="cudnnGetCudartVersion" shape="rect">3.2.43.&nbsp;<kbd class="ph userinput">cudnnGetCudartVersion()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">The same version of a given cuDNN library can be compiled against different CUDA
                                 toolkit versions. This routine returns the CUDA toolkit version that the currently used
                                 cuDNN library has been compiled against.</span></div><pre xml:space="preserve">size_t cudnnGetCudartVersion()</pre></div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetDropoutDescriptor"><a name="cudnnGetDropoutDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetDropoutDescriptor" name="cudnnGetDropoutDescriptor" shape="rect">3.2.44.&nbsp;<kbd class="ph userinput">cudnnGetDropoutDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries the fields of a previously initialized dropout
                                 descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetDropoutDescriptor(
    cudnnDropoutDescriptor_t    dropoutDesc,
    cudnnHandle_t               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                      *dropout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       **states,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span>         *seed)</pre><div class="section" id="cudnnGetDropoutDescriptor__section_q2n_fn2_1jb"><a name="cudnnGetDropoutDescriptor__section_q2n_fn2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized dropout descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropout</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The probability with which the value from input is set to
                                       0 during the dropout layer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">states</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to user-allocated GPU memory that holds random
                                       number generator states.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seed</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Seed used to initialize random number generator
                                       states.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetDropoutDescriptor__section_mzx_fn2_1jb"><a name="cudnnGetDropoutDescriptor__section_mzx_fn2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">One or more of the arguments was an invalid pointer.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetErrorString"><a name="cudnnGetErrorString" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetErrorString" name="cudnnGetErrorString" shape="rect">3.2.45.&nbsp;<kbd class="ph userinput">cudnnGetErrorString()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function converts the cuDNN status code to a <samp class="ph codeph">NULL</samp>
                                 terminated (ASCIIZ) static string. For example, when the input argument is
                                 <samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp>, the returned string is
                                 <samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp>. When an invalid status value is passed to the
                                 function, the returned string is <samp class="ph codeph">CUDNN_UNKNOWN_STATUS</samp>.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> * cudnnGetErrorString(cudnnStatus_t status)</pre><div class="section" id="cudnnGetErrorString__section_ukc_2q2_1jb"><a name="cudnnGetErrorString__section_ukc_2q2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">status</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. cuDNN enumerant status code.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetErrorString__section_lgq_2q2_1jb"><a name="cudnnGetErrorString__section_lgq_2q2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <p class="p">Pointer to a static, <samp class="ph codeph">NULL</samp> terminated string with the status
                                 name.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetFilter4dDescriptor"><a name="cudnnGetFilter4dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFilter4dDescriptor" name="cudnnGetFilter4dDescriptor" shape="rect">3.2.46.&nbsp;<kbd class="ph userinput">cudnnGetFilter4dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries the parameters of the previously initialized
                                 <samp class="ph codeph">Filter4d</samp> descriptor object. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFilter4dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t     filterDesc,
    cudnnDataType_t            *dataType,
    cudnnTensorFormat_t        *format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *k,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *w)</pre><div class="section" id="cudnnGetFilter4dDescriptor__section_zl2_jq2_1jb"><a name="cudnnGetFilter4dDescriptor__section_zl2_jq2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">format</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Type of format.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">k</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of output feature maps.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">c</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of input feature maps.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">h</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Height of each filter.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Width of each filter.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetFilter4dDescriptor__section_wzn_jq2_1jb"><a name="cudnnGetFilter4dDescriptor__section_wzn_jq2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetFilterNdDescriptor"><a name="cudnnGetFilterNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFilterNdDescriptor" name="cudnnGetFilterNdDescriptor" shape="rect">3.2.47.&nbsp;<kbd class="ph userinput">cudnnGetFilterNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries a previously initialized <samp class="ph codeph">FilterNd</samp>
                                 descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFilterNdDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             nbDimsRequested,
    cudnnDataType_t                *dataType,
    cudnnTensorFormat_t            *format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             filterDimA[])</pre><div class="section" id="cudnnGetFilterNdDescriptor__section_iv2_sq2_1jb"><a name="cudnnGetFilterNdDescriptor__section_iv2_sq2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDimsRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the expected filter descriptor. It is also
                                       the minimum size of the arrays <samp class="ph codeph">filterDimA</samp> in order to
                                       be able to hold the results.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">format</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Type of format.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Actual dimension of the filter.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimensions of at least
                                       <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the filter
                                       parameters from the provided filter descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetFilterNdDescriptor__section_el4_sq2_1jb"><a name="cudnnGetFilterNdDescriptor__section_el4_sq2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The parameter <samp class="ph codeph">nbDimsRequested</samp> is negative.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetFilterSizeInBytes"><a name="cudnnGetFilterSizeInBytes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFilterSizeInBytes" name="cudnnGetFilterSizeInBytes" shape="rect">3.2.48.&nbsp;<kbd class="ph userinput">cudnnGetFilterSizeInBytes()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the size of the filter tensor in memory with respect to the
                                 given descriptor. It can be used to know the amount of GPU memory to be allocated to
                                 hold that filter tensor.</span></div><pre xml:space="preserve">cudnnStatus_t
cudnnGetFilterSizeInBytes(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t filterDesc, size_t *size) ;
</pre><div class="section" id="cudnnGetFilterSizeInBytes__section_ckg_xzc_z3b"><a name="cudnnGetFilterSizeInBytes__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">size</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. size in bytes needed to hold the tensor in GPU
                                       memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetFilterSizeInBytes__section_zpy_xzc_z3b"><a name="cudnnGetFilterSizeInBytes__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">filterDesc</samp> is valid.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">filerDesc</samp> is invald.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetLRNDescriptor"><a name="cudnnGetLRNDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetLRNDescriptor" name="cudnnGetLRNDescriptor" shape="rect">3.2.49.&nbsp;<kbd class="ph userinput">cudnnGetLRNDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves values stored in the previously initialized
                                 <samp class="ph codeph">LRN</samp> descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetLRNDescriptor(
    cudnnLRNDescriptor_t    normDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>               *lrnN,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 *lrnAlpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 *lrnBeta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 *lrnK)</pre><div class="section" id="cudnnGetLRNDescriptor__section_ncp_jw2_1jb"><a name="cudnnGetLRNDescriptor__section_ncp_jw2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created LRN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lrnN</samp>, <samp class="ph codeph">lrnAlpha</samp>,
                                       <samp class="ph codeph">lrnBeta</samp>, <samp class="ph codeph">lrnK</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointers to receive values of parameters stored in the
                                       descriptor object. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetLRNDescriptor" title="This function initializes a previously created LRN descriptor object." shape="rect">cudnnSetLRNDescriptor()</a></samp>. Any of these pointers
                                       can be <samp class="ph codeph">NULL</samp> (no value is returned for the corresponding
                                       parameter). 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetLRNDescriptor__section_dty_jw2_1jb"><a name="cudnnGetLRNDescriptor__section_dty_jw2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">Function completed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetOpTensorDescriptor"><a name="cudnnGetOpTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetOpTensorDescriptor" name="cudnnGetOpTensorDescriptor" shape="rect">3.2.50.&nbsp;<kbd class="ph userinput">cudnnGetOpTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the configuration of the passed tensor pointwise math
                                 descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetOpTensorDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnOpTensorDescriptor_t opTensorDesc,
    cudnnOpTensorOp_t               *opTensorOp,
    cudnnDataType_t                 *opTensorCompType,
    cudnnNanPropagation_t           *opTensorNanOpt)</pre><div class="section" id="cudnnGetOpTensorDescriptor__section_lyc_vy2_1jb"><a name="cudnnGetOpTensorDescriptor__section_lyc_vy2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor pointwise math descriptor passed to get the
                                       configuration from.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorOp</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the tensor pointwise math operation type,
                                       associated with this tensor pointwise math descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorCompType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the cuDNN data-type associated with this
                                       tensor pointwise math descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the NAN propagation option associated with
                                       this tensor pointwise math descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetOpTensorDescriptor__section_dzm_vy2_1jb"><a name="cudnnGetOpTensorDescriptor__section_dzm_vy2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Input tensor pointwise math descriptor passed is invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetPooling2dDescriptor"><a name="cudnnGetPooling2dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPooling2dDescriptor" name="cudnnGetPooling2dDescriptor" shape="rect">3.2.51.&nbsp;<kbd class="ph userinput">cudnnGetPooling2dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries a previously created <samp class="ph codeph">Pooling2D</samp> descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPooling2dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
    cudnnPoolingMode_t                 *mode,
    cudnnNanPropagation_t              *maxpoolingNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *windowHeight,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *windowWidth,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *verticalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *horizontalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *verticalStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *horizontalStride)</pre><div class="section" id="cudnnGetPooling2dDescriptor__section_lvp_yy2_1jb"><a name="cudnnGetPooling2dDescriptor__section_lvp_yy2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created pooling descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the pooling mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxpoolingNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the Nan propagation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">windowHeight</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Height of the pooling window.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">windowWidth</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Width of the pooling window.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">verticalPadding</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Size of vertical padding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">horizontalPadding</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Size of horizontal padding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">verticalStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pooling vertical stride.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">horizontalStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pooling horizontal stride.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetPooling2dDescriptor__section_r3b_zy2_1jb"><a name="cudnnGetPooling2dDescriptor__section_r3b_zy2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetPooling2dForwardOutputDim"><a name="cudnnGetPooling2dForwardOutputDim" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPooling2dForwardOutputDim" name="cudnnGetPooling2dForwardOutputDim" shape="rect">3.2.52.&nbsp;<kbd class="ph userinput">cudnnGetPooling2dForwardOutputDim()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function provides the output dimensions of a tensor after
                                 <samp class="ph codeph">Pooling2D</samp> has been applied.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPooling2dForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       inputDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outN,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outC,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outH,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outW)</pre><div class="p">Each dimension <samp class="ph codeph">h</samp> and <samp class="ph codeph">w</samp> of the output images is computed
                              as follows:<pre xml:space="preserve">
    outputDim = 1 + (inputDim + 2*padding - windowDim)/poolingStride;
    </pre></div>
                           <div class="section" id="cudnnGetPooling2dForwardOutputDim__section_erp_jz2_1jb"><a name="cudnnGetPooling2dForwardOutputDim__section_erp_jz2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized pooling
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">N</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of images in the output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">C</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of channels in the output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">H</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Height of images in the output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">W</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Width of images in the output.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetPooling2dForwardOutputDim__section_sf1_kz2_1jb"><a name="cudnnGetPooling2dForwardOutputDim__section_sf1_kz2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetPooling2dForwardOutputDim__ul_c1g_nyh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetPooling2dForwardOutputDim__ul_c1g_nyh_s1b">
                                          <li class="li"><samp class="ph codeph">poolingDesc</samp> has not been initialized.
                                          </li>
                                          <li class="li"><samp class="ph codeph">poolingDesc</samp> or <samp class="ph codeph">inputDesc</samp> has
                                             an invalid number of dimensions (2 and 4 respectively are
                                             required).
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetPoolingNdDescriptor"><a name="cudnnGetPoolingNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPoolingNdDescriptor" name="cudnnGetPoolingNdDescriptor" shape="rect">3.2.53.&nbsp;<kbd class="ph userinput">cudnnGetPoolingNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries a previously initialized generic <samp class="ph codeph">PoolingNd</samp>
                                 descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPoolingNdDescriptor(
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 nbDimsRequested,
cudnnPoolingMode_t                 *mode,
cudnnNanPropagation_t              *maxpoolingNanOpt,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *nbDims,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 windowDimA[],
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 paddingA[],
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 strideA[])</pre><div class="section" id="cudnnGetPoolingNdDescriptor__section_yjg_rz2_1jb"><a name="cudnnGetPoolingNdDescriptor__section_yjg_rz2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created pooling descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDimsRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the expected pooling descriptor. It is also
                                       the minimum size of the arrays <samp class="ph codeph">windowDimA</samp>,
                                       <samp class="ph codeph">paddingA</samp>, and <samp class="ph codeph">strideA</samp> in order to
                                       be able to hold the results.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the pooling mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxpoolingNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the Nan propagation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Actual dimension of the pooling descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">windowDimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimension of at least
                                       <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the window
                                       parameters from the provided pooling descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddingA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimension of at least
                                       <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the
                                       padding parameters from the provided pooling descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">strideA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimension at least
                                       <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the stride
                                       parameters from the provided pooling descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetPoolingNdDescriptor__section_brq_rz2_1jb"><a name="cudnnGetPoolingNdDescriptor__section_brq_rz2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was queried successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The parameter <samp class="ph codeph">nbDimsRequested</samp> is greater than
                                       <samp class="ph codeph">CUDNN_DIM_MAX</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetPoolingNdForwardOutputDim"><a name="cudnnGetPoolingNdForwardOutputDim" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPoolingNdForwardOutputDim" name="cudnnGetPoolingNdForwardOutputDim" shape="rect">3.2.54.&nbsp;<kbd class="ph userinput">cudnnGetPoolingNdForwardOutputDim()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function provides the output dimensions of a tensor after
                                 <samp class="ph codeph">PoolingNd</samp> has been applied.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPoolingNdForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t  poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   inputDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             outDimA[])</pre><div class="p">Each dimension of the <samp class="ph codeph">(nbDims-2)-D</samp> images of the output tensor is
                              computed as follows:<pre xml:space="preserve">
    outputDim = 1 + (inputDim + 2*padding - windowDim)/poolingStride;
    </pre></div>
                           <div class="section" id="cudnnGetPoolingNdForwardOutputDim__section_m44_21f_1jb"><a name="cudnnGetPoolingNdForwardOutputDim__section_m44_21f_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized pooling
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of dimensions in which pooling is to be
                                       applied.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">outDimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of <samp class="ph codeph">nbDims</samp> output dimensions.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetPoolingNdForwardOutputDim__section_u11_f1f_1jb"><a name="cudnnGetPoolingNdForwardOutputDim__section_u11_f1f_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetPoolingNdForwardOutputDim__ul_vff_ryh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetPoolingNdForwardOutputDim__ul_vff_ryh_s1b">
                                          <li class="li"><samp class="ph codeph">poolingDesc</samp> has not been initialized.
                                          </li>
                                          <li class="li">The value of <samp class="ph codeph">nbDims</samp> is inconsistent with the
                                             dimensionality of <samp class="ph codeph">poolingDesc</samp> and
                                             <samp class="ph codeph">inputDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetProperty"><a name="cudnnGetProperty" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetProperty" name="cudnnGetProperty" shape="rect">3.2.55.&nbsp;<kbd class="ph userinput">cudnnGetProperty()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function writes a specific part of the cuDNN library version number into the
                                 provided host storage.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetProperty(
    libraryPropertyType     type,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    *value)</pre><div class="section" id="cudnnGetProperty__section_pkc_l1f_1jb"><a name="cudnnGetProperty__section_pkc_l1f_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">type</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant type that instructs the function to report the
                                       numerical value of the cuDNN major version, minor version, or the patch
                                       level depending on whether <samp class="ph codeph">type</samp> is set to
                                       <samp class="ph codeph">MAJOR_VERSION</samp>, <samp class="ph codeph">MINOR_VERSION</samp>, or
                                       <samp class="ph codeph">PATCH_LEVEL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">value</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Host pointer where the version information should be
                                       written.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetProperty__section_l1l_l1f_1jb"><a name="cudnnGetProperty__section_l1l_l1f_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd">Invalid value of the <samp class="ph codeph">type</samp> argument.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">Version information was stored successfully at the provided
                                       address.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetReduceTensorDescriptor"><a name="cudnnGetReduceTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetReduceTensorDescriptor" name="cudnnGetReduceTensorDescriptor" shape="rect">3.2.56.&nbsp;<kbd class="ph userinput">cudnnGetReduceTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries a previously initialized reduce tensor descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetReduceTensorDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t reduceTensorDesc,
    cudnnReduceTensorOp_t               *reduceTensorOp,
    cudnnDataType_t                     *reduceTensorCompType,
    cudnnNanPropagation_t               *reduceTensorNanOpt,
    cudnnReduceTensorIndices_t          *reduceTensorIndices,
    cudnnIndicesType_t                  *reduceTensorIndicesType)</pre><div class="section" id="cudnnGetReduceTensorDescriptor__section_f5x_q1f_1jb"><a name="cudnnGetReduceTensorDescriptor__section_f5x_q1f_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized reduce tensor
                                       descriptor object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorOp</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the reduced tensor operation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorCompType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the computation datatype of the
                                       reduction.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the Nan propagation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorIndices</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the reduced tensor indices.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorIndicesType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Enumerant to specify the reduced tensor indices
                                       type.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetReduceTensorDescriptor__section_umh_r1f_1jb"><a name="cudnnGetReduceTensorDescriptor__section_umh_r1f_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was queried successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">reduceTensorDesc</samp> is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetReductionIndicesSize"><a name="cudnnGetReductionIndicesSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetReductionIndicesSize" name="cudnnGetReductionIndicesSize" shape="rect">3.2.57.&nbsp;<kbd class="ph userinput">cudnnGetReductionIndicesSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This is a helper function to return the minimum size of the index space to be
                                 passed to the reduction given the input and output tensors.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetReductionIndicesSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t reduceDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       cDesc,
    size_t                              *sizeInBytes)</pre><div class="section" id="cudnnGetReductionIndicesSize__section_oxl_1bf_1jb"><a name="cudnnGetReductionIndicesSize__section_oxl_1bf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized reduce tensor
                                       descriptor object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">aDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the input tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the output tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum size of the index space to be passed to the
                                       reduction.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetReductionIndicesSize__section_egv_1bf_1jb"><a name="cudnnGetReductionIndicesSize__section_egv_1bf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The index space size is returned successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetReductionWorkspaceSize"><a name="cudnnGetReductionWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetReductionWorkspaceSize" name="cudnnGetReductionWorkspaceSize" shape="rect">3.2.58.&nbsp;<kbd class="ph userinput">cudnnGetReductionWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This is a helper function to return the minimum size of the workspace to be
                                 passed to the reduction given the input and output tensors.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetReductionWorkspaceSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t reduceDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       cDesc,
    size_t                              *sizeInBytes)</pre><div class="section" id="cudnnGetReductionWorkspaceSize__section_hk3_fbf_1jb"><a name="cudnnGetReductionWorkspaceSize__section_hk3_fbf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized reduce tensor
                                       descriptor object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">aDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the input tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the output tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum size of the index space to be passed to the
                                       reduction.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetReductionWorkspaceSize__section_ivs_fbf_1jb"><a name="cudnnGetReductionWorkspaceSize__section_ivs_fbf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The workspace size is returned successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetStream"><a name="cudnnGetStream" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetStream" name="cudnnGetStream" shape="rect">3.2.59.&nbsp;<kbd class="ph userinput">cudnnGetStream()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves the user CUDA stream programmed in the cuDNN handle. When
                                 the user's CUDA stream is not set in the cuDNN handle, this function reports the
                                 null-stream. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetStream(
    cudnnHandle_t   handle,
    cudaStream_t   *streamId)</pre><div class="section" id="cudnnGetStream__section_lct_jhk_1jb"><a name="cudnnGetStream__section_lct_jhk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the cuDNN handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">streamID</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer where the current CUDA stream from the cuDNN
                                       handle should be stored.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetStream__section_zvd_khk_1jb"><a name="cudnnGetStream__section_zvd_khk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid (<samp class="ph codeph">NULL</samp>) handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The stream identifier was retrieved successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetTensor4dDescriptor"><a name="cudnnGetTensor4dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensor4dDescriptor" name="cudnnGetTensor4dDescriptor" shape="rect">3.2.60.&nbsp;<kbd class="ph userinput">cudnnGetTensor4dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries the parameters of the previously initialized
                                 <samp class="ph codeph">Tensor4d</samp> descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensor4dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  tensorDesc,
    cudnnDataType_t         *dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *nStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *cStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *hStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *wStride)</pre><div class="section" id="cudnnGetTensor4dDescriptor__section_ufm_xhk_1jb"><a name="cudnnGetTensor4dDescriptor__section_ufm_xhk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">n</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">c</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of feature maps per image.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">h</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Height of each feature map.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Width of each feature map.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Stride between two consecutive images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Stride between two consecutive feature maps.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Stride between two consecutive rows.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Stride between two consecutive columns.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetTensor4dDescriptor__section_kzc_yhk_1jb"><a name="cudnnGetTensor4dDescriptor__section_kzc_yhk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The operation succeeded.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetTensorNdDescriptor"><a name="cudnnGetTensorNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensorNdDescriptor" name="cudnnGetTensorNdDescriptor" shape="rect">3.2.61.&nbsp;<kbd class="ph userinput">cudnnGetTensorNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves values stored in a previously initialized
                                 <samp class="ph codeph">TensorNd</samp> descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensorNdDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   tensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             nbDimsRequested,
    cudnnDataType_t                *dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             dimA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             strideA[])</pre><div class="section" id="cudnnGetTensorNdDescriptor__section_jjx_f3k_1jb"><a name="cudnnGetTensorNdDescriptor__section_jjx_f3k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDimsRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of dimensions to extract from a given tensor
                                       descriptor. It is also the minimum size of the arrays
                                       <samp class="ph codeph">dimA</samp> and <samp class="ph codeph">strideA</samp>. If this number
                                       is greater than the resulting <samp class="ph codeph">nbDims[0]</samp>, only
                                       <samp class="ph codeph">nbDims[0]</samp> dimensions will be returned.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Actual number of dimensions of the tensor will be
                                       returned in <samp class="ph codeph">nbDims[0]</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimensions of at least
                                       <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the
                                       dimensions from the provided tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">strideA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimensions of at least
                                       <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the
                                       strides from the provided tensor descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetTensorNdDescriptor__section_bxg_g3k_1jb"><a name="cudnnGetTensorNdDescriptor__section_bxg_g3k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The results were returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either <samp class="ph codeph">tensorDesc</samp> or <samp class="ph codeph">nbDims</samp> pointer is
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetTensorSizeInBytes"><a name="cudnnGetTensorSizeInBytes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensorSizeInBytes" name="cudnnGetTensorSizeInBytes" shape="rect">3.2.62.&nbsp;<kbd class="ph userinput">cudnnGetTensorSizeInBytes()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the size of the tensor in memory in respect to the given
                                 descriptor. This function can be used to know the amount of GPU memory to be allocated
                                 to hold that tensor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensorSizeInBytes(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   tensorDesc,
    size_t                         *size)</pre><div class="section" id="cudnnGetTensorSizeInBytes__section_ijf_w3k_1jb"><a name="cudnnGetTensorSizeInBytes__section_ijf_w3k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">size</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Size in bytes needed to hold the tensor in GPU
                                       memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetTensorSizeInBytes__section_xd4_w3k_1jb"><a name="cudnnGetTensorSizeInBytes__section_xd4_w3k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The results were returned successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetTensorTransformDescriptor"><a name="cudnnGetTensorTransformDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensorTransformDescriptor" name="cudnnGetTensorTransformDescriptor" shape="rect">3.2.63.&nbsp;<kbd class="ph userinput">cudnnGetTensorTransformDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the values stored in a previously initialized tensor
                                 			transform descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t transformDesc,
	uint32_t nbDimsRequested,
	cudnnTensorFormat_t *destFormat,
	int32_t padBeforeA[],
	int32_t padAfterA[],
	uint32_t foldA[],
	cudnnFoldingDirection_t *direction);
</pre><div class="section" id="cudnnGetTensorTransformDescriptor__section_idl_djk_1jb"><a name="cudnnGetTensorTransformDescriptor__section_idl_djk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transformDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized tensor transform descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDimsRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of dimensions to consider. For more
                                       							information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#tensor-descriptor" target="_blank" shape="rect">Tensor Descriptor</a>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">destFormat</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The transform format that will be returned.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">padBeforeA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. An array filled with the amount of padding to add before
                                       							each dimension. The dimension of this <samp class="ph codeph">padBeforeA[]</samp>
                                       							parameter is equal to <samp class="ph codeph">nbDimsRequested</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">padAfterA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. An array filled with the amount of padding to add after
                                       							each dimension. The dimension of this <samp class="ph codeph">padBeforeA[]</samp>
                                       							parameter is equal to <samp class="ph codeph">nbDimsRequested</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">foldA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. An array that was filled with the folding parameters for
                                       							each spatial dimension. The dimension of this <samp class="ph codeph">foldA[]</samp>
                                       							array is <samp class="ph codeph">nbDimsRequested-2</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">direction</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The setting that selects folding or unfolding. For more information, refer
                                       							to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFoldingDirection_t" shape="rect">cudnnFoldingDirection_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetTensorTransformDescriptor__section_cby_djk_1jb"><a name="cudnnGetTensorTransformDescriptor__section_cby_djk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The results were obtained successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If <samp class="ph codeph">transformDesc</samp> is <samp class="ph codeph">NULL</samp> or if
                                       								<samp class="ph codeph">nbDimsRequested</samp> is less than 3 or greater than
                                       								<samp class="ph codeph">CUDNN_DIM_MAX</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetVersion"><a name="cudnnGetVersion" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetVersion" name="cudnnGetVersion" shape="rect">3.2.64.&nbsp;<kbd class="ph userinput">cudnnGetVersion()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the version number of the cuDNN library. It returns the
                                 <samp class="ph codeph">CUDNN_VERSION</samp> defined present in the <samp class="ph codeph">cudnn.h</samp>
                                 header file. Starting with release R2, the routine can be used to identify dynamically
                                 the current cuDNN library used by the application. The defined
                                 <samp class="ph codeph">CUDNN_VERSION</samp> can be used to have the same application linked
                                 against different cuDNN versions using conditional compilation statements. </span></div><pre xml:space="preserve">size_t cudnnGetVersion()</pre></div>
                     </div>
                     <div class="topic concept nested2" id="cudnnInitTransformDest"><a name="cudnnInitTransformDest" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnInitTransformDest" name="cudnnInitTransformDest" shape="rect">3.2.65.&nbsp;<kbd class="ph userinput">cudnnInitTransformDest()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function initializes and returns a destination tensor descriptor
                              			<samp class="ph codeph">destDesc</samp> for tensor transform operations. The initialization is done
                              		with the desired parameters described in the transform descriptor <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnInitTransformDest(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorTransformDescriptor_t transformDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t srcDesc,
	cudnnTensorDescriptor_t destDesc,
	size_t *destSizeInBytes);
</pre><div class="note note"><span class="notetitle">Note:</span> The returned tensor descriptor will be packed.
                           </div>
                           <div class="section" id="cudnnInitTransformDest__section_lrm_pmk_1jb"><a name="cudnnInitTransformDest__section_lrm_pmk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transformDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor transform
                                       							descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">srcDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">destDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle of the tensor descriptor that will be initialized
                                       							and returned.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">destSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A pointer to hold the size, in bytes, of the new
                                       							tensor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnInitTransformDest__section_zqg_smk_1jb"><a name="cudnnInitTransformDest__section_zqg_smk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The tensor descriptor was initialized successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If either <samp class="ph codeph">srcDesc</samp> or <samp class="ph codeph">destDesc</samp> is
                                       								<samp class="ph codeph">NULL</samp>, or if the tensor descriptors
                                       								<samp class="ph codeph">nbDims</samp> is incorrect. For more information, refer to
                                       								<a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#tensor-descriptor" target="_blank" shape="rect">Tensor Descriptor</a>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">If the provided configuration is not 4D.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">Function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnLRNCrossChannelForward"><a name="cudnnLRNCrossChannelForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLRNCrossChannelForward" name="cudnnLRNCrossChannelForward" shape="rect">3.2.66.&nbsp;<kbd class="ph userinput">cudnnLRNCrossChannelForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function performs the forward LRN layer computation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnLRNCrossChannelForward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnLRNMode_t                   lrnMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><div class="note note"><span class="notetitle">Note:</span> Supported formats are: <samp class="ph codeph">positive-strided</samp>, NCHW and NHWC for 4D
                              <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and only NCDHW DHW-packed for 5D (for
                              both <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>). Only non-overlapping 4D and 5D tensors
                              are supported. NCHW layout is preferred for performance.
                           </div>
                           <div class="section" id="cudnnLRNCrossChannelForward__section_flj_b4k_1jb"><a name="cudnnLRNCrossChannelForward__section_flj_b4k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized LRN parameter
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lrnMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. LRN layer mode of operation. Currently only
                                       <samp class="ph codeph">CUDNN_LRN_CROSS_CHANNEL_DIM1</samp> is implemented.
                                       Normalization is performed along the tensor's <samp class="ph codeph">dimA[1]</samp>.
                                       
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor objects for the input and output
                                       tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Input tensor data pointer in device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Output tensor data pointer in device memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnLRNCrossChannelForward__section_sw1_c4k_1jb"><a name="cudnnLRNCrossChannelForward__section_sw1_c4k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnLRNCrossChannelForward__ul_bhx_s13_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelForward__ul_bhx_s13_s1b">
                                          <li class="li">One of the tensor pointers <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Number of input tensor dimensions is 2 or less.</li>
                                          <li class="li">LRN descriptor parameters are outside of their valid
                                             ranges.
                                          </li>
                                          <li class="li">One of the tensor parameters is 5D but is not in NCDHW
                                             DHW-packed format.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. Refer to the
                                       following examples of non-supported configurations:<a name="cudnnLRNCrossChannelForward__ul_jhx_s13_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelForward__ul_jhx_s13_s1b">
                                          <li class="li">Any of the input tensor datatypes is not the same as any of the
                                             output tensor datatype.
                                          </li>
                                          <li class="li"><samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp> tensor dimensions
                                             mismatch.
                                          </li>
                                          <li class="li">Any tensor parameters strides are negative.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnNormalizationForwardInference"><a name="cudnnNormalizationForwardInference" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNormalizationForwardInference" name="cudnnNormalizationForwardInference" shape="rect">3.2.67.&nbsp;<kbd class="ph userinput">cudnnNormalizationForwardInference()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs the forward normalization layer computation for the inference
                              phase. Per-channel normalization layer is based on the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch
                                 Normalization: Accelerating Deep Network Training by Reducing Internal Covariate
                                 Shift</a> paper. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t
cudnnNormalizationForwardInference(cudnnHandle_t handle,
                                   cudnnNormMode_t mode,
                                   cudnnNormOps_t normOps,
                                   cudnnNormAlgo_t algo,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *alpha,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *beta,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t xDesc,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *x,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normScaleBiasDesc,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *normScale,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *normBias,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normMeanVarDesc,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *estimatedMean,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *estimatedVariance,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t zDesc,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *z,
                                   cudnnActivationDescriptor_t activationDesc,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t yDesc,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *y,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> epsilon,
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> groupCnt);
</pre><p class="p">Only 4D and 5D tensors are supported.</p>
                           <div class="p">The input transformation performed by this function is defined
                              as:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">y = beta*y + alpha *[normBias + (normScale * (x-estimatedMean)/sqrt(epsilon + estimatedVariance)]</kbd></pre></div>
                           <p class="p">The <samp class="ph codeph">epsilon</samp> value has to be the same during training, backpropagation,
                              and inference.
                           </p>
                           <p class="p">For the training phase, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp>.
                           </p>
                           <p class="p">Higher performance can be obtained when HW-packed tensors are used for all of
                              <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>.
                           </p>
                           <div class="section" id="cudnnNormalizationForwardInference__section_kz3_xmc_z3b"><a name="cudnnNormalizationForwardInference__section_kz3_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect"><u class="ph u">cudnnHandle_t</u></a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (per-channel or per-activation). For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormMode_t" shape="rect">cudnnNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of post-operative. Currently,
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> and
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> are not
                                       supported.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Algorithm to be performed. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormAlgo_t" shape="rect">cudnnNormAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as
                                          follows:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</kbd></pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handles to the previously initialized tensor
                                       descriptors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>, for the layers <samp class="ph codeph">x</samp>
                                       input data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">yDesc</samp>, for the <samp class="ph codeph">y</samp> output of
                                       the normalization layer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">zDesc</samp>, <samp class="ph codeph">*z</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. Tensor descriptors and pointers in device memory for
                                          residual addition to the result of the normalization operation,
                                          prior to the activation. <samp class="ph codeph">zDesc</samp> and
                                          <samp class="ph codeph">*z</samp> are optional and are only used when
                                          <samp class="ph codeph">normOps</samp> is
                                          <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp>, otherwise
                                          users may pass <samp class="ph codeph">NULL</samp>. When in use,
                                          <samp class="ph codeph">z</samp> should have exactly the same dimension as
                                          <samp class="ph codeph">x</samp> and the final output <samp class="ph codeph">y</samp>. For
                                          more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                       </p>
                                       <p class="p">Since <samp class="ph codeph">normOps</samp> is only supported for
                                          <samp class="ph codeph">CUDNN_NORM_OPS_NORM</samp>, we can set these to
                                          <samp class="ph codeph">NULL</samp> for now.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normScaleBiasDesc</samp>, <samp class="ph codeph">normScale</samp>,
                                       <samp class="ph codeph">normBias</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Tensor descriptors and pointers in device memory for the
                                       normalization scale and bias parameters (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network
                                          Training by Reducing Internal Covariate Shift</a> paper, bias is
                                       referred to as beta and scale as gamma).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMeanVarDesc</samp>, <samp class="ph codeph">estimatedMean</samp>,
                                       <samp class="ph codeph">estimatedVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Mean and variance tensors and their tensor descriptors.
                                       The <samp class="ph codeph">estimatedMean</samp> and
                                       <samp class="ph codeph">estimatedVariance</samp> inputs, accumulated during the
                                       training phase from the <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp> call,
                                       should be passed as inputs here.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">normOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise the user may pass <samp class="ph codeph">NULL</samp>.
                                       Since <samp class="ph codeph">normOps</samp> is only supported for
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM</samp>, we can set these to
                                       <samp class="ph codeph">NULL</samp> for now.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in the normalization formula. Its value
                                       should be equal to or greater than zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">groupCnt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of grouped convolutions. Currently, only
                                       <samp class="ph codeph">1</samp> is supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnNormalizationForwardInference__section_xs5_xmc_z3b"><a name="cudnnNormalizationForwardInference__section_xs5_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A compute or data type other than what is supported was chosen, or an
                                       unknown algorithm type was chosen.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnNormalizationForwardInference__ul_zpd_lg3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnNormalizationForwardInference__ul_zpd_lg3_s1b">
                                          <li class="li">One of the pointers <samp class="ph codeph">alpha</samp>,
                                             <samp class="ph codeph">beta</samp>, <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp>, <samp class="ph codeph">normScale</samp>,
                                             <samp class="ph codeph">normBias</samp>, <samp class="ph codeph">estimatedMean</samp>,
                                             and <samp class="ph codeph">estimatedInvVariance</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                             tensor descriptor dimensions is not within the range of [4,5]
                                             (only 4D and 5D tensors are supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">normScaleBiasDesc</samp> and
                                             <samp class="ph codeph">normMeanVarDesc</samp> dimensions are not 1xCx1x1
                                             for 4D and 1xCx1x1x1 for 5D for per-channel, and are not 1xCxHxW
                                             for 4D and 1xCxDxHxW for 5D for per-activation mode.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than zero.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp> and
                                             <samp class="ph codeph">yDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A compute or data type other than <samp class="ph codeph">FLOAT</samp> was chosen, or
                                       an unknown algorithm type was chosen.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnOpsInferVersionCheck"><a name="cudnnOpsInferVersionCheck" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpsInferVersionCheck" name="cudnnOpsInferVersionCheck" shape="rect">3.2.68.&nbsp;<kbd class="ph userinput">cudnnOpsInferVersionCheck()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function is the first of a series of corresponding functions that check for
                                 consistent library versions among DLL files for different modules.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnOpsInferVersionCheck(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)</pre><div class="section" id="cudnnOpsInferVersionCheck__section_zpy_xzc_z3b"><a name="cudnnOpsInferVersionCheck__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The version of this DLL file is consistent with cuDNN DLLs on which it
                                       depends.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_VERSION_MISMATCH</samp></dt>
                                    <dd class="dd">The version of this DLL file does not match that of a cuDNN DLLs on
                                       which it depends.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnOpTensor"><a name="cudnnOpTensor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpTensor" name="cudnnOpTensor" shape="rect">3.2.69.&nbsp;<kbd class="ph userinput">cudnnOpTensor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function implements the equation <samp class="ph codeph">C = op(alpha1[0] * A, alpha2[0] * B) +
                                 			beta[0] * C</samp>, given the tensors <samp class="ph codeph">A</samp>, <samp class="ph codeph">B</samp>, and
                              			<samp class="ph codeph">C</samp> and the scaling factors <samp class="ph codeph">alpha1</samp>,
                              			<samp class="ph codeph">alpha2</samp>, and <samp class="ph codeph">beta</samp>. The <samp class="ph codeph">op</samp> to use is
                              		indicated by the descriptor <samp class="ph codeph"><a class="xref" href="index.html#cudnnOpTensorDescriptor_t" shape="rect">cudnnOpTensorDescriptor_t</a></samp>,
                              		meaning, the type of <samp class="ph codeph">opTensorDesc</samp>. Currently-supported ops are listed by
                              		the <samp class="ph codeph"><a class="xref" href="index.html#cudnnOpTensorOp_t" shape="rect">cudnnOpTensorOp_t</a></samp> enum. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnOpTensor(
    cudnnHandle_t                     handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnOpTensorDescriptor_t   opTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *alpha1,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *A,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *alpha2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     bDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *B,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *C)</pre><div class="p">The following restrictions on the input and destination tensors apply:<a name="cudnnOpTensor__ul_atx_hl5_yhb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnOpTensor__ul_atx_hl5_yhb">
                                 <li class="li liexpand">Each dimension of the input tensor <samp class="ph codeph">A</samp> must match the
                                    					corresponding dimension of the destination tensor <samp class="ph codeph">C</samp>, and each
                                    					dimension of the input tensor <samp class="ph codeph">B</samp> must match the corresponding
                                    					dimension of the destination tensor <samp class="ph codeph">C</samp> or must be equal to 1. In
                                    					the latter case, the same value from the input tensor <samp class="ph codeph">B</samp> for
                                    					those dimensions will be used to blend into the <samp class="ph codeph">C</samp> tensor.
                                 </li>
                                 <li class="li liexpand">The data types of the input tensors <samp class="ph codeph">A</samp> and <samp class="ph codeph">B</samp>, and the
                                    					destination tensor C, must satisfy <samp class="ph codeph"><a class="xref" href="index.html#cudnnOpTensor__table_supported_datatypes" shape="rect">Table 13</a></samp>. 
                                 </li>
                              </ul>
                           </div>
                           <div class="p">
                              <div class="tablenoborder"><a name="cudnnOpTensor__table_supported_datatypes" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnOpTensor__table_supported_datatypes" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 13. Supported Datatypes for <samp class="ph codeph">cudnnOpTensor()</samp></span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" align="center" valign="top" width="29.537953795379536%" id="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">opTensorCompType</samp> in <samp class="ph codeph">opTensorDesc</samp></th>
                                          <th class="entry" align="center" valign="top" width="19.966996699669963%" id="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">A</samp></th>
                                          <th class="entry" align="center" valign="top" width="16.5016501650165%" id="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">B</samp></th>
                                          <th class="entry" align="center" valign="top" width="33.993399339933994%" id="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">C</samp>  (destination)
                                          </th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">HALF</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">HALF</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">BFLOAT16</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">BFLOAT16</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">HALF</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">HALF</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">HALF</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">HALF</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">INT8</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">BFLOAT16</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e16241" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT</samp></td>
                                          <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e16249" rowspan="1" colspan="1"><samp class="ph codeph">BFLOAT16</samp></td>
                                          <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e16253" rowspan="1" colspan="1"><samp class="ph codeph">BFLOAT16</samp></td>
                                          <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e16257" rowspan="1" colspan="1"><samp class="ph codeph">BFLOAT16</samp></td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                              <div class="note note"><span class="notetitle">Note:</span><samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp> is not supported as input tensor format. All
                                 				tensors up to dimension five (5) are supported. This routine does not support tensor
                                 				formats beyond these dimensions.
                              </div>
                           </div>
                           <div class="section" id="cudnnOpTensor__section_qb3_vsm_1jb"><a name="cudnnOpTensor__section_qb3_vsm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized op tensor
                                       							descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha1</samp>, <samp class="ph codeph">alpha2</samp>,
                                       							<samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          								blend the source value with prior value in the destination tensor as
                                          								follows:<pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">aDesc</samp>, <samp class="ph codeph">bDesc</samp>,
                                       							<samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">A</samp>, <samp class="ph codeph">B</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to data of the tensors described by the
                                       								<samp class="ph codeph">aDesc</samp> and <samp class="ph codeph">bDesc</samp> descriptors,
                                       							respectively.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">C</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                       								<samp class="ph codeph">cDesc</samp> descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnOpTensor__section_lms_vsm_1jb"><a name="cudnnOpTensor__section_lms_vsm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function executed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. Refer to the
                                       							following examples of non-supported configurations:<a name="cudnnOpTensor__ul_qcb_qr1_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnOpTensor__ul_qcb_qr1_s1b">
                                          <li class="li">The dimensions of the bias tensor and the output tensor
                                             									dimensions are above 5.
                                          </li>
                                          <li class="li"><samp class="ph codeph">opTensorCompType</samp> is not set as stated
                                             									above.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The data type of the destination tensor <samp class="ph codeph">C</samp> is
                                       							unrecognized, or the restrictions on the input and destination tensors,
                                       							stated above, are not met.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnPoolingForward"><a name="cudnnPoolingForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingForward" name="cudnnPoolingForward" shape="rect">3.2.70.&nbsp;<kbd class="ph userinput">cudnnPoolingForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes pooling of input values (meaning, the maximum or average
                                 of several adjacent values) to produce an output with smaller height and/or
                                 width.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnPoolingForward(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t   poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><p class="p">All tensor formats are supported, best performance is expected when using
                              <samp class="ph codeph">HW-packed</samp> tensors. Only 2 and 3 spatial dimensions are allowed.
                              Vectorized tensors are only supported if they have 2 spatial dimensions.
                           </p>
                           <p class="p">The dimensions of the output tensor <samp class="ph codeph">yDesc</samp> can be smaller or bigger than
                              the dimensions advised by the routine <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetPooling2dForwardOutputDim" title="This function provides the output dimensions of a tensor after Pooling2D has been applied." shape="rect">cudnnGetPooling2dForwardOutputDim()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetPoolingNdForwardOutputDim" title="This function provides the output dimensions of a tensor after PoolingNd has been applied." shape="rect">cudnnGetPoolingNdForwardOutputDim()</a></samp>.
                           </p>
                           <p class="p">For average pooling, the compute type is <samp class="ph codeph">float</samp> even for integer input
                              and output data type. Output round is nearest-even and clamp to the most negative or
                              most positive value of type if out of range.
                           </p>
                           <div class="section" id="cudnnPoolingForward__section_hxr_jvm_1jb"><a name="cudnnPoolingForward__section_hxr_jvm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized pooling
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor. Must be of type <samp class="ph codeph">FLOAT</samp>,
                                       <samp class="ph codeph">DOUBLE</samp>, <samp class="ph codeph">HALF</samp>,
                                       <samp class="ph codeph">INT8</samp>, <samp class="ph codeph">INT8x4</samp>,
                                       <samp class="ph codeph">INT8x32</samp>, or <samp class="ph codeph">BFLOAT16</samp>. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor. Must be of type <samp class="ph codeph">FLOAT</samp>,
                                       <samp class="ph codeph">DOUBLE</samp>, <samp class="ph codeph">HALF</samp>,
                                       <samp class="ph codeph">INT8</samp>, <samp class="ph codeph">INT8x4</samp>,
                                       <samp class="ph codeph">INT8x32</samp>, or <samp class="ph codeph">BFLOAT16</samp>. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnPoolingForward__section_esb_kvm_1jb"><a name="cudnnPoolingForward__section_esb_kvm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnPoolingForward__ul_e2z_5yh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnPoolingForward__ul_e2z_5yh_s1b">
                                          <li class="li">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp> of the
                                             input tensor and output tensors differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output
                                             tensors differs.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnQueryRuntimeError"><a name="cudnnQueryRuntimeError" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnQueryRuntimeError" name="cudnnQueryRuntimeError" shape="rect">3.2.71.&nbsp;<kbd class="ph userinput">cudnnQueryRuntimeError()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">cuDNN library functions perform extensive input argument checking before
                                 launching GPU kernels. The last step is to verify that the GPU kernel actually started.
                                 When a kernel fails to start, <samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp> is returned
                                 by the corresponding API call. Typically, after a GPU kernel starts, no runtime checks
                                 are performed by the kernel itself - numerical results are simply written to output
                                 buffers.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnQueryRuntimeError(
    cudnnHandle_t            handle,
    cudnnStatus_t           *rstatus,
    cudnnErrQueryMode_t      mode,
    cudnnRuntimeTag_t       *tag)</pre><p class="p">When the <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp> mode is selected in
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp> or
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp>, the algorithm
                              may encounter numerical overflows where <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp>
                              performs just fine albeit at a slower speed. The user can invoke
                              <samp class="ph codeph">cudnnQueryRuntimeError()</samp> to make sure numerical overflows did not
                              occur during the kernel execution. Those issues are reported by the kernel that performs
                              computations.
                           </p>
                           <p class="p"><samp class="ph codeph">cudnnQueryRuntimeError()</samp> can be used in polling and blocking software
                              control flows. There are two polling modes (<samp class="ph codeph">CUDNN_ERRQUERY_RAWCODE</samp> and
                              <samp class="ph codeph">CUDNN_ERRQUERY_NONBLOCKING</samp>) and one blocking mode
                              <samp class="ph codeph">CUDNN_ERRQUERY_BLOCKING</samp>.
                           </p>
                           <p class="p"><samp class="ph codeph">CUDNN_ERRQUERY_RAWCODE</samp> reads the error storage location regardless of
                              the kernel completion status. The kernel might not even start and the error storage
                              (allocated per cuDNN handle) might be used by an earlier call.
                           </p>
                           <p class="p"><samp class="ph codeph">CUDNN_ERRQUERY_NONBLOCKING</samp> checks if all tasks in the user stream are
                              completed. The <samp class="ph codeph">cudnnQueryRuntimeError()</samp> function will return
                              immediately and report <samp class="ph codeph">CUDNN_STATUS_RUNTIME_IN_PROGRESS</samp> in
                              <samp class="ph codeph">rstatus</samp> if some tasks in the user stream are pending. Otherwise,
                              the function will copy the remote kernel error code to <samp class="ph codeph">rstatus</samp>.
                           </p>
                           <p class="p">In the blocking mode (<samp class="ph codeph">CUDNN_ERRQUERY_BLOCKING</samp>), the function waits for
                              all tasks to drain in the user stream before reporting the remote kernel error code. The
                              blocking flavor can be further adjusted by calling <samp class="ph codeph">cudaSetDeviceFlags</samp>
                              with the <samp class="ph codeph">cudaDeviceScheduleSpin</samp>,
                              <samp class="ph codeph">cudaDeviceScheduleYield</samp>, or
                              <samp class="ph codeph">cudaDeviceScheduleBlockingSync</samp> flag.
                           </p>
                           <p class="p"><samp class="ph codeph">CUDNN_ERRQUERY_NONBLOCKING</samp> and <samp class="ph codeph">CUDNN_ERRQUERY_BLOCKING</samp>
                              modes should not be used when the user stream is changed in the cuDNN handle, meaning,
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetStream" title="This function sets the user's CUDA stream in the cuDNN handle. The new stream will be used to launch cuDNN GPU kernels or to synchronize to this stream when cuDNN kernels are launched in the internal streams. If the cuDNN library stream is not set, all kernels use the default (NULL) stream. Setting the user stream in the cuDNN handle guarantees the issue-order execution of cuDNN calls and other GPU kernels launched in the same stream." shape="rect">cudnnSetStream()</a></samp> is invoked between functions
                              that report runtime kernel errors and the <samp class="ph codeph">cudnnQueryRuntimeError()</samp>
                              function.
                           </p>
                           <p class="p">The remote error status reported in <samp class="ph codeph">rstatus</samp> can be set to:
                              <samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp>,
                              <samp class="ph codeph">CUDNN_STATUS_RUNTIME_IN_PROGRESS</samp>, or
                              <samp class="ph codeph">CUDNN_STATUS_RUNTIME_FP_OVERFLOW</samp>. The remote kernel error is
                              automatically cleared by <samp class="ph codeph">cudnnQueryRuntimeError()</samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">cudnnQueryRuntimeError()</samp> function should be used in conjunction
                              with <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp> and
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> when the
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp> argument is
                              <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp>. 
                           </div>
                           <div class="section" id="cudnnQueryRuntimeError__section_ctt_dxm_1jb"><a name="cudnnQueryRuntimeError__section_ctt_dxm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rstatus</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the user's error code storage.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Remote error query mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tag</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Currently, this argument should be
                                       <samp class="ph codeph">NULL</samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnQueryRuntimeError__section_a3d_2xm_1jb"><a name="cudnnQueryRuntimeError__section_a3d_2xm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">No errors detected (<samp class="ph codeph">rstatus</samp> holds a valid value).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid input argument.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">A stream blocking synchronization or a non-blocking stream query
                                       failed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">The device cannot access zero-copy memory to report kernel errors.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnReduceTensor"><a name="cudnnReduceTensor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReduceTensor" name="cudnnReduceTensor" shape="rect">3.2.72.&nbsp;<kbd class="ph userinput">cudnnReduceTensor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function reduces tensor <samp class="ph codeph">A</samp> by implementing the equation <samp class="ph codeph">C
                                 = alpha * reduce op ( A ) + beta * C</samp>, given tensors <samp class="ph codeph">A</samp> and
                              <samp class="ph codeph">C</samp> and scaling factors <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp>.
                              The reduction op to use is indicated by the descriptor <samp class="ph codeph">reduceTensorDesc</samp>.
                              Currently-supported ops are listed by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensorOp_t" shape="rect">cudnnReduceTensorOp_t</a></samp> enum. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnReduceTensor(
    cudnnHandle_t                           handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t     reduceTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                   *indices,
    size_t                                  indicesSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                   *workspace,
    size_t                                  workspaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *A,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                   *C)</pre><p class="p">Each dimension of the output tensor <samp class="ph codeph">C</samp> must match the corresponding
                              dimension of the input tensor <samp class="ph codeph">A</samp> or must be equal to 1. The dimensions
                              equal to 1 indicate the dimensions of <samp class="ph codeph">A</samp> to be reduced.
                           </p>
                           <p class="p">The implementation will generate indices for the min and max ops only, as indicated by
                              the <samp class="ph codeph"><a class="xref" href="index.html#cudnnReduceTensorIndices_t" shape="rect">cudnnReduceTensorIndices_t</a></samp> enum of the
                              <samp class="ph codeph">reduceTensorDesc</samp>. Requesting indices for the other reduction ops
                              results in an error. The data type of the indices is indicated by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnIndicesType_t" shape="rect">cudnnIndicesType_t</a></samp> enum; currently only the 32-bit (unsigned
                              int) type is supported.
                           </p>
                           <p class="p">The indices returned by the implementation are not absolute indices but relative to the
                              dimensions being reduced. The indices are also flattened, meaning, not coordinate
                              tuples.
                           </p>
                           <p class="p">The data types of the tensors <samp class="ph codeph">A</samp> and <samp class="ph codeph">C</samp> must match if of
                              type double. In this case, <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> and the
                              computation enum of <samp class="ph codeph">reduceTensorDesc</samp> are all assumed to be of type
                              double.
                           </p>
                           <div class="p">The <samp class="ph codeph">HALF</samp> and <samp class="ph codeph">INT8</samp> data types may be mixed with the
                              <samp class="ph codeph">FLOAT</samp> data types. In these cases, the computation enum of
                              <samp class="ph codeph">reduceTensorDesc</samp> is required to be of type
                              <samp class="ph codeph">FLOAT</samp>.
                              <div class="note note"><span class="notetitle">Note:</span> Up to dimension 8, all tensor formats are supported.
                                 Beyond those dimensions, this routine is not supported.
                              </div>
                           </div>
                           <div class="section" id="cudnnReduceTensor__section_zwm_hym_1jb"><a name="cudnnReduceTensor__section_zwm_hym_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized reduce tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">indices</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously allocated space for writing
                                       indices.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">indicesSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the above previously allocated space.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously allocated space for the reduction
                                       implementation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the above previously allocated space.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the source value with prior value in the destination tensor as
                                          follows:<pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">aDesc</samp>, <samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">A</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">aDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">C</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">cDesc</samp> descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnReduceTensor__section_wnx_hym_1jb"><a name="cudnnReduceTensor__section_wnx_hym_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function executed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. See the
                                       following for some examples of non-supported configurations:<a name="cudnnReduceTensor__ul_orx_tr1_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnReduceTensor__ul_orx_tr1_s1b">
                                          <li class="li">The dimensions of the input tensor and the output tensor are
                                             above 8.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reduceTensorCompType</samp> is not set as stated
                                             above.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The corresponding dimensions of the input and output tensors all match,
                                       or the conditions in the above paragraphs are unmet.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_INVALID_VALUE</samp></dt>
                                    <dd class="dd">The allocations for the indices or workspace are insufficient.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRestoreAlgorithm"><a name="cudnnRestoreAlgorithm" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRestoreAlgorithm" name="cudnnRestoreAlgorithm" shape="rect">3.2.73.&nbsp;<kbd class="ph userinput">cudnnRestoreAlgorithm()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function reads algorithm metadata from the host memory space provided by the user in
                              <samp class="ph codeph">algoSpace</samp>, allowing the user to use the results of RNN finds from
                              previous cuDNN sessions.
                           </p><pre xml:space="preserve">cudnnStatus_t cudnnRestoreAlgorithm(
    cudnnHandle_t               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*                       algoSpace,
    size_t                      algoSpaceSizeInBytes,
    cudnnAlgorithmDescriptor_t  algoDesc)</pre><div class="section" id="cudnnRestoreAlgorithm__section_ywp_4lr_1jb"><a name="cudnnRestoreAlgorithm__section_ywp_4lr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created algorithm descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the host memory to be read.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Amount of host memory needed as a workspace to be able to
                                       hold the metadata from the specified <samp class="ph codeph">algoDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRestoreAlgorithm__section_ikc_plr_1jb"><a name="cudnnRestoreAlgorithm__section_ikc_plr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The metadata is from a different cuDNN version.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions is met:<a name="cudnnRestoreAlgorithm__ul_asq_plr_1jb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRestoreAlgorithm__ul_asq_plr_1jb">
                                          <li class="li">One of the arguments is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The metadata is corrupted.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRestoreDropoutDescriptor"><a name="cudnnRestoreDropoutDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRestoreDropoutDescriptor" name="cudnnRestoreDropoutDescriptor" shape="rect">3.2.74.&nbsp;<kbd class="ph userinput">cudnnRestoreDropoutDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function restores a dropout descriptor to a previously saved-off
                                 state.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnRestoreDropoutDescriptor(
    cudnnDropoutDescriptor_t dropoutDesc,
    cudnnHandle_t            handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                    dropout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *states,
    size_t                   stateSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span>       seed)</pre><div class="section" id="cudnnRestoreDropoutDescriptor__section_lx4_vlr_1jb"><a name="cudnnRestoreDropoutDescriptor__section_lx4_vlr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Previously created dropout descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropout</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Probability with which the value from an input tensor is
                                       set to <samp class="ph codeph">0</samp> when performing dropout.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">states</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to GPU memory that holds random number generator
                                       states initialized by a prior call to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetDropoutDescriptor" title="This function initializes a previously created dropout descriptor object. If the states argument is equal to NULL, then the random number generator states won't be initialized, and only the dropout value will be set. The user is expected not to change the memory pointed at by states for the duration of the computation." shape="rect">cudnnSetDropoutDescriptor()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">stateSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size in bytes of buffer holding random number generator
                                       <samp class="ph codeph">states</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seed</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Seed used in prior calls to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetDropoutDescriptor" title="This function initializes a previously created dropout descriptor object. If the states argument is equal to NULL, then the random number generator states won't be initialized, and only the dropout value will be set. The user is expected not to change the memory pointed at by states for the duration of the computation." shape="rect">cudnnSetDropoutDescriptor()</a></samp> that initialized
                                       <samp class="ph codeph">states</samp> buffer. Using a different seed from this has
                                       no effect. A change of seed, and subsequent update to random number
                                       generator states can be achieved by calling <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetDropoutDescriptor" title="This function initializes a previously created dropout descriptor object. If the states argument is equal to NULL, then the random number generator states won't be initialized, and only the dropout value will be set. The user is expected not to change the memory pointed at by states for the duration of the computation." shape="rect">cudnnSetDropoutDescriptor()</a></samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRestoreDropoutDescriptor__section_evz_vlr_1jb"><a name="cudnnRestoreDropoutDescriptor__section_evz_vlr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">states</samp> buffer size (as indicated in
                                       <samp class="ph codeph">stateSizeInBytes</samp>) is too small.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSaveAlgorithm"><a name="cudnnSaveAlgorithm" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSaveAlgorithm" name="cudnnSaveAlgorithm" shape="rect">3.2.75.&nbsp;<kbd class="ph userinput">cudnnSaveAlgorithm()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function writes algorithm metadata into the host memory space provided by the user
                              in <samp class="ph codeph">algoSpace</samp>, allowing the user to preserve the results of RNN finds
                              after cuDNN exits.
                           </p><pre xml:space="preserve">cudnnStatus_t cudnnSaveAlgorithm(
    cudnnHandle_t          		handle,
    cudnnAlgorithmDescriptor_t 	algoDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*                  		algoSpace
    size_t                 		algoSpaceSizeInBytes)</pre><div class="section" id="cudnnSaveAlgorithm__section_emr_lgt_1jb"><a name="cudnnSaveAlgorithm__section_emr_lgt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created algorithm descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the host memory to be written.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Amount of host memory needed as a workspace to be able to
                                       save the metadata from the specified <samp class="ph codeph">algoDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSaveAlgorithm__section_hl1_pgt_1jb"><a name="cudnnSaveAlgorithm__section_hl1_pgt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions is met:<a name="cudnnSaveAlgorithm__ul_lcg_pgt_1jb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSaveAlgorithm__ul_lcg_pgt_1jb">
                                          <li class="li">One of the arguments is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">algoSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnScaleTensor"><a name="cudnnScaleTensor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnScaleTensor" name="cudnnScaleTensor" shape="rect">3.2.76.&nbsp;<kbd class="ph userinput">cudnnScaleTensor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function scales all the elements of a tensor by a given factor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnScaleTensor(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *alpha)</pre><div class="section" id="cudnnScaleTensor__section_a1s_5gt_1jb"><a name="cudnnScaleTensor__section_a1s_5gt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">yDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer in the host memory to a single value that all
                                       elements of the tensor will be scaled with. For more information, refer
                                       to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnScaleTensor__section_wz3_vgt_1jb"><a name="cudnnScaleTensor__section_wz3_vgt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">One of the provided pointers is <samp class="ph codeph">NIL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetActivationDescriptor"><a name="cudnnSetActivationDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetActivationDescriptor" name="cudnnSetActivationDescriptor" shape="rect">3.2.77.&nbsp;<kbd class="ph userinput">cudnnSetActivationDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic activation descriptor
                                 object. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetActivationDescriptor(
    cudnnActivationDescriptor_t         activationDesc,
    cudnnActivationMode_t               mode,
    cudnnNanPropagation_t               reluNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              coef)</pre><div class="section" id="cudnnSetActivationDescriptor__section_vr5_fmt_1jb"><a name="cudnnSetActivationDescriptor__section_vr5_fmt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created activation
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the activation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reluNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the <samp class="ph codeph">Nan</samp> propagation
                                       mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">coef</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Floating point number. When the activation mode (refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationMode_t" shape="rect">cudnnActivationMode_t</a></samp>) is set
                                       to <samp class="ph codeph">CUDNN_ACTIVATION_CLIPPED_RELU</samp>, this input specifies
                                       the clipping threshold; and when the activation mode is set to
                                       <samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp>, this input specifies the
                                       upper bound.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetActivationDescriptor__section_lw2_gmt_1jb"><a name="cudnnSetActivationDescriptor__section_lw2_gmt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">mode</samp> or <samp class="ph codeph">reluNanOpt</samp> has an invalid
                                       enumerant value.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetActivationDescriptorSwishBeta"><a name="cudnnSetActivationDescriptorSwishBeta" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetActivationDescriptorSwishBeta" name="cudnnSetActivationDescriptorSwishBeta" shape="rect">3.2.78.&nbsp;<kbd class="ph userinput">cudnnSetActivationDescriptorSwishBeta()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function sets the beta parameter of the SWISH activation function to
                                 <samp class="ph codeph">swish_beta</samp>.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetActivationDescriptorSwishBeta(cudnnActivationDescriptor_t activationDesc, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> swish_beta)</pre><div class="section" id="cudnnSetActivationDescriptorSwishBeta__section_mlq_dy3_z3b"><a name="cudnnSetActivationDescriptorSwishBeta__section_mlq_dy3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created activation
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">swish_beta</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The value to set the SWISH activations' beta parameter
                                       to.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetActivationDescriptorSwishBeta__section_tyg_2y3_z3b"><a name="cudnnSetActivationDescriptorSwishBeta__section_tyg_2y3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The value was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The activation descriptor is a <samp class="ph codeph">NULL</samp> pointer.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetAlgorithmDescriptor"><a name="cudnnSetAlgorithmDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetAlgorithmDescriptor" name="cudnnSetAlgorithmDescriptor" shape="rect">3.2.79.&nbsp;<kbd class="ph userinput">cudnnSetAlgorithmDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function initializes a previously created generic algorithm descriptor object.</p><pre xml:space="preserve">cudnnStatus_t cudnnSetAlgorithmDescriptor(
    cudnnAlgorithmDescriptor_t      algorithmDesc,
    cudnnAlgorithm_t                algorithm)</pre><div class="section" id="cudnnSetAlgorithmDescriptor__section_gnl_pnt_1jb"><a name="cudnnSetAlgorithmDescriptor__section_gnl_pnt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algorithmDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created algorithm
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algorithm</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Struct to specify the algorithm.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetAlgorithmDescriptor__section_u4v_pnt_1jb"><a name="cudnnSetAlgorithmDescriptor__section_u4v_pnt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetAlgorithmPerformance"><a name="cudnnSetAlgorithmPerformance" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetAlgorithmPerformance" name="cudnnSetAlgorithmPerformance" shape="rect">3.2.80.&nbsp;<kbd class="ph userinput">cudnnSetAlgorithmPerformance()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function initializes a previously created generic algorithm performance object.</p><pre xml:space="preserve">cudnnStatus_t cudnnSetAlgorithmPerformance(
    cudnnAlgorithmPerformance_t	    algoPerf,
    cudnnAlgorithmDescriptor_t      algoDesc,
    cudnnStatus_t                   status,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                           time,
    size_t                          memory)</pre><div class="section" id="cudnnSetAlgorithmPerformance__section_fpm_mb5_1jb"><a name="cudnnSetAlgorithmPerformance__section_fpm_mb5_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoPerf</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created algorithm
                                       performance object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algoDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The algorithm descriptor which the performance results
                                       describe.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">status</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The cuDNN status returned from running the
                                       <samp class="ph codeph">algoDesc</samp> algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">time</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The GPU time spent running the <samp class="ph codeph">algoDesc</samp>
                                       algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">memory</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The GPU memory needed to run the <samp class="ph codeph">algoDesc</samp>
                                       algorithm.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetAlgorithmPerformance__section_npw_mb5_1jb"><a name="cudnnSetAlgorithmPerformance__section_npw_mb5_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">mode</samp> or <samp class="ph codeph">reluNanOpt</samp> has an invalid
                                       enumerate value.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetCallback"><a name="cudnnSetCallback" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetCallback" name="cudnnSetCallback" shape="rect">3.2.81.&nbsp;<kbd class="ph userinput">cudnnSetCallback()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function sets the internal states of cuDNN error reporting
                                 functionality.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetCallback(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>            mask,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                *udata,
        cudnnCallback_t     fptr)</pre><div class="section" id="cudnnSetCallback__section_djx_f3z_1jb"><a name="cudnnSetCallback__section_djx_f3z_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mask</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. An unsigned integer. The four least significant bits
                                          (LSBs) of this unsigned integer are used for switching on and off
                                          the different levels of error reporting messages. This applies for
                                          both the default callbacks, and for the customized callbacks. The
                                          bit position is in correspondence with the enum of
                                          <samp class="ph codeph">cudnnSeverity_t</samp>. The user may utilize the
                                          predefined macros <samp class="ph codeph">CUDNN_SEV_ERROR_EN</samp>,
                                          <samp class="ph codeph">CUDNN_SEV_WARNING_EN</samp>, and
                                          <samp class="ph codeph">CUDNN_SEV_INFO_EN</samp> to form the bit mask. When a
                                          bit is set to <samp class="ph codeph">1</samp>, the corresponding message channel
                                          is enabled. 
                                       </p>
                                       <div class="p">For example, when bit 3 is set to <samp class="ph codeph">1</samp>, the API logging
                                          is enabled. Currently, only the log output of level
                                          <samp class="ph codeph">CUDNN_SEV_INFO</samp> is functional; the others are
                                          not yet implemented. When used for turning on and off the logging
                                          with the default callback, the user may pass <samp class="ph codeph">NULL</samp>
                                          to <samp class="ph codeph">udata</samp> and <samp class="ph codeph">fptr</samp>. In addition,
                                          the environment variable <samp class="ph codeph">CUDNN_LOGDEST_DBG</samp> must be
                                          set. For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#backward-compatibility" target="_blank" shape="rect">Deprecation Policy</a>.<a name="cudnnSetCallback__ul_ldz_r3z_1jb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnSetCallback__ul_ldz_r3z_1jb">
                                             <li class="li"><samp class="ph codeph">CUDNN_SEV_INFO_EN</samp>= 0b1000
                                                (functional).
                                             </li>
                                             <li class="li"><samp class="ph codeph">CUDNN_SEV_ERROR_EN</samp>= 0b0010 (not yet
                                                functional).
                                             </li>
                                             <li class="li"><samp class="ph codeph">CUDNN_SEV_WARNING_EN</samp>= 0b0100 (not yet
                                                functional).
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The output of <samp class="ph codeph">CUDNN_SEV_FATAL</samp> is always enabled and
                                          cannot be disabled.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">udata</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A pointer provided by the user. This pointer will be
                                       passed to the users custom logging callback function. The data it
                                       points to will not be read, nor be changed by cuDNN. This pointer may be
                                       used in many ways, such as in a mutex or in a communication socket for
                                       the users callback function for logging. If the user is utilizing the
                                       default callback function, or doesnt want to use this input in the
                                       customized callback function, they may pass in <samp class="ph codeph">NULL</samp>.
                                       
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">fptr</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A pointer to a user-supplied callback function. When
                                       <samp class="ph codeph">NULL</samp> is passed to this pointer, then cuDNN switches
                                       back to the built-in default callback function. The user-supplied
                                       callback function prototype must be similar to the following (also
                                       defined in the header file):
                                       <pre xml:space="preserve">void customizedLoggingCallback (cudnnSeverity_t sev, void *udata, const cudnnDebug_t *dbg, const char *msg);</pre><a name="cudnnSetCallback__ul_zfm_jn5_k2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetCallback__ul_zfm_jn5_k2b">
                                          <li class="li">The structure <samp class="ph codeph">cudnnDebug_t</samp> is defined in the
                                             header file. It provides the metadata, such as time, time since
                                             start, stream ID, process and thread ID, that the user may
                                             choose to print or store in their customized callback. 
                                          </li>
                                          <li class="li">The variable <samp class="ph codeph">msg</samp> is the logging message
                                             generated by cuDNN. Each line of this message is terminated by
                                             <samp class="ph codeph">\0</samp>, and the end of the message is
                                             terminated by <samp class="ph codeph">\0\0</samp>. Users may select what is
                                             necessary to show in the log, and may reformat the string. 
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetCallback__section_enq_g3z_1jb"><a name="cudnnSetCallback__section_enq_g3z_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetDropoutDescriptor"><a name="cudnnSetDropoutDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetDropoutDescriptor" name="cudnnSetDropoutDescriptor" shape="rect">3.2.82.&nbsp;<kbd class="ph userinput">cudnnSetDropoutDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created dropout descriptor object. If the
                                 <samp class="ph codeph">states</samp> argument is equal to <samp class="ph codeph">NULL</samp>, then the random
                                 number generator states won't be initialized, and only the <samp class="ph codeph">dropout</samp>
                                 value will be set. The user is expected not to change the memory pointed at by
                                 <samp class="ph codeph">states</samp> for the duration of the computation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetDropoutDescriptor(
    cudnnDropoutDescriptor_t    dropoutDesc,
    cudnnHandle_t               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                       dropout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *states,
    size_t                      stateSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span>          seed)</pre><p class="p">When the <samp class="ph codeph">states</samp> argument is not <samp class="ph codeph">NULL</samp>, a cuRAND
                              initialization kernel is invoked by <samp class="ph codeph">cudnnSetDropoutDescriptor()</samp>. This
                              kernel requires a substantial amount of GPU memory for the stack. Memory is released
                              when the kernel finishes. The <samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp> status is
                              returned when no sufficient free memory is available for the GPU stack.
                           </p>
                           <div class="section" id="cudnnSetDropoutDescriptor__section_ah3_3kb_bjb"><a name="cudnnSetDropoutDescriptor__section_ah3_3kb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Previously created dropout descriptor object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropout</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The probability with which the value from input is set to
                                       zero during the dropout layer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">states</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to user-allocated GPU memory that will hold
                                       random number generator states.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">stateSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided memory for the
                                       states.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seed</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Seed used to initialize random number generator
                                       states.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetDropoutDescriptor__section_hmr_3kb_bjb"><a name="cudnnSetDropoutDescriptor__section_hmr_3kb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">sizeInBytes</samp> argument is less than the value
                                       returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnDropoutGetStatesSize" shape="rect">cudnnDropoutGetStatesSize()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function failed to temporarily extend the GPU stack.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">Internally used CUDA functions returned an error status.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetFilter4dDescriptor"><a name="cudnnSetFilter4dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFilter4dDescriptor" name="cudnnSetFilter4dDescriptor" shape="rect">3.2.83.&nbsp;<kbd class="ph userinput">cudnnSetFilter4dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created filter descriptor object into a 4D
                                 filter. The layout of the filters must be contiguous in memory.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFilter4dDescriptor(
    cudnnFilterDescriptor_t    filterDesc,
    cudnnDataType_t            dataType,
    cudnnTensorFormat_t        format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        k,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        w)</pre><p class="p">Tensor format <samp class="ph codeph">CUDNN_TENSOR_NHWC</samp> has limited support in <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>.
                           </p>
                           <div class="section" id="cudnnSetFilter4dDescriptor__section_x1g_hbg_bjb"><a name="cudnnSetFilter4dDescriptor__section_x1g_hbg_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created filter
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">format</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>.Type of the filter layout format. If this input is set
                                          to <samp class="ph codeph">CUDNN_TENSOR_NCHW</samp>, which is one of the enumerant
                                          values allowed by <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a></samp> descriptor, then the layout of the filter is in the
                                          form of <samp class="ph codeph">KCRS</samp>, where:<a name="cudnnSetFilter4dDescriptor__ul_rtw_jbg_bjb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnSetFilter4dDescriptor__ul_rtw_jbg_bjb">
                                             <li class="li"><samp class="ph codeph">K</samp> represents the number of output feature
                                                maps
                                             </li>
                                             <li class="li"><samp class="ph codeph">C</samp> is the number of input feature maps
                                             </li>
                                             <li class="li"><samp class="ph codeph">R</samp> is the number of rows per filter
                                             </li>
                                             <li class="li"><samp class="ph codeph">S</samp> is the number of columns per filter
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">If this input is set to <samp class="ph codeph">CUDNN_TENSOR_NHWC</samp>, then the
                                          layout of the filter is in the form of <samp class="ph codeph">KRSC</samp>. For
                                          more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a></samp>. 
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">k</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of output feature maps.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">c</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of input feature maps.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">h</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Height of each filter.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Width of each filter.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetFilter4dDescriptor__section_ucp_hbg_bjb"><a name="cudnnSetFilter4dDescriptor__section_ucp_hbg_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the parameters <samp class="ph codeph">k</samp>, <samp class="ph codeph">c</samp>,
                                       <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> is negative or
                                       <samp class="ph codeph">dataType</samp> or <samp class="ph codeph">format</samp> has an invalid
                                       enumerant value.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetFilterNdDescriptor"><a name="cudnnSetFilterNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFilterNdDescriptor" name="cudnnSetFilterNdDescriptor" shape="rect">3.2.84.&nbsp;<kbd class="ph userinput">cudnnSetFilterNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created filter descriptor object. The
                                 layout of the filters must be contiguous in memory.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFilterNdDescriptor(
    cudnnFilterDescriptor_t filterDesc,
    cudnnDataType_t         dataType,
    cudnnTensorFormat_t     format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               filterDimA[])</pre><p class="p">The tensor format <samp class="ph codeph">CUDNN_TENSOR_NHWC</samp> has limited support in <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>. 
                           </p>
                           <div class="section" id="cudnnSetFilterNdDescriptor__section_j1k_xfh_bjb"><a name="cudnnSetFilterNdDescriptor__section_j1k_xfh_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created filter
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">format</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>.Type of the filter layout format. If this input is set
                                          to <samp class="ph codeph">CUDNN_TENSOR_NCHW</samp>, which is one of the enumerant
                                          values allowed by <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a></samp> descriptor, then the layout of the filter is as
                                          follows: <a name="cudnnSetFilterNdDescriptor__ul_qyq_1h5_k2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnSetFilterNdDescriptor__ul_qyq_1h5_k2b">
                                             <li class="li">For <samp class="ph codeph">N=4</samp>, a 4D filter descriptor, the filter
                                                layout is in the form of <samp class="ph codeph">KCRS</samp>: <a name="cudnnSetFilterNdDescriptor__ul_ad3_thh_bjb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="cudnnSetFilterNdDescriptor__ul_ad3_thh_bjb">
                                                   <li class="li"><samp class="ph codeph">K</samp> represents the number of output
                                                      feature maps
                                                   </li>
                                                   <li class="li"><samp class="ph codeph">C</samp> is the number of input feature
                                                      maps
                                                   </li>
                                                   <li class="li"><samp class="ph codeph">R</samp> is the number of rows per
                                                      filter
                                                   </li>
                                                   <li class="li"><samp class="ph codeph">S</samp> is the number of columns per
                                                      filter
                                                   </li>
                                                </ul>
                                             </li>
                                             <li class="li">For <samp class="ph codeph">N=3</samp>, a 3D filter descriptor, the number
                                                <samp class="ph codeph">S</samp> (number of columns per filter) is
                                                omitted. 
                                             </li>
                                             <li class="li">For <samp class="ph codeph">N=5</samp> and greater, the layout of the
                                                higher dimensions immediately follows <samp class="ph codeph">RS</samp>.
                                                
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">On the other hand, if this input is set to
                                          <samp class="ph codeph">CUDNN_TENSOR_NHWC</samp>, then the layout of the
                                          filter is as follows: <a name="cudnnSetFilterNdDescriptor__ul_txm_jh5_k2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnSetFilterNdDescriptor__ul_txm_jh5_k2b">
                                             <li class="li">For <samp class="ph codeph">N=4</samp>, a 4D filter descriptor, the filter
                                                layout is in the form of <samp class="ph codeph">KRSC</samp>. 
                                             </li>
                                             <li class="li">For <samp class="ph codeph">N=3</samp>, a 3D filter descriptor, the number
                                                <samp class="ph codeph">S</samp> (number of columns per filter) is
                                                omitted and the layout of <samp class="ph codeph">C</samp> immediately
                                                follows <samp class="ph codeph">R</samp>. 
                                             </li>
                                             <li class="li">For <samp class="ph codeph">N=5</samp> and greater, the layout of the
                                                higher dimensions are inserted between <samp class="ph codeph">S</samp>
                                                and <samp class="ph codeph">C</samp>. For more information, refer to
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a></samp>.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the filter.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                       size of the filter for each dimension.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetFilterNdDescriptor__section_td5_xfh_bjb"><a name="cudnnSetFilterNdDescriptor__section_td5_xfh_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the elements of the array <samp class="ph codeph">filterDimA</samp> is
                                       negative or <samp class="ph codeph">dataType</samp> or <samp class="ph codeph">format</samp> has an
                                       invalid enumerant value.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The parameter <samp class="ph codeph">nbDims</samp> exceeds
                                       <samp class="ph codeph">CUDNN_DIM_MAX</samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetLRNDescriptor"><a name="cudnnSetLRNDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetLRNDescriptor" name="cudnnSetLRNDescriptor" shape="rect">3.2.85.&nbsp;<kbd class="ph userinput">cudnnSetLRNDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created LRN descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetLRNDescriptor(
    cudnnLRNDescriptor_t   normDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>               lrnN,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 lrnAlpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 lrnBeta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 lrnK)</pre><div class="note note"><span class="notetitle">Note:</span><a name="cudnnSetLRNDescriptor__ul_ox2_hxh_bjb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetLRNDescriptor__ul_ox2_hxh_bjb">
                                 <li class="li">Macros <samp class="ph codeph">CUDNN_LRN_MIN_N</samp>, <samp class="ph codeph">CUDNN_LRN_MAX_N</samp>,
                                    <samp class="ph codeph">CUDNN_LRN_MIN_K</samp>, <samp class="ph codeph">CUDNN_LRN_MIN_BETA</samp>
                                    defined in <samp class="ph codeph">cudnn.h</samp> specify valid ranges for parameters.
                                 </li>
                                 <li class="li">Values of double parameters will be cast down to the tensor
                                    <samp class="ph codeph">datatype</samp> during computation.
                                 </li>
                              </ul>
                           </div>
                           <div class="section" id="cudnnSetLRNDescriptor__section_syc_m13_bjb"><a name="cudnnSetLRNDescriptor__section_syc_m13_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created LRN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lrnN</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Normalization window width in elements. The LRN layer uses
                                       a window <samp class="ph codeph">[center-lookBehind, center+lookAhead]</samp>, where
                                       <samp class="ph codeph">lookBehind = floor( (lrnN-1)/2 )</samp>, <samp class="ph codeph">lookAhead
                                          = lrnN-lookBehind-1</samp>. So for <samp class="ph codeph">n=10</samp>, the
                                       window is <samp class="ph codeph">[k-4...k...k+5]</samp> with a total of 10 samples.
                                       For the <samp class="ph codeph">DivisiveNormalization</samp> layer, the window has the
                                       same extent as above in all spatial dimensions
                                       (<samp class="ph codeph">dimA[2]</samp>, <samp class="ph codeph">dimA[3]</samp>,
                                       <samp class="ph codeph">dimA[4]</samp>). By default, <samp class="ph codeph">lrnN</samp> is set
                                       to <samp class="ph codeph">5</samp> in <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateLRNDescriptor" title="This function allocates the memory needed to hold the data needed for LRN and DivisiveNormalization layers operation and returns a descriptor used with subsequent layer forward and backward calls." shape="rect">cudnnCreateLRNDescriptor()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lrnAlpha</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Value of the alpha variance scaling parameter in the
                                       normalization formula. Inside the library code, this value is divided by
                                       the window width for LRN and by <samp class="ph codeph">(window
                                          width)^#spatialDimensions</samp> for
                                       <samp class="ph codeph">DivisiveNormalization</samp>. By default, this value is
                                       set to <samp class="ph codeph">1e-4</samp> in <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateLRNDescriptor" title="This function allocates the memory needed to hold the data needed for LRN and DivisiveNormalization layers operation and returns a descriptor used with subsequent layer forward and backward calls." shape="rect">cudnnCreateLRNDescriptor()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lrnBeta</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Value of the beta power parameter in the normalization
                                       formula. By default, this value is set to <samp class="ph codeph">0.75</samp> in
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateLRNDescriptor" title="This function allocates the memory needed to hold the data needed for LRN and DivisiveNormalization layers operation and returns a descriptor used with subsequent layer forward and backward calls." shape="rect">cudnnCreateLRNDescriptor()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lrnK</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Value of the <samp class="ph codeph">k</samp> parameter in the
                                       normalization formula. By default, this value is set to
                                       <samp class="ph codeph">2.0</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetLRNDescriptor__section_e2n_m13_bjb"><a name="cudnnSetLRNDescriptor__section_e2n_m13_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">One of the input parameters was out of valid range as described
                                       above.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetOpTensorDescriptor"><a name="cudnnSetOpTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetOpTensorDescriptor" name="cudnnSetOpTensorDescriptor" shape="rect">3.2.86.&nbsp;<kbd class="ph userinput">cudnnSetOpTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a tensor pointwise math descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetOpTensorDescriptor(
    cudnnOpTensorDescriptor_t   opTensorDesc,
    cudnnOpTensorOp_t           opTensorOp,
    cudnnDataType_t             opTensorCompType,
    cudnnNanPropagation_t       opTensorNanOpt)</pre><div class="section" id="cudnnSetOpTensorDescriptor__section_d4y_3b3_bjb"><a name="cudnnSetOpTensorDescriptor__section_d4y_3b3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the structure holding the description of the
                                       tensor pointwise math descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorOp</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor pointwise math operation for this tensor pointwise
                                       math descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorCompType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Computation datatype for this tensor pointwise math
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">opTensorNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. NAN propagation policy.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetOpTensorDescriptor__section_lkj_jb3_bjb"><a name="cudnnSetOpTensorDescriptor__section_lkj_jb3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the input parameters passed is invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetPooling2dDescriptor"><a name="cudnnSetPooling2dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetPooling2dDescriptor" name="cudnnSetPooling2dDescriptor" shape="rect">3.2.87.&nbsp;<kbd class="ph userinput">cudnnSetPooling2dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic pooling descriptor object
                                 into a 2D description.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetPooling2dDescriptor(
    cudnnPoolingDescriptor_t    poolingDesc,
    cudnnPoolingMode_t          mode,
    cudnnNanPropagation_t       maxpoolingNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         windowHeight,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         windowWidth,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         verticalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         horizontalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         verticalStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         horizontalStride)</pre><div class="section" id="cudnnSetPooling2dDescriptor__section_qph_cq3_bjb"><a name="cudnnSetPooling2dDescriptor__section_qph_cq3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created pooling
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the pooling mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxpoolingNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">windowHeight</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Height of the pooling window.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">windowWidth</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Width of the pooling window.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">verticalPadding</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of vertical padding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">horizontalPadding</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of horizontal padding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">verticalStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pooling vertical stride.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">horizontalStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pooling horizontal stride.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetPooling2dDescriptor__section_eyv_cq3_bjb"><a name="cudnnSetPooling2dDescriptor__section_eyv_cq3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the parameters <samp class="ph codeph">windowHeight</samp>,
                                       <samp class="ph codeph">windowWidth</samp>, <samp class="ph codeph">verticalStride</samp>,
                                       <samp class="ph codeph">horizontalStride</samp> is negative or
                                       <samp class="ph codeph">mode</samp> or <samp class="ph codeph">maxpoolingNanOpt</samp> has an
                                       invalid enumerate value.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetPoolingNdDescriptor"><a name="cudnnSetPoolingNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetPoolingNdDescriptor" name="cudnnSetPoolingNdDescriptor" shape="rect">3.2.88.&nbsp;<kbd class="ph userinput">cudnnSetPoolingNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic pooling descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetPoolingNdDescriptor(
    cudnnPoolingDescriptor_t     poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingMode_t     mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnNanPropagation_t  maxpoolingNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    windowDimA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    paddingA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    strideA[])</pre><div class="section" id="cudnnSetPoolingNdDescriptor__section_t2b_xq3_bjb"><a name="cudnnSetPoolingNdDescriptor__section_t2b_xq3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created pooling
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the pooling mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxpoolingNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph"><samp class="ph codeph">nbDims</samp></samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the pooling operation. Must be greater than
                                       zero. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">windowDimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                       window size for each dimension. The value of array elements must be
                                       greater than zero. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddingA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                       padding size for each dimension. Negative padding is allowed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">strideA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                       striding size for each dimension. The value of array elements must be
                                       greater than zero (meaning, negative striding size is not allowed).
                                       
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetPoolingNdDescriptor__section_sqk_xq3_bjb"><a name="cudnnSetPoolingNdDescriptor__section_sqk_xq3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was initialized successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">If (<samp class="ph codeph">nbDims</samp> &gt; <samp class="ph codeph">CUDNN_DIM_MAX-2</samp>). 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either <samp class="ph codeph">nbDims</samp>, or at least one of the elements of the
                                       arrays <samp class="ph codeph">windowDimA</samp> or <samp class="ph codeph">strideA</samp> is
                                       negative, or <samp class="ph codeph">mode</samp> or <samp class="ph codeph">maxpoolingNanOpt</samp>
                                       has an invalid enumerate value.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetReduceTensorDescriptor"><a name="cudnnSetReduceTensorDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetReduceTensorDescriptor" name="cudnnSetReduceTensorDescriptor" shape="rect">3.2.89.&nbsp;<kbd class="ph userinput">cudnnSetReduceTensorDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created reduce tensor descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetReduceTensorDescriptor(
    cudnnReduceTensorDescriptor_t   reduceTensorDesc,
    cudnnReduceTensorOp_t           reduceTensorOp,
    cudnnDataType_t                 reduceTensorCompType,
    cudnnNanPropagation_t           reduceTensorNanOpt,
    cudnnReduceTensorIndices_t      reduceTensorIndices,
    cudnnIndicesType_t              reduceTensorIndicesType)</pre><div class="section" id="cudnnSetReduceTensorDescriptor__section_aj1_lr3_bjb"><a name="cudnnSetReduceTensorDescriptor__section_aj1_lr3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created reduce tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorOp</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the reduce tensor operation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorCompType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the computation datatype of the
                                       reduction.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorIndices</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the reduced tensor indices.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reduceTensorIndicesType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the reduce tensor indices type.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetReduceTensorDescriptor__section_pwj_lr3_bjb"><a name="cudnnSetReduceTensorDescriptor__section_pwj_lr3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">reduceTensorDesc</samp> is <samp class="ph codeph">NULL</samp>
                                       (<samp class="ph codeph">reduceTensorOp</samp>,
                                       <samp class="ph codeph">reduceTensorCompType</samp>,
                                       <samp class="ph codeph">reduceTensorNanOpt</samp>,
                                       <samp class="ph codeph">reduceTensorIndices</samp> or
                                       <samp class="ph codeph">reduceTensorIndicesType</samp> has an invalid enumerant
                                       value).
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetSpatialTransformerNdDescriptor"><a name="cudnnSetSpatialTransformerNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetSpatialTransformerNdDescriptor" name="cudnnSetSpatialTransformerNdDescriptor" shape="rect">3.2.90.&nbsp;<kbd class="ph userinput">cudnnSetSpatialTransformerNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic spatial transformer
                                 descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetSpatialTransformerNdDescriptor(
    cudnnSpatialTransformerDescriptor_t     stDesc,
    cudnnSamplerType_t                      samplerType,
    cudnnDataType_t                         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               dimA[])</pre><div class="section" id="cudnnSetSpatialTransformerNdDescriptor__section_ay3_1rc_cjb"><a name="cudnnSetSpatialTransformerNdDescriptor__section_ay3_1rc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">stDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Previously created spatial transformer descriptor
                                       object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">samplerType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the sampler type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the transformed tensor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                       size of the transformed tensor for every dimension. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetSpatialTransformerNdDescriptor__section_y3s_1rc_cjb"><a name="cudnnSetSpatialTransformerNdDescriptor__section_y3s_1rc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSetSpatialTransformerNdDescriptor__ul_pqt_333_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetSpatialTransformerNdDescriptor__ul_pqt_333_s1b">
                                          <li class="li"> Either <samp class="ph codeph">stDesc</samp> or <samp class="ph codeph">dimA</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"> Either <samp class="ph codeph">dataType</samp> or
                                             <samp class="ph codeph">samplerType</samp> has an invalid enumerant
                                             value.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetStream"><a name="cudnnSetStream" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetStream" name="cudnnSetStream" shape="rect">3.2.91.&nbsp;<kbd class="ph userinput">cudnnSetStream()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function sets the user's CUDA stream in the cuDNN handle. The new stream
                                 will be used to launch cuDNN GPU kernels or to synchronize to this stream when cuDNN
                                 kernels are launched in the internal streams. If the cuDNN library stream is not set,
                                 all kernels use the default (<samp class="ph codeph">NULL</samp>) stream. Setting the user stream in
                                 the cuDNN handle guarantees the issue-order execution of cuDNN calls and other GPU
                                 kernels launched in the same stream.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetStream(
    cudnnHandle_t   handle,
    cudaStream_t    streamId)</pre><p class="p">With CUDA 11.x or later, internal streams have the same priority as the stream set by the
                              last call to this function. In CUDA graph capture mode, CUDA 11.8 or later is required
                              in order for the stream priorities to match.
                           </p>
                           <div class="section" id="cudnnSetStream__section_jlx_3rc_cjb"><a name="cudnnSetStream__section_jlx_3rc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the cuDNN handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">streamID</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. New CUDA stream to be written to the cuDNN handle.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetStream__section_wyg_jrc_cjb"><a name="cudnnSetStream__section_wyg_jrc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid (<samp class="ph codeph">NULL</samp>) handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">Mismatch between the user stream and the cuDNN handle context.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The new stream was set successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetTensor"><a name="cudnnSetTensor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensor" name="cudnnSetTensor" shape="rect">3.2.92.&nbsp;<kbd class="ph userinput">cudnnSetTensor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function sets all the elements of a tensor to a given value. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensor(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *valuePtr)</pre><div class="section" id="cudnnSetTensor__section_n2x_vrc_cjb"><a name="cudnnSetTensor__section_n2x_vrc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">yDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">valuePtr</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer in host memory to a single value. All elements of
                                       the <samp class="ph codeph">y</samp> tensor will be set to <samp class="ph codeph">value[0]</samp>.
                                       The data type of the element in <samp class="ph codeph">value[0]</samp> has to match
                                       the data type of tensor <samp class="ph codeph">y</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetTensor__section_zrg_wrc_cjb"><a name="cudnnSetTensor__section_zrg_wrc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">One of the provided pointers is <samp class="ph codeph">NIL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetTensor4dDescriptor"><a name="cudnnSetTensor4dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensor4dDescriptor" name="cudnnSetTensor4dDescriptor" shape="rect">3.2.93.&nbsp;<kbd class="ph userinput">cudnnSetTensor4dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic tensor descriptor object
                                 into a 4D tensor. The strides of the four dimensions are inferred from the format
                                 parameter and set in such a way that the data is contiguous in memory with no padding
                                 between dimensions. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensor4dDescriptor(
    cudnnTensorDescriptor_t tensorDesc,
    cudnnTensorFormat_t     format,
    cudnnDataType_t         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     w)</pre><p class="p">The total size of a tensor including the potential padding between dimensions is limited
                              to 2 Giga-elements of type <samp class="ph codeph">datatype</samp>.
                           </p>
                           <div class="section" id="cudnnSetTensor4dDescriptor__section_ws4_dsc_cjb"><a name="cudnnSetTensor4dDescriptor__section_ws4_dsc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">format</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Type of format.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">n</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">c</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of feature maps per image.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">h</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Height of each feature map.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Width of each feature map.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetTensor4dDescriptor__section_axx_dsc_cjb"><a name="cudnnSetTensor4dDescriptor__section_axx_dsc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the parameters <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                       <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> was negative or
                                       <samp class="ph codeph">format</samp> has an invalid enumerant value or
                                       <samp class="ph codeph">dataType</samp> has an invalid enumerant value.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The total size of the tensor descriptor exceeds the maximum limit of 2
                                       Giga-elements.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetTensor4dDescriptorEx"><a name="cudnnSetTensor4dDescriptorEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensor4dDescriptorEx" name="cudnnSetTensor4dDescriptorEx" shape="rect">3.2.94.&nbsp;<kbd class="ph userinput">cudnnSetTensor4dDescriptorEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic tensor descriptor object
                                 into a 4D tensor, similarly to <samp class="ph codeph">cudnnSetTensor4dDescriptor()</samp> but with
                                 the strides explicitly passed as parameters. This can be used to lay out the 4D tensor
                                 in any order or simply to define gaps between dimensions.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensor4dDescriptorEx(
    cudnnTensorDescriptor_t     tensorDesc,
    cudnnDataType_t             dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         nStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         cStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         hStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         wStride)</pre><p class="p">At present, some cuDNN routines have limited support for strides. Those routines will
                              return <samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp> if a 4D tensor object with an
                              unsupported stride is used. <samp class="ph codeph"><a class="xref" href="index.html#cudnnTransformTensor" title="This function copies the scaled data from one tensor to another tensor with a different layout. Those descriptors need to have the same dimensions but not necessarily the same strides. The input and output tensors must not overlap in any way (meaning, tensors cannot be transformed in place). This function can be used to convert a tensor with an unsupported format to a supported one." shape="rect">cudnnTransformTensor()</a></samp> can
                              be used to convert the data to a supported layout.
                           </p>
                           <p class="p">The total size of a tensor including the potential padding between dimensions is limited
                              to 2 Giga-elements of type <samp class="ph codeph">datatype</samp>.
                           </p>
                           <div class="section" id="cudnnSetTensor4dDescriptorEx__section_uyl_tsc_cjb"><a name="cudnnSetTensor4dDescriptorEx__section_uyl_tsc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">n</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">c</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of feature maps per image.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">h</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Height of each feature map.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Width of each feature map.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Stride between two consecutive images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Stride between two consecutive feature maps.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Stride between two consecutive rows.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wStride</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Stride between two consecutive columns.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetTensor4dDescriptorEx__section_uzv_tsc_cjb"><a name="cudnnSetTensor4dDescriptorEx__section_uzv_tsc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the parameters <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                       <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> or <samp class="ph codeph">nStride</samp>,
                                       <samp class="ph codeph">cStride</samp>, <samp class="ph codeph">hStride</samp>,
                                       <samp class="ph codeph">wStride</samp> is negative or <samp class="ph codeph">dataType</samp>
                                       has an invalid enumerant value.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The total size of the tensor descriptor exceeds the maximum limit of 2
                                       Giga-elements.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetTensorNdDescriptor"><a name="cudnnSetTensorNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensorNdDescriptor" name="cudnnSetTensorNdDescriptor" shape="rect">3.2.95.&nbsp;<kbd class="ph userinput">cudnnSetTensorNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic tensor descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensorNdDescriptor(
    cudnnTensorDescriptor_t tensorDesc,
    cudnnDataType_t         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               dimA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               strideA[])</pre><p class="p">The total size of a tensor including the potential padding between dimensions is limited
                              to 2 Giga-elements of type <samp class="ph codeph">datatype</samp>. Tensors are restricted to having
                              at least 4 dimensions, and at most <samp class="ph codeph">CUDNN_DIM_MAX</samp> dimensions (defined in
                              <samp class="ph codeph">cudnn.h</samp>). When working with lower dimensional data, it is
                              recommended that the user create a 4D tensor, and set the size along unused dimensions
                              to 1. 
                           </p>
                           <div class="section" id="cudnnSetTensorNdDescriptor__section_yxn_htc_cjb"><a name="cudnnSetTensorNdDescriptor__section_yxn_htc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the tensor. 
                                       <div class="note note"><span class="notetitle">Note:</span> Do not use 2 dimensions.
                                          Due to historical reasons, the minimum number of dimensions in the
                                          filter descriptor is three. For more information, refer to
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNLinLayerBiasParams" shape="rect">cudnnGetRNNLinLayerBiasParams()</a></samp>.
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> that contain
                                       the size of the tensor for every dimension. The size along unused
                                       dimensions should be set to <samp class="ph codeph">1</samp>. By convention, the
                                       ordering of dimensions in the array follows the format - <samp class="ph codeph">[N, C,
                                          D, H, W]</samp>, with <samp class="ph codeph">W</samp> occupying the smallest
                                       index in the array.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">strideA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> that contain
                                       the stride of the tensor for every dimension. By convention, the
                                       ordering of the strides in the array follows the format -
                                       <samp class="ph codeph">[Nstride, Cstride, Dstride, Hstride, Wstride]</samp>, with
                                       <samp class="ph codeph">Wstride</samp> occupying the smallest index in the
                                       array.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetTensorNdDescriptor__section_hjb_3tc_cjb"><a name="cudnnSetTensorNdDescriptor__section_hjb_3tc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the elements of the array <samp class="ph codeph">dimA</samp> was
                                       negative or zero, or <samp class="ph codeph">dataType</samp> has an invalid enumerant
                                       value.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The parameter <samp class="ph codeph">nbDims</samp> is outside the range <samp class="ph codeph">[4,
                                          CUDNN_DIM_MAX]</samp>, or the total size of the tensor descriptor
                                       exceeds the maximum limit of 2 Giga-elements. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetTensorNdDescriptorEx"><a name="cudnnSetTensorNdDescriptorEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensorNdDescriptorEx" name="cudnnSetTensorNdDescriptorEx" shape="rect">3.2.96.&nbsp;<kbd class="ph userinput">cudnnSetTensorNdDescriptorEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes an <samp class="ph codeph">Nd</samp> tensor descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensorNdDescriptorEx(
    cudnnTensorDescriptor_t tensorDesc,
    cudnnTensorFormat_t     format,
    cudnnDataType_t         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               dimA[])</pre><div class="section" id="cudnnSetTensorNdDescriptorEx__section_grq_stc_cjb"><a name="cudnnSetTensorNdDescriptorEx__section_grq_stc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the tensor descriptor struct to be
                                       initialized.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">format</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor format.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor data type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the tensor. 
                                       <div class="note note"><span class="notetitle">Note:</span> Do not use 2 dimensions.
                                          Due to historical reasons, the minimum number of dimensions in the
                                          filter descriptor is three. For more information, refer to
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNLinLayerBiasParams" shape="rect">cudnnGetRNNLinLayerBiasParams()</a></samp>.
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array containing the size of each dimension. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetTensorNdDescriptorEx__section_zsb_ttc_cjb"><a name="cudnnSetTensorNdDescriptorEx__section_zsb_ttc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Tensor descriptor was not allocated properly; or input parameters are
                                       not set correctly.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Dimension size requested is larger than maximum dimension size
                                       supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetTensorTransformDescriptor"><a name="cudnnSetTensorTransformDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensorTransformDescriptor" name="cudnnSetTensorTransformDescriptor" shape="rect">3.2.97.&nbsp;<kbd class="ph userinput">cudnnSetTensorTransformDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function initializes a tensor transform descriptor that was previously created
                              		using the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateTensorTransformDescriptor" shape="rect">cudnnCreateTensorTransformDescriptor()</a></samp>
                              		function. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t transformDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> uint32_t nbDims,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorFormat_t destFormat,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> int32_t padBeforeA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> int32_t padAfterA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> uint32_t foldA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFoldingDirection_t direction);
</pre><div class="section" id="cudnnSetTensorTransformDescriptor__section_cxb_f5c_cjb"><a name="cudnnSetTensorTransformDescriptor__section_cxb_f5c_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transformDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The tensor transform descriptor to be initialized.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The dimensionality of the transform operands. Must be
                                       							greater than 2. For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#tensor-descriptor" target="_blank" shape="rect">Tensor Descriptor</a>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">destFormat</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The desired destination format.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">padBeforeA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array that contains the amount of padding that should
                                       							be added before each dimension. Set to <samp class="ph codeph">NULL</samp> for no
                                       							padding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">padAfterA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array that contains the amount of padding that should
                                       							be added after each dimension. Set to <samp class="ph codeph">NULL</samp> for no
                                       							padding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">foldA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array that contains the folding parameters for each
                                       							spatial dimension (dimensions 2 and up). Set to <samp class="ph codeph">NULL</samp>
                                       							for no folding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">direction</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Selects folding or unfolding. This input has no effect when folding
                                       							parameters are all &lt;= 1. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFoldingDirection_t" shape="rect">cudnnFoldingDirection_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetTensorTransformDescriptor__section_ltn_f5c_cjb"><a name="cudnnSetTensorTransformDescriptor__section_ltn_f5c_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function was launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The parameter <samp class="ph codeph">transformDesc</samp> is <samp class="ph codeph">NULL</samp>,
                                       							or if <samp class="ph codeph">direction</samp> is invalid, or <samp class="ph codeph">nbDims</samp>
                                       							is &lt;= 2.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">If the dimension size requested is larger than maximum dimension size
                                       							supported (meaning, one of the <samp class="ph codeph">nbDims</samp> is larger than
                                       								<samp class="ph codeph">CUDNN_DIM_MAX</samp>), or if <samp class="ph codeph">destFromat</samp>
                                       							is something other than <samp class="ph codeph">NCHW</samp> or
                                       							<samp class="ph codeph">NHWC</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSoftmaxForward"><a name="cudnnSoftmaxForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxForward" name="cudnnSoftmaxForward" shape="rect">3.2.98.&nbsp;<kbd class="ph userinput">cudnnSoftmaxForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This routine computes the softmax function.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSoftmaxForward(
    cudnnHandle_t                    handle,
    cudnnSoftmaxAlgorithm_t          algorithm,
    cudnnSoftmaxMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><p class="p">All tensor formats are supported for all modes and algorithms with 4 and 5D tensors.
                              Performance is expected to be highest with <samp class="ph codeph">NCHW fully-packed</samp> tensors.
                              For more than 5 dimensions tensors must be packed in their spatial dimensions.
                           </p>
                           <div class="section" id="cudnnSoftmaxForward__section_bls_p2l_35b"><a name="cudnnSoftmaxForward__section_bls_p2l_35b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Data Types</h4>
                              <div class="p">This function supports the following data types:<a name="cudnnSoftmaxForward__ul_mht_n2l_35b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnSoftmaxForward__ul_mht_n2l_35b">
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_HALF</samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_INT8</samp></li>
                                 </ul>
                              </div>
                           </div>
                           <div class="section" id="cudnnSoftmaxForward__section_vkj_fxc_cjb"><a name="cudnnSoftmaxForward__section_vkj_fxc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algorithm</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the softmax algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the softmax mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*result + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSoftmaxForward__section_gms_fxc_cjb"><a name="cudnnSoftmaxForward__section_gms_fxc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSoftmaxForward__ul_zvp_2xh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSoftmaxForward__ul_zvp_2xh_s1b">
                                          <li class="li">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                             <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> of the input tensor
                                             and output tensors differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output
                                             tensors differ.
                                          </li>
                                          <li class="li">The parameters <samp class="ph codeph">algorithm</samp> or
                                             <samp class="ph codeph">mode</samp> have an invalid enumerant value.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSpatialTfGridGeneratorForward"><a name="cudnnSpatialTfGridGeneratorForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfGridGeneratorForward" name="cudnnSpatialTfGridGeneratorForward" shape="rect">3.2.99.&nbsp;<kbd class="ph userinput">cudnnSpatialTfGridGeneratorForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function generates a grid of coordinates in the input tensor corresponding
                                 to each pixel from the output tensor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfGridGeneratorForward(
    cudnnHandle_t                               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t   stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *theta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                       *grid)</pre><p class="p">Only 2D transformation is supported.</p>
                           <div class="section" id="cudnnSpatialTfGridGeneratorForward__section_fg3_szc_cjb"><a name="cudnnSpatialTfGridGeneratorForward__section_fg3_szc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">stDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously created spatial transformer descriptor
                                       object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">theta</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Affine transformation matrix. It should be of size
                                       <samp class="ph codeph">n*2*3</samp> for a 2d transformation, where
                                       <samp class="ph codeph">n</samp> is the number of images specified in
                                       <samp class="ph codeph">stDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">grid</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A grid of coordinates. It is of size
                                       <samp class="ph codeph">n*h*w*2</samp> for a 2d transformation, where
                                       <samp class="ph codeph">n</samp>, <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> is
                                       specified in <samp class="ph codeph">stDesc</samp>. In the 4th dimension, the first
                                       coordinate is <samp class="ph codeph">x</samp>, and the second coordinate is
                                       <samp class="ph codeph">y</samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSpatialTfGridGeneratorForward__section_vly_szc_cjb"><a name="cudnnSpatialTfGridGeneratorForward__section_vly_szc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSpatialTfGridGeneratorForward__ul_v1w_m33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorForward__ul_v1w_m33_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"> One of the parameters <samp class="ph codeph">grid</samp> or
                                             <samp class="ph codeph">theta</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. Refer to the
                                       following examples of non-supported configurations:<a name="cudnnSpatialTfGridGeneratorForward__ul_abw_m33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorForward__ul_abw_m33_s1b">
                                          <li class="li">The dimension of the transformed tensor specified in
                                             <samp class="ph codeph">stDesc</samp> &gt; 4.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSpatialTfSamplerForward"><a name="cudnnSpatialTfSamplerForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfSamplerForward" name="cudnnSpatialTfSamplerForward" shape="rect">3.2.100.&nbsp;<kbd class="ph userinput">cudnnSpatialTfSamplerForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function performs a sampler operation and generates the output tensor using
                                 the grid given by the grid generator.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfSamplerForward(
    cudnnHandle_t                              handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t  stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *grid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *beta,
    cudnnTensorDescriptor_t                    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                      *y)</pre><p class="p">Only 2D transformation is supported.</p>
                           <div class="section" id="cudnnSpatialTfSamplerForward__section_qvg_mbd_cjb"><a name="cudnnSpatialTfSamplerForward__section_qvg_mbd_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">stDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously created spatial transformer descriptor
                                       object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the source value with prior value in the destination tensor as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*srcValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">grid</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A grid of coordinates generated by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSpatialTfGridGeneratorForward" title="This function generates a grid of coordinates in the input tensor corresponding to each pixel from the output tensor." shape="rect">cudnnSpatialTfGridGeneratorForward()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSpatialTfSamplerForward__section_jpp_mbd_cjb"><a name="cudnnSpatialTfSamplerForward__section_jpp_mbd_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSpatialTfSamplerForward__ul_mqz_t33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerForward__ul_mqz_t33_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"> One of the parameters <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp> or
                                             <samp class="ph codeph">grid</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. Refer to the
                                       following examples of non-supported configurations:<a name="cudnnSpatialTfSamplerForward__ul_rqz_t33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerForward__ul_rqz_t33_s1b">
                                          <li class="li">The dimension of transformed tensor &gt; 4. </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnTransformFilter"><a name="cudnnTransformFilter" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTransformFilter" name="cudnnTransformFilter" shape="rect">3.2.101.&nbsp;<kbd class="ph userinput">cudnnTransformFilter()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function converts the filter between different formats, data types, or
                                 dimensions based on the described transformation. It can be used to convert a filter
                                 with an unsupported layout format to a filter with a supported layout
                                 format.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnTransformFilter(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorTransformDescriptor_t transDesc,                                    
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *alpha,                                           
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t srcDesc,                        
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *srcData,   
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *beta, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t destDesc, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *destData);</pre><p class="p">This function copies the scaled data from the input filter <samp class="ph codeph">srcDesc</samp> to
                              the output tensor <samp class="ph codeph">destDesc</samp> with a different layout. If the filter
                              descriptors of <samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> have different
                              dimensions, they must be consistent with folding and padding amount and order specified
                              in <samp class="ph codeph">transDesc</samp>.
                           </p>
                           <div class="p">The <samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> tensors must not overlap in
                              any way (that is, tensors cannot be transformed in place).
                              <div class="note note"><span class="notetitle">Note:</span> When performing a
                                 folding transform or a zero-padding transform, the scaling factors
                                 (<samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp>) should be set to (1, 0).
                                 However, unfolding transforms support any (<samp class="ph codeph">alpha</samp>,
                                 <samp class="ph codeph">beta</samp>) values. This function is thread safe.
                              </div>
                           </div>
                           <div class="section" id="cudnnTransformFilter__section_pst_skn_y3b"><a name="cudnnTransformFilter__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A descriptor containing the details of the requested
                                       filter transformation. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorTransformDescriptor_t" shape="rect">cudnnTensorTransformDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. Pointers, in the host memory, to the scaling factors
                                          used to scale the data in the input tensor <samp class="ph codeph">srcDesc</samp>.
                                          <samp class="ph codeph">beta</samp> is used to scale the destination tensor,
                                          while <samp class="ph codeph">alpha</samp> is used to scale the source tensor. For
                                          more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                       <p class="p">The beta scaling value is not honored in the folding and zero-padding
                                          cases. Unfolding supports any (<samp class="ph codeph">alpha</samp>,
                                          <samp class="ph codeph">beta</samp>).
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">srcDesc</samp>, <samp class="ph codeph">destDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handles to the previously initiated filter descriptors.
                                       <samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> must not
                                       overlap. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">srcData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointers, in the host memory, to the data of the tensor
                                       described by <samp class="ph codeph">srcDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">destData</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointers, in the host memory, to the data of the tensor
                                       described by <samp class="ph codeph">destDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnTransformFilter__section_vzb_skn_y3b"><a name="cudnnTransformFilter__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">A parameter is uninitialized or initialized incorrectly, or the number
                                       of dimensions is different between <samp class="ph codeph">srcDesc</samp> and
                                       <samp class="ph codeph">destDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. Also, in the
                                       folding and padding paths, any value other than <samp class="ph codeph">A=1</samp> and
                                       <samp class="ph codeph">B=0</samp> will result in a
                                       <samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnTransformTensor"><a name="cudnnTransformTensor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTransformTensor" name="cudnnTransformTensor" shape="rect">3.2.102.&nbsp;<kbd class="ph userinput">cudnnTransformTensor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function copies the scaled data from one tensor to another tensor with a
                                 different layout. Those descriptors need to have the same dimensions but not necessarily
                                 the same strides. The input and output tensors must not overlap in any way (meaning,
                                 tensors cannot be transformed in place). This function can be used to convert a tensor
                                 with an unsupported format to a supported one.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnTransformTensor(
    cudnnHandle_t                  handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *y)</pre><div class="section" id="cudnnTransformTensor__section_hzr_qcd_cjb"><a name="cudnnTransformTensor__section_hzr_qcd_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the source value with prior value in the destination tensor as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*srcValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">xDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">yDesc</samp> descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnTransformTensor__section_m5d_rcd_cjb"><a name="cudnnTransformTensor__section_m5d_rcd_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                       <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> or the
                                       <samp class="ph codeph">dataType</samp> of the two tensor descriptors are
                                       different.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnTransformTensorEx"><a name="cudnnTransformTensorEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTransformTensorEx" name="cudnnTransformTensorEx" shape="rect">3.2.103.&nbsp;<kbd class="ph userinput">cudnnTransformTensorEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function converts the tensor layouts between different formats. It can be
                                 			used to convert a tensor with an unsupported layout format to a tensor with a supported
                                 			layout format.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnTransformTensorEx(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorTransformDescriptor_t transDesc,                                    
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *alpha,                                           
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t srcDesc,                        
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *srcData,   
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *beta, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t destDesc, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *destData);
</pre><p class="p">This function copies the scaled data from the input tensor <samp class="ph codeph">srcDesc</samp> to the
                              			output tensor <samp class="ph codeph">destDesc</samp> with a different layout. The tensor descriptors
                              			of <samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> should have the same
                              			dimensions but need not have the same strides. 
                           </p>
                           <div class="p">The <samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> tensors must not overlap in any way
                              			(that is, tensors cannot be transformed in place). 
                              <div class="note note"><span class="notetitle">Note:</span> When performing a folding
                                 				transform or a zero-padding transform, the scaling factors
                                 					<samp class="ph codeph">(alpha,beta)</samp> should be set to (1, 0). However, unfolding
                                 				transforms support any <samp class="ph codeph">(alpha,beta)</samp> values. This function is thread
                                 				safe. 
                              </div>
                           </div>
                           <div class="section" id="cudnnTransformTensorEx__section_d5s_fdd_cjb"><a name="cudnnTransformTensorEx__section_d5s_fdd_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A descriptor containing the details of the requested tensor transformation.
                                       							For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorTransformDescriptor_t" shape="rect">cudnnTensorTransformDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. Pointers, in the host memory, to the scaling factors used to scale the data
                                          								in the input tensor <samp class="ph codeph">srcDesc</samp>. <samp class="ph codeph">beta</samp>
                                          								is used to scale the destination tensor, while
                                          									<samp class="ph codeph">alpha</samp> is used to scale the source tensor. For
                                          								more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                       <p class="p">The beta scaling value is not honored in the folding and zero-padding
                                          								cases. Unfolding supports any (<samp class="ph codeph">alpha</samp>,
                                          									<samp class="ph codeph">beta</samp>).
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">srcDesc</samp>, <samp class="ph codeph">destDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handles to the previously initiated tensor descriptors.
                                       								<samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> must not
                                       							overlap. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">srcData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointers, in the host memory, to the data of the tensor
                                       							described by <samp class="ph codeph">srcDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">destData</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointers, in the host memory, to the data of the tensor
                                       							described by <samp class="ph codeph">destDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnTransformTensorEx__section_wk2_gdd_cjb"><a name="cudnnTransformTensorEx__section_wk2_gdd_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function was launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">A parameter is uninitialized or initialized incorrectly, or the number
                                       							of dimensions is different between <samp class="ph codeph">srcDesc</samp> and
                                       								<samp class="ph codeph">destDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Function does not support the provided configuration. Also, in the
                                       							folding and padding paths, any value other than <samp class="ph codeph">A=1</samp> and
                                       								<samp class="ph codeph">B=0</samp> will result in a
                                       								<samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">Function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="cudnn-ops-train-so-library"><a name="cudnn-ops-train-so-library" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cudnn-ops-train-so-library" name="cudnn-ops-train-so-library" shape="rect">4.&nbsp;<kbd class="ph userinput">cudnn_ops_train.so</kbd> Library</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">This entity contains common training routines and algorithms, such as batch
                           normalization, softmax, dropout, and so on. The <samp class="ph codeph">cudnn_ops_train</samp> library
                           depends on <samp class="ph codeph">cudnn_ops_infer</samp>.</span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="cudnn-ops-train-so-api"><a name="cudnn-ops-train-so-api" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-ops-train-so-api" name="cudnn-ops-train-so-api" shape="rect">4.1.&nbsp;API Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the API functions in the <samp class="ph codeph">cudnn_ops_train.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnnActivationBackward"><a name="cudnnActivationBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationBackward" name="cudnnActivationBackward" shape="rect">4.1.1.&nbsp;<kbd class="ph userinput">cudnnActivationBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This routine computes the gradient of a neuron activation function.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnActivationBackward(
    cudnnHandle_t                    handle,
    cudnnActivationDescriptor_t      activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx)</pre><p class="p">In-place operation is allowed for this routine; meaning <samp class="ph codeph">dy</samp> and
                              <samp class="ph codeph">dx</samp> pointers may be equal. However, this requires the corresponding
                              tensor descriptors to be identical (particularly, the strides of the input and output
                              must match for an in-place operation to be allowed).
                           </p>
                           <p class="p">All tensor formats are supported for 4 and 5 dimensions, however, the best performance is
                              obtained when the strides of <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">xDesc</samp> are equal
                              and <samp class="ph codeph">HW-packed</samp>. For more than 5 dimensions the tensors must have their
                              spatial dimensions packed.
                           </p>
                           <div class="section" id="cudnnActivationBackward__section_pst_skn_y3b"><a name="cudnnActivationBackward__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Activation descriptor. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*result + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">dxDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnActivationBackward__section_vzb_skn_y3b"><a name="cudnnActivationBackward__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnActivationBackward__ul_p1s_hzh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnActivationBackward__ul_p1s_hzh_s1b">
                                          <li class="li">The strides <samp class="ph codeph">nStride</samp>, <samp class="ph codeph">cStride</samp>,
                                             <samp class="ph codeph">hStride</samp> and <samp class="ph codeph">wStride</samp> of the
                                             input differential tensor and output differential tensor differ
                                             and in-place operation is used.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. Refer to the
                                       following examples of non-supported configurations:<a name="cudnnActivationBackward__ul_w1s_hzh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnActivationBackward__ul_w1s_hzh_s1b">
                                          <li class="li">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                             <samp class="ph codeph">h</samp>, and <samp class="ph codeph">w</samp> of the input
                                             tensor and output tensor differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output
                                             tensor differs.
                                          </li>
                                          <li class="li">The strides <samp class="ph codeph">nStride</samp>, <samp class="ph codeph">cStride</samp>,
                                             <samp class="ph codeph">hStride</samp>, and <samp class="ph codeph">wStride</samp> of
                                             the input tensor and the input differential tensor differ.
                                          </li>
                                          <li class="li">The strides <samp class="ph codeph">nStride</samp>, <samp class="ph codeph">cStride</samp>,
                                             <samp class="ph codeph">hStride</samp>, and <samp class="ph codeph">wStride</samp> of
                                             the output tensor and the output differential tensor
                                             differ.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBatchNormalizationBackward"><a name="cudnnBatchNormalizationBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationBackward" name="cudnnBatchNormalizationBackward" shape="rect">4.1.2.&nbsp;<kbd class="ph userinput">cudnnBatchNormalizationBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs the backward batch normalization layer computation. This layer
                              is based on the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate
                                 Shift</a> paper. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnBatchNormalizationBackward(
      cudnnHandle_t                    handle,
      cudnnBatchNormMode_t             mode,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alphaDataDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *betaDataDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alphaParamDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *betaParamDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    bnScaleBiasDiffDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnScale,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultBnScaleDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultBnBiasDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           epsilon,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *savedMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *savedInvVariance)</pre><p class="p">Only 4D and 5D tensors are supported.</p>
                           <p class="p">The <samp class="ph codeph">epsilon</samp> value has to be the same during training, backpropagation,
                              and inference.
                           </p>
                           <p class="p">Higher performance can be obtained when <samp class="ph codeph">HW-packed</samp> tensors are used for
                              all of <samp class="ph codeph">x</samp>, <samp class="ph codeph">dy</samp>, and <samp class="ph codeph">dx</samp>.
                           </p>
                           <p class="p">For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp> for the secondary tensor descriptor generation for the parameters used
                              in this function.
                           </p>
                           <div class="section" id="cudnnBatchNormalizationBackward__section_qll_w5n_y3b"><a name="cudnnBatchNormalizationBackward__section_qll_w5n_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alphaDataDiff</samp>, <samp class="ph codeph">*betaDataDiff</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the gradient output <samp class="ph codeph">dx</samp> with a prior value in
                                          the destination tensor as follows:
                                          <pre xml:space="preserve">dstValue = alphaDataDiff[0]*resultValue + betaDataDiff[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alphaParamDiff</samp>, <samp class="ph codeph">*betaParamDiff</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the gradient outputs <samp class="ph codeph">resultBnScaleDiff</samp> and
                                          <samp class="ph codeph">resultBnBiasDiff</samp> with prior values in the
                                          destination tensor as follows:
                                          <pre xml:space="preserve">dstValue = alphaParamDiff[0]*resultValue + betaParamDiff[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>. 
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dxDesc</samp>, <samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Handles to the previously initialized tensor
                                       descriptors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*x</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>, for the layers <samp class="ph codeph">x</samp>
                                       data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dyDesc</samp>, for the backpropagated differential
                                       <samp class="ph codeph">dy</samp> input.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs/Outputs</em>. Data pointer to GPU memory associated with the
                                       tensor descriptor <samp class="ph codeph">dxDesc</samp>, for the resulting
                                       differential output with respect to <samp class="ph codeph">x</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnScaleBiasDiffDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Shared tensor descriptor for the following five tensors:
                                       <samp class="ph codeph">bnScale</samp>, <samp class="ph codeph">resultBnScaleDiff</samp>,
                                       <samp class="ph codeph">resultBnBiasDiff</samp>, <samp class="ph codeph">savedMean</samp>, and
                                       <samp class="ph codeph">savedInvVariance</samp>. The dimensions for this tensor
                                       descriptor are dependent on normalization mode. For more information,
                                       refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp>.
                                       <div class="note note"><span class="notetitle">Note:</span> The data type of this tensor descriptor must be
                                          <samp class="ph codeph">float</samp> for FP16 and FP32 input tensors, and
                                          <samp class="ph codeph">double</samp> for FP64 input tensors.
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*bnScale</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer in the device memory for the batch normalization
                                       <samp class="ph codeph">scale</samp> parameter (in the original paper the quantity
                                       <samp class="ph codeph">scale</samp> is referred to as gamma). 
                                       <div class="note note"><span class="notetitle">Note:</span> The
                                          <samp class="ph codeph">bnBias</samp> parameter is not needed for this layer's
                                          computation.
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">resultBnScaleDiff</samp>,
                                       <samp class="ph codeph">resultBnBiasDiff</samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Pointers in device memory for the resulting scale and
                                       bias differentials computed by this routine. Note that these scale and
                                       bias gradients are weight gradients specific to this batch normalization
                                       operation, and by definition are not backpropagated. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in batch normalization formula. Its
                                       value should be equal to or greater than the value defined for
                                       <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp> in <samp class="ph codeph">cudnn.h</samp>.
                                       The same <samp class="ph codeph">epsilon</samp> value should be used in forward and
                                       backward functions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*savedMean</samp>, <samp class="ph codeph">*savedInvVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Optional cache parameters containing saved intermediate
                                       results that were computed during the forward pass. For this to work
                                       correctly, the layer's <samp class="ph codeph">x</samp> and <samp class="ph codeph">bnScale</samp>
                                       data have to remain unchanged until this backward function is called.
                                       
                                       <div class="note note"><span class="notetitle">Note:</span> Both these parameters can be <samp class="ph codeph">NULL</samp> but only at
                                          the same time. It is recommended to use this cache since the memory
                                          overhead is relatively small. 
                                       </div>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationBackward__section_r3x_s4f_vlb"><a name="cudnnBatchNormalizationBackward__section_r3x_s4f_vlb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <div class="p">This function supports the following combinations of data types for various
                                 descriptors.
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnBatchNormalizationBackward__table_g4k_rpf_vlb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnBatchNormalizationBackward__table_g4k_rpf_vlb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 14. Supported Configurations for
                                             <samp class="ph codeph">cudnnBatchNormalizationBackward()</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e24152" rowspan="1" colspan="1">Data Type Configurations</th>
                                             <th class="entry" valign="top" width="20%" id="d54e24155" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e24159" rowspan="1" colspan="1"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e24163" rowspan="1" colspan="1"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e24170" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e24152" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24155" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24159" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24163" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24170" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e24152" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24155" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24159" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24163" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24170" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e24152" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24155" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24159" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24163" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24170" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e24152" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24155" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24159" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24163" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e24170" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationBackward__section_rzt_x5n_y3b"><a name="cudnnBatchNormalizationBackward__section_rzt_x5n_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnBatchNormalizationBackward__ul_gx5_kph_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBatchNormalizationBackward__ul_gx5_kph_jt">
                                          <li class="li">Any of the pointers <samp class="ph codeph">alpha</samp>,
                                             <samp class="ph codeph">beta</samp>, <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">dy</samp>, <samp class="ph codeph">dx</samp>,
                                             <samp class="ph codeph">bnScale</samp>,
                                             <samp class="ph codeph">resultBnScaleDiff</samp>, and
                                             <samp class="ph codeph">resultBnBiasDiff</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> or
                                             <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not
                                             within the range of <samp class="ph codeph">[4,5]</samp> (only 4D and 5D
                                             tensors are supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">bnScaleBiasDiffDesc</samp> dimensions are not 1xCx1x1
                                             for 4D and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for
                                             4D and 1xCxDxHxW for 5D for per-activation mode.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">savedMean</samp>,
                                             <samp class="ph codeph">savedInvVariance</samp> pointers is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than
                                             <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp>.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for any pair of
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, and
                                             <samp class="ph codeph">dxDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBatchNormalizationBackwardEx"><a name="cudnnBatchNormalizationBackwardEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationBackwardEx" name="cudnnBatchNormalizationBackwardEx" shape="rect">4.1.3.&nbsp;<kbd class="ph userinput">cudnnBatchNormalizationBackwardEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function is an extension of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> for performing the backward
                              batch normalization layer computation with a fast NHWC semi-persistent kernel.
                              <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnBatchNormalizationBackwardEx (
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *alphaDataDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *betaDataDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *alphaParamDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *betaParamDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *xData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *yData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *dyData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dzDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dzData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dxData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dBnScaleBiasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnScaleData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnBiasData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dBnScaleData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dBnBiasData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              epsilon,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *savedMean,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *savedInvVariance,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *workspace,
    size_t                              workSpaceSizeInBytes
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *reserveSpace
    size_t                              reserveSpaceSizeInBytes);</pre><div class="p">This API will trigger the new semi-persistent NHWC kernel when the following conditions
                              are true:<a name="cudnnBatchNormalizationBackwardEx__ul_xtn_fyn_y3b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationBackwardEx__ul_xtn_fyn_y3b">
                                 <li class="li">All tensors, namely, <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>,
                                    <samp class="ph codeph">dz</samp>, <samp class="ph codeph">dy</samp> and <samp class="ph codeph">dx</samp> must be
                                    NHWC-fully packed, and must be of the type
                                    <samp class="ph codeph">CUDNN_DATA_HALF</samp>.
                                 </li>
                                 <li class="li">The input parameter <samp class="ph codeph">mode</samp> must be set to
                                    <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workspace</samp> is not <samp class="ph codeph">NULL</samp>.
                                 </li>
                                 <li class="li">Before cuDNN version 8.2.0, the tensor <samp class="ph codeph">C</samp> dimension should
                                    always be a multiple of 4. After 8.2.0, the tensor <samp class="ph codeph">C</samp> dimension
                                    should be a multiple of 4 only when <samp class="ph codeph">bnOps</samp> is
                                    <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationBackwardExWorkspaceSize" title="This function returns the amount of GPU memory workspace the user should allocate to be able to call cudnnGetBatchNormalizationBackwardExWorkspaceSize() function for the specified bnOps input setting. The workspace allocated will then be passed to the function cudnnGetBatchNormalizationBackwardExWorkspaceSize()." shape="rect">cudnnGetBatchNormalizationBackwardExWorkspaceSize()</a></samp>. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationTrainingExReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the batch normalization operation, for the specified bnOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</a></samp>.
                                 </li>
                                 <li class="li">The content in <samp class="ph codeph">reserveSpace</samp> stored by <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTrainingEx" shape="rect">cudnnBatchNormalizationForwardTrainingEx()</a></samp> must be
                                    preserved.
                                 </li>
                              </ul>
                           </div>
                           <p class="p">If <samp class="ph codeph">workspace</samp> is <samp class="ph codeph">NULL</samp> and
                              <samp class="ph codeph">workSpaceSizeInBytes</samp> of zero is passed in, this API will function
                              exactly like the non-extended function
                              <samp class="ph codeph">cudnnBatchNormalizationBackward</samp>.
                           </p>
                           <p class="p">This <samp class="ph codeph">workspace</samp> is not required to be clean. Moreover, the
                              <samp class="ph codeph">workspace</samp> does not have to remain unchanged between the forward and
                              backward pass, as it is not used for passing any information.
                           </p>
                           <p class="p">This extended function can accept a <samp class="ph codeph">*workspace</samp> pointer to the GPU
                              workspace, and <samp class="ph codeph">workSpaceSizeInBytes</samp>, the size of the workspace, from
                              the user.
                           </p>
                           <p class="p">The <samp class="ph codeph">bnOps</samp> input can be used to set this function to perform either only
                              the batch normalization, or batch normalization followed by activation, or batch
                              normalization followed by element-wise addition and then activation.
                           </p>
                           <p class="p">Only 4D and 5D tensors are supported. The <samp class="ph codeph">epsilon</samp> value has to be the
                              same during the training, the backpropagation, and the inference.
                           </p>
                           <p class="p">When the tensor layout is NCHW, higher performance can be obtained when HW-packed tensors
                              are used for <samp class="ph codeph">x</samp>, <samp class="ph codeph">dy</samp>, and <samp class="ph codeph">dx</samp>.
                           </p>
                           <div class="section" id="cudnnBatchNormalizationBackwardEx__section_myb_czn_y3b"><a name="cudnnBatchNormalizationBackwardEx__section_myb_czn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation. Currently,
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp> and
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp> are only
                                       supported in the NHWC layout. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormOps_t" shape="rect">cudnnBatchNormOps_t</a></samp>. This
                                       input can be used to set this function to perform either only the batch
                                       normalization, or batch normalization followed by activation, or batch
                                       normalization followed by element-wise addition and then activation. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alphaDataDiff</samp>, <samp class="ph codeph">*betaDataDiff</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the gradient output <samp class="ph codeph">dx</samp> with a prior value in
                                          the destination tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alphaParamDiff</samp>, <samp class="ph codeph">*betaParamDiff</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the gradient outputs <samp class="ph codeph">dBnScaleData</samp> and
                                          <samp class="ph codeph">dBnBiasData</samp> with prior values in the
                                          destination tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">*x</samp>, <samp class="ph codeph">yDesc</samp>,
                                       <samp class="ph codeph">*yData</samp>, <samp class="ph codeph">dyDesc</samp>,
                                       <samp class="ph codeph">*dyData</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Tensor descriptors and pointers in the device memory for
                                       the layer's <samp class="ph codeph">x</samp> data, backpropagated gradient input
                                       <samp class="ph codeph">dy</samp>, the original forward output <samp class="ph codeph">y</samp>
                                       data. <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">yData</samp> are not needed
                                       if <samp class="ph codeph">bnOps</samp> is set to
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN</samp>, users may pass
                                       <samp class="ph codeph">NULL</samp>. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph"><strong class="ph b">dzDesc</strong></samp>, <samp class="ph codeph"><strong class="ph b">dxDesc</strong></samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Tensor descriptors and pointers in the device memory for
                                       the computed gradient output <samp class="ph codeph">dz</samp>, and
                                       <samp class="ph codeph">dx</samp>. <samp class="ph codeph">dzDesc</samp> is not needed when
                                       <samp class="ph codeph">bnOps</samp> is <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN</samp> or
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp>, users may pass
                                       <samp class="ph codeph">NULL</samp>. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph"><strong class="ph b">*dzData</strong></samp>, <samp class="ph codeph"><strong class="ph b">*dxData</strong></samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Tensor descriptors and pointers in the device memory for
                                       the computed gradient output <samp class="ph codeph">dz</samp>, and
                                       <samp class="ph codeph">dx</samp>. <samp class="ph codeph">*dzData</samp> is not needed when
                                       <samp class="ph codeph">bnOps</samp> is <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN</samp> or
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp>, users may pass
                                       <samp class="ph codeph">NULL</samp>. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dBnScaleBiasDesc</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. Shared tensor descriptor for the following six tensors:
                                          <samp class="ph codeph">bnScaleData</samp>, <samp class="ph codeph">bnBiasData</samp>,
                                          <samp class="ph codeph">dBnScaleData</samp>, <samp class="ph codeph">dBnBiasData</samp>,
                                          <samp class="ph codeph">savedMean</samp>, and
                                          <samp class="ph codeph">savedInvVariance</samp>. For more information, refer
                                          to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp>.
                                       </p>
                                       <div class="p">The dimensions for this tensor descriptor are dependent on
                                          normalization mode. 
                                          <div class="note note"><span class="notetitle">Note:</span> The data type of this tensor descriptor
                                             must be <samp class="ph codeph">float</samp> for FP16 and FP32 input tensors
                                             and <samp class="ph codeph">double</samp> for FP64 input tensors. 
                                          </div>
                                          
                                          For
                                          more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*bnScaleData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer in the device memory for the batch normalization
                                       scale parameter (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating
                                          Deep Network Training by Reducing Internal Covariate Shift</a>
                                       paper, the quantity scale is referred to as gamma).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*bnBiasData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointers in the device memory for the batch normalization
                                       bias parameter (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating
                                          Deep Network Training by Reducing Internal Covariate Shift</a>
                                       paper, bias is referred to as beta). This parameter is used only when
                                       activation should be performed. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*dBnScaleData</samp>, <samp class="ph codeph">*dBnBiasData</samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Pointers in the device memory for the gradients of
                                       <samp class="ph codeph">bnScaleData</samp> and <samp class="ph codeph">bnBiasData</samp>,
                                       respectively. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in batch normalization formula. Its
                                       value should be equal to or greater than the value defined for
                                       <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp> in <samp class="ph codeph">cudnn.h</samp>.
                                       The same epsilon value should be used in forward and backward
                                       functions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*savedMean</samp>, <samp class="ph codeph">*savedInvVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Optional cache parameters containing saved intermediate
                                       results computed during the forward pass. For this to work correctly,
                                       the layer's <samp class="ph codeph">x</samp> and <samp class="ph codeph">bnScaleData</samp>,
                                       <samp class="ph codeph">bnBiasData</samp> data has to remain unchanged until this
                                       backward function is called. Note that both these parameters can be
                                       <samp class="ph codeph">NULL</samp> but only at the same time. It is recommended
                                       to use this cache since the memory overhead is relatively small. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">bnOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise the user may pass
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace. If
                                       <samp class="ph codeph">workspace</samp> is <samp class="ph codeph">NULL</samp> and
                                       <samp class="ph codeph">workSpaceSizeInBytes</samp> of zero is passed in, then
                                       this API will function exactly like the non-extended function
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the workspace. It must be large enough to
                                       trigger the fast NHWC semi-persistent kernel by this function. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace for the
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the <samp class="ph codeph">reserveSpace</samp>. It must be
                                       equal or larger than the amount required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationTrainingExReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the batch normalization operation, for the specified bnOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</a></samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationBackwardEx__section_qys_2pf_vlb"><a name="cudnnBatchNormalizationBackwardEx__section_qys_2pf_vlb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <div class="p">This function supports the following combinations of data types for various
                                 descriptors.
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnBatchNormalizationBackwardEx__table_g4k_rpf_vlb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnBatchNormalizationBackwardEx__table_g4k_rpf_vlb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 15. Supported Configurations for
                                             <samp class="ph codeph">cudnnBatchNormalizationBackwardEx()</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e25192" rowspan="1" colspan="1">Data Type Configurations</th>
                                             <th class="entry" valign="top" width="20%" id="d54e25195" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e25199" rowspan="1" colspan="1"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e25203" rowspan="1" colspan="1"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e25210" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25192" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25195" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25199" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25203" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25210" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25192" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25195" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25199" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25203" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25210" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25192" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25195" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25199" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25203" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25210" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25192" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25195" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25199" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25203" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25210" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationBackwardEx__section_zbf_dzn_y3b"><a name="cudnnBatchNormalizationBackwardEx__section_zbf_dzn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnBatchNormalizationBackwardEx__ul_gx5_kph_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBatchNormalizationBackwardEx__ul_gx5_kph_jt">
                                          <li class="li">Any of the pointers <samp class="ph codeph">alphaDataDiff</samp>,
                                             <samp class="ph codeph">betaDataDiff</samp>,
                                             <samp class="ph codeph">alphaParamDiff</samp>,
                                             <samp class="ph codeph">betaParamDiff</samp>, <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">dy</samp>, <samp class="ph codeph">dx</samp>,
                                             <samp class="ph codeph">bnScale</samp>,
                                             <samp class="ph codeph">resultBnScaleDiff</samp>, and
                                             <samp class="ph codeph">resultBnBiasDiff</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not
                                             within the range of <samp class="ph codeph">[4,5]</samp> (only 4D and 5D
                                             tensors are supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">dBnScaleBiasDesc</samp> dimensions not 1xCx1x1 for 4D
                                             and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and
                                             1xCxDxHxW for 5D for per-activation mode.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">savedMean</samp>,
                                             <samp class="ph codeph">savedInvVariance</samp> pointers is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than
                                             <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp>.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for any pair of
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBatchNormalizationForwardTraining"><a name="cudnnBatchNormalizationForwardTraining" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationForwardTraining" name="cudnnBatchNormalizationForwardTraining" shape="rect">4.1.4.&nbsp;<kbd class="ph userinput">cudnnBatchNormalizationForwardTraining()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs the forward batch normalization layer computation for the
                              training phase. This layer is based on the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network Training
                                 by Reducing Internal Covariate Shift</a> paper. <span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnBatchNormalizationForwardTraining(
      cudnnHandle_t                    handle,
      cudnnBatchNormMode_t             mode,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    bnScaleBiasMeanVarDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnScale,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnBias,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           exponentialAverageFactor,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultRunningMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultRunningVariance,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           epsilon,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultSaveMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultSaveInvVariance)</pre><p class="p">Only 4D and 5D tensors are supported.</p>
                           <p class="p">The <span class="keyword apiname">epsilon</span> value has to be the same during training, backpropagation,
                              and inference.
                           </p>
                           <p class="p">For the inference phase, use
                              <span class="keyword apiname">cudnnBatchNormalizationForwardInference</span>.
                           </p>
                           <p class="p">Higher performance can be obtained when HW-packed tensors are used for both
                              <span class="keyword apiname">x</span> and <span class="keyword apiname">y</span>.
                           </p>
                           <p class="p">Refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp> for the
                              secondary tensor descriptor generation for the parameters used in this function.
                           </p>
                           <div class="section" id="cudnnBatchNormalizationForwardTraining__section_ach_rqt_y3b"><a name="cudnnBatchNormalizationForwardTraining__section_ach_rqt_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd">Handle to a previously created cuDNN library descriptor. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd">Mode of operation (spatial or per-activation). For more information,
                                       refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">Tensor descriptors and pointers in device memory for the layer's
                                       <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp> data. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">*x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>, for the layers <samp class="ph codeph">x</samp>
                                       input data.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">*y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">yDesc</samp>, for the <samp class="ph codeph">y</samp>output of
                                       the batch normalization layer.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></dt>
                                    <dd class="dd">Shared tensor descriptor <samp class="ph codeph">desc</samp> for the secondary tensor
                                       that was derived by <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp>. The dimensions for this tensor descriptor are dependent
                                       on the normalization mode.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">bnScale</samp>, <samp class="ph codeph">bnBias</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Pointers in device memory for the batch normalization
                                       scale and bias parameters (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network
                                          Training by Reducing Internal Covariate Shift</a> paper, bias is
                                       referred to as beta and scale as gamma). Note that
                                       <samp class="ph codeph">bnBias</samp> parameter can replace the previous layer's
                                       bias parameter for improved efficiency.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">exponentialAverageFactor</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Factor used in the moving average computation as
                                          follows:<pre xml:space="preserve">runningMean = runningMean*(1-factor) + newMean*factor</pre></div>
                                       <div class="p">Use a <samp class="ph codeph">factor=1/(1+n)</samp> at <samp class="ph codeph">N</samp>-th call
                                          to the function to get the Cumulative Moving Average (CMA) behavior,
                                          for example:<pre xml:space="preserve">CMA[n] = (x[1]+...+x[n])/n</pre></div>
                                       <div class="p">For
                                          example:<pre xml:space="preserve">CMA[n+1] = (n*CMA[n]+x[n+1])/(n+1)
= ((n+1)*CMA[n]-CMA[n])/(n+1) + x[n+1]/(n+1)
= CMA[n]*(1-1/(n+1))+x[n+1]*1/(n+1)
= CMA[n]*(1-factor) + x(n+1)*factor
</pre></div>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">resultRunningMean</samp>,
                                       <samp class="ph codeph">resultRunningVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs/Outputs</em>. Running mean and variance tensors (these have the
                                       same descriptor as the bias and scale). Both of these pointers can be
                                       <samp class="ph codeph">NULL</samp> but only at the same time. The value stored in
                                       <samp class="ph codeph">resultRunningVariance</samp> (or passed as an input in
                                       inference mode) is the sample variance and is the moving average of
                                       <samp class="ph codeph">variance[x]</samp> where the variance is computed either
                                       over batch or spatial+batch dimensions depending on the mode. If these
                                       pointers are not <samp class="ph codeph">NULL</samp>, the tensors should be
                                       initialized to some reasonable values or to 0.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in the batch normalization formula. Its
                                       value should be equal to or greater than the value defined for
                                       <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp> in <samp class="ph codeph">cudnn.h</samp>.
                                       The same <samp class="ph codeph">epsilon</samp> value should be used in forward and
                                       backward functions.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">resultSaveMean</samp>,
                                       <samp class="ph codeph">resultSaveInvVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Optional cache to save intermediate results computed
                                       during the forward pass. These buffers can be used to speed up the
                                       backward pass when supplied to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> function.
                                       The intermediate results stored in <samp class="ph codeph">resultSaveMean</samp> and
                                       <samp class="ph codeph">resultSaveInvVariance</samp> buffers should not be used
                                       directly by the user. Depending on the batch normalization mode, the
                                       results stored in <samp class="ph codeph">resultSaveInvVariance</samp> may vary. For
                                       the cache to work correctly, the input layer data must remain unchanged
                                       until the backward function is called. Note that both parameters can be
                                       <samp class="ph codeph">NULL</samp> but only at the same time. In such a case,
                                       intermediate statistics will not be saved, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> will have to
                                       re-compute them. It is recommended to use this cache as the memory
                                       overhead is relatively small because these tensors have a much lower
                                       product of dimensions than the data tensors. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationForwardTraining__section_scs_qpf_vlb"><a name="cudnnBatchNormalizationForwardTraining__section_scs_qpf_vlb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <div class="p">This function supports the following combinations of data types for various
                                 descriptors.
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnBatchNormalizationForwardTraining__table_g4k_rpf_vlb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnBatchNormalizationForwardTraining__table_g4k_rpf_vlb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 16. Supported Configurations for
                                             <samp class="ph codeph">cudnnBatchNormalizationForwardTraining()</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e25861" rowspan="1" colspan="1">Data Type Configurations</th>
                                             <th class="entry" valign="top" width="20%" id="d54e25864" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e25868" rowspan="1" colspan="1"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e25872" rowspan="1" colspan="1"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e25879" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25861" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25864" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25868" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25872" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25879" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25861" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25864" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25868" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25872" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25879" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25861" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25864" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25868" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25872" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25879" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e25861" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25864" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25868" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25872" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e25879" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationForwardTraining__section_yrj_sqt_y3b"><a name="cudnnBatchNormalizationForwardTraining__section_yrj_sqt_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnBatchNormalizationForwardTraining__ul_qnn_k4g_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardTraining__ul_qnn_k4g_jt">
                                          <li class="li">One of the pointers <samp class="ph codeph">alpha</samp>,
                                             <samp class="ph codeph">beta</samp>, <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp>, <samp class="ph codeph">bnScale</samp>, and
                                             <samp class="ph codeph">bnBias</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                             tensor descriptor dimensions is not within the range of
                                             <samp class="ph codeph">[4,5]</samp> (only 4D and 5D tensors are
                                             supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> dimensions are not
                                             1xCx1x1 for 4D and 1xCx1x1x1 for 5D for spatial, and are not
                                             1xCxHxW for 4D and 1xCxDxHxW for 5D for per-activation
                                             mode.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">resultSaveMean</samp>,
                                             <samp class="ph codeph">resultSaveInvVariance</samp> pointers are
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">resultRunningMean</samp>,
                                             <samp class="ph codeph">resultRunningInvVariance</samp> pointers are
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than
                                             <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp>.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp> or
                                             <samp class="ph codeph">yDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBatchNormalizationForwardTrainingEx"><a name="cudnnBatchNormalizationForwardTrainingEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationForwardTrainingEx" name="cudnnBatchNormalizationForwardTrainingEx" shape="rect">4.1.5.&nbsp;<kbd class="ph userinput">cudnnBatchNormalizationForwardTrainingEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function is an extension of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp> for performing the
                              forward batch normalization layer computation. <span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnBatchNormalizationForwardTrainingEx(
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *xData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       zDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *zData, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *yData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       bnScaleBiasMeanVarDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnScaleData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnBiasData, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              exponentialAverageFactor,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *resultRunningMeanData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *resultRunningVarianceData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              epsilon,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *saveMean,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *saveInvVariance,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *workspace,
    size_t                              workSpaceSizeInBytes
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *reserveSpace
    size_t                              reserveSpaceSizeInBytes);</pre><div class="p">This API will trigger the new semi-persistent NHWC kernel when the following conditions
                              are true:<a name="cudnnBatchNormalizationForwardTrainingEx__ul_wsp_3tt_y3b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardTrainingEx__ul_wsp_3tt_y3b">
                                 <li class="li">All tensors, namely, <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>,
                                    <samp class="ph codeph">dz</samp>, <samp class="ph codeph">dy</samp> and <samp class="ph codeph">dx</samp> must be
                                    NHWC-fully packed and must be of the type <samp class="ph codeph">CUDNN_DATA_HALF</samp>. 
                                 </li>
                                 <li class="li">The input parameter <samp class="ph codeph">mode</samp> must be set to
                                    <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workspace</samp> is not <samp class="ph codeph">NULL</samp>.
                                 </li>
                                 <li class="li">Before cuDNN version 8.2.0, the tensor <samp class="ph codeph">C</samp> dimension should
                                    always be a multiple of 4. After 8.2.0, the tensor <samp class="ph codeph">C</samp> dimension
                                    should be a multiple of 4 only when <samp class="ph codeph">bnOps</samp> is
                                    <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize" title="This function returns the amount of GPU memory workspace the user should allocate to be able to call cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize() function for the specified bnOps input setting. The workspace allocated should then be passed by the user to the function cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()." shape="rect">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</a></samp>. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationTrainingExReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the batch normalization operation, for the specified bnOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</a></samp>.
                                 </li>
                                 <li class="li">The content in <samp class="ph codeph">reserveSpace</samp> stored by <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTrainingEx" shape="rect">cudnnBatchNormalizationForwardTrainingEx()</a></samp> must be
                                    preserved.
                                 </li>
                              </ul>
                           </div>
                           <p class="p">If <samp class="ph codeph">workspace</samp> is <samp class="ph codeph">NULL</samp> and
                              <samp class="ph codeph">workSpaceSizeInBytes</samp> of zero is passed in, this API will function
                              exactly like the non-extended function <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp>.
                           </p>
                           <p class="p">This workspace is not required to be clean. Moreover, the workspace does not have to
                              remain unchanged between the forward and backward pass, as it is not used for passing
                              any information.
                           </p>
                           <p class="p">This extended function can accept a <samp class="ph codeph">*workspace</samp> pointer to the GPU
                              workspace, and <samp class="ph codeph">workSpaceSizeInBytes</samp>, the size of the workspace, from
                              the user.
                           </p>
                           <p class="p">The <samp class="ph codeph">bnOps</samp> input can be used to set this function to perform either only
                              the batch normalization, or batch normalization followed by activation, or batch
                              normalization followed by element-wise addition and then activation.
                           </p>
                           <p class="p">Only 4D and 5D tensors are supported. The <samp class="ph codeph">epsilon</samp> value has to be the
                              same during the training, the backpropagation, and the inference.
                           </p>
                           <p class="p">When the tensor layout is NCHW, higher performance can be obtained when HW-packed tensors
                              are used for <samp class="ph codeph">x</samp>, <samp class="ph codeph">dy</samp>, and <samp class="ph codeph">dx</samp>.
                           </p>
                           <div class="section" id="cudnnBatchNormalizationForwardTrainingEx__section_dqt_l5t_y3b"><a name="cudnnBatchNormalizationForwardTrainingEx__section_dqt_l5t_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd">Handle to a previously created cuDNN library descriptor. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd">Mode of operation (spatial or per-activation). For more information,
                                       refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormOps_t" shape="rect">cudnnBatchNormOps_t</a></samp>. This input can be used to set this function to perform
                                       either only the batch normalization, or batch normalization followed by
                                       activation, or batch normalization followed by element-wise addition and
                                       then activation. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alpha</samp>, <samp class="ph codeph">*beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">*xData</samp>, <samp class="ph codeph">zDesc</samp>,
                                       <samp class="ph codeph">*zData</samp>, <samp class="ph codeph">yDesc</samp>,
                                       <samp class="ph codeph">*yData</samp></dt>
                                    <dd class="dd">Tensor descriptors and pointers in device memory for the layer's input
                                       <samp class="ph codeph">x</samp> and output <samp class="ph codeph">y</samp>, and for the
                                       optional <samp class="ph codeph">z</samp> tensor input for residual addition to the
                                       result of the batch normalization operation, prior to the activation.
                                       The optional <samp class="ph codeph">zDes</samp> and <samp class="ph codeph">*zData</samp>
                                       descriptors are only used when <samp class="ph codeph">bnOps</samp> is
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp>, otherwise
                                       users may pass <samp class="ph codeph">NULL</samp>. When in use, <samp class="ph codeph">z</samp>
                                       should have exactly the same dimension as <samp class="ph codeph">x</samp> and the
                                       final output <samp class="ph codeph">y</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></dt>
                                    <dd class="dd">Shared tensor descriptor <samp class="ph codeph">desc</samp> for the secondary tensor
                                       that was derived by <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp>. The dimensions for this tensor descriptor are dependent
                                       on the normalization mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*bnScaleData</samp>, <samp class="ph codeph">*bnBiasData</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Pointers in device memory for the batch normalization
                                       scale and bias parameters (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network
                                          Training by Reducing Internal Covariate Shift</a> paper, bias is
                                       referred to as beta and scale as gamma). Note that
                                       <samp class="ph codeph">bnBiasData</samp> parameter can replace the previous
                                       layer's bias parameter for improved efficiency.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">exponentialAverageFactor</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Factor used in the moving average computation as
                                       follows:<pre xml:space="preserve">runningMean = runningMean*(1-factor) + newMean*factor</pre><div class="p">Use
                                          a <samp class="ph codeph">factor=1/(1+n)</samp> at <samp class="ph codeph">N</samp>-th call to
                                          the function to get the Cumulative Moving Average (CMA) behavior,
                                          for
                                          example:<pre xml:space="preserve">CMA[n] = (x[1]+...+x[n])/n</pre></div>
                                       <div class="p">For
                                          example:<pre xml:space="preserve">CMA[n+1] = (n*CMA[n]+x[n+1])/(n+1)
= ((n+1)*CMA[n]-CMA[n])/(n+1) + x[n+1]/(n+1)
= CMA[n]*(1-1/(n+1))+x[n+1]*1/(n+1)
= CMA[n]*(1-factor) + x(n+1)*factor
</pre></div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*resultRunningMeanData</samp>,
                                       <samp class="ph codeph">*resultRunningVarianceData</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs/Outputs</em>. Pointers to the running mean and running variance
                                       data. Both these pointers can be <samp class="ph codeph">NULL</samp> but only at the
                                       same time. The value stored in
                                       <samp class="ph codeph">resultRunningVarianceData</samp> (or passed as an input in
                                       inference mode) is the sample variance and is the moving average of
                                       <samp class="ph codeph">variance[x]</samp> where the variance is computed either
                                       over batch or spatial+batch dimensions depending on the mode. If these
                                       pointers are not <samp class="ph codeph">NULL</samp>, the tensors should be
                                       initialized to some reasonable values or to <samp class="ph codeph">0</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in the batch normalization formula. Its
                                       value should be equal to or greater than the value defined for
                                       <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp> in <samp class="ph codeph">cudnn.h</samp>.
                                       The same <samp class="ph codeph">epsilon</samp> value should be used in forward and
                                       backward functions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*saveMean</samp>, <samp class="ph codeph">*saveInvVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Optional cache parameters containing saved intermediate
                                       results computed during the forward pass. For this to work correctly,
                                       the layer's <samp class="ph codeph">x</samp> and <samp class="ph codeph">bnScaleData</samp>,
                                       <samp class="ph codeph">bnBiasData</samp> data has to remain unchanged until this
                                       backward function is called. Note that both these parameters can be
                                       <samp class="ph codeph">NULL</samp> but only at the same time. It is recommended
                                       to use this cache since the memory overhead is relatively small. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The tensor descriptor for the activation operation. When
                                       the <samp class="ph codeph">bnOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise user may pass <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*workspace</samp>, <samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. <samp class="ph codeph">*workspace</samp> is a pointer to the GPU
                                       workspace, and <samp class="ph codeph">workSpaceSizeInBytes</samp> is the size of the
                                       workspace. When <samp class="ph codeph">*workspace</samp> is not <samp class="ph codeph">NULL</samp>
                                       and <samp class="ph codeph">*workSpaceSizeInBytes</samp> is large enough, and the
                                       tensor layout is NHWC and the data type configuration is supported, then
                                       this function will trigger a new semi-persistent NHWC kernel for batch
                                       normalization. The workspace is not required to be clean. Also, the
                                       workspace does not need to remain unchanged between the forward and
                                       backward passes. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace for the
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the <samp class="ph codeph">reserveSpace</samp>. Must be
                                       equal or larger than the amount required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationTrainingExReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the batch normalization operation, for the specified bnOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</a></samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationForwardTrainingEx__section_zjf_ypf_vlb"><a name="cudnnBatchNormalizationForwardTrainingEx__section_zjf_ypf_vlb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <div class="p">This function supports the following combinations of data types for various
                                 descriptors.
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnBatchNormalizationForwardTrainingEx__table_g4k_rpf_vlb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnBatchNormalizationForwardTrainingEx__table_g4k_rpf_vlb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 17. Supported Configurations for
                                             <samp class="ph codeph">cudnnBatchNormalizationForwardTrainingEx()</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e26748" rowspan="1" colspan="1">Data Type Configurations</th>
                                             <th class="entry" valign="top" width="20%" id="d54e26751" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e26755" rowspan="1" colspan="1"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e26759" rowspan="1" colspan="1"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e26766" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e26748" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26751" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26755" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26759" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26766" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e26748" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26751" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26755" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26759" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26766" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e26748" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26751" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26755" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26759" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26766" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e26748" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26751" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26755" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26759" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e26766" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnBatchNormalizationForwardTrainingEx__section_p1g_m5t_y3b"><a name="cudnnBatchNormalizationForwardTrainingEx__section_p1g_m5t_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnBatchNormalizationForwardTrainingEx__ul_qnn_k4g_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardTrainingEx__ul_qnn_k4g_jt">
                                          <li class="li">One of the pointers <samp class="ph codeph">alpha</samp>,
                                             <samp class="ph codeph">beta</samp>, <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp>, <samp class="ph codeph">bnScaleData</samp>, and
                                             <samp class="ph codeph">bnBiasData</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                             tensor descriptor dimensions is not within the
                                             <samp class="ph codeph">[4,5]</samp> range (only 4D and 5D tensors are
                                             supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> dimensions are not
                                             1xCx1x1 for 4D and 1xCx1x1x1 for 5D for spatial, and are not
                                             1xCxHxW for 4D and 1xCxDxHxW for 5D for per-activation mode. 
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">saveMean</samp>,
                                             <samp class="ph codeph">saveInvVariance</samp> pointers are
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">resultRunningMeanData</samp>,
                                             <samp class="ph codeph">resultRunningInvVarianceData</samp> pointers are
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than
                                             <samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp>.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp> and
                                             <samp class="ph codeph">yDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDivisiveNormalizationBackward"><a name="cudnnDivisiveNormalizationBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDivisiveNormalizationBackward" name="cudnnDivisiveNormalizationBackward" shape="rect">4.1.6.&nbsp;<kbd class="ph userinput">cudnnDivisiveNormalizationBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function performs the backward <samp class="ph codeph">DivisiveNormalization</samp> layer
                                 computation. </span></div><pre xml:space="preserve"> cudnnStatus_t cudnnDivisiveNormalizationBackward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnDivNormMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *means,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dMeans)</pre><p class="p">Supported tensor formats are NCHW for 4D and NCDHW for 5D with any non-overlapping
                              non-negative strides. Only 4D and 5D tensors are supported. 
                           </p>
                           <div class="section" id="cudnnDivisiveNormalizationBackward__section_jdt_cbh_z3b"><a name="cudnnDivisiveNormalizationBackward__section_jdt_cbh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized LRN parameter
                                       descriptor (this descriptor is used for both LRN and
                                       <samp class="ph codeph">DivisiveNormalization</samp> layers).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. <samp class="ph codeph">DivisiveNormalization</samp> layer mode of
                                       operation. Currently only
                                       <samp class="ph codeph">CUDNN_DIVNORM_PRECOMPUTED_MEANS</samp> is implemented.
                                       Normalization is performed using the means input tensor that is expected
                                       to be precomputed by the user. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">x</samp>, <samp class="ph codeph">means</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor and pointers in device memory for the
                                       layer's x and means data. Note that the <samp class="ph codeph">means</samp> tensor is
                                       expected to be precomputed by the user. It can also contain any valid
                                       values (not required to be actual <samp class="ph codeph">means</samp>, and can be for
                                       instance a result of a convolution with a Gaussian kernel).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor pointer in device memory for the layer's
                                       <samp class="ph codeph">dy</samp> cumulative loss differential data (error
                                       backpropagation).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">temp</samp>, <samp class="ph codeph">temp2</samp></dt>
                                    <dd class="dd"><em class="ph i">Workspace</em>. Temporary tensors in device memory. These are used for
                                       computing intermediate values during the backward pass. These tensors do
                                       not have to be preserved from forward to backward pass. Both use
                                       <samp class="ph codeph">xDesc</samp> as a descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor for <samp class="ph codeph">dx</samp> and
                                       <samp class="ph codeph">dMeans</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp>, <samp class="ph codeph">dMeans</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Tensor pointers (in device memory) for the layers
                                       resulting in cumulative gradients <samp class="ph codeph">dx</samp> and
                                       <samp class="ph codeph">dMeans</samp> (<samp class="ph codeph">dLoss/dx</samp> and
                                       <samp class="ph codeph">dLoss/dMeans</samp>). Both share the same descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDivisiveNormalizationBackward__section_xvd_2bh_z3b"><a name="cudnnDivisiveNormalizationBackward__section_xvd_2bh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnDivisiveNormalizationBackward__ul_zsg_fb3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnDivisiveNormalizationBackward__ul_zsg_fb3_s1b">
                                          <li class="li">One of the tensor pointers <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">dx</samp>, <samp class="ph codeph">temp</samp>,
                                             <samp class="ph codeph">tmep2</samp>, and <samp class="ph codeph">dy</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Number of any of the input or output tensor dimensions is not
                                             within the <samp class="ph codeph">[4,5]</samp> range.
                                          </li>
                                          <li class="li">Either alpha or beta pointer is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">A mismatch in dimensions between <samp class="ph codeph">xDesc</samp> and
                                             <samp class="ph codeph">dxDesc</samp>.
                                          </li>
                                          <li class="li">LRN descriptor parameters are outside of their valid
                                             ranges.
                                          </li>
                                          <li class="li">Any of the tensor strides is negative.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_UNSUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration, for example,
                                       any of the input and output tensor strides mismatch (for the same
                                       dimension) is a non-supported configuration.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDropoutBackward"><a name="cudnnDropoutBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutBackward" name="cudnnDropoutBackward" shape="rect">4.1.7.&nbsp;<kbd class="ph userinput">cudnnDropoutBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function performs backward dropout operation over <samp class="ph codeph">dy</samp>
                                 returning results in <samp class="ph codeph">dx</samp>. If during forward dropout operation value from
                                 <samp class="ph codeph">x</samp> was propagated to <samp class="ph codeph">y</samp> then during backward
                                 operation value from <samp class="ph codeph">dy</samp> will be propagated to <samp class="ph codeph">dx</samp>,
                                 otherwise, <samp class="ph codeph">dx</samp> value will be set to <samp class="ph codeph">0</samp>.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutBackward(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnDropoutDescriptor_t  dropoutDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dydesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dxdesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">Better performance is obtained for fully packed tensors.</p>
                           <div class="section" id="cudnnDropoutBackward__section_znc_tdh_z3b"><a name="cudnnDropoutBackward__section_znc_tdh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously created dropout descriptor object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">dyDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to data of the tensor described by the
                                       <samp class="ph codeph">dxDesc</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to user-allocated GPU memory used by this
                                       function. It is expected that <samp class="ph codeph">reserveSpace</samp> was
                                       populated during a call to <samp class="ph codeph">cudnnDropoutForward</samp> and has
                                       not been changed. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided memory for the
                                       reserve space.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDropoutBackward__section_cgp_tdh_z3b"><a name="cudnnDropoutBackward__section_cgp_tdh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnDropoutBackward__ul_hmp_5h3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnDropoutBackward__ul_hmp_5h3_s1b">
                                          <li class="li">The number of elements of input tensor and output tensors
                                             differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output
                                             tensors differs.
                                          </li>
                                          <li class="li">The strides of the input tensor and output tensors differ and
                                             in-place operation is used (i.e., <samp class="ph codeph">x</samp> and
                                             <samp class="ph codeph">y</samp> pointers are equal).
                                          </li>
                                          <li class="li">The provided <samp class="ph codeph">reserveSpaceSizeInBytes</samp> is less
                                             than the value returned by
                                             <samp class="ph codeph">cudnnDropoutGetReserveSpaceSize</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">cudnnSetDropoutDescriptor</samp> has not been called
                                             on <samp class="ph codeph">dropoutDesc</samp> with the
                                             non-<samp class="ph codeph">NULL</samp><samp class="ph codeph">states</samp> argument.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetBatchNormalizationBackwardExWorkspaceSize"><a name="cudnnGetBatchNormalizationBackwardExWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetBatchNormalizationBackwardExWorkspaceSize" name="cudnnGetBatchNormalizationBackwardExWorkspaceSize" shape="rect">4.1.8.&nbsp;<kbd class="ph userinput">cudnnGetBatchNormalizationBackwardExWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the amount of GPU memory workspace the user should allocate
                                 to be able to call <samp class="ph codeph">cudnnGetBatchNormalizationBackwardExWorkspaceSize()</samp>
                                 function for the specified <samp class="ph codeph">bnOps</samp> input setting. The workspace allocated
                                 will then be passed to the function
                                 <samp class="ph codeph">cudnnGetBatchNormalizationBackwardExWorkspaceSize()</samp>. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetBatchNormalizationBackwardExWorkspaceSize(
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dzDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dBnScaleBiasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc, 
    size_t                              *sizeInBytes);
</pre><div class="section" id="cudnnGetBatchNormalizationBackwardExWorkspaceSize__section_h4k_kkd_1jb"><a name="cudnnGetBatchNormalizationBackwardExWorkspaceSize__section_h4k_kkd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormOps_t" shape="rect">cudnnBatchNormOps_t</a></samp>. This input can be used to set this function to perform
                                       either only the batch normalization, or batch normalization followed by
                                       activation, or batch normalization followed by element-wise addition and
                                       then activation. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                       <samp class="ph codeph">dzDesc</samp>, <samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd">Tensor descriptors and pointers in the device memory for the layer's
                                       <samp class="ph codeph">x</samp> data, back propagated differential
                                       <samp class="ph codeph">dy</samp> (inputs), the optional <samp class="ph codeph">y</samp> input
                                       data, the optional <samp class="ph codeph">dz</samp> output, and the
                                       <samp class="ph codeph">dx</samp> output, which is the resulting differential with
                                       respect to <samp class="ph codeph">x</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dBnScaleBiasDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Shared tensor descriptor for the following six tensors:
                                       <samp class="ph codeph">bnScaleData</samp>, <samp class="ph codeph">bnBiasData</samp>,
                                       <samp class="ph codeph">dBnScaleData</samp>, <samp class="ph codeph">dBnBiasData</samp>,
                                       <samp class="ph codeph">savedMean</samp>, and <samp class="ph codeph">savedInvVariance</samp>.
                                       This is the shared tensor descriptor desc for the secondary tensor that
                                       was derived by <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp>. The dimensions for this tensor descriptor are dependent
                                       on normalization mode. Note that the data type of this tensor descriptor
                                       must be <samp class="ph codeph">float</samp> for FP16 and FP32 input tensors, and
                                       <samp class="ph codeph">double</samp> for FP64 input tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">bnOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp>, then this
                                       activation is used, otherwise user may pass <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory required for the workspace, as
                                       determined by this function, to be able to execute the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize" title="This function returns the amount of GPU memory workspace the user should allocate to be able to call cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize() function for the specified bnOps input setting. The workspace allocated should then be passed by the user to the function cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()." shape="rect">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</a></samp> function with the specified <samp class="ph codeph">bnOps</samp> input
                                       setting. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetBatchNormalizationBackwardExWorkspaceSize__section_owv_kkd_1jb"><a name="cudnnGetBatchNormalizationBackwardExWorkspaceSize__section_owv_kkd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetBatchNormalizationBackwardExWorkspaceSize__ul_gx5_kph_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetBatchNormalizationBackwardExWorkspaceSize__ul_gx5_kph_jt">
                                          <li class="li">Number of <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> or
                                             <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not
                                             within the range of <samp class="ph codeph">[4,5]</samp> (only 4D and 5D
                                             tensors are supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">dBnScaleBiasDesc</samp> dimensions not 1xCx1x1 for 4D
                                             and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and
                                             1xCxDxHxW for 5D for per-activation mode. 
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for any pair of
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize"><a name="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize" name="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize" shape="rect">4.1.9.&nbsp;<kbd class="ph userinput">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the amount of GPU memory workspace the user should allocate
                                 to be able to call
                                 <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</samp> function
                                 for the specified <samp class="ph codeph">bnOps</samp> input setting. The workspace allocated should
                                 then be passed by the user to the function
                                 <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</samp>. </span></div><pre xml:space="preserve"> cudnnStatus_t cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize(
    cudnnHandle_t                           handle,
    cudnnBatchNormMode_t                    mode,
    cudnnBatchNormOps_t                     bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           zDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           yDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           bnScaleBiasMeanVarDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t       activationDesc, 
    size_t                                  *sizeInBytes);</pre><div class="section" id="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize__section_kdc_dmd_1jb"><a name="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize__section_kdc_dmd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormOps_t" shape="rect">cudnnBatchNormOps_t</a></samp>. This input can be used to set this function to perform
                                       either only the batch normalization, or batch normalization followed by
                                       activation, or batch normalization followed by element-wise addition and
                                       then activation. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">zDesc</samp>,
                                       <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">Tensor descriptors and pointers in the device memory for the layer's
                                       <samp class="ph codeph">x</samp> data, the optional <samp class="ph codeph">z</samp> input data,
                                       and the <samp class="ph codeph">y</samp> output. <samp class="ph codeph">zDesc</samp> is only needed
                                       when <samp class="ph codeph">bnOps</samp> is
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp>, otherwise
                                       the user may pass <samp class="ph codeph">NULL</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Shared tensor descriptor for the following six tensors:
                                       <samp class="ph codeph">bnScaleData, bnBiasData, dBnScaleData, dBnBiasData,
                                          savedMean,</samp> and <samp class="ph codeph">savedInvVariance</samp>. This is
                                       the shared tensor descriptor desc for the secondary tensor that was
                                       derived by <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" title="This function derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor." shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp>. The dimensions for this tensor descriptor are dependent
                                       on normalization mode. Note that the data type of this tensor descriptor
                                       must be <samp class="ph codeph">float</samp> for FP16 and FP32 input tensors, and
                                       <samp class="ph codeph">double</samp> for FP64 input tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">bnOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise the user may pass
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory required for the workspace, as
                                       determined by this function, to be able to execute the
                                       <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</samp>
                                       function with the specified <samp class="ph codeph">bnOps</samp> input setting. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize__section_o4r_2md_1jb"><a name="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize__section_o4r_2md_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize__ul_qnn_k4g_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize__ul_qnn_k4g_jt">
                                          <li class="li">Number of <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> or
                                             <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not
                                             within the range of <samp class="ph codeph">[4,5]</samp> (only 4D and 5D
                                             tensors are supported). 
                                          </li>
                                          <li class="li"><samp class="ph codeph">dBnScaleBiasDesc</samp> dimensions not 1xCx1x1 for 4D
                                             and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and
                                             1xCxDxHxW for 5D for per-activation mode. 
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp> or
                                             <samp class="ph codeph">yDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetBatchNormalizationTrainingExReserveSpaceSize"><a name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetBatchNormalizationTrainingExReserveSpaceSize" name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize" shape="rect">4.1.10.&nbsp;<kbd class="ph userinput">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the amount of reserve GPU memory workspace the user should
                                 allocate for the batch normalization operation, for the specified <samp class="ph codeph">bnOps</samp>
                                 input setting. In contrast to the <samp class="ph codeph">workspace</samp>, the reserved space should
                                 be preserved between the forward and backward calls, and the data should not be
                                 altered.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetBatchNormalizationTrainingExReserveSpaceSize(
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc, 
    size_t                              *sizeInBytes);</pre><div class="section" id="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__section_rpz_1qd_1jb"><a name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__section_rpz_1qd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bnOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormOps_t" shape="rect">cudnnBatchNormOps_t</a></samp>. This input can be used to set this function to perform
                                       either only the batch normalization, or batch normalization followed by
                                       activation, or batch normalization followed by element-wise addition and
                                       then activation. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd">Tensor descriptors for the layer's <samp class="ph codeph">x</samp> data. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">bnOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise user may pass <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory reserved.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__section_ytl_bqd_1jb"><a name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__section_ytl_bqd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__ul_gx5_kph_jt" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__ul_gx5_kph_jt">
                                          <li class="li">The <samp class="ph codeph">xDesc</samp> tensor descriptor dimension is not
                                             within the <samp class="ph codeph">[4,5]</samp> range (only 4D and 5D tensors
                                             are supported).
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetNormalizationBackwardWorkspaceSize"><a name="cudnnGetNormalizationBackwardWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetNormalizationBackwardWorkspaceSize" name="cudnnGetNormalizationBackwardWorkspaceSize" shape="rect">4.1.11.&nbsp;<kbd class="ph userinput">cudnnGetNormalizationBackwardWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the amount of GPU memory workspace the user should allocate to
                              be able to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationBackward" shape="rect">cudnnNormalizationBackward()</a></samp> function for
                              the specified <samp class="ph codeph">normOps</samp> and <samp class="ph codeph">algo</samp> input setting. The
                              workspace allocated will then be passed to the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationBackward" shape="rect">cudnnNormalizationBackward()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t
cudnnGetNormalizationBackwardWorkspaceSize(cudnnHandle_t handle,
                                           cudnnNormMode_t mode,
                                           cudnnNormOps_t normOps,
                                           cudnnNormAlgo_t algo,
                                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t xDesc,
                                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t yDesc,
                                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dyDesc,
     	                               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dzDesc,
                                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dxDesc,
                                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dNormScaleBiasDesc,
      	                              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t activationDesc,
                                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normMeanVarDesc,
                                           size_t *sizeInBytes,
                                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> groupCnt);
</pre><div class="section" id="cudnnGetNormalizationBackwardWorkspaceSize__section_l1g_xmn_y3b"><a name="cudnnGetNormalizationBackwardWorkspaceSize__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (per-channel or per-activation). For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormMode_t" shape="rect">cudnnNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of post-operative. Currently
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> and
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> are only
                                       supported in the NHWC layout. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormOps_t" shape="rect">cudnnNormOps_t</a></samp>. This input can
                                       be used to set this function to perform either only the normalization,
                                       or normalization followed by activation, or normalization followed by
                                       element-wise addition and then activation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Algorithm to be performed. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormAlgo_t" shape="rect">cudnnNormAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                       <samp class="ph codeph">dzDesc</samp>, <samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd">Tensor descriptors and pointers in the device memory for the layer's
                                       <samp class="ph codeph">x</samp> data, back propagated differential
                                       <samp class="ph codeph">dy</samp> (inputs), the optional <samp class="ph codeph">y</samp> input
                                       data, the optional <samp class="ph codeph">dz</samp> output, and the
                                       <samp class="ph codeph">dx</samp> output, which is the resulting differential with
                                       respect to <samp class="ph codeph">x</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dNormScaleBiasDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Shared tensor descriptor for the following four tensors:
                                       <samp class="ph codeph">normScaleData</samp>, <samp class="ph codeph">normBiasData</samp>,
                                       <samp class="ph codeph">dNormScaleData</samp>, <samp class="ph codeph">dNormBiasData</samp>. The
                                       dimensions for this tensor descriptor are dependent on normalization
                                       mode. Note that the data type of this tensor descriptor must be float
                                       for FP16 and FP32 input tensors, and double for FP64 input tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">normOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp>, then this
                                       activation is used, otherwise the user may pass
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMeanVarDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Shared tensor descriptor for the following tensors:
                                       <samp class="ph codeph">savedMean</samp> and <samp class="ph codeph">savedInvVariance</samp>.
                                       The dimensions for this tensor descriptor are dependent on normalization
                                       mode. Note that the data type of this tensor descriptor must be float
                                       for FP16 and FP32 input tensors, and double for FP64 input tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory required for the workspace, as
                                       determined by this function, to be able to execute the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">cudnnGetNormalizationForwardTrainingWorkspaceSize()</a></samp> function with the specified <samp class="ph codeph">normOps</samp>
                                       input setting.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">groupCnt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of grouped convolutions. Currently, only
                                       <samp class="ph codeph">1</samp> is supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetNormalizationBackwardWorkspaceSize__section_zgs_xmn_y3b"><a name="cudnnGetNormalizationBackwardWorkspaceSize__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">
                                       <div class="p">At least one of the following conditions are met:<a name="cudnnGetNormalizationBackwardWorkspaceSize__ul_ztm_frf_vlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetNormalizationBackwardWorkspaceSize__ul_ztm_frf_vlb">
                                             <li class="li">Number of <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> or
                                                <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is
                                                not within the range of [4,5] (only 4D and 5D tensors are
                                                supported).
                                             </li>
                                             <li class="li"><samp class="ph codeph">dNormScaleBiasDesc</samp> dimensions not 1xCx1x1
                                                for 4D and 1xCx1x1x1 for 5D for per-channel, and are not
                                                1xCxHxW for 4D and 1xCxDxHxW for 5D for per-activation
                                                mode.
                                             </li>
                                             <li class="li">Dimensions or data types mismatch for any pair of
                                                <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                                <samp class="ph codeph">dxDesc</samp>.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetNormalizationForwardTrainingWorkspaceSize"><a name="cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetNormalizationForwardTrainingWorkspaceSize" name="cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">4.1.12.&nbsp;<kbd class="ph userinput">cudnnGetNormalizationForwardTrainingWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the amount of GPU memory workspace the user should allocate to
                              be able to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp> function
                              for the specified <samp class="ph codeph">normOps</samp> and <samp class="ph codeph">algo</samp> input setting. The
                              workspace allocated should then be passed by the user to the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t
cudnnGetNormalizationForwardTrainingWorkspaceSize(cudnnHandle_t handle,
                                                  cudnnNormMode_t mode,
                                                  cudnnNormOps_t normOps,
                                                  cudnnNormAlgo_t algo,
                                  	         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t xDesc,
                                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t zDesc,
                                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t yDesc,
                             	              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normScaleBiasDesc,
                                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t activationDesc,
                                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normMeanVarDesc,
                                                  size_t *sizeInBytes,
                                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> groupCnt);
</pre><div class="section" id="cudnnGetNormalizationForwardTrainingWorkspaceSize__section_l1g_xmn_y3b"><a name="cudnnGetNormalizationForwardTrainingWorkspaceSize__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (per-channel or per-activation). For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormMode_t" shape="rect">cudnnNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of post-operative. Currently
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> and
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> are only
                                       supported in the NHWC layout. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormOps_t" shape="rect">cudnnNormOps_t</a></samp>. This input can
                                       be used to set this function to perform either only the normalization,
                                       or normalization followed by activation, or normalization followed by
                                       element-wise addition and then activation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Algorithm to be performed. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormAlgo_t" shape="rect">cudnnNormAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">zDesc</samp>, <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">Tensor descriptors and pointers in the device memory for the layer's
                                       <samp class="ph codeph">x</samp> data, the optional <samp class="ph codeph">z</samp> input data,
                                       and the <samp class="ph codeph">y</samp> output. <samp class="ph codeph">zDesc</samp> is only needed
                                       when <samp class="ph codeph">normOps</samp> is
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp>, otherwise the
                                       user may pass <samp class="ph codeph">NULL</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normScaleBiasDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Shared tensor descriptor for the following tensors:
                                       <samp class="ph codeph">normScaleData</samp> and <samp class="ph codeph">normBiasData</samp>.
                                       The dimensions for this tensor descriptor are dependent on normalization
                                       mode. Note that the data type of this tensor descriptor must be float
                                       for FP16 and FP32 input tensors, and double for FP64 input tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">normOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp>, then this
                                       activation is used, otherwise the user may pass
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMeanVarDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Shared tensor descriptor for the following tensors:
                                       <samp class="ph codeph">savedMean</samp> and <samp class="ph codeph">savedInvVariance</samp>.
                                       The dimensions for this tensor descriptor are dependent on normalization
                                       mode. Note that the data type of this tensor descriptor must be float
                                       for FP16 and FP32 input tensors, and double for FP64 input tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory required for the workspace, as
                                       determined by this function, to be able to execute the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">cudnnGetNormalizationForwardTrainingWorkspaceSize()</a></samp> function with the specified <samp class="ph codeph">normOps</samp>
                                       input setting.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">groupCnt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of grouped convolutions. Currently, only
                                       <samp class="ph codeph">1</samp> is supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetNormalizationForwardTrainingWorkspaceSize__section_zgs_xmn_y3b"><a name="cudnnGetNormalizationForwardTrainingWorkspaceSize__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">
                                       <div class="p">At least one of the following conditions are met:<a name="cudnnGetNormalizationForwardTrainingWorkspaceSize__ul_ynq_ntf_vlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetNormalizationForwardTrainingWorkspaceSize__ul_ynq_ntf_vlb">
                                             <li class="li">Number of <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> or
                                                <samp class="ph codeph">zDesc</samp> tensor descriptor dimensions is
                                                not within the range of [4,5] (only 4D and 5D tensors are
                                                supported).
                                             </li>
                                             <li class="li"><samp class="ph codeph">normScaleBiasDesc</samp> dimensions not 1xCx1x1
                                                for 4D and 1xCx1x1x1 for 5D for per-channel, and are not
                                                1xCxHxW for 4D and 1xCxDxHxW for 5D for per-activation
                                                mode.
                                             </li>
                                             <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp>
                                                or <samp class="ph codeph">yDesc</samp>.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetNormalizationTrainingReserveSpaceSize"><a name="cudnnGetNormalizationTrainingReserveSpaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetNormalizationTrainingReserveSpaceSize" name="cudnnGetNormalizationTrainingReserveSpaceSize" shape="rect">4.1.13.&nbsp;<kbd class="ph userinput">cudnnGetNormalizationTrainingReserveSpaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the amount of reserve GPU memory workspace the user should
                                 allocate for the normalization operation, for the specified <samp class="ph codeph">normOps</samp>
                                 input setting. In contrast to the workspace, the reserved space should be preserved
                                 between the forward and backward calls, and the data should not be altered.</span></div><pre xml:space="preserve">cudnnStatus_t
cudnnGetNormalizationTrainingReserveSpaceSize(cudnnHandle_t handle,
                                              cudnnNormMode_t mode,
                     	                  cudnnNormOps_t normOps,
                                              cudnnNormAlgo_t algo,
                                              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t activationDesc,
                                              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t xDesc,
                                              size_t *sizeInBytes,
                                              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> groupCnt);
</pre><div class="section" id="cudnnGetNormalizationTrainingReserveSpaceSize__section_l1g_xmn_y3b"><a name="cudnnGetNormalizationTrainingReserveSpaceSize__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (per-channel or per-activation). For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormMode_t" shape="rect">cudnnNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of post-operative. Currently
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> and
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> are only
                                       supported in the NHWC layout. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormOps_t" shape="rect">cudnnNormOps_t</a></samp> . This input
                                       can be used to set this function to perform either only the
                                       normalization, or normalization followed by activation, or normalization
                                       followed by element-wise addition and then activation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Algorithm to be performed. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormAlgo_t" shape="rect">cudnnNormAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd">Tensor descriptors for the layer's <samp class="ph codeph">x</samp> data. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">normOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise the user may pass
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory reserved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">groupCnt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of grouped convolutions. Currently, only
                                       <samp class="ph codeph">1</samp> is supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetNormalizationTrainingReserveSpaceSize__section_zgs_xmn_y3b"><a name="cudnnGetNormalizationTrainingReserveSpaceSize__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetNormalizationTrainingReserveSpaceSize__ul_yhm_rvf_vlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetNormalizationTrainingReserveSpaceSize__ul_yhm_rvf_vlb">
                                          <li class="li">The <samp class="ph codeph">xDesc</samp> tensor descriptor dimension is not
                                             within the [4,5] range (only 4D and 5D tensors are
                                             supported).
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnLRNCrossChannelBackward"><a name="cudnnLRNCrossChannelBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLRNCrossChannelBackward" name="cudnnLRNCrossChannelBackward" shape="rect">4.1.14.&nbsp;<kbd class="ph userinput">cudnnLRNCrossChannelBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function performs the backward LRN layer computation. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnLRNCrossChannelBackward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnLRNMode_t                   lrnMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx)</pre><p class="p">Supported formats are: <samp class="ph codeph">positive-strided</samp>, NCHW and NHWC for 4D
                              <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and only NCDHW DHW-packed for 5D (for
                              both <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>). Only non-overlapping 4D and 5D tensors
                              are supported. NCHW layout is preferred for performance.
                           </p>
                           <div class="section" id="cudnnLRNCrossChannelBackward__section_k3n_1nk_1jb"><a name="cudnnLRNCrossChannelBackward__section_k3n_1nk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized LRN parameter
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lrnMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. LRN layer mode of operation. Currently, only
                                       <samp class="ph codeph">CUDNN_LRN_CROSS_CHANNEL_DIM1</samp> is implemented.
                                       Normalization is performed along the tensor's <samp class="ph codeph">dimA[1]</samp>.
                                       
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor and pointer in device memory for the
                                       layer's <samp class="ph codeph">y</samp> data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor and pointer in device memory for the
                                       layer's input cumulative loss differential data <samp class="ph codeph">dy</samp>
                                       (including error backpropagation).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor and pointer in device memory for the
                                       layer's <samp class="ph codeph">x</samp> data. Note that these values are not modified
                                       during backpropagation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp>, <samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Tensor descriptor and pointer in device memory for the
                                       layer's resulting cumulative loss differential data <samp class="ph codeph">dx</samp>
                                       (including error backpropagation).
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnLRNCrossChannelBackward__section_ugx_1nk_1jb"><a name="cudnnLRNCrossChannelBackward__section_ugx_1nk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnLRNCrossChannelBackward__ul_uhk_x13_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelBackward__ul_uhk_x13_s1b">
                                          <li class="li">One of the tensor pointers <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Number of input tensor dimensions is 2 or less.</li>
                                          <li class="li">LRN descriptor parameters are outside of their valid
                                             ranges.
                                          </li>
                                          <li class="li">One of the tensor parameters is 5D but is not in NCDHW
                                             DHW-packed format.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. See the
                                       following for some examples of non-supported configurations:<a name="cudnnLRNCrossChannelBackward__ul_c3k_x13_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelBackward__ul_c3k_x13_s1b">
                                          <li class="li">Any of the input tensor datatypes is not the same as any of the
                                             output tensor datatype.
                                          </li>
                                          <li class="li">Any pairwise tensor dimensions mismatch for <samp class="ph codeph">x</samp>,
                                             <samp class="ph codeph">y</samp>, <samp class="ph codeph">dx</samp>, or
                                             <samp class="ph codeph">dy</samp>.
                                          </li>
                                          <li class="li">Any tensor parameters strides are negative.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnNormalizationBackward"><a name="cudnnNormalizationBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNormalizationBackward" name="cudnnNormalizationBackward" shape="rect">4.1.15.&nbsp;<kbd class="ph userinput">cudnnNormalizationBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs backward normalization layer computation that is specified by
                              mode. Per-channel normalization layer is based on the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch
                                 Normalization: Accelerating Deep Network Training by Reducing Internal Covariate
                                 Shift</a> paper.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t
cudnnNormalizationBackward(cudnnHandle_t handle,
                           cudnnNormMode_t mode,
                           cudnnNormOps_t normOps,
                           cudnnNormAlgo_t algo,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *alphaDataDiff,
          	          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *betaDataDiff,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *alphaParamDiff,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *betaParamDiff,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t xDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *xData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t yDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *yData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dyDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dyData,
               	     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dzDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dzData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dxDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dxData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t dNormScaleBiasDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *normScaleData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *normBiasData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dNormScaleData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dNormBiasData,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> epsilon,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normMeanVarDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *savedMean,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *savedInvVariance,
                           cudnnActivationDescriptor_t activationDesc,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
                           size_t workSpaceSizeInBytes,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace,
                           size_t reserveSpaceSizeInBytes,
           	         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> groupCnt)</pre><p class="p">Only 4D and 5D tensors are supported.</p>
                           <p class="p">The <samp class="ph codeph">epsilon</samp> value has to be the same during training, backpropagation,
                              and inference. This workspace is not required to be clean. Moreover, the workspace does
                              not have to remain unchanged between the forward and backward pass, as it is not used
                              for passing any information.
                           </p>
                           <p class="p">This function can accept a <samp class="ph codeph">*workspace</samp> pointer to the GPU workspace, and
                              <samp class="ph codeph">workSpaceSizeInBytes</samp>, the size of the workspace, from the user.
                           </p>
                           <p class="p">The <samp class="ph codeph">normOps</samp> input can be used to set this function to perform either
                              only the normalization, or normalization followed by activation, or normalization
                              followed by element-wise addition and then activation.
                           </p>
                           <p class="p">When the tensor layout is NCHW, higher performance can be obtained when HW-packed tensors
                              are used for <samp class="ph codeph">x</samp>, <samp class="ph codeph">dy</samp>, or <samp class="ph codeph">dx</samp>.
                           </p>
                           <div class="p">Higher performance for <samp class="ph codeph">CUDNN_NORM_PER_CHANNEL</samp> mode can be obtained when
                              the following conditions are true:<a name="cudnnNormalizationBackward__ul_kqp_ryf_vlb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnNormalizationBackward__ul_kqp_ryf_vlb">
                                 <li class="li">All tensors, namely, <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>,
                                    <samp class="ph codeph">dz</samp>, <samp class="ph codeph">dy</samp>, and <samp class="ph codeph">dx</samp> must be
                                    NHWC-fully packed, and must be of the type
                                    <samp class="ph codeph">CUDNN_DATA_HALF</samp>.
                                 </li>
                                 <li class="li">The tensor C dimension should be a multiple of 4.</li>
                                 <li class="li">The input parameter mode must be set to
                                    <samp class="ph codeph">CUDNN_NORM_PER_CHANNEL</samp>.
                                 </li>
                                 <li class="li">The input parameter algo must be set to
                                    <samp class="ph codeph">CUDNN_NORM_ALGO_PERSIST</samp>.
                                 </li>
                                 <li class="li">Workspace is not <samp class="ph codeph">NULL</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationBackwardWorkspaceSize" shape="rect">cudnnGetNormalizationBackwardWorkspaceSize()</a></samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationTrainingReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetNormalizationTrainingReserveSpaceSize()</a></samp>.
                                 </li>
                                 <li class="li">The content in <samp class="ph codeph">reserveSpace</samp> stored by <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp> must be
                                    preserved.
                                 </li>
                              </ul>
                           </div>
                           <div class="section" id="cudnnNormalizationBackward__section_l1g_xmn_y3b"><a name="cudnnNormalizationBackward__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Mode of operation (per-channel or per-activation). For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormMode_t" shape="rect">cudnnNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normOps</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input.</em> Mode of post-operative. Currently
                                          <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> and
                                          <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> are only
                                          supported in the NHWC layout. For more information, refer to
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormOps_t" shape="rect">cudnnNormOps_t</a></samp>. This input
                                          can be used to set this function to perform either only the
                                          normalization, or normalization followed by activation, or
                                          normalization followed by element-wise addition and then
                                          activation.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input.</em> Algorithm to be performed. For more information, refer
                                          to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormAlgo_t" shape="rect">cudnnNormAlgo_t</a></samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alphaDataDiff</samp>, <samp class="ph codeph">*betaDataDiff</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs.</em> Pointers to scaling factors (in host memory) used to
                                          blend the gradient output <samp class="ph codeph">dx</samp> with a prior value in
                                          the destination tensor as
                                          follows:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</kbd></pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alphaParamDiff</samp>, <samp class="ph codeph">*betaParamDiff</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs.</em> Pointers to scaling factors (in host memory) used to
                                          blend the gradient outputs <samp class="ph codeph">dNormScaleData</samp> and
                                          <samp class="ph codeph">dNormBiasData</samp> with prior values in the
                                          destination tensor as
                                          follows:<pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</kbd></pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">*xData</samp>, <samp class="ph codeph">yDesc</samp>,
                                       <samp class="ph codeph">*yData</samp>, <samp class="ph codeph">dyDesc</samp>,
                                       <samp class="ph codeph">*dyData</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs.</em> Tensor descriptors and pointers in the device memory for
                                       the layer's x data, backpropagated gradient input <samp class="ph codeph">dy</samp>,
                                       the original forward output <samp class="ph codeph">y</samp> data.
                                       <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">yData</samp> are not needed if
                                       <samp class="ph codeph">normOps</samp> is set to
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM</samp>, users may pass
                                       <samp class="ph codeph">NULL</samp>. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dzDesc</samp>, <samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Tensor descriptors and pointers in the device memory for
                                       the computed gradient output <samp class="ph codeph">dz</samp> and
                                       <samp class="ph codeph">dx</samp>. <samp class="ph codeph">dzDesc</samp> is not needed when
                                       <samp class="ph codeph">normOps</samp> is <samp class="ph codeph">CUDNN_NORM_OPS_NORM</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp>, users may pass
                                       <samp class="ph codeph">NULL</samp>. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*dzData</samp>, <samp class="ph codeph">*dxData</samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Tensor descriptors and pointers in the device memory for
                                       the computed gradient output <samp class="ph codeph">dz</samp> and
                                       <samp class="ph codeph">dx</samp>. <samp class="ph codeph">*dzData</samp> is not needed when
                                       <samp class="ph codeph">normOps</samp> is <samp class="ph codeph">CUDNN_NORM_OPS_NORM</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp>, users may pass
                                       <samp class="ph codeph">NULL</samp>. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dNormScaleBiasDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Shared tensor descriptor for the following six tensors:
                                          <samp class="ph codeph">normScaleData</samp>, <samp class="ph codeph">normBiasData</samp>,
                                          <samp class="ph codeph">dNormScaleData</samp>, and
                                          <samp class="ph codeph">dNormBiasData</samp>. The dimensions for this tensor
                                          descriptor are dependent on normalization mode.
                                          <div class="note note"><span class="notetitle">Note:</span> The data type
                                             of this tensor descriptor must be float for FP16 and FP32 input
                                             tensors and double for FP64 input tensors.
                                          </div>
                                       </div>
                                       <p class="p">For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*normScaleData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer in the device memory for the normalization scale
                                       parameter (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating
                                          Deep Network Training by Reducing Internal Covariate Shift</a>
                                       paper, the quantity scale is referred to as gamma).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*normBiasData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointers in the device memory for the normalization bias
                                       parameter (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating
                                          Deep Network Training by Reducing Internal Covariate Shift</a>
                                       paper, bias is referred to as beta). This parameter is used only when
                                       activation should be performed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*dNormScaleData</samp>, <samp class="ph codeph">*dNormBiasData</samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Pointers in the device memory for the gradients of
                                       <samp class="ph codeph">normScaleData</samp> and <samp class="ph codeph">normBiasData</samp>,
                                       respectively.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in normalization formula. Its value
                                       should be equal to or greater than zero. The same epsilon value should
                                       be used in forward and backward functions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMeanVarDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Shared tensor descriptor for the following tensors:
                                          <samp class="ph codeph">savedMean</samp> and
                                          <samp class="ph codeph">savedInvVariance</samp>. The dimensions for this tensor
                                          descriptor are dependent on normalization mode.
                                          <div class="note note"><span class="notetitle">Note:</span> The data type
                                             of this tensor descriptor must be float for FP16 and FP32 input
                                             tensors and double for FP64 input tensors.
                                          </div>
                                       </div>
                                       <p class="p">For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*savedMean</samp>, <samp class="ph codeph">*savedInvVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Optional cache parameters containing saved intermediate
                                       results computed during the forward pass. For this to work correctly,
                                       the layer's <samp class="ph codeph">x</samp> and <samp class="ph codeph">normScaleData</samp>,
                                       <samp class="ph codeph">normBiasData</samp> data has to remain unchanged until
                                       this backward function is called. Note that both these parameters can be
                                       <samp class="ph codeph">NULL</samp> but only at the same time. It is recommended
                                       to use this cache since the memory overhead is relatively small.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the activation operation. When the
                                       <samp class="ph codeph">normOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise the user may pass
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the workspace. It must be large enough to
                                       trigger the fast NHWC semi-persistent kernel by this function.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace for the
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the <samp class="ph codeph">reserveSpace</samp>. It must be
                                       equal or larger than the amount required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationTrainingReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetNormalizationTrainingReserveSpaceSize()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">groupCnt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of grouped convolutions. Currently, only
                                       <samp class="ph codeph">1</samp> is supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnNormalizationBackward__section_zgs_xmn_y3b"><a name="cudnnNormalizationBackward__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnNormalizationBackward__ul_fnb_szf_vlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnNormalizationBackward__ul_fnb_szf_vlb">
                                          <li class="li">Any of the pointers <samp class="ph codeph">alphaDataDiff</samp>,
                                             <samp class="ph codeph">betaDataDiff</samp>,
                                             <samp class="ph codeph">alphaParamDiff</samp>,
                                             <samp class="ph codeph">betaParamDiff</samp>, <samp class="ph codeph">xData</samp>,
                                             <samp class="ph codeph">dyData</samp>, <samp class="ph codeph">dxData</samp>,
                                             <samp class="ph codeph">normScaleData</samp>,
                                             <samp class="ph codeph">dNormScaleData</samp>, and
                                             <samp class="ph codeph">dNormBiasData</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not
                                             within the range of [4,5] (only 4D and 5D tensors are
                                             supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">dNormScaleBiasDesc</samp> dimensions not 1xCx1x1 for
                                             4D and 1xCx1x1x1 for 5D for per-channel, and are not 1xCxHxW for
                                             4D and 1xCxDxHxW for 5D for per-activation mode.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">savedMean</samp>,
                                             <samp class="ph codeph">savedInvVariance</samp> pointers is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than zero.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for any pair of
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                             <samp class="ph codeph">dxDesc</samp>,
                                             <samp class="ph codeph">dNormScaleBiasDesc</samp>, or
                                             <samp class="ph codeph">normMeanVarDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnNormalizationForwardTraining"><a name="cudnnNormalizationForwardTraining" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNormalizationForwardTraining" name="cudnnNormalizationForwardTraining" shape="rect">4.1.16.&nbsp;<kbd class="ph userinput">cudnnNormalizationForwardTraining()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function performs the forward normalization layer computation for the training
                              phase. Depending on mode, different normalization operations will be performed. Per-channel
                              layer is based on the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network Training by Reducing
                                 Internal Covariate Shift</a> paper. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t
cudnnNormalizationForwardTraining(cudnnHandle_t handle,
                                  cudnnNormMode_t mode,
                                  cudnnNormOps_t normOps,
                                  cudnnNormAlgo_t algo,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *alpha,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *beta,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t xDesc,
                     	      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *xData,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normScaleBiasDesc,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *normScale,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *normBias,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> exponentialAverageFactor,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t normMeanVarDesc,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *resultRunningMean,
                           	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *resultRunningVariance,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> epsilon,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *resultSaveMean,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *resultSaveInvVariance,
                                  cudnnActivationDescriptor_t activationDesc,
                       	    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t zDesc,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *zData,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t yDesc,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *yData,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workspace,
                                  size_t workSpaceSizeInBytes,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace,
                                  size_t reserveSpaceSizeInBytes,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> groupCnt);</pre><p class="p">Only 4D and 5D tensors are supported.</p>
                           <p class="p">The <samp class="ph codeph">epsilon</samp> value has to be the same during training, back propagation,
                              and inference.
                           </p>
                           <p class="p">For the inference phase, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardInference" shape="rect">cudnnNormalizationForwardInference()</a></samp>.
                           </p>
                           <p class="p">Higher performance can be obtained when HW-packed tensors are used for both
                              <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>.
                           </p>
                           <div class="p">This API will trigger the new semi-persistent NHWC kernel when the following conditions
                              are true:<a name="cudnnNormalizationForwardTraining__ul_rlq_v2g_vlb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnNormalizationForwardTraining__ul_rlq_v2g_vlb">
                                 <li class="li">All tensors, namely, <samp class="ph codeph">xData</samp>, <samp class="ph codeph">yData</samp> must be
                                    NHWC-fully packed and must be of the type <samp class="ph codeph">CUDNN_DATA_HALF</samp>.
                                 </li>
                                 <li class="li">The tensor C dimension should be a multiple of 4.</li>
                                 <li class="li">The input parameter mode must be set to
                                    <samp class="ph codeph">CUDNN_NORM_PER_CHANNEL</samp>.
                                 </li>
                                 <li class="li">The input parameter algo must be set to
                                    <samp class="ph codeph">CUDNN_NORM_ALGO_PERSIST</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workspace</samp> is not <samp class="ph codeph">NULL</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationForwardTrainingWorkspaceSize" shape="rect">cudnnGetNormalizationForwardTrainingWorkspaceSize()</a></samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is equal to or larger than the amount
                                    required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationTrainingReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetNormalizationTrainingReserveSpaceSize()</a></samp>.
                                 </li>
                                 <li class="li">The content in <samp class="ph codeph">reserveSpace</samp> stored by <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormalizationForwardTraining" shape="rect">cudnnNormalizationForwardTraining()</a></samp> must be
                                    preserved.
                                 </li>
                              </ul>
                           </div>
                           <p class="p">This <samp class="ph codeph">workspace</samp> is not required to be clean. Moreover, the
                              <samp class="ph codeph">workspace</samp> does not have to remain unchanged between the forward and
                              backward pass, as it is not used for passing any information. This extended function can
                              accept a <samp class="ph codeph">*workspace</samp> pointer to the GPU workspace, and
                              <samp class="ph codeph">workSpaceSizeInBytes</samp>, the size of the workspace, from the user.
                           </p>
                           <p class="p">The <samp class="ph codeph">normOps</samp> input can be used to set this function to perform either
                              only the normalization, or normalization followed by activation, or normalization
                              followed by element-wise addition and then activation.
                           </p>
                           <p class="p">Only 4D and 5D tensors are supported. The <samp class="ph codeph">epsilon</samp> value has to be the
                              same during the training, the backpropagation, and the inference.
                           </p>
                           <p class="p">When the tensor layout is NCHW, higher performance can be obtained when HW-packed tensors
                              are used for <samp class="ph codeph">xData</samp>, <samp class="ph codeph">yData</samp>.
                           </p>
                           <div class="section" id="cudnnNormalizationForwardTraining__section_l1g_xmn_y3b"><a name="cudnnNormalizationForwardTraining__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of operation (per-channel or per-activation). For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormMode_t" shape="rect">cudnnNormMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normOps</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Mode of post-operative. Currently
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> and
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> are only
                                       supported in the NHWC layout. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormOps_t" shape="rect">cudnnNormOps_t</a></samp>. This input can
                                       be used to set this function to perform either only the normalization,
                                       or normalization followed by activation, or normalization followed by
                                       element-wise addition and then activation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Algorithm to be performed. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnNormAlgo_t" shape="rect">cudnnNormAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*alpha</samp>, <samp class="ph codeph">*beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to
                                          blend the layer output value with prior value in the destination
                                          tensor as
                                          follows:<pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handles to the previously initialized tensor
                                       descriptors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*xData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>, for the layers <samp class="ph codeph">x</samp>
                                       input data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*yData</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">yDesc</samp>, for the <samp class="ph codeph">y</samp> output of
                                       the normalization layer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">zDesc</samp>, <samp class="ph codeph">*zData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Tensor descriptors and pointers in device memory for
                                       residual addition to the result of the normalization operation, prior to
                                       the activation. <samp class="ph codeph">zDesc</samp> and <samp class="ph codeph">*zData</samp> are
                                       optional and are only used when <samp class="ph codeph">normOps</samp> is
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp>, otherwise the
                                       user may pass <samp class="ph codeph">NULL</samp>. When in use, <samp class="ph codeph">z</samp>
                                       should have exactly the same dimension as <samp class="ph codeph">xData</samp> and the
                                       final output <samp class="ph codeph">yData</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normScaleBiasDesc</samp>, <samp class="ph codeph">normScale</samp>,
                                       <samp class="ph codeph">normBias</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Tensor descriptors and pointers in device memory for the
                                       normalization scale and bias parameters (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch Normalization: Accelerating Deep Network
                                          Training by Reducing Internal Covariate Shift</a> paper, bias is
                                       referred to as beta and scale as gamma). The dimensions for the tensor
                                       descriptor are dependent on the normalization mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">exponentialAverageFactor</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Factor used in the moving average computation as
                                          follows:<pre xml:space="preserve">runningMean = runningMean*(1-factor) + newMean*factor</pre></div>
                                       <div class="p">Use a <samp class="ph codeph">factor=1/(1+n)</samp> at N-th call to the function to
                                          get the Cumulative Moving Average (CMA) behavior, for
                                          example:<pre xml:space="preserve">CMA[n] = (x[1]+...+x[n])/n</pre></div>
                                       <div class="p">For
                                          example:<pre xml:space="preserve">CMA[n+1] = (n*CMA[n]+x[n+1])/(n+1)
= ((n+1)*CMA[n]-CMA[n])/(n+1) + x[n+1]/(n+1)
= CMA[n]*(1-1/(n+1))+x[n+1]*1/(n+1)
= CMA[n]*(1-factor) + x(n+1)*factor
</pre></div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMeanVarDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. Tensor descriptor used for following tensors:
                                       <samp class="ph codeph">resultRunningMean</samp>,
                                       <samp class="ph codeph">resultRunningVariance</samp>,
                                       <samp class="ph codeph">resultSaveMean</samp>,
                                       <samp class="ph codeph">resultSaveInvVariance</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*resultRunningMean</samp>,
                                       <samp class="ph codeph">*resultRunningVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs/Outputs</em>. Pointers to the running mean and running variance
                                       data. Both these pointers can be <samp class="ph codeph">NULL</samp> but only at the
                                       same time. The value stored in <samp class="ph codeph">resultRunningVariance</samp>
                                       (or passed as an input in inference mode) is the sample variance and is
                                       the moving average of <samp class="ph codeph">variance[x]</samp> where the variance is
                                       computed either over batch or spatial+batch dimensions depending on the
                                       mode. If these pointers are not <samp class="ph codeph">NULL</samp>, the tensors
                                       should be initialized to some reasonable values or to 0.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">epsilon</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Epsilon value used in the normalization formula. Its value
                                       should be equal to or greater than zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*resultSaveMean</samp>,
                                       <samp class="ph codeph">*resultSaveInvVariance</samp></dt>
                                    <dd class="dd"><em class="ph i">Outputs</em>. Optional cache parameters containing saved intermediate
                                       results computed during the forward pass. For this to work correctly,
                                       the layer's <samp class="ph codeph">x</samp> and <samp class="ph codeph">normScale</samp>,
                                       <samp class="ph codeph">normBias</samp> data has to remain unchanged until this
                                       backward function is called. Note that both these parameters can be
                                       <samp class="ph codeph">NULL</samp> but only at the same time. It is recommended
                                       to use this cache since the memory overhead is relatively small.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The tensor descriptor for the activation operation. When
                                       the <samp class="ph codeph">normOps</samp> input is set to either
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ACTIVATION</samp> or
                                       <samp class="ph codeph">CUDNN_NORM_OPS_NORM_ADD_ACTIVATION</samp> then this
                                       activation is used, otherwise the user may pass
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*workspace</samp>, <samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Inputs</em>. <samp class="ph codeph">*workspace</samp> is a pointer to the GPU
                                       workspace, and <samp class="ph codeph">workSpaceSizeInBytes</samp> is the size of the
                                       workspace. When <samp class="ph codeph">*workspace</samp> is not <samp class="ph codeph">NULL</samp>
                                       and <samp class="ph codeph">*workSpaceSizeInBytes</samp> is large enough, and the
                                       tensor layout is NHWC and the data type configuration is supported, then
                                       this function will trigger a semi-persistent NHWC kernel for
                                       normalization. The workspace is not required to be clean. Also, the
                                       workspace does not need to remain unchanged between the forward and
                                       backward passes.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace for the
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the <samp class="ph codeph">reserveSpace</samp>. Must be
                                       equal or larger than the amount required by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetNormalizationTrainingReserveSpaceSize" title="This function returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered." shape="rect">cudnnGetNormalizationTrainingReserveSpaceSize()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">groupCnt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of grouped convolutions. Currently, only
                                       <samp class="ph codeph">1</samp> is supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnNormalizationForwardTraining__section_qys_2pf_vlb"><a name="cudnnNormalizationForwardTraining__section_qys_2pf_vlb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <div class="p">This function supports the following combinations of data types for various
                                 descriptors.
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnNormalizationForwardTraining__table_m3v_fpf_vlb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnNormalizationForwardTraining__table_m3v_fpf_vlb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 18. Supported Configurations for
                                             <samp class="ph codeph">cudnnNormalizationForwardTraining()</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="33.33333333333333%" id="d54e31139" rowspan="1" colspan="1">Data Type Configurations</th>
                                             <th class="entry" valign="top" width="33.33333333333333%" id="d54e31142" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                                <samp class="ph codeph">zDesc</samp></th>
                                             <th class="entry" valign="top" width="33.33333333333333%" id="d54e31152" rowspan="1" colspan="1"><samp class="ph codeph">normScaleBiasDesc</samp>,
                                                <samp class="ph codeph">normMeanVarDesc</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31139" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31142" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31152" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31139" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31142" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31152" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31139" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31142" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31152" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31139" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31142" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e31152" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnNormalizationForwardTraining__section_zgs_xmn_y3b"><a name="cudnnNormalizationForwardTraining__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The computation was performed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnNormalizationForwardTraining__ul_lkr_3gg_vlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnNormalizationForwardTraining__ul_lkr_3gg_vlb">
                                          <li class="li">One of the pointers <samp class="ph codeph">alpha</samp>,
                                             <samp class="ph codeph">beta</samp>, <samp class="ph codeph">xData</samp>,
                                             <samp class="ph codeph">yData</samp>, <samp class="ph codeph">normScale</samp>, and
                                             <samp class="ph codeph">normBias</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                             tensor descriptor dimensions is not within the [4,5] range (only
                                             4D and 5D tensors are supported).
                                          </li>
                                          <li class="li"><samp class="ph codeph">normScaleBiasDesc</samp> dimensions are not 1xCx1x1
                                             for 4D and 1xCx1x1x1 for 5D for per-channel mode, and are not
                                             1xCxHxW for 4D and 1xCxDxHxW for 5D for per-activation
                                             mode.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">resultSaveMean</samp>,
                                             <samp class="ph codeph">resultSaveInvVariance</samp> pointers are
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Exactly one of <samp class="ph codeph">resultRunningMean</samp>,
                                             <samp class="ph codeph">resultRunningInvVariance</samp> pointers are
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">epsilon</samp> value is less than zero.
                                          </li>
                                          <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp> or
                                             <samp class="ph codeph">yDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnOpsTrainVersionCheck"><a name="cudnnOpsTrainVersionCheck" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpsTrainVersionCheck" name="cudnnOpsTrainVersionCheck" shape="rect">4.1.17.&nbsp;<kbd class="ph userinput">cudnnOpsTrainVersionCheck()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function checks whether the version of the <samp class="ph codeph">OpsTrain</samp> subset
                                 of the library is consistent with the other sub-libraries.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnOpsTrainVersionCheck(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)</pre><div class="section" id="cudnnOpsTrainVersionCheck__section_zpy_xzc_z3b"><a name="cudnnOpsTrainVersionCheck__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The version is consistent with other sub-libraries.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_VERSION_MISMATCH</samp></dt>
                                    <dd class="dd">The version of <samp class="ph codeph">OpsTrain</samp> is not consistent with other
                                       sub-libraries. Users should check the installation and make sure all
                                       sub-component versions are consistent.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnPoolingBackward"><a name="cudnnPoolingBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingBackward" name="cudnnPoolingBackward" shape="rect">4.1.18.&nbsp;<kbd class="ph userinput">cudnnPoolingBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes the gradient of a pooling operation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnPoolingBackward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *xData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *dx)</pre><div class="p">As of cuDNN version 6.0, a deterministic algorithm is implemented for max backwards
                              pooling. This algorithm can be chosen via the pooling mode enum of
                              <samp class="ph codeph">poolingDesc</samp>. The deterministic algorithm has been measured to be up
                              to 50% slower than the legacy max backwards pooling algorithm, or up to 20% faster,
                              depending upon the use case.
                              <div class="note note"><span class="notetitle">Note:</span> Tensor vectorization is not supported for any tensor
                                 descriptor arguments in this function. Best performance is expected when using
                                 <samp class="ph codeph">HW-packed</samp> tensors. Only 2 and 3 spatial dimensions are
                                 supported.
                              </div>
                           </div>
                           <p class="p"><samp class="ph codeph">cudnnPoolingBackward()</samp> allows both <samp class="ph codeph">x</samp> and
                              <samp class="ph codeph">y</samp> data pointers (together with the related tensor descriptor
                              handles) to be <samp class="ph codeph">NULL</samp> for avg-pooling. This could save memory footprint
                              and bandwidth.
                           </p>
                           <div class="section" id="cudnnPoolingBackward__section_fvs_wtm_1jb"><a name="cudnnPoolingBackward__section_fvs_wtm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">poolingDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized pooling
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor. Can be <samp class="ph codeph">NULL</samp> for average pooling.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">yDesc</samp>. Can be <samp class="ph codeph">NULL</samp> for
                                       average pooling.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor. Must be of type <samp class="ph codeph">FLOAT</samp>,
                                       <samp class="ph codeph">DOUBLE</samp>, <samp class="ph codeph">HALF</samp>, or
                                       <samp class="ph codeph">BFLOAT16</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dyData</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor. Can be <samp class="ph codeph">NULL</samp> for average pooling.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">xDesc</samp>. Can be <samp class="ph codeph">NULL</samp>
                                       for average pooling.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output differential
                                       tensor descriptor. Must be of type <samp class="ph codeph">FLOAT</samp>,
                                       <samp class="ph codeph">DOUBLE</samp>, <samp class="ph codeph">HALF</samp>, or
                                       <samp class="ph codeph">BFLOAT16</samp>. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">dxDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnPoolingBackward__section_ib2_xtm_1jb"><a name="cudnnPoolingBackward__section_ib2_xtm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnPoolingBackward__ul_zmt_yyh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnPoolingBackward__ul_zmt_yyh_s1b">
                                          <li class="li">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                             <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> of the
                                             <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">dyDesc</samp> tensors
                                             differ.
                                          </li>
                                          <li class="li">The strides <samp class="ph codeph">nStride</samp>, <samp class="ph codeph">cStride</samp>,
                                             <samp class="ph codeph">hStride</samp>, <samp class="ph codeph">wStride</samp> of the
                                             <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">dyDesc</samp> tensors
                                             differ.
                                          </li>
                                          <li class="li">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                             <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> of the
                                             <samp class="ph codeph">dxDesc</samp> and <samp class="ph codeph">dxDesc</samp> tensors
                                             differ.
                                          </li>
                                          <li class="li">The strides <samp class="ph codeph">nStride</samp>, <samp class="ph codeph">cStride</samp>,
                                             <samp class="ph codeph">hStride</samp>, <samp class="ph codeph">wStride</samp> of the
                                             <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dxDesc</samp> tensors
                                             differ.
                                          </li>
                                          <li class="li">The datatype of the four tensors differ.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. See the
                                       following for some examples of non-supported configurations:<a name="cudnnPoolingBackward__ul_hnt_yyh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnPoolingBackward__ul_hnt_yyh_s1b">
                                          <li class="li">The <samp class="ph codeph">wStride</samp> of input tensor or output tensor is
                                             not <samp class="ph codeph">1</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSoftmaxBackward"><a name="cudnnSoftmaxBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxBackward" name="cudnnSoftmaxBackward" shape="rect">4.1.19.&nbsp;<kbd class="ph userinput">cudnnSoftmaxBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This routine computes the gradient of the softmax function.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSoftmaxBackward(
    cudnnHandle_t                    handle,
    cudnnSoftmaxAlgorithm_t          algorithm,
    cudnnSoftmaxMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *yData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx)</pre><p class="p">In-place operation is allowed for this routine; meaning, <samp class="ph codeph">dy</samp> and
                              <samp class="ph codeph">dx</samp> pointers may be equal. However, this requires
                              <samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dxDesc</samp> descriptors to be identical
                              (particularly, the strides of the input and output must match for in-place operation to
                              be allowed).
                           </p>
                           <p class="p">All tensor formats are supported for all modes and algorithms with 4 and 5D tensors.
                              Performance is expected to be highest with <samp class="ph codeph">NCHW fully-packed</samp> tensors.
                              For more than 5 dimensions tensors must be packed in their spatial dimensions.
                           </p>
                           <div class="section" id="cudnnSoftmaxBackward__section_bls_p2l_35b"><a name="cudnnSoftmaxBackward__section_bls_p2l_35b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Data Types</h4>
                              <div class="p">This function supports the following data types:<a name="cudnnSoftmaxBackward__ul_mht_n2l_35b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnSoftmaxBackward__ul_mht_n2l_35b">
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_HALF</samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></li>
                                 </ul>
                              </div>
                           </div>
                           <div class="section" id="cudnnSoftmaxBackward__section_plp_kwc_cjb"><a name="cudnnSoftmaxBackward__section_plp_kwc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algorithm</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the softmax algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant to specify the softmax mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*result + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dyData</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">dxDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSoftmaxBackward__section_ibz_kwc_cjb"><a name="cudnnSoftmaxBackward__section_ibz_kwc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSoftmaxBackward__ul_dx5_3xh_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSoftmaxBackward__ul_dx5_3xh_s1b">
                                          <li class="li">The dimensions <samp class="ph codeph">n</samp>, <samp class="ph codeph">c</samp>,
                                             <samp class="ph codeph">h</samp>, <samp class="ph codeph">w</samp> of the
                                             <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">dyDesc</samp> and
                                             <samp class="ph codeph">dxDesc</samp> tensors differ.
                                          </li>
                                          <li class="li">The strides <samp class="ph codeph">nStride</samp>, <samp class="ph codeph">cStride</samp>,
                                             <samp class="ph codeph">hStride</samp>, <samp class="ph codeph">wStride</samp> of the
                                             <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">dyDesc</samp> tensors
                                             differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">datatype</samp> of the three tensors differs.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSpatialTfGridGeneratorBackward"><a name="cudnnSpatialTfGridGeneratorBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfGridGeneratorBackward" name="cudnnSpatialTfGridGeneratorBackward" shape="rect">4.1.20.&nbsp;<kbd class="ph userinput">cudnnSpatialTfGridGeneratorBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes the gradient of a grid generation operation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfGridGeneratorBackward(
    cudnnHandle_t                               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t   stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *dgrid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                       *dtheta)</pre><p class="p">Only 2d transformation is supported.</p>
                           <div class="section" id="cudnnSpatialTfGridGeneratorBackward__section_adj_jzc_cjb"><a name="cudnnSpatialTfGridGeneratorBackward__section_adj_jzc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">stDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously created spatial transformer descriptor
                                       object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dgrid</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory contains the input differential
                                       data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dtheta</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory contains the output
                                       differential data. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSpatialTfGridGeneratorBackward__section_tmt_jzc_cjb"><a name="cudnnSpatialTfGridGeneratorBackward__section_tmt_jzc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSpatialTfGridGeneratorBackward__ul_uwl_q33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorBackward__ul_uwl_q33_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">One of the parameters <samp class="ph codeph">dgrid</samp> or
                                             <samp class="ph codeph">dtheta</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. See the
                                       following for some examples of non-supported configurations:<a name="cudnnSpatialTfGridGeneratorBackward__ul_axl_q33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorBackward__ul_axl_q33_s1b">
                                          <li class="li">The dimension of the transformed tensor specified in
                                             <samp class="ph codeph">stDesc</samp> &gt; 4.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSpatialTfSamplerBackward"><a name="cudnnSpatialTfSamplerBackward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfSamplerBackward" name="cudnnSpatialTfSamplerBackward" shape="rect">4.1.21.&nbsp;<kbd class="ph userinput">cudnnSpatialTfSamplerBackward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes the gradient of a sampling operation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfSamplerBackward(
    cudnnHandle_t                              handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t  stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                      *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *alphaDgrid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *grid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *betaDgrid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                      *dgrid)</pre><p class="p">Only 2d transformation is supported.</p>
                           <div class="section" id="cudnnSpatialTfSamplerBackward__section_brg_31d_cjb"><a name="cudnnSpatialTfSamplerBackward__section_brg_31d_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">stDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously created spatial transformer descriptor
                                       object.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the source value with prior value in the destination tensor as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*srcValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output differential
                                       tensor descriptor. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">dxDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alphaDgrid</samp>, <samp class="ph codeph">betaDgrid</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the gradient outputs <samp class="ph codeph">dgrid</samp> with prior value
                                          in the destination pointer as follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*srcValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">grid</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A grid of coordinates generated by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSpatialTfGridGeneratorForward" title="This function generates a grid of coordinates in the input tensor corresponding to each pixel from the output tensor." shape="rect">cudnnSpatialTfGridGeneratorForward()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dgrid</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory contains the output
                                       differential data. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSpatialTfSamplerBackward__section_zrq_31d_cjb"><a name="cudnnSpatialTfSamplerBackward__section_zrq_31d_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The call was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSpatialTfSamplerBackward__ul_eqg_x33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerBackward__ul_eqg_x33_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"> One of the parameters <samp class="ph codeph">x</samp>, <samp class="ph codeph">dx</samp>,
                                             <samp class="ph codeph">y</samp>, <samp class="ph codeph">dy</samp>,
                                             <samp class="ph codeph">grid</samp>, <samp class="ph codeph">dgrid</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li"> The dimension of <samp class="ph codeph">dy</samp> differs from those
                                             specified in <samp class="ph codeph">stDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. See the
                                       following for some examples of non-supported configurations:<a name="cudnnSpatialTfSamplerBackward__ul_iqg_x33_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerBackward__ul_iqg_x33_s1b">
                                          <li class="li">The dimension of transformed tensor &gt; 4. </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="cudnn-cnn-infer-so-library"><a name="cudnn-cnn-infer-so-library" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cudnn-cnn-infer-so-library" name="cudnn-cnn-infer-so-library" shape="rect">5.&nbsp;<kbd class="ph userinput">cudnn_cnn_infer.so</kbd> Library</a></h2>
                  <div class="body conbody">
                     <div class="abstract">This entity contains all routines related to convolutional neural networks needed at
                        inference time. The <samp class="ph codeph">cudnn_cnn_infer</samp> library depends on
                        <samp class="ph codeph">cudnn_ops_infer</samp>.  <span class="shortdesc"></span></div>
                     <p class="p">For the backend data and descriptor types, refer to the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a> section. 
                     </p>
                  </div>
                  <div class="topic concept nested1" id="cudnn-cnn-infer-so-data-types"><a name="cudnn-cnn-infer-so-data-types" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-infer-so-data-types" name="cudnn-cnn-infer-so-data-types" shape="rect">5.1.&nbsp;Data Type References</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the data type references in the <samp class="ph codeph">cudnn_cnn_infer.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnn-cnn-infer-so-opaque"><a name="cudnn-cnn-infer-so-opaque" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-infer-so-opaque" name="cudnn-cnn-infer-so-opaque" shape="rect">5.1.1.&nbsp;Pointer To Opaque Struct Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the pointers to the opaque struct types in the
                                 <samp class="ph codeph">cudnn_cnn_infer.so</samp> library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionDescriptor_t"><a name="cudnnConvolutionDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionDescriptor_t" name="cudnnConvolutionDescriptor_t" shape="rect">5.1.1.1.&nbsp;<kbd class="ph userinput">cudnnConvolutionDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnConvolutionDescriptor_t</samp> is a pointer to an opaque structure
                                 holding the description of a convolution operation. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateConvolutionDescriptor" shape="rect">cudnnCreateConvolutionDescriptor()</a></samp> is used to create one instance,
                                 and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetConvolutionNdDescriptor" title="This function initializes a previously created generic convolution descriptor object into a Nd correlation. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer. The convolution computation will be done in the specified dataType, which can be potentially different from the input/output tensors." shape="rect">cudnnSetConvolutionNdDescriptor()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetConvolution2dDescriptor" title="This function initializes a previously created convolution descriptor object into a 2D correlation. This function assumes that the tensor and filter descriptors correspond to the forward convolution path and checks if their settings are valid. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer." shape="rect">cudnnSetConvolution2dDescriptor()</a></samp> must be used to initialize this
                                 instance.  <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnn-cnn-infer-so-struct"><a name="cudnn-cnn-infer-so-struct" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-infer-so-struct" name="cudnn-cnn-infer-so-struct" shape="rect">5.1.2.&nbsp;Struct Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the struct types in the <samp class="ph codeph">cudnn_cnn_infer.so</samp>
                                 library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionBwdDataAlgoPerf_t"><a name="cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdDataAlgoPerf_t" name="cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">5.1.2.1.&nbsp;<kbd class="ph userinput">cudnnConvolutionBwdDataAlgoPerf_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnConvolutionBwdDataAlgoPerf_t</samp> is a structure containing
                                 performance results returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionBackwardDataAlgorithm" shape="rect">cudnnFindConvolutionBackwardDataAlgorithm()</a></samp> or heuristic results
                                 returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardDataAlgorithm_v7" shape="rect">cudnnGetConvolutionBackwardDataAlgorithm_v7()</a></samp>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnConvolutionBwdDataAlgoPerf_t__section_ekh_vdr_2jb"><a name="cudnnConvolutionBwdDataAlgoPerf_t__section_ekh_vdr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Data Members</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnConvolutionBwdDataAlgo_t algo</samp></dt>
                                       <dd class="dd">The algorithm runs to obtain the associated performance metrics. </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnStatus_t status</samp></dt>
                                       <dd class="dd">If any error occurs during the workspace allocation or timing of
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>,
                                          this status will represent that error. Otherwise, this status will be
                                          the return status of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>.<a name="cudnnConvolutionBwdDataAlgoPerf_t__ul_lwp_lsz_r1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnConvolutionBwdDataAlgoPerf_t__ul_lwp_lsz_r1b">
                                             <li class="li"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp> if any error occurred
                                                during workspace allocation or if the provided workspace is
                                                insufficient.
                                             </li>
                                             <li class="li"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp> if any error
                                                occurred during timing calculations or workspace
                                                deallocation.
                                             </li>
                                             <li class="li">Otherwise, this will be the return status of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>.
                                             </li>
                                          </ul>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">float time</samp></dt>
                                       <dd class="dd">The execution time of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp> (in
                                          milliseconds).
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">size_t memory</samp></dt>
                                       <dd class="dd">The workspace size (in bytes). </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnDeterminism_t determinism</samp></dt>
                                       <dd class="dd">The determinism of the algorithm.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnMathType_t mathType</samp></dt>
                                       <dd class="dd">The math type provided to the algorithm.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">int reserved[3]</samp></dt>
                                       <dd class="dd">Reserved space for future properties.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionFwdAlgoPerf_t"><a name="cudnnConvolutionFwdAlgoPerf_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionFwdAlgoPerf_t" name="cudnnConvolutionFwdAlgoPerf_t" shape="rect">5.1.2.2.&nbsp;<kbd class="ph userinput">cudnnConvolutionFwdAlgoPerf_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnConvolutionFwdAlgoPerf_t</samp> is a structure containing performance
                                 results returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionForwardAlgorithm" shape="rect">cudnnFindConvolutionForwardAlgorithm()</a></samp>
                                 or heuristic results returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">cudnnGetConvolutionForwardAlgorithm_v7()</a></samp>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnConvolutionFwdAlgoPerf_t__section_dxm_d2r_2jb"><a name="cudnnConvolutionFwdAlgoPerf_t__section_dxm_d2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Data Members</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnConvolutionFwdAlgo_t algo</samp></dt>
                                       <dd class="dd">The algorithm runs to obtain the associated performance metrics.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnStatus_t status</samp></dt>
                                       <dd class="dd">If any error occurs during the workspace allocation or timing of
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>, this
                                          status will represent that error. Otherwise, this status will be the
                                          return status of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>.<a name="cudnnConvolutionFwdAlgoPerf_t__ul_xsg_trz_r1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnConvolutionFwdAlgoPerf_t__ul_xsg_trz_r1b">
                                             <li class="li"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp> if any error occurred
                                                during workspace allocation or if the provided workspace is
                                                insufficient.
                                             </li>
                                             <li class="li"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp> if any error
                                                occurred during timing calculations or workspace
                                                deallocation.
                                             </li>
                                             <li class="li">Otherwise, this will be the return status of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>.
                                             </li>
                                          </ul>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">float time</samp></dt>
                                       <dd class="dd">The execution time of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp> (in milliseconds). 
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">size_t memory</samp></dt>
                                       <dd class="dd">The workspace size (in bytes). </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnDeterminism_t determinism</samp></dt>
                                       <dd class="dd">The determinism of the algorithm.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnMathType_t mathType</samp></dt>
                                       <dd class="dd">The math type provided to the algorithm.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">int reserved[3]</samp></dt>
                                       <dd class="dd">Reserved space for future properties.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnn-cnn-infer-so-enum-types"><a name="cudnn-cnn-infer-so-enum-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-infer-so-enum-types" name="cudnn-cnn-infer-so-enum-types" shape="rect">5.1.3.&nbsp;Enumeration Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the enumeration types in the <samp class="ph codeph">cudnn_cnn_infer.so</samp>
                                 library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionBwdDataAlgo_t"><a name="cudnnConvolutionBwdDataAlgo_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdDataAlgo_t" name="cudnnConvolutionBwdDataAlgo_t" shape="rect">5.1.3.1.&nbsp;<kbd class="ph userinput">cudnnConvolutionBwdDataAlgo_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnConvolutionBwdDataAlgo_t</samp> is an enumerated type that exposes
                                    the different algorithms available to execute the backward data convolution
                                    operation.</span></div>
                              <div class="section" id="cudnnConvolutionBwdDataAlgo_t__section_wpx_tdr_2jb"><a name="cudnnConvolutionBwdDataAlgo_t__section_wpx_tdr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_0</samp></dt>
                                       <dd class="dd">This algorithm expresses the convolution as a sum of matrix products
                                          without actually explicitly forming the matrix that holds the input
                                          tensor data. The sum is done using the atomic add operation, thus the
                                          results are non-deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_1</samp></dt>
                                       <dd class="dd">This algorithm expresses the convolution as a matrix product without
                                          actually explicitly forming the matrix that holds the input tensor data.
                                          The results are deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT</samp></dt>
                                       <dd class="dd">This algorithm uses a Fast-Fourier Transform approach to compute the
                                          convolution. A significant memory workspace is needed to store
                                          intermediate results. The results are deterministic. 
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING</samp></dt>
                                       <dd class="dd">This algorithm uses the Fast-Fourier Transform approach but splits the
                                          inputs into tiles. A significant memory workspace is needed to store
                                          intermediate results but less than
                                          <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT</samp> for large size
                                          images. The results are deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD</samp></dt>
                                       <dd class="dd">This algorithm uses the Winograd Transform approach to compute the
                                          convolution. A reasonably sized workspace is needed to store
                                          intermediate results. The results are deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED</samp></dt>
                                       <dd class="dd">This algorithm uses the Winograd Transform approach to compute the
                                          convolution. A significant workspace may be needed to store intermediate
                                          results. The results are deterministic.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionBwdFilterAlgo_t"><a name="cudnnConvolutionBwdFilterAlgo_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdFilterAlgo_t" name="cudnnConvolutionBwdFilterAlgo_t" shape="rect">5.1.3.2.&nbsp;<kbd class="ph userinput">cudnnConvolutionBwdFilterAlgo_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnConvolutionBwdFilterAlgo_t</samp> is an enumerated type that
                                    exposes the different algorithms available to execute the backward filter convolution
                                    operation. </span></div>
                              <div class="section" id="cudnnConvolutionBwdFilterAlgo_t__section_b5d_ydr_2jb"><a name="cudnnConvolutionBwdFilterAlgo_t__section_b5d_ydr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0</samp></dt>
                                       <dd class="dd">This algorithm expresses the convolution as a sum of matrix products
                                          without actually explicitly forming the matrix that holds the input
                                          tensor data. The sum is done using the atomic add operation, thus the
                                          results are non-deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1</samp></dt>
                                       <dd class="dd">This algorithm expresses the convolution as a matrix product without
                                          actually explicitly forming the matrix that holds the input tensor data.
                                          The results are deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT</samp></dt>
                                       <dd class="dd">This algorithm uses the Fast-Fourier Transform approach to compute the
                                          convolution. A significant workspace is needed to store intermediate
                                          results. The results are deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3</samp></dt>
                                       <dd class="dd">This algorithm is similar to
                                          <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0</samp> but uses some
                                          small workspace to precompute some indices. The results are also
                                          non-deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_WINOGRAD_NONFUSED</samp></dt>
                                       <dd class="dd">This algorithm uses the Winograd Transform approach to compute the
                                          convolution. A significant workspace may be needed to store intermediate
                                          results. The results are deterministic.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT_TILING</samp></dt>
                                       <dd class="dd">This algorithm uses the Fast-Fourier Transform approach to compute the
                                          convolution but splits the input tensor into tiles. A significant
                                          workspace may be needed to store intermediate results. The results are
                                          deterministic. 
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionFwdAlgo_t"><a name="cudnnConvolutionFwdAlgo_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionFwdAlgo_t" name="cudnnConvolutionFwdAlgo_t" shape="rect">5.1.3.3.&nbsp;<kbd class="ph userinput">cudnnConvolutionFwdAlgo_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnConvolutionFwdAlgo_t</samp> is an enumerated type that exposes the
                                    different algorithms available to execute the forward convolution operation.</span></div>
                              <div class="section" id="cudnnConvolutionFwdAlgo_t__section_j23_c2r_2jb"><a name="cudnnConvolutionFwdAlgo_t__section_j23_c2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM</samp></dt>
                                       <dd class="dd">This algorithm expresses the convolution as a matrix product without
                                          actually explicitly forming the matrix that holds the input tensor data. 
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM</samp></dt>
                                       <dd class="dd">This algorithm expresses convolution as a matrix product without
                                          actually explicitly forming the matrix that holds the input tensor data,
                                          but still needs some memory workspace to precompute some indices in
                                          order to facilitate the implicit construction of the matrix that holds
                                          the input tensor data. 
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_GEMM</samp></dt>
                                       <dd class="dd">This algorithm expresses the convolution as an explicit matrix product.
                                          A significant memory workspace is needed to store the matrix that holds
                                          the input tensor data.
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_DIRECT</samp></dt>
                                       <dd class="dd">This algorithm expresses the convolution as a direct convolution (for
                                          example, without implicitly or explicitly doing a matrix
                                          multiplication).
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT</samp></dt>
                                       <dd class="dd">This algorithm uses the Fast-Fourier Transform approach to compute the
                                          convolution. A significant memory workspace is needed to store
                                          intermediate results.
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING</samp></dt>
                                       <dd class="dd">This algorithm uses the Fast-Fourier Transform approach but splits the
                                          inputs into tiles. A significant memory workspace is needed to store
                                          intermediate results but less than
                                          <samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT</samp> for large size
                                          images.
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD</samp></dt>
                                       <dd class="dd">This algorithm uses the Winograd Transform approach to compute the
                                          convolution. A reasonably sized workspace is needed to store
                                          intermediate results.
                                       </dd>
                                       <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED</samp></dt>
                                       <dd class="dd">This algorithm uses the Winograd Transform approach to compute the
                                          convolution. A significant workspace may be needed to store intermediate
                                          results.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionMode_t"><a name="cudnnConvolutionMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionMode_t" name="cudnnConvolutionMode_t" shape="rect">5.1.3.4.&nbsp;<kbd class="ph userinput">cudnnConvolutionMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnConvolutionMode_t</samp> is an enumerated type used by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetConvolution2dDescriptor" title="This function initializes a previously created convolution descriptor object into a 2D correlation. This function assumes that the tensor and filter descriptors correspond to the forward convolution path and checks if their settings are valid. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer." shape="rect">cudnnSetConvolution2dDescriptor()</a></samp> to configure a convolution
                                 descriptor. The filter used for the convolution can be applied in two different ways,
                                 corresponding mathematically to a convolution or to a cross-correlation. (A
                                 cross-correlation is equivalent to a convolution with its filter rotated by 180
                                 degrees.) <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnConvolutionMode_t__section_pld_g2r_2jb"><a name="cudnnConvolutionMode_t__section_pld_g2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CONVOLUTION</samp></dt>
                                       <dd class="dd">In this mode, a convolution operation will be done when applying the
                                          filter to the images. 
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp></dt>
                                       <dd class="dd">In this mode, a cross-correlation operation will be done when applying
                                          the filter to the images. 
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnReorderType_t"><a name="cudnnReorderType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReorderType_t" name="cudnnReorderType_t" shape="rect">5.1.3.5.&nbsp;<kbd class="ph userinput">cudnnReorderType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnReorderType_t</samp> is an enumerated type to set the convolution
                                 		reordering type. The reordering type can be set by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetConvolutionReorderType" title="This function sets the convolution reorder type for the given convolution descriptor." shape="rect">cudnnSetConvolutionReorderType()</a></samp> and its status can be read by
                                 				<samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionReorderType" title="This function retrieves the convolution reorder type from the given convolution descriptor." shape="rect">cudnnGetConvolutionReorderType()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
	CUDNN_DEFAULT_REORDER = 0,
	CUDNN_NO_REORDER      = 1,
	} cudnnReorderType_t;		</pre></div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnn-cnn-infer-so-api"><a name="cudnn-cnn-infer-so-api" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-infer-so-api" name="cudnn-cnn-infer-so-api" shape="rect">5.2.&nbsp;API Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the API functions in the <samp class="ph codeph">cudnn_cnn_infer.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnnCnnInferVersionCheck"><a name="cudnnCnnInferVersionCheck" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCnnInferVersionCheck" name="cudnnCnnInferVersionCheck" shape="rect">5.2.1.&nbsp;<kbd class="ph userinput">cudnnCnnInferVersionCheck()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function checks whether the version of the <samp class="ph codeph">CnnInfer</samp> subset
                                 of the library is consistent with the other sub-libraries.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCnnInferVersionCheck(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)</pre><div class="section" id="cudnnCnnInferVersionCheck__section_zpy_xzc_z3b"><a name="cudnnCnnInferVersionCheck__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The version is consistent with other sub-libraries.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_VERSION_MISMATCH</samp></dt>
                                    <dd class="dd">The version of <samp class="ph codeph">CnnInfer</samp> is not consistent with other
                                       sub-libraries. Users should check the installation and make sure all
                                       sub-component versions are consistent.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnConvolutionBackwardData"><a name="cudnnConvolutionBackwardData" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBackwardData" name="cudnnConvolutionBackwardData" shape="rect">5.2.2.&nbsp;<kbd class="ph userinput">cudnnConvolutionBackwardData()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function computes the convolution data gradient of the tensor
                              		<samp class="ph codeph">dy</samp>, where <samp class="ph codeph">y</samp> is the output of the forward convolution in
                              				<samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>. It uses the specified
                              			<samp class="ph codeph">algo</samp>, and returns the results in the output tensor <samp class="ph codeph">dx</samp>.
                              		Scaling factors <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> can be used to scale the
                              		computed result or accumulate with the current <samp class="ph codeph">dx</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBackwardData(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionBwdDataAlgo_t       algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *dx)</pre><div class="section" id="cudnnConvolutionBackwardData__section_rhs_vf5_y3b"><a name="cudnnConvolutionBackwardData__section_rhs_vf5_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          								blend the computation result with prior value in the output layer as
                                          								follows:
                                          								<pre xml:space="preserve">dstValue = alpha[0]*result + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor. For more information,
                                       							refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       							descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor descriptor.
                                       							For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the input
                                       							differential tensor descriptor <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor. For more information, refer
                                       							to <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies which backward data convolution algorithm should be
                                       							used to compute the results. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBwdDataAlgo_t" title="cudnnConvolutionBwdDataAlgo_t is an enumerated type that exposes the different algorithms available to execute the backward data convolution operation." shape="rect">cudnnConvolutionBwdDataAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to be
                                       							able to execute the specified algorithm. If no workspace is needed for a
                                       							particular algorithm, that pointer can be <samp class="ph codeph">NIL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       								<samp class="ph codeph">workSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       							descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       							output tensor descriptor <samp class="ph codeph">dxDesc</samp> that carries the
                                       							result.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBackwardData__section_a33_wbv_y3b"><a name="cudnnConvolutionBackwardData__section_a33_wbv_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <div class="p">This function supports the following combinations of data types for <samp class="ph codeph">wDesc</samp>,
                                 					<samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">convDesc</samp>, and <samp class="ph codeph">dxDesc</samp>.
                                 					
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_izw_3kb_s1b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_izw_3kb_s1b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 19. Supported Configurations for <samp class="ph codeph">cudnnConvolutionBackwardData()</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="30.087527352297595%" id="d54e33961" rowspan="1" colspan="1">Data Type Configurations</th>
                                             <th class="entry" valign="top" width="34.9562363238512%" id="d54e33964" rowspan="1" colspan="1"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp> and
                                                										<samp class="ph codeph">dxDesc</samp> Data Type
                                             </th>
                                             <th class="entry" valign="top" width="34.9562363238512%" id="d54e33975" rowspan="1" colspan="1"><samp class="ph codeph">convDesc</samp> Data Type
                                             </th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.087527352297595%" headers="d54e33961" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp> (only supported on
                                                									architectures with true FP16 support, meaning, compute
                                                									capability 5.3 and later) 
                                             </td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33964" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33975" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.087527352297595%" headers="d54e33961" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33964" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33975" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.087527352297595%" headers="d54e33961" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33964" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33975" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.087527352297595%" headers="d54e33961" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33964" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33975" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.087527352297595%" headers="d54e33961" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33964" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="34.9562363238512%" headers="d54e33975" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBackwardData__section_yjv_xbv_y3b"><a name="cudnnConvolutionBackwardData__section_yjv_xbv_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported algorithms</h4>
                              <div class="note note"><span class="notetitle">Note:</span> Specifying a separate algorithm can cause changes in performance, support and
                                 				computation determinism. See the following for a list of algorithm options, and
                                 				their respective supported parameters and deterministic behavior.
                              </div>
                              <p class="p">The table below shows the list of the supported 2D and 3D convolutions. The 2D
                                 				convolutions are described first, followed by the 3D convolutions. 
                              </p>
                              <div class="p">For the following terms, the short-form versions shown in the parentheses are used in
                                 				the table below, for brevity:<a name="cudnnConvolutionBackwardData__ul_pjh_q35_y3b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardData__ul_pjh_q35_y3b">
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_0 <strong class="ph b">(_ALGO_0)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_1 <strong class="ph b">(_ALGO_1)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT <strong class="ph b">(_FFT)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING
                                          							<strong class="ph b">(_FFT_TILING)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD
                                          						<strong class="ph b">(_WINOGRAD)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED
                                          								<strong class="ph b">(_WINOGRAD_NONFUSED)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NCHW <strong class="ph b">(_NCHW)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NHWC <strong class="ph b">(_NHWC)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C <strong class="ph b">(_NCHW_VECT_C)</strong></samp></li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_vcd_y35_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_vcd_y35_y3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 20. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionBackwardData()</samp> 2D
                                             						Convolutions: <samp class="ph codeph">wDesc: _NHWC</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e34166" rowspan="1"><strong class="ph b">Filter descriptor <samp class="ph codeph">wDesc: _NHWC</samp> (refer to
                                                   												<samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a></samp>)</strong></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34182" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34185" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34188" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34194" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dxDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34199" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34203" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34166 d54e34182" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">_ALGO_0</samp></p>
                                                <p class="p"><samp class="ph codeph">_ALGO_1</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34166 d54e34185" rowspan="1" colspan="1">&nbsp;</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34166 d54e34188" rowspan="1" colspan="1">NHWC HWC-packed </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34166 d54e34194" rowspan="1" colspan="1">NHWC HWC-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34166 d54e34199" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34166 d54e34203" rowspan="1" colspan="1">&nbsp;</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_m3w_bk5_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_m3w_bk5_y3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 21. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionBackwardData()</samp> 2D
                                             						Convolutions: <samp class="ph codeph">wDesc: _NCHW</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e34280" rowspan="1"><strong class="ph b">Filter descriptor <samp class="ph codeph">wDesc:
                                                      											_NCHW</samp>.</strong></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34290" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34293" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34296" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34302" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dxDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34307" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34311" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34290" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">_ALGO_0</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34293" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34296" rowspan="1" colspan="1">NCHW CHW-packed </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34302" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34307" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34311" rowspan="1" colspan="1"><strong class="ph b">Dilation</strong>: greater than 0 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34290" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_1</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34293" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34296" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34302" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34307" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34311" rowspan="1" colspan="1"><strong class="ph b">Dilation</strong>: greater than 0 for all dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group
                                                   										Count Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34290" rowspan="1" colspan="1"><samp class="ph codeph">_FFT</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34293" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34296" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34302" rowspan="1" colspan="1">NCHW HW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34307" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34311" rowspan="1" colspan="1"><strong class="ph b">Dilation</strong>: 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                                <p class="p"><samp class="ph codeph">dxDesc</samp>
                                                   										feature map height + 2 * <samp class="ph codeph">convDesc</samp>
                                                   										zero-padding height must equal 256 or
                                                   											less
                                                </p>
                                                <p class="p"><samp class="ph codeph">dxDesc</samp> feature map width + 2
                                                   										* <samp class="ph codeph">convDesc</samp> zero-padding width must equal
                                                   										256 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp> vertical and
                                                   										horizontal filter stride must equal
                                                   											1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										height
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										width
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34290" rowspan="1" colspan="1"><samp class="ph codeph">_FFT_TILING</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34293" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34296" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34302" rowspan="1" colspan="1">NCHW HW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34307" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp>
                                                   										is also supported when the task can be handled by 1D FFT,
                                                   										meaning, one of the filter dimensions, width or height is
                                                   										1.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34311" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                                <p class="p">When neither of
                                                   											<samp class="ph codeph">wDesc</samp> filter dimension is 1, the filter
                                                   										width and height must not be larger than 32
                                                </p>
                                                <p class="p">When
                                                   										either of <samp class="ph codeph">wDesc</samp> filter dimension is 1, the
                                                   										largest filter dimension should not exceed
                                                   											256
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp> vertical and
                                                   										horizontal filter stride must equal 1 when either the filter
                                                   										width or filter height is 1, otherwise, the stride can be 1
                                                   										or 2
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										height
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										width
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34290" rowspan="1" colspan="1"><samp class="ph codeph">_WINOGRAD</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34293" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34296" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34302" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34307" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34311" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp>
                                                   										vertical and horizontal filter stride must equal
                                                   											1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must be
                                                   										3
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width must be
                                                   									3
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34290" rowspan="1" colspan="1"><samp class="ph codeph">_WINOGRAD_NONFUSED</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34293" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34296" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34302" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34307" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34280 d54e34311" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp>
                                                   										vertical and horizontal filter stride must equal
                                                   											1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter (height, width)
                                                   										must be (3,3) or (5,5)
                                                </p>
                                                <p class="p">If <samp class="ph codeph">wDesc</samp>
                                                   										filter (height, width) is (5,5) then the data type config
                                                   											<samp class="ph codeph">TRUE_HALF_CONFIG</samp> is not
                                                   									supported
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_ky2_gr5_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_ky2_gr5_y3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 22. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionBackwardData()</samp> 3D
                                             						Convolutions: <samp class="ph codeph">wDesc: _NCHW</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e34684" rowspan="1"><strong class="ph b">Filter descriptor <samp class="ph codeph">wDesc:
                                                      											_NCHW</samp>.</strong></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34694" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34697" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34700" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34706" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dxDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34711" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34715" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34694" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_0</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34697" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34700" rowspan="1" colspan="1">NCDHW CDHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34706" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCDHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34711" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34715" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> greater than 0 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34694" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_1</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34697" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34700" rowspan="1" colspan="1">NCDHW
                                                <p class="p">CDHW-packed</p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34706" rowspan="1" colspan="1">NCDHW
                                                <p class="p">CDHW-packed</p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34711" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIGDOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34715" rowspan="1" colspan="1"><strong class="ph b">Dilation</strong>: 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34694" rowspan="1" colspan="1"><samp class="ph codeph">_FFT_TILING</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34697" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34700" rowspan="1" colspan="1">NCDHW CDHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34706" rowspan="1" colspan="1">NCDHW DHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34711" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34684 d54e34715" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter
                                                   										height must equal 16 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp>
                                                   										filter width must equal 16 or
                                                   											less
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter depth must
                                                   										equal 16 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp> must have
                                                   										all filter strides equal to 1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp>
                                                   										filter height must be greater than <samp class="ph codeph">convDesc</samp>
                                                   										zero-padding height
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter
                                                   										width must be greater than <samp class="ph codeph">convDesc</samp>
                                                   										zero-padding width
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter depth
                                                   										must be greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										width
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_zgy_w2p_5lb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_zgy_w2p_5lb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 23. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionBackwardData()</samp> 3D
                                             						Convolutions: <samp class="ph codeph">wDesc: _NHWC</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e34915" rowspan="1"><strong class="ph b">Filter descriptor <samp class="ph codeph">wDesc:
                                                      											_NHWC</samp></strong></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34924" rowspan="1" colspan="1"><strong class="ph b">Algo Name (3D Convolutions)</strong></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34928" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34931" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34937" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dxDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34942" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e34946" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34915 d54e34924" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_1</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34915 d54e34928" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34915 d54e34931" rowspan="1" colspan="1">NDHWC
                                                <p class="p">DHWC-packed</p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34915 d54e34937" rowspan="1" colspan="1">NDHWC
                                                <p class="p">DHWC-packed</p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34915 d54e34942" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PESUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e34915 d54e34946" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> Greater than 0 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   										Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBackwardData__section_ygy_jg5_y3b"><a name="cudnnConvolutionBackwardData__section_ygy_jg5_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The operation was launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnConvolutionBackwardData__ul_ibx_3kb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardData__ul_ibx_3kb_s1b">
                                          <li class="li">At least one of the following is <samp class="ph codeph">NULL</samp>:
                                             										<samp class="ph codeph">handle</samp>, <samp class="ph codeph">dyDesc</samp>,
                                             										<samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">convDesc</samp>,
                                             										<samp class="ph codeph">dxDesc</samp>, <samp class="ph codeph">dy</samp>,
                                             										<samp class="ph codeph">w</samp>, <samp class="ph codeph">dx</samp>,
                                             										<samp class="ph codeph">alpha</samp>, and  <samp class="ph codeph">beta</samp></li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp> and <samp class="ph codeph">dyDesc</samp> have a
                                             									non-matching number of dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp> and <samp class="ph codeph">dxDesc</samp> have a
                                             									non-matching number of dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp> has fewer than three number of
                                             									dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dxDesc</samp>, and
                                             										<samp class="ph codeph">dyDesc</samp> have a non-matching data type.
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp> and <samp class="ph codeph">dxDesc</samp> have a
                                             									non-matching number of input feature maps per image (or group in
                                             									case of grouped convolutions).
                                          </li>
                                          <li class="li"><samp class="ph codeph">dyDesc</samp> spatial sizes do not match with the
                                             									expected size as determined by
                                             										<samp class="ph codeph">cudnnGetConvolutionNdForwardOutputDim</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionBackwardData__ul_mbx_3kb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardData__ul_mbx_3kb_s1b">
                                          <li class="li"><samp class="ph codeph">dyDesc</samp> or <samp class="ph codeph">dxDesc</samp> have a
                                             									negative tensor striding
                                          </li>
                                          <li class="li"><samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">wDesc</samp> or
                                             										<samp class="ph codeph">dxDesc</samp> has a number of dimensions that is
                                             									not 4 or 5
                                          </li>
                                          <li class="li">The chosen algo does not support the parameters provided; see
                                             									above for an exhaustive list of parameters that support each
                                             									algo
                                          </li>
                                          <li class="li"><samp class="ph codeph">dyDesc</samp> or <samp class="ph codeph">wDesc</samp> indicate an
                                             									output channel count that isn't a multiple of group count (if
                                             									group count has been set in <samp class="ph codeph">convDesc</samp>).
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">An error occurs during the texture binding of texture object creation
                                       							associated with the filter data or the input differential tensor
                                       							data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnConvolutionBiasActivationForward"><a name="cudnnConvolutionBiasActivationForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBiasActivationForward" name="cudnnConvolutionBiasActivationForward" shape="rect">5.2.3.&nbsp;<kbd class="ph userinput">cudnnConvolutionBiasActivationForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function applies a bias and then an activation to the convolutions or
                              cross-correlations of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>, returning
                              results in <samp class="ph codeph">y</samp>. The full computation follows the equation <samp class="ph codeph">y = act (
                                 alpha1 * conv(x) + alpha2 * z + bias )</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBiasActivationForward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha1,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionFwdAlgo_t           algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       zDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *z,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       biasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *bias,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *y)</pre><p class="p">The routine <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolution2dForwardOutputDim" title="This function returns the dimensions of the resulting 4D tensor of a 2D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor This function can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution." shape="rect">cudnnGetConvolution2dForwardOutputDim()</a></samp> or
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionNdForwardOutputDim" title="This function returns the dimensions of the resulting Nd tensor of a nbDims-2-D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor This function can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution." shape="rect">cudnnGetConvolutionNdForwardOutputDim()</a></samp> can be
                              used to determine the proper dimensions of the output tensor descriptor
                              <samp class="ph codeph">yDesc</samp> with respect to <samp class="ph codeph">xDesc</samp>,
                              <samp class="ph codeph">convDesc</samp>, and <samp class="ph codeph">wDesc</samp>. 
                           </p>
                           <p class="p">Only the <samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM</samp> algo is
                              enabled with <samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp>. In other words, in the
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a></samp> structure of the
                              input <samp class="ph codeph">activationDesc</samp>, if the mode of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationMode_t" shape="rect">cudnnActivationMode_t</a></samp> field is set to the enum value
                              <samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp>, then the input <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionFwdAlgo_t" title="cudnnConvolutionFwdAlgo_t is an enumerated type that exposes the different algorithms available to execute the forward convolution operation." shape="rect">cudnnConvolutionFwdAlgo_t</a></samp> of this function <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBiasActivationForward" shape="rect">cudnnConvolutionBiasActivationForward()</a></samp> must be set to the
                              enum value <samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM</samp>. For more
                              information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetActivationDescriptor" title="This function initializes a previously created generic activation descriptor object." shape="rect">cudnnSetActivationDescriptor()</a></samp>.
                           </p>
                           <p class="p">Device pointer <samp class="ph codeph">z</samp> and <samp class="ph codeph">y</samp> may be pointing to the same
                              buffer, however, <samp class="ph codeph">x</samp> cannot point to the same buffer as
                              <samp class="ph codeph">z</samp> or <samp class="ph codeph">y</samp>.
                           </p>
                           <div class="section" id="cudnnConvolutionBiasActivationForward__section_v5b_l51_z3b"><a name="cudnnConvolutionBiasActivationForward__section_v5b_l51_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha1</samp>, <samp class="ph codeph">alpha2</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result of convolution with <samp class="ph codeph">z</samp>
                                          and bias as follows:
                                          <pre xml:space="preserve">y = act ( alpha1 * conv(x) + alpha2 * z + bias )</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies which convolution algorithm
                                       should be used to compute the results. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionFwdAlgo_t" title="cudnnConvolutionFwdAlgo_t is an enumerated type that exposes the different algorithms available to execute the forward convolution operation." shape="rect">cudnnConvolutionFwdAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to be
                                       able to execute the specified algorithm. If no workspace is needed for a
                                       particular algorithm, that pointer can be <samp class="ph codeph">NIL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">zDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">z</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">zDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">biasDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bias</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">biasDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">activationDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized activation descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       tensor descriptor <samp class="ph codeph">yDesc</samp> that carries the result of the
                                       convolution.
                                    </dd>
                                 </dl>
                              </div>
                              <p class="p">For the convolution step, this function supports the specific combinations of data
                                 types for <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">convDesc</samp>,
                                 and <samp class="ph codeph">yDesc</samp> as listed in the documentation of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>. The following table specifies
                                 the supported combinations of data types for <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>,
                                 <samp class="ph codeph">z</samp>, <samp class="ph codeph">bias</samp>, and
                                 <samp class="ph codeph">alpha1/alpha2</samp>.
                              </p>
                              <div class="tablenoborder"><a name="cudnnConvolutionBiasActivationForward__table_vmm_yhb_s1b" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBiasActivationForward__table_vmm_yhb_s1b" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 24. Supported Combinations of Data Types (<samp class="ph codeph">X</samp> =
                                          <samp class="ph codeph">CUDNN_DATA</samp>) for
                                          <samp class="ph codeph">cudnnConvolutionBiasActivationForward()</samp></span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="16.666666666666664%" id="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">x</samp></th>
                                          <th class="entry" valign="top" width="16.666666666666664%" id="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">w</samp></th>
                                          <th class="entry" valign="top" width="16.666666666666664%" id="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">convDesc</samp></th>
                                          <th class="entry" valign="top" width="16.666666666666664%" id="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">y and z</samp></th>
                                          <th class="entry" valign="top" width="16.666666666666664%" id="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">bias</samp></th>
                                          <th class="entry" valign="top" width="16.666666666666664%" id="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">alpha1/alpha2</samp></th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_HALF</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_HALF</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_HALF</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_HALF</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_BFLOAT16</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_BFLOAT16</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_BFLOAT16</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_BFLOAT16</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_UINT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_UINT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_UINT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_UINT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35719" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35723" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35727" rowspan="1" colspan="1"><samp class="ph codeph">X_INT32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35731" rowspan="1" colspan="1"><samp class="ph codeph">X_INT8x32</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35735" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="16.666666666666664%" headers="d54e35740" rowspan="1" colspan="1"><samp class="ph codeph">X_FLOAT</samp></td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBiasActivationForward__section_ufc_n51_z3b"><a name="cudnnConvolutionBiasActivationForward__section_ufc_n51_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">In addition to the error values listed by the documentation of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>, the possible error values
                                 returned by this function and their meanings are listed below.
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The operation was launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionBiasActivationForward__ul_dnm_yhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionBiasActivationForward__ul_dnm_yhb_s1b">
                                          <li class="li">At least one of the following is <samp class="ph codeph">NULL</samp>:
                                             <samp class="ph codeph">handle</samp>, <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">convDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">zDesc</samp>,
                                             <samp class="ph codeph">biasDesc</samp>, <samp class="ph codeph">activationDesc</samp>,
                                             <samp class="ph codeph">xData</samp>, <samp class="ph codeph">wData</samp>,
                                             <samp class="ph codeph">yData</samp>, <samp class="ph codeph">zData</samp>,
                                             <samp class="ph codeph">bias</samp>, <samp class="ph codeph">alpha1</samp>, and
                                             <samp class="ph codeph">alpha2</samp>.
                                          </li>
                                          <li class="li">The number of dimensions of <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">yDesc</samp>, and
                                             <samp class="ph codeph">zDesc</samp> is not equal to the array length of
                                             <samp class="ph codeph">convDesc</samp> + 2.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration. Some examples
                                       of non-supported configurations are as follows: <a name="cudnnConvolutionBiasActivationForward__ul_fnm_yhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionBiasActivationForward__ul_fnm_yhb_s1b">
                                          <li class="li">The <samp class="ph codeph">mode</samp> of <samp class="ph codeph">activationDesc</samp> is
                                             not <samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp> or
                                             <samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">reluNanOpt</samp> of
                                             <samp class="ph codeph">activationDesc</samp> is not
                                             <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>.
                                          </li>
                                          <li class="li">The second stride of <samp class="ph codeph">biasDesc</samp> is not equal to
                                             one.
                                          </li>
                                          <li class="li">The first dimension of <samp class="ph codeph">biasDesc</samp> is not equal to
                                             one.
                                          </li>
                                          <li class="li">The second dimension of <samp class="ph codeph">biasDesc</samp> and the first
                                             dimension of <samp class="ph codeph">filterDesc</samp> are not equal.
                                          </li>
                                          <li class="li">The data type of <samp class="ph codeph">biasDesc</samp> does not correspond
                                             to the data type of <samp class="ph codeph">yDesc</samp> as listed in the
                                             above data types table.
                                          </li>
                                          <li class="li"><samp class="ph codeph">zDesc</samp> and <samp class="ph codeph">destDesc</samp> do not
                                             match.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnConvolutionForward"><a name="cudnnConvolutionForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionForward" name="cudnnConvolutionForward" shape="rect">5.2.4.&nbsp;<kbd class="ph userinput">cudnnConvolutionForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function executes convolutions or cross-correlations over <samp class="ph codeph">x</samp> using
                                 			filters specified with <samp class="ph codeph">w</samp>, returning results in <samp class="ph codeph">y</samp>.
                                 			Scaling factors <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> can be used to scale
                                 			the input tensor and the output tensor respectively.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionForward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionFwdAlgo_t           algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *y)</pre><p class="p">The routine <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolution2dForwardOutputDim" title="This function returns the dimensions of the resulting 4D tensor of a 2D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor This function can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution." shape="rect">cudnnGetConvolution2dForwardOutputDim()</a></samp> or
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionNdForwardOutputDim" title="This function returns the dimensions of the resulting Nd tensor of a nbDims-2-D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor This function can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution." shape="rect">cudnnGetConvolutionNdForwardOutputDim()</a></samp> can be
                              			used to determine the proper dimensions of the output tensor descriptor
                              				<samp class="ph codeph">yDesc</samp> with respect to <samp class="ph codeph">xDesc</samp>,
                              				<samp class="ph codeph">convDesc</samp>, and <samp class="ph codeph">wDesc</samp>. 
                           </p>
                           <div class="section" id="cudnnConvolutionForward__section_b5l_fkb_z3b"><a name="cudnnConvolutionForward__section_b5l_fkb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          								blend the computation result with prior value in the output layer as
                                          								follows:
                                          								<pre xml:space="preserve">dstValue = alpha[0]*result + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. For more information,
                                       							refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       							descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor. For more information,
                                       							refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       							descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor. For more information, refer
                                       							to <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies which convolution algorithm should be used to
                                       							compute the results. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionFwdAlgo_t" title="cudnnConvolutionFwdAlgo_t is an enumerated type that exposes the different algorithms available to execute the forward convolution operation." shape="rect">cudnnConvolutionFwdAlgo_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to be
                                       							able to execute the specified algorithm. If no workspace is needed for a
                                       							particular algorithm, that pointer can be <samp class="ph codeph">NIL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       								<samp class="ph codeph">workSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       							tensor descriptor <samp class="ph codeph">yDesc</samp> that carries the result of the
                                       							convolution.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionForward__section_lq3_glb_z3b"><a name="cudnnConvolutionForward__section_lq3_glb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <p class="p">This function supports the following combinations of data types for
                                 					<samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">convDesc</samp>, and
                                 					<samp class="ph codeph">yDesc</samp>. 
                              </p>
                              <div class="tablenoborder"><a name="cudnnConvolutionForward__table_wst_5hb_s1b" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_wst_5hb_s1b" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 25. Supported Configurations for <samp class="ph codeph">cudnnConvolutionForward()</samp></span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="22.29428455614106%" id="d54e36667" rowspan="1" colspan="1">Data Type Configurations</th>
                                          <th class="entry" valign="top" width="25.90190514795298%" id="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">wDesc</samp></th>
                                          <th class="entry" valign="top" width="25.90190514795298%" id="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">convDesc</samp></th>
                                          <th class="entry" valign="top" width="25.90190514795298%" id="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp> (only supported on
                                             								architectures with true FP16 support, meaning, compute capability
                                             								5.3 and later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp> (only support on
                                             								architecture with <samp class="ph codeph">bfloat16</samp> support, meaning,
                                             								compute capability 8.0 and later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">INT8_CONFIG</samp> (only supported on architectures
                                             								with DP4A support, meaning, compute capability 6.1 and
                                             								later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">INT8_EXT_CONFIG</samp> (only supported on architectures
                                             								with DP4A support, meaning, compute capability 6.1 and
                                             								later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">INT8x4_CONFIG</samp> (only supported on architectures
                                             								with DP4A support, meaning, compute capability 6.1 and
                                             								later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8x4</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">INT8x4_EXT_CONFIG</samp> (only supported on
                                             								architectures with DP4A support, meaning, compute capability 6.1 and
                                             								later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8x4</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">UINT8_CONFIG</samp> (only supported on architectures
                                             								with DP4A support, meaning, compute capability 6.1 and
                                             								later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">xDesc</samp>: <samp class="ph codeph">CUDNN_DATA_UINT8</samp></p>
                                             <p class="p"><samp class="ph codeph">wDesc</samp>: <samp class="ph codeph">CUDNN_DATA_INT8</samp></p>
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">UINT8x4_CONFIG</samp> (only supported on architectures with DP4A support,
                                             								meaning, compute capability 6.1 and later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">xDesc</samp>: <samp class="ph codeph">CUDNN_DATA_UINT8x4</samp></p>
                                             <p class="p"><samp class="ph codeph">wDesc</samp>: <samp class="ph codeph">CUDNN_DATA_INT8x4</samp></p>
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8x4</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">UINT8_EXT_CONFIG</samp> (only supported on
                                             								architectures with DP4A support, meaning, compute capability 6.1 and
                                             								later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">xDesc</samp>: <samp class="ph codeph">CUDNN_DATA_UINT8</samp></p>
                                             <p class="p"><samp class="ph codeph">wDesc</samp>: <samp class="ph codeph">CUDNN_DATA_INT8</samp></p>
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">UINT8x4_EXT_CONFIG</samp> (only supported on architectures with DP4A
                                             								support, meaning, compute capability 6.1 and later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1">
                                             <p class="p"><samp class="ph codeph">xDesc</samp>: <samp class="ph codeph">CUDNN_DATA_UINT8x4</samp></p>
                                             <p class="p"><samp class="ph codeph">wDesc</samp>: <samp class="ph codeph">CUDNN_DATA_INT8x4</samp></p>
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="22.29428455614106%" headers="d54e36667" rowspan="1" colspan="1"><samp class="ph codeph">INT8x32_CONFIG</samp> (only supported on architectures
                                             								with IMMA support, meaning compute capability 7.5 and later)
                                          </td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36670" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8x32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36678" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT32</samp></td>
                                          <td class="entry" valign="top" width="25.90190514795298%" headers="d54e36682" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_INT8x32</samp></td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionForward__section_rph_4mb_z3b"><a name="cudnnConvolutionForward__section_rph_4mb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported algorithms</h4>
                              <div class="note note"><span class="notetitle">Note:</span> For this function, all algorithms perform deterministic computations. Specifying a
                                 				separate algorithm can cause changes in performance and support. 
                              </div>
                              <p class="p">The table below shows the list of the supported 2D and 3D convolutions. The 2D
                                 				convolutions are described first, followed by the 3D convolutions. 
                              </p>
                              <div class="p">For the following terms, the short-form versions shown in the parenthesis are used in
                                 				the table below, for brevity: <a name="cudnnConvolutionForward__ul_zzv_zmb_z3b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnConvolutionForward__ul_zzv_zmb_z3b">
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM
                                          							<strong class="ph b">(_IMPLICIT_GEMM)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM
                                          								<strong class="ph b">(_IMPLICIT_PRECOMP_GEMM)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_GEMM <strong class="ph b">(_GEMM)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_DIRECT <strong class="ph b">(_DIRECT)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT <strong class="ph b">(_FFT)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING
                                          						<strong class="ph b">(_FFT_TILING)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD <strong class="ph b">(_WINOGRAD)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED
                                          								<strong class="ph b">(_WINOGRAD_NONFUSED)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NCHW <strong class="ph b">(_NCHW)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NHWC <strong class="ph b">(_NHWC)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C <strong class="ph b">(_NCHW_VECT_C)</strong></samp></li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionForward__table_hnx_pnb_z3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_hnx_pnb_z3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 26. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionForward()</samp> 2D Convolutions:
                                             							<samp class="ph codeph">wDesc: _NCHW</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e37141" rowspan="1">Filter descriptor <samp class="ph codeph">wDesc: _NCHW</samp> (refer to
                                                											<samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a></samp>)
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group count
                                                   										support: Greater than 0, for all algos.
                                                </p>
                                             </th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e37160" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37163" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37168" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">yDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37173" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37176" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_GEMM</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37163" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37168" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37173" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37176" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> Greater than 0 for all dimensions
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_PRECOMP_GEMM</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37163" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37168" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37173" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37176" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all dimensions
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_GEMM</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37163" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37168" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37173" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37176" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all dimensions
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_FFT</samp></td>
                                             <td class="entry" rowspan="2" valign="top" width="20%" headers="d54e37141 d54e37163" colspan="1">NCHW HW-packed</td>
                                             <td class="entry" rowspan="2" valign="top" width="20%" headers="d54e37141 d54e37168" colspan="1">NCHW HW-packed</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37173" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37176" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">xDesc</samp> feature map height +
                                                   										2 * <samp class="ph codeph">convDesc</samp> zero-padding height must equal
                                                   										256 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">xDesc</samp> feature map width +
                                                   										2 * <samp class="ph codeph">convDesc</samp> zero-padding width must equal
                                                   										256 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp> vertical and
                                                   										horizontal filter stride must equal
                                                   											1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										height
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										width
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_FFT_TILING</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37173" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp>
                                                   										is also supported when the task can be handled by 1D FFT,
                                                   										meaning, one of the filter dimensions, width or height is
                                                   										1.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37176" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all dimensions
                                                <p class="p">When neither of
                                                   											<samp class="ph codeph">wDesc</samp> filter dimension is 1, the filter
                                                   										width and height must not be larger than 32
                                                </p>
                                                <p class="p">When
                                                   										either of <samp class="ph codeph">wDesc</samp> filter dimension is 1, the
                                                   										largest filter dimension should not exceed
                                                   											256
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp> vertical and
                                                   										horizontal filter stride must equal 1 when either the filter
                                                   										width or filter height is 1, otherwise the stride can be a 1
                                                   										or 2
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										height
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										width
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_WINOGRAD</samp></td>
                                             <td class="entry" rowspan="2" valign="top" width="20%" headers="d54e37141 d54e37163" colspan="1">All except<samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" rowspan="2" valign="top" width="20%" headers="d54e37141 d54e37168" colspan="1">All except<samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37173" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37176" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> vertical and
                                                   										horizontal filter stride must equal
                                                   											1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must be
                                                   										3
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width must be
                                                   									3
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_WINOGRAD_NONFUSED</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37173" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37176" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                											dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> vertical and
                                                   										horizontal filter stride must equal
                                                   											1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter (height, width)
                                                   										must be (3,3) or (5,5)
                                                </p>
                                                <p class="p">If <samp class="ph codeph">wDesc</samp>
                                                   										filter (height, width) is (5,5), then data type config
                                                   											<samp class="ph codeph">TRUE_HALF_CONFIG</samp> is not
                                                   									supported.
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37141 d54e37160" rowspan="1" colspan="1"><samp class="ph codeph">_DIRECT</samp></td>
                                             <td class="entry" colspan="4" valign="top" headers="d54e37141 d54e37163 d54e37168 d54e37173 d54e37176" rowspan="1">Currently not implemented in cuDNN.</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="tablenoborder"><a name="cudnnConvolutionForward__table_ilj_crb_z3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_ilj_crb_z3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 27. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionForward()</samp> 2D Convolutions:
                                             							<samp class="ph codeph">wDesc: _NCHWC</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e37530" rowspan="1">Filter descriptor <samp class="ph codeph">wDesc: _NCHWC</samp><p class="p"><samp class="ph codeph">convDesc</samp> Group count support: Greater than
                                                   										0.
                                                </p>
                                             </th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e37543" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37546" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37550" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37554" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37557" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37543" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_GEMM</samp><p class="p"><samp class="ph codeph">_IMPLICIT_PRECOMP_GEMM</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37546" rowspan="1" colspan="1"><samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37550" rowspan="1" colspan="1"><samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37554" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">INT8x4_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">UINT8x4_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37557" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all dimensions
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37543" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_PRECOMP_GEMM</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37546" rowspan="1" colspan="1"><samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37550" rowspan="1" colspan="1"><samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37554" rowspan="1" colspan="1"><samp class="ph codeph">INT8x32_CONFIG</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37530 d54e37557" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all dimensions
                                                <p class="p">Requires compute
                                                   										capability 7.2 or above.
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="tablenoborder"><a name="cudnnConvolutionForward__table_wll_ssb_z3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_wll_ssb_z3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 28. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionForward()</samp> 2D Convolutions:
                                             							<samp class="ph codeph">wDesc: _NHWC</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e37654" rowspan="1">Filter descriptor <samp class="ph codeph">wDesc: _NHWC</samp><p class="p"><samp class="ph codeph">convDesc</samp> Group count support: Greater than
                                                   										0.
                                                </p>
                                             </th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e37667" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37670" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37674" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37678" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37681" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37667" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_GEMM</samp><p class="p"><samp class="ph codeph">_IMPLICIT_PRECOMP_GEMM</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37670" rowspan="1" colspan="1">NHWC fully-packed</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37674" rowspan="1" colspan="1">NHWC fully-packed</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37678" rowspan="1" colspan="1"><samp class="ph codeph">INT8_CONFIG</samp><p class="p"><samp class="ph codeph">INT8_EXT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">UINT8_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">UINT8_EXT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37681" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all dimensions 
                                                <p class="p">Input and output
                                                   										feature maps must be a multiple of 4. Output features maps
                                                   										can be non-multiple in the case of
                                                   											<samp class="ph codeph">INT8_EXT_CONFIG</samp> or
                                                   											<samp class="ph codeph">UINT8_EXT_CONFIG</samp>.
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37667" rowspan="1" colspan="1">
                                                <p class="p"><samp class="ph codeph">_IMPLICIT_GEMM</samp></p>
                                                <p class="p"><samp class="ph codeph">_IMPLICIT_PRECOMP_GEMM</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37670" rowspan="1" colspan="1">NHWC HWC-packed.</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37674" rowspan="1" colspan="1">
                                                <p class="p">NHWC HWC-packed.</p>
                                                <p class="p">NCHW CHW-packed</p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37678" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37654 d54e37681" rowspan="1" colspan="1">&nbsp;</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionForward__table_c5k_2tb_z3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_c5k_2tb_z3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 29. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionForward()</samp> 3D Convolutions:
                                             							<samp class="ph codeph">wDesc: _NCHW</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e37808" rowspan="1">Filter descriptor <samp class="ph codeph">wDesc: _NCHW</samp><p class="p"><samp class="ph codeph">convDesc</samp> Group count support: Greater than
                                                   										0, for all algos.
                                                </p>
                                             </th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e37821" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37824" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37828" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37832" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37835" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37821" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_GEMM</samp></td>
                                             <td class="entry" rowspan="2" valign="top" width="20%" headers="d54e37808 d54e37824" colspan="1">All except
                                                									<samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" rowspan="2" valign="top" width="20%" headers="d54e37808 d54e37828" colspan="1">All except
                                                									<samp class="ph codeph">_NCHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" rowspan="3" valign="top" width="20%" headers="d54e37808 d54e37832" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37835" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> Greater than 0 for all dimensions
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37821" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_PRECOMP_GEMM</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37835" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> Greater than 0 for all dimensions
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37821" rowspan="1" colspan="1"><samp class="ph codeph">_FFT_TILING</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37824" rowspan="1" colspan="1">NCDHW DHW-packed</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37828" rowspan="1" colspan="1">NCDHW DHW-packed</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37808 d54e37835" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all dimensions
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must
                                                   										equal 16 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width
                                                   										must equal 16 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter
                                                   										depth must equal 16 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp>
                                                   										must have all filter strides equal to
                                                   											1
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter height must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										height
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter width must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										width
                                                </p>
                                                <p class="p"><samp class="ph codeph">wDesc</samp> filter depth must be
                                                   										greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   										depth
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionForward__table_adj_wgp_5lb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_adj_wgp_5lb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 30. Supported Algorithms for <samp class="ph codeph">cudnnConvolutionForward()</samp> 3D Convolutions:
                                             							<samp class="ph codeph">wDesc: _NHWC</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e37979" rowspan="1">Filter descriptor <samp class="ph codeph">wDesc: _NHWC</samp><p class="p"><samp class="ph codeph">convDesc</samp> Group count support: Greater than
                                                   										0, for all algos.
                                                </p>
                                             </th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e37992" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="20%" id="d54e37995" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e37999" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e38003" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="20%" id="d54e38006" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e37979 d54e37992" rowspan="1" colspan="1"><samp class="ph codeph">_IMPLICIT_PRECOMP_GEMM</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37979 d54e37995" rowspan="1" colspan="1">NDHWC
                                                <p class="p">DHWC-packed</p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37979 d54e37999" rowspan="1" colspan="1">NDHWC
                                                <p class="p">DHWC-packed</p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37979 d54e38003" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e37979 d54e38006" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> Greater than 0 for all dimensions
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="note note"><span class="notetitle">Note:</span> Tensors can be converted to and from <samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp> with
                                 						<samp class="ph codeph"><a class="xref" href="index.html#cudnnTransformTensor" title="This function copies the scaled data from one tensor to another tensor with a different layout. Those descriptors need to have the same dimensions but not necessarily the same strides. The input and output tensors must not overlap in any way (meaning, tensors cannot be transformed in place). This function can be used to convert a tensor with an unsupported format to a supported one." shape="rect">cudnnTransformTensor()</a></samp>.
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionForward__section_kkk_3kb_z3b"><a name="cudnnConvolutionForward__section_kkk_3kb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The operation was launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionForward__ul_fvt_5hb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionForward__ul_fvt_5hb_s1b">
                                          <li class="li">At least one of the following is <samp class="ph codeph">NULL</samp>: handle,
                                             										<samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             										<samp class="ph codeph">convDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                             										<samp class="ph codeph">xData</samp>, <samp class="ph codeph">w</samp>,
                                             										<samp class="ph codeph">yData</samp>, <samp class="ph codeph">alpha</samp>, and
                                             										<samp class="ph codeph">beta</samp></li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> have a
                                             									non-matching number of dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">wDesc</samp> have a
                                             									non-matching number of dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> has fewer than three number of
                                             									dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>'s number of dimensions is not equal to
                                             										<samp class="ph codeph">convDesc</samp> array length + 2
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">wDesc</samp> have a
                                             									non-matching number of input feature maps per image (or group in
                                             									case of grouped convolutions)
                                          </li>
                                          <li class="li"><samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">wDesc</samp> indicate an
                                             									output channel count that isn't a multiple of group count (if
                                             									group count has been set in <samp class="ph codeph">convDesc</samp>).
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, and
                                             										<samp class="ph codeph">yDesc</samp> have a non-matching data type
                                          </li>
                                          <li class="li">For some spatial dimension, <samp class="ph codeph">wDesc</samp> has a spatial
                                             									size that is larger than the input spatial size (including
                                             									zero-padding size)
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionForward__ul_jvt_5hb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionForward__ul_jvt_5hb_s1b">
                                          <li class="li"><samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> have negative
                                             									tensor striding
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, or
                                             										<samp class="ph codeph">yDesc</samp> has a number of dimensions that is
                                             									not 4 or 5
                                          </li>
                                          <li class="li"><samp class="ph codeph">yDesc</samp> spatial sizes do not match with the expected size as determined
                                             									by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionNdForwardOutputDim" title="This function returns the dimensions of the resulting Nd tensor of a nbDims-2-D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor This function can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution." shape="rect">cudnnGetConvolutionNdForwardOutputDim()</a></samp></li>
                                          <li class="li">The chosen algo does not support the parameters provided; see
                                             									above for an exhaustive list of parameters supported for each
                                             									algo
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">An error occurs during the texture object creation associated with the
                                       							filter data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateConvolutionDescriptor"><a name="cudnnCreateConvolutionDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateConvolutionDescriptor" name="cudnnCreateConvolutionDescriptor" shape="rect">5.2.5.&nbsp;<kbd class="ph userinput">cudnnCreateConvolutionDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function creates a convolution descriptor object by allocating the memory needed
                              to hold its opaque structure. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a></samp>.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateConvolutionDescriptor(
    cudnnConvolutionDescriptor_t *convDesc)</pre><div class="section" id="cudnnCreateConvolutionDescriptor__section_eqk_1xb_z3b"><a name="cudnnCreateConvolutionDescriptor__section_eqk_1xb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyConvolutionDescriptor"><a name="cudnnDestroyConvolutionDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyConvolutionDescriptor" name="cudnnDestroyConvolutionDescriptor" shape="rect">5.2.6.&nbsp;<kbd class="ph userinput">cudnnDestroyConvolutionDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created convolution descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyConvolutionDescriptor(
    cudnnConvolutionDescriptor_t convDesc)</pre><div class="section" id="cudnnDestroyConvolutionDescriptor__section_klt_41d_z3b"><a name="cudnnDestroyConvolutionDescriptor__section_klt_41d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindConvolutionBackwardDataAlgorithm"><a name="cudnnFindConvolutionBackwardDataAlgorithm" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardDataAlgorithm" name="cudnnFindConvolutionBackwardDataAlgorithm" shape="rect">5.2.7.&nbsp;<kbd class="ph userinput">cudnnFindConvolutionBackwardDataAlgorithm()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function attempts all algorithms available for <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>. It will attempt both the provided
                              <samp class="ph codeph">convDesc mathType</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> (assuming the
                              two differ). <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardDataAlgorithm(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdDataAlgoPerf_t     *perfResults)</pre><p class="p">Algorithms without the <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> availability will only be tried
                              with <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>, and returned as such.
                           </p>
                           <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned in
                              the user-allocated array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">cudnnConvolutionBwdDataAlgoPerf_t</a></samp>. These metrics are written in a sorted fashion where the first element
                              has the lowest compute time. The total number of resulting algorithms can be queried
                              through the API <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardDataAlgorithmMaxCount()</a></samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFindConvolutionBackwardDataAlgorithm__ul_tl1_2gh_z3b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithm__ul_tl1_2gh_z3b">
                                 <li class="li">This function is host blocking.</li>
                                 <li class="li">It is recommended to run this function prior to allocating layer data; doing
                                    otherwise may needlessly inhibit some algorithm options due to resource
                                    usage.
                                 </li>
                              </ul>
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardDataAlgorithm__section_ax1_fgh_z3b"><a name="cudnnFindConvolutionBackwardDataAlgorithm__section_ax1_fgh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardDataAlgorithm__section_eyw_fgh_z3b"><a name="cudnnFindConvolutionBackwardDataAlgorithm__section_eyw_fgh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardDataAlgorithm__ul_hh5_ljb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithm__ul_hh5_ljb_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp> has fewer than 1 dimension.
                                          </li>
                                          <li class="li">Either <samp class="ph codeph">returnedCount</samp> or
                                             <samp class="ph codeph">perfResults</samp> is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">This function was unable to allocate memory to store sample input,
                                       filters and output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardDataAlgorithm__ul_nh5_ljb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithm__ul_nh5_ljb_s1b">
                                          <li class="li">The function was unable to allocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate sample input, filters and
                                             output.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindConvolutionBackwardDataAlgorithmEx"><a name="cudnnFindConvolutionBackwardDataAlgorithmEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardDataAlgorithmEx" name="cudnnFindConvolutionBackwardDataAlgorithmEx" shape="rect">5.2.8.&nbsp;<kbd class="ph userinput">cudnnFindConvolutionBackwardDataAlgorithmEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function attempts all algorithms available for <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>. It will attempt both the provided
                              <samp class="ph codeph">convDescv mathType</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> (assuming
                              the two differ). <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardDataAlgorithmEx(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdDataAlgoPerf_t     *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *workSpace,
    size_t                                 workSpaceSizeInBytes)</pre><p class="p">Algorithms without the <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> availability will only be
                              tried with <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>, and returned as such.
                           </p>
                           <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are
                              returned in the user-allocated array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">cudnnConvolutionBwdDataAlgoPerf_t</a></samp>. These metrics are written
                              in a sorted fashion where the first element has the lowest compute time. The total
                              number of resulting algorithms can be queried through the API <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardDataAlgorithmMaxCount()</a></samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardDataAlgorithmEx__section_mgz_mhh_z3b"><a name="cudnnFindConvolutionBackwardDataAlgorithmEx__section_mgz_mhh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       tensor descriptor <samp class="ph codeph">dxDesc</samp>. The content of this tensor
                                       will be overwritten with arbitrary values.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory is a necessary workspace for
                                       some algorithms. The size of this workspace will determine the
                                       availability of algorithms. A nil pointer is considered a
                                       <samp class="ph codeph">workSpace</samp> of 0 bytes.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardDataAlgorithmEx__section_dxw_nhh_z3b"><a name="cudnnFindConvolutionBackwardDataAlgorithmEx__section_dxw_nhh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_nmk_rjb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_nmk_rjb_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dxDesc</samp> has fewer than 1 dimension.
                                          </li>
                                          <li class="li"><samp class="ph codeph">w</samp>, <samp class="ph codeph">dy</samp>, or <samp class="ph codeph">dx</samp>
                                             is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li">Either <samp class="ph codeph">returnedCount</samp> or
                                             <samp class="ph codeph">perfResults</samp> is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_rmk_rjb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_rmk_rjb_s1b">
                                          <li class="li">The function was unable to allocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate sample input, filters and
                                             output.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindConvolutionForwardAlgorithm"><a name="cudnnFindConvolutionForwardAlgorithm" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionForwardAlgorithm" name="cudnnFindConvolutionForwardAlgorithm" shape="rect">5.2.9.&nbsp;<kbd class="ph userinput">cudnnFindConvolutionForwardAlgorithm()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function attempts all algorithms available for <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>. It will attempt both the provided
                              <samp class="ph codeph">convDesc mathType</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> (assuming the
                              two differ). <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionForwardAlgorithm(
    cudnnHandle_t                      handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t      wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               *returnedAlgoCount,
    cudnnConvolutionFwdAlgoPerf_t     *perfResults)
</pre><p class="p">Algorithms without the <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> availability will only be tried
                              with <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>, and returned as such.
                           </p>
                           <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned in
                              the user-allocated array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionFwdAlgoPerf_t" shape="rect">cudnnConvolutionFwdAlgoPerf_t</a></samp>. These metrics are written in a sorted fashion where the first element
                              has the lowest compute time. The total number of resulting algorithms can be queried
                              through the API <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">cudnnGetConvolutionForwardAlgorithmMaxCount()</a></samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFindConvolutionForwardAlgorithm__ul_mpv_zth_z3b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithm__ul_mpv_zth_z3b">
                                 <li class="li">This function is host blocking.</li>
                                 <li class="li">It is recommended to run this function prior to allocating layer data; doing
                                    otherwise may needlessly inhibit some algorithm options due to resource
                                    usage.
                                 </li>
                              </ul>
                           </div>
                           <div class="section" id="cudnnFindConvolutionForwardAlgorithm__section_d1g_c5h_z3b"><a name="cudnnFindConvolutionForwardAlgorithm__section_d1g_c5h_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindConvolutionForwardAlgorithm__section_ec5_c5h_z3b"><a name="cudnnFindConvolutionForwardAlgorithm__section_ec5_c5h_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionForwardAlgorithm__ul_cfc_bhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithm__ul_cfc_bhb_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, or
                                             <samp class="ph codeph">yDesc</samp> are not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, or
                                             <samp class="ph codeph">yDesc</samp> has fewer than 1 dimension.
                                          </li>
                                          <li class="li">Either <samp class="ph codeph">returnedCount</samp> or
                                             <samp class="ph codeph">perfResults</samp> is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">This function was unable to allocate memory to store sample input,
                                       filters and output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionForwardAlgorithm__ul_kfc_bhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithm__ul_kfc_bhb_s1b">
                                          <li class="li">The function was unable to allocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate sample input, filters and
                                             output.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindConvolutionForwardAlgorithmEx"><a name="cudnnFindConvolutionForwardAlgorithmEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionForwardAlgorithmEx" name="cudnnFindConvolutionForwardAlgorithmEx" shape="rect">5.2.10.&nbsp;<kbd class="ph userinput">cudnnFindConvolutionForwardAlgorithmEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function attempts all algorithms available for <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>. It will attempt both the provided
                              <samp class="ph codeph">convDesc mathType</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> (assuming the
                              two differ). <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionForwardAlgorithmEx(
    cudnnHandle_t                      handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t      wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               *returnedAlgoCount,
    cudnnConvolutionFwdAlgoPerf_t     *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *workSpace,
    size_t                             workSpaceSizeInBytes)</pre><p class="p">Algorithms without the <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> availability will only be tried
                              with <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>, and returned as such.
                           </p>
                           <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned in
                              the user-allocated array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionFwdAlgoPerf_t" shape="rect">cudnnConvolutionFwdAlgoPerf_t</a></samp>. These metrics are written in a sorted fashion where the first element
                              has the lowest compute time. The total number of resulting algorithms can be queried
                              through the API <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">cudnnGetConvolutionForwardAlgorithmMaxCount()</a></samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                           </div>
                           <div class="section" id="cudnnFindConvolutionForwardAlgorithmEx__section_fdq_pvh_z3b"><a name="cudnnFindConvolutionForwardAlgorithmEx__section_fdq_pvh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>. The content of this tensor
                                       will be overwritten with arbitrary values.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory is a necessary workspace for
                                       some algorithms. The size of this workspace will determine the
                                       availability of algorithms. A nil pointer is considered a
                                       <samp class="ph codeph">workSpace</samp> of 0 bytes.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindConvolutionForwardAlgorithmEx__section_yf4_qvh_z3b"><a name="cudnnFindConvolutionForwardAlgorithmEx__section_yf4_qvh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionForwardAlgorithmEx__ul_m1w_fhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithmEx__ul_m1w_fhb_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, or
                                             <samp class="ph codeph">yDesc</samp> are not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, or
                                             <samp class="ph codeph">yDesc</samp> has fewer than 1 dimension.
                                          </li>
                                          <li class="li"><samp class="ph codeph">x</samp>, <samp class="ph codeph">w</samp>, or <samp class="ph codeph">y</samp> is
                                             <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li">Either <samp class="ph codeph">returnedCount</samp> or
                                             <samp class="ph codeph">perfResults</samp> is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionForwardAlgorithmEx__ul_z1w_fhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithmEx__ul_z1w_fhb_s1b">
                                          <li class="li">The function was unable to allocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate sample input, filters and
                                             output.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolution2dDescriptor"><a name="cudnnGetConvolution2dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolution2dDescriptor" name="cudnnGetConvolution2dDescriptor" shape="rect">5.2.11.&nbsp;<kbd class="ph userinput">cudnnGetConvolution2dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries a previously initialized 2D convolution descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolution2dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *pad_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *pad_w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *u,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *v,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *dilation_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *dilation_w,
    cudnnConvolutionMode_t             *mode,
    cudnnDataType_t                    *computeType)</pre><div class="section" id="cudnnGetConvolution2dDescriptor__section_n3g_zrd_1jb"><a name="cudnnGetConvolution2dDescriptor__section_n3g_zrd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created convolution
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">pad_h</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Zero-padding height: number of rows of zeros implicitly
                                       concatenated onto the top and onto the bottom of input images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">pad_w</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Zero-padding width: number of columns of zeros implicitly
                                       concatenated onto the left and onto the right of input images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">u</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Vertical filter stride.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">v</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Horizontal filter stride.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dilation_h</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Filter height dilation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dilation_w</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Filter width dilation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Convolution mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">computeType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Compute precision.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolution2dDescriptor__section_kkx_csd_1jb"><a name="cudnnGetConvolution2dDescriptor__section_kkx_csd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The operation was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The parameter <samp class="ph codeph">convDesc</samp> is <samp class="ph codeph">NIL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolution2dForwardOutputDim"><a name="cudnnGetConvolution2dForwardOutputDim" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolution2dForwardOutputDim" name="cudnnGetConvolution2dForwardOutputDim" shape="rect">5.2.12.&nbsp;<kbd class="ph userinput">cudnnGetConvolution2dForwardOutputDim()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the dimensions of the resulting 4D tensor of a 2D
                                 convolution, given the convolution descriptor, the input tensor descriptor and the
                                 filter descriptor This function can help to setup the output tensor and allocate the
                                 proper amount of memory prior to launch the actual convolution.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolution2dForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       inputTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       filterDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *w)</pre><p class="p">Each dimension <samp class="ph codeph">h</samp> and <samp class="ph codeph">w</samp> of the output images is computed
                              as follows:
                           </p><pre xml:space="preserve">
    outputDim = 1 + ( inputDim + 2*pad - (((filterDim-1)*dilation)+1) )/convolutionStride;
    </pre><div class="note note"><span class="notetitle">Note:</span> The dimensions provided by this routine must be strictly respected when calling
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardBias" title="This function computes the convolution function gradient with respect to the bias, which is the sum of every element belonging to the same feature map across all of the images of the input tensor. Therefore, the number of elements produced is equal to the number of features maps of the input tensor." shape="rect">cudnnConvolutionBackwardBias()</a></samp>. Providing a smaller or larger
                              output tensor is not supported by the convolution routines.
                           </div>
                           <div class="section" id="cudnnGetConvolution2dForwardOutputDim__section_y3n_ssd_1jb"><a name="cudnnGetConvolution2dForwardOutputDim__section_y3n_ssd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created convolution
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">n</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of output images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">c</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Number of output feature maps per image.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">h</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Height of each output feature map.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Width of each output feature map.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolution2dForwardOutputDim__section_ftx_ssd_1jb"><a name="cudnnGetConvolution2dForwardOutputDim__section_ftx_ssd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">One or more of the descriptors has not been created correctly or there
                                       is a mismatch between the feature maps of
                                       <samp class="ph codeph">inputTensorDesc</samp> and
                                       <samp class="ph codeph">filterDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionBackwardDataAlgorithmMaxCount"><a name="cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardDataAlgorithmMaxCount" name="cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">5.2.13.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionBackwardDataAlgorithmMaxCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the maximum number of algorithms which can be returned from
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionBackwardDataAlgorithm" shape="rect">cudnnFindConvolutionBackwardDataAlgorithm()</a></samp> and
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">cudnnGetConvolutionForwardAlgorithm_v7()</a></samp>. This is
                              the sum of all algorithms plus the sum of all algorithms with Tensor Core operations
                              supported for the current device. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardDataAlgorithmMaxCount(
    cudnnHandle_t       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                 *count)</pre><div class="section" id="cudnnGetConvolutionBackwardDataAlgorithmMaxCount__section_jwj_j5d_1jb"><a name="cudnnGetConvolutionBackwardDataAlgorithmMaxCount__section_jwj_j5d_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">count</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The resulting maximum number of algorithms.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionBackwardDataAlgorithmMaxCount__section_xj5_j5d_1jb"><a name="cudnnGetConvolutionBackwardDataAlgorithmMaxCount__section_xj5_j5d_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The provided handle is not allocated properly.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionBackwardDataAlgorithm_v7"><a name="cudnnGetConvolutionBackwardDataAlgorithm_v7" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardDataAlgorithm_v7" name="cudnnGetConvolutionBackwardDataAlgorithm_v7" shape="rect">5.2.14.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionBackwardDataAlgorithm_v7()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function serves as a heuristic for obtaining the best suited algorithm for
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp> for the given layer
                              specifications. This function will return all algorithms (including
                              <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> versions
                              of algorithms where <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> may be available) sorted by
                              expected (based on internal heuristic) relative performance with the fastest being index 0
                              of <samp class="ph codeph">perfResults</samp>. For an exhaustive search for the fastest algorithm, use
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionBackwardDataAlgorithm" shape="rect">cudnnFindConvolutionBackwardDataAlgorithm()</a></samp>. The
                              total number of resulting algorithms can be queried through the
                              <samp class="ph codeph">returnedAlgoCount</samp> variable. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardDataAlgorithm_v7(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdDataAlgoPerf_t     *perfResults)</pre><div class="section" id="cudnnGetConvolutionBackwardDataAlgorithm_v7__section_sdc_vtd_1jb"><a name="cudnnGetConvolutionBackwardDataAlgorithm_v7__section_sdc_vtd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionBackwardDataAlgorithm_v7__section_uzm_vtd_1jb"><a name="cudnnGetConvolutionBackwardDataAlgorithm_v7__section_uzm_vtd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionBackwardDataAlgorithm_v7__ul_zxk_1kb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardDataAlgorithm_v7__ul_zxk_1kb_s1b">
                                          <li class="li">One of the parameters <samp class="ph codeph">handle</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                             <samp class="ph codeph">convDesc</samp>, <samp class="ph codeph">dxDesc</samp>,
                                             <samp class="ph codeph">perfResults</samp>, or
                                             <samp class="ph codeph">returnedAlgoCount</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The numbers of feature maps of the input tensor and output
                                             tensor differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or
                                             the filters are different.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedAlgoCount</samp> is less than or equal to
                                             0.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionBackwardDataWorkspaceSize"><a name="cudnnGetConvolutionBackwardDataWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardDataWorkspaceSize" name="cudnnGetConvolutionBackwardDataWorkspaceSize" shape="rect">5.2.15.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionBackwardDataWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the amount of GPU memory workspace the user needs to allocate to
                              be able to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp> with the
                              specified algorithm. The workspace allocated will then be passed to the routine
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData()</a></samp>. The specified
                              algorithm can be the result of the call to <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardDataAlgorithm_v7" shape="rect">cudnnGetConvolutionBackwardDataAlgorithm_v7()</a></samp> or can be chosen
                              arbitrarily by the user. Note that not every algorithm is available for every configuration
                              of the input tensor and/or every configuration of the convolution
                              descriptor. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardDataWorkspaceSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    cudnnConvolutionBwdDataAlgo_t       algo,
    size_t                             *sizeInBytes)</pre><div class="section" id="cudnnGetConvolutionBackwardDataWorkspaceSize__section_fys_p5d_1jb"><a name="cudnnGetConvolutionBackwardDataWorkspaceSize__section_fys_p5d_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies the chosen convolution
                                       algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to
                                       execute a forward convolution with the specified
                                       <samp class="ph codeph">algo</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionBackwardDataWorkspaceSize__section_brd_q5d_1jb"><a name="cudnnGetConvolutionBackwardDataWorkspaceSize__section_brd_q5d_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionBackwardDataWorkspaceSize__ul_lg1_fkb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardDataWorkspaceSize__ul_lg1_fkb_s1b">
                                          <li class="li">The numbers of feature maps of the input tensor and output
                                             tensor differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or
                                             the filter are different.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The combination of the tensor descriptors, filter descriptor and
                                       convolution descriptor is not supported for the specified
                                       algorithm.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionForwardAlgorithmMaxCount"><a name="cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionForwardAlgorithmMaxCount" name="cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">5.2.16.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionForwardAlgorithmMaxCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the maximum number of algorithms which can be returned from
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionForwardAlgorithm" shape="rect">cudnnFindConvolutionForwardAlgorithm()</a></samp> and
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">cudnnGetConvolutionForwardAlgorithm_v7()</a></samp>. This is
                              the sum of all algorithms plus the sum of all algorithms with Tensor Core operations
                              supported for the current device. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionForwardAlgorithmMaxCount(
    cudnnHandle_t   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>             *count)</pre><div class="section" id="cudnnGetConvolutionForwardAlgorithmMaxCount__section_dkc_3c2_1jb"><a name="cudnnGetConvolutionForwardAlgorithmMaxCount__section_dkc_3c2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">count</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The resulting maximum number of algorithms.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionForwardAlgorithmMaxCount__section_fsm_3c2_1jb"><a name="cudnnGetConvolutionForwardAlgorithmMaxCount__section_fsm_3c2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The provided handle is not allocated properly.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionForwardAlgorithm_v7"><a name="cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionForwardAlgorithm_v7" name="cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">5.2.17.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionForwardAlgorithm_v7()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function serves as a heuristic for obtaining the best suited algorithm for
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp> for the given layer
                              specifications. This function will return all algorithms (including
                              <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> versions
                              of algorithms where <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> may be available) sorted by
                              expected (based on internal heuristic) relative performance with the fastest being index 0
                              of <samp class="ph codeph">perfResults</samp>. For an exhaustive search for the fastest algorithm, use
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionForwardAlgorithm" shape="rect">cudnnFindConvolutionForwardAlgorithm()</a></samp>. The total
                              number of resulting algorithms can be queried through the <samp class="ph codeph">returnedAlgoCount</samp>
                              variable. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionForwardAlgorithm_v7(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                           requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *returnedAlgoCount,
    cudnnConvolutionFwdAlgoPerf_t      *perfResults)
</pre><div class="section" id="cudnnGetConvolutionForwardAlgorithm_v7__section_abx_rb2_1jb"><a name="cudnnGetConvolutionForwardAlgorithm_v7__section_abx_rb2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized convolution filter
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionForwardAlgorithm_v7__section_kfh_sb2_1jb"><a name="cudnnGetConvolutionForwardAlgorithm_v7__section_kfh_sb2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionForwardAlgorithm_v7__ul_xz5_nhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionForwardAlgorithm_v7__ul_xz5_nhb_s1b">
                                          <li class="li">One of the parameters <samp class="ph codeph">handle</samp>,
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">convDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">perfResults</samp>, or
                                             <samp class="ph codeph">returnedAlgoCount</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">Either <samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">wDesc</samp> have
                                             different dimensions from <samp class="ph codeph">xDesc</samp>.
                                          </li>
                                          <li class="li">The data types of tensors <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">wDesc</samp> are not all
                                             the same.
                                          </li>
                                          <li class="li">The number of feature maps in <samp class="ph codeph">xDesc</samp> and
                                             <samp class="ph codeph">wDesc</samp> differs.
                                          </li>
                                          <li class="li">The tensor <samp class="ph codeph">xDesc</samp> has a dimension smaller than
                                             3.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedAlgoCount</samp> is less than or equal to
                                             0.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionForwardWorkspaceSize"><a name="cudnnGetConvolutionForwardWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionForwardWorkspaceSize" name="cudnnGetConvolutionForwardWorkspaceSize" shape="rect">5.2.18.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionForwardWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the amount of GPU memory workspace the user needs to allocate to
                              be able to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp> with the specified
                              algorithm. The workspace allocated will then be passed to the routine <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>. The specified algorithm can be the
                              result of the call to <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">cudnnGetConvolutionForwardAlgorithm_v7()</a></samp> or can be chosen arbitrarily by the user. Note that not every algorithm is
                              available for every configuration of the input tensor and/or every configuration of the
                              convolution descriptor.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionForwardWorkspaceSize(
    cudnnHandle_t   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t         xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnFilterDescriptor_t         wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t         yDesc,
    cudnnConvolutionFwdAlgo_t               algo,
    size_t                                 *sizeInBytes)</pre><div class="section" id="cudnnGetConvolutionForwardWorkspaceSize__section_gjw_xc2_1jb"><a name="cudnnGetConvolutionForwardWorkspaceSize__section_gjw_xc2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized <samp class="ph codeph">x</samp>
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized <samp class="ph codeph">y</samp>
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies the chosen convolution
                                       algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to
                                       execute a forward convolution with the specified
                                       <samp class="ph codeph">algo</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionForwardWorkspaceSize__section_nrl_yc2_1jb"><a name="cudnnGetConvolutionForwardWorkspaceSize__section_nrl_yc2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionForwardWorkspaceSize__ul_lmf_rhb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionForwardWorkspaceSize__ul_lmf_rhb_s1b">
                                          <li class="li">One of the parameters <samp class="ph codeph">handle</samp>,
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">convDesc</samp>, or <samp class="ph codeph">yDesc</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The tensor <samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">wDesc</samp> are
                                             not of the same dimension as <samp class="ph codeph">xDesc</samp>.
                                          </li>
                                          <li class="li">The tensor <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> or
                                             <samp class="ph codeph">wDesc</samp> are not of the same data type.
                                          </li>
                                          <li class="li">The numbers of feature maps of the tensor <samp class="ph codeph">xDesc</samp>
                                             and <samp class="ph codeph">wDesc</samp> differ.
                                          </li>
                                          <li class="li">The tensor <samp class="ph codeph">xDesc</samp> has a dimension smaller than
                                             3.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The combination of the tensor descriptors, filter descriptor and
                                       convolution descriptor is not supported for the specified
                                       algorithm.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionGroupCount"><a name="cudnnGetConvolutionGroupCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionGroupCount" name="cudnnGetConvolutionGroupCount" shape="rect">5.2.19.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionGroupCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the group count specified in the given convolution
                                 descriptor. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionGroupCount(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *groupCount)</pre><div class="section" id="cudnnGetConvolutionGroupCount__section_gvx_md2_1jb"><a name="cudnnGetConvolutionGroupCount__section_gvx_md2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The group count was returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid convolution descriptor was provided.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionMathType"><a name="cudnnGetConvolutionMathType" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionMathType" name="cudnnGetConvolutionMathType" shape="rect">5.2.20.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionMathType()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the math type specified in a given convolution descriptor. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionMathType(
    cudnnConvolutionDescriptor_t    convDesc,
    cudnnMathType_t                *mathType)</pre><div class="section" id="cudnnGetConvolutionMathType__section_hbg_4d2_1jb"><a name="cudnnGetConvolutionMathType__section_hbg_4d2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The math type was returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid convolution descriptor was provided.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionNdDescriptor"><a name="cudnnGetConvolutionNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionNdDescriptor" name="cudnnGetConvolutionNdDescriptor" shape="rect">5.2.21.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function queries a previously initialized convolution descriptor
                                 object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionNdDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 arrayLengthRequested,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *arrayLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 padA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 filterStrideA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 dilationA[],
    cudnnConvolutionMode_t             *mode,
    cudnnDataType_t                    *dataType)</pre><div class="section" id="cudnnGetConvolutionNdDescriptor__section_vhx_qd2_1jb"><a name="cudnnGetConvolutionNdDescriptor__section_vhx_qd2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created convolution
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">arrayLengthRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the expected convolution descriptor. It is
                                       also the minimum size of the arrays <samp class="ph codeph">padA</samp>,
                                       <samp class="ph codeph">filterStrideA</samp>, and <samp class="ph codeph">dilationA</samp> in
                                       order to be able to hold the results.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">arrayLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Actual dimension of the convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">padA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimension of at least
                                       <samp class="ph codeph">arrayLengthRequested</samp> that will be filled with the
                                       padding parameters from the provided convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterStrideA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimension of at least
                                       <samp class="ph codeph">arrayLengthRequested</samp> that will be filled with the
                                       filter stride from the provided convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dilationA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimension of at least
                                       <samp class="ph codeph">arrayLengthRequested</samp> that will be filled with the
                                       dilation parameters from the provided convolution descriptor. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Convolution mode of the provided descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Datatype of the provided descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionNdDescriptor__section_rbh_rd2_1jb"><a name="cudnnGetConvolutionNdDescriptor__section_rbh_rd2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionNdDescriptor__ul_egc_pgb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionNdDescriptor__ul_egc_pgb_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">convDesc</samp> is
                                             <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">arrayLengthRequest</samp> is negative.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">arrayLengthRequested</samp> is greater than
                                       <samp class="ph codeph">CUDNN_DIM_MAX-2</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionNdForwardOutputDim"><a name="cudnnGetConvolutionNdForwardOutputDim" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionNdForwardOutputDim" name="cudnnGetConvolutionNdForwardOutputDim" shape="rect">5.2.22.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionNdForwardOutputDim()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the dimensions of the resulting <samp class="ph codeph">Nd</samp> tensor
                                 of a <samp class="ph codeph">nbDims-2-D</samp> convolution, given the convolution descriptor, the
                                 input tensor descriptor and the filter descriptor This function can help to setup the
                                 output tensor and allocate the proper amount of memory prior to launch the actual
                                 convolution. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionNdForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       inputTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       filterDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 tensorOuputDimA[])</pre><div class="p">Each dimension of the <samp class="ph codeph">(nbDims-2)-D</samp> images of the output tensor is
                              computed as follows:<pre xml:space="preserve">
    outputDim = 1 + ( inputDim + 2*pad - (((filterDim-1)*dilation)+1) )/convolutionStride;
    </pre></div>
                           <div class="note note"><span class="notetitle">Note:</span> The dimensions provided by this routine must be strictly respected when calling
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp> or <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardBias" title="This function computes the convolution function gradient with respect to the bias, which is the sum of every element belonging to the same feature map across all of the images of the input tensor. Therefore, the number of elements produced is equal to the number of features maps of the input tensor." shape="rect">cudnnConvolutionBackwardBias()</a></samp>. Providing a smaller or larger
                              output tensor is not supported by the convolution routines.
                           </div>
                           <div class="section" id="cudnnGetConvolutionNdForwardOutputDim__section_xpt_322_1jb"><a name="cudnnGetConvolutionNdForwardOutputDim__section_xpt_322_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created convolution
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputTensorDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the output tensor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">tensorOuputDimA</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Array of dimensions <samp class="ph codeph">nbDims</samp> that contains
                                       on exit of this routine the sizes of the output tensor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionNdForwardOutputDim__section_u42_j22_1jb"><a name="cudnnGetConvolutionNdForwardOutputDim__section_u42_j22_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionNdForwardOutputDim__ul_spl_tgb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionNdForwardOutputDim__ul_spl_tgb_s1b">
                                          <li class="li">One of the parameters <samp class="ph codeph">convDesc</samp>,
                                             <samp class="ph codeph">inputTensorDesc</samp>, and
                                             <samp class="ph codeph">filterDesc</samp> is nil.
                                          </li>
                                          <li class="li">The dimension of the filter descriptor
                                             <samp class="ph codeph">filterDesc</samp> is different from the dimension
                                             of input tensor descriptor
                                             <samp class="ph codeph">inputTensorDesc</samp>.
                                          </li>
                                          <li class="li">The dimension of the convolution descriptor is different from
                                             the dimension of input tensor descriptor
                                             <samp class="ph codeph">inputTensorDesc-2</samp>.
                                          </li>
                                          <li class="li">The features map of the filter descriptor
                                             <samp class="ph codeph">filterDesc</samp> is different from the one of
                                             input tensor descriptor <samp class="ph codeph">inputTensorDesc</samp>.
                                          </li>
                                          <li class="li">The size of the dilated filter <samp class="ph codeph">filterDesc</samp> is
                                             larger than the padded sizes of the input tensor.
                                          </li>
                                          <li class="li">The dimension <samp class="ph codeph">nbDims</samp> of the output array is
                                             negative or greater than the dimension of input tensor
                                             descriptor <samp class="ph codeph">inputTensorDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The routine exited successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionReorderType"><a name="cudnnGetConvolutionReorderType" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionReorderType" name="cudnnGetConvolutionReorderType" shape="rect">5.2.23.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionReorderType()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves the convolution reorder type from the given convolution
                                 			descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionReorderType(
	cudnnConvolutionDescriptor_t convDesc,
	cudnnReorderType_t *reorderType);		</pre><div class="section" id="cudnnGetConvolutionReorderType__section_zl5_gf2_1jb"><a name="cudnnGetConvolutionReorderType__section_zl5_gf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The convolution descriptor from which the reorder type
                                       							should be retrieved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reorderType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The retrieved reorder type. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnReorderType_t" shape="rect">cudnnReorderType_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionReorderType__section_d2h_hf2_1jb"><a name="cudnnGetConvolutionReorderType__section_d2h_hf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">One of the inputs to this function is not valid.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The reorder type is retrieved successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetFoldedConvBackwardDataDescriptors"><a name="cudnnGetFoldedConvBackwardDataDescriptors" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFoldedConvBackwardDataDescriptors" name="cudnnGetFoldedConvBackwardDataDescriptors" shape="rect">5.2.24.&nbsp;<kbd class="ph userinput">cudnnGetFoldedConvBackwardDataDescriptors()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function calculates folding descriptors for backward data gradients. It
                                 takes as input the data descriptors along with the convolution descriptor and computes
                                 the folded data descriptors and the folding transform descriptors. These can then be
                                 used to do the actual folding transform.</span></div><pre xml:space="preserve">cudnnStatus_t
cudnnGetFoldedConvBackwardDataDescriptors(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnHandle_t handle,
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t filterDesc,
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t diffDesc,
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t convDesc,
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t gradDesc,
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorFormat_t transformFormat,
                                          cudnnFilterDescriptor_t foldedFilterDesc,
                                          cudnnTensorDescriptor_t paddedDiffDesc,
                                          cudnnConvolutionDescriptor_t foldedConvDesc,
                                          cudnnTensorDescriptor_t foldedGradDesc,
                                          cudnnTensorTransformDescriptor_t filterFoldTransDesc,
                                          cudnnTensorTransformDescriptor_t diffPadTransDesc,
                                          cudnnTensorTransformDescriptor_t gradFoldTransDesc,
                                          cudnnTensorTransformDescriptor_t gradUnfoldTransDesc) ;
</pre><div class="section" id="cudnnGetFoldedConvBackwardDataDescriptors__section_l1g_xmn_y3b"><a name="cudnnGetFoldedConvBackwardDataDescriptors__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Filter descriptor before folding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">diffDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Diff descriptor before folding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Convolution descriptor before folding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Gradient descriptor before folding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">transformFormat</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Transform format for folding.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">foldedFilterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Folded filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddedDiffDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Padded <samp class="ph codeph">Diff</samp> descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">foldedConvDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Folded convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">foldedGradDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Folded gradient descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterFoldTransDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Folding transform descriptor for filter.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">diffPadTransDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Folding transform descriptor for
                                       <samp class="ph codeph">Desc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradFoldTransDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Folding transform descriptor for gradient.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradUnfoldTransDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Unfolding transform descriptor for folded gradient.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetFoldedConvBackwardDataDescriptors__section_zgs_xmn_y3b"><a name="cudnnGetFoldedConvBackwardDataDescriptors__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">Folded descriptors were computed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If any of the input parameters is <samp class="ph codeph">NULL</samp> or if the input
                                       tensor has more than 4 dimensions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">Computing the folded descriptors failed.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnIm2Col"><a name="cudnnIm2Col" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnIm2Col" name="cudnnIm2Col" shape="rect">5.2.25.&nbsp;<kbd class="ph userinput">cudnnIm2Col()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function constructs the <samp class="ph codeph">A</samp> matrix necessary to perform a
                                 forward pass of GEMM convolution. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnIm2Col(
    cudnnHandle_t                   handle,
    cudnnTensorDescriptor_t         srcDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *srcData,
    cudnnFilterDescriptor_t         filterDesc,   
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *colBuffer)</pre><div class="p">This <samp class="ph codeph">A</samp> matrix has a height of
                              <samp class="ph codeph">batch_size*y_height*y_width</samp> and width of
                              <samp class="ph codeph">input_channels*filter_height*filter_width</samp>, where:<a name="cudnnIm2Col__ul_hcw_skk_1jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnIm2Col__ul_hcw_skk_1jb">
                                 <li class="li"><samp class="ph codeph">batch_size</samp> is <samp class="ph codeph">srcDesc</samp> first dimension
                                 </li>
                                 <li class="li"><samp class="ph codeph">y_height/y_width</samp> are computed from
                                    <samp class="ph codeph">cudnnGetConvolutionNdForwardOutputDim()</samp></li>
                                 <li class="li"><samp class="ph codeph">input_channels</samp> is <samp class="ph codeph">srcDesc</samp> second dimension
                                    (when in NCHW layout)
                                 </li>
                                 <li class="li"><samp class="ph codeph">filter_height/filter_width</samp> are <samp class="ph codeph">wDesc</samp> third and
                                    fourth dimension
                                 </li>
                              </ul>
                           </div>
                           <p class="p">The <samp class="ph codeph">A</samp> matrix is stored in format HW fully-packed in GPU memory.
                           </p>
                           <div class="section" id="cudnnIm2Col__section_fmn_xkk_1jb"><a name="cudnnIm2Col__section_fmn_xkk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">srcDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">srcData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the input
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized convolution
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">colBuffer</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory storing the output
                                       matrix.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnIm2Col__section_njx_xkk_1jb"><a name="cudnnIm2Col__section_njx_xkk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">srcData</samp> or <samp class="ph codeph">colBuffer</samp> is
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Any of <samp class="ph codeph">srcDesc</samp>, <samp class="ph codeph">filterDesc</samp>,
                                       <samp class="ph codeph">convDesc</samp> has <samp class="ph codeph">dataType</samp> of
                                       <samp class="ph codeph">CUDNN_DATA_INT8</samp>,
                                       <samp class="ph codeph">CUDNN_DATA_INT8x4</samp>, <samp class="ph codeph">CUDNN_DATA_INT8</samp> or
                                       <samp class="ph codeph">CUDNN_DATA_INT8x4</samp><samp class="ph codeph">convDesc</samp> has <samp class="ph codeph">groupCount</samp> larger than
                                       1.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The CUDA kernel execution was unsuccessful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The output data array is successfully generated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnReorderFilterAndBias"><a name="cudnnReorderFilterAndBias" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReorderFilterAndBias" name="cudnnReorderFilterAndBias" shape="rect">5.2.26.&nbsp;<kbd class="ph userinput">cudnnReorderFilterAndBias()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function <samp class="ph codeph"><a class="xref" href="index.html#cudnnReorderFilterAndBias" shape="rect">cudnnReorderFilterAndBias()</a></samp>, reorders
                              		the filter and bias values for tensors with data type <samp class="ph codeph">CUDNN_DATA_INT8x32</samp>
                              		and tensor format <samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp>. It can be used to enhance the
                              		inference time by separating the reordering operation from convolution. Currently, only 2D
                              		filters are supported. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnReorderFilterAndBias(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t filterDesc,
	cudnnReorderType_t reorderType,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *filterData,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reorderedFilterData,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> reorderBias,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *biasData,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reorderedBiasData);		</pre><p class="p">Filter and bias tensors with data type <samp class="ph codeph">CUDNN_DATA_INT8x32</samp> (also implying
                              			tensor format <samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp>) requires permutation of output
                              			channel axes in order to take advantage of the Tensor Core IMMA instruction. This is
                              			done in every <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp> and
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBiasActivationForward" shape="rect">cudnnConvolutionBiasActivationForward()</a></samp> call
                              			when the reorder type attribute of the convolution descriptor is set to
                              				<samp class="ph codeph">CUDNN_DEFAULT_REORDER</samp>. Users can avoid the repeated reordering
                              			kernel call by first using this call to reorder the filter and bias tensor and call the
                              			convolution forward APIs with reorder type set to <samp class="ph codeph">CUDNN_NO_REORDER</samp>.
                           </p>
                           <p class="p">For example, convolutions in a neural network of multiple layers can require reordering of
                              			kernels at every layer, which can take up a significant fraction of the total inference
                              			time. Using this function, the reordering can be done one time on the filter and bias
                              			data. This is followed by the convolution operations at the multiple layers, which
                              			enhance the inference time. 
                           </p>
                           <div class="section" id="cudnnReorderFilterAndBias__section_enc_zym_1jb"><a name="cudnnReorderFilterAndBias__section_enc_zym_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the kernel dataset.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reorderType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Setting to either perform reordering or not. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnReorderType_t" shape="rect">cudnnReorderType_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the filter (kernel) data location in the device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reorderedFilterData</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the location in the device memory where the
                                       							reordered filter data will be written to, by this function. This tensor
                                       							has the same dimensions as <samp class="ph codeph">filterData</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reorderBias</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. If &gt; 0, then reorders the bias data also. If &lt;= 0 then
                                       							does not perform reordering operations on the bias data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">biasData</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the bias data location in the device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reorderedBiasData</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the location in the device memory where the
                                       							reordered bias data will be written to, by this function. This tensor
                                       							has the same dimensions as <samp class="ph codeph">biasData</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnReorderFilterAndBias__section_scg_1zm_1jb"><a name="cudnnReorderFilterAndBias__section_scg_1zm_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">Reordering was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">Either the reordering of the filter data or of the bias data
                                       							failed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The handle, filter descriptor, filter data, or reordered data is NULL.
                                       							Or, if the bias reordering is requested (<samp class="ph codeph">reorderBias &gt;
                                          								0</samp>), the bias data or reordered bias data is NULL. This
                                       							status can also be returned if the filter dimension size is not
                                       								<samp class="ph codeph">4</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Filter descriptor data type is not <samp class="ph codeph">CUDNN_DATA_INT8x32</samp>;
                                       							the filter descriptor tensor is not in a vectorized layout
                                       								(<samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp>).
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetConvolution2dDescriptor"><a name="cudnnSetConvolution2dDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolution2dDescriptor" name="cudnnSetConvolution2dDescriptor" shape="rect">5.2.27.&nbsp;<kbd class="ph userinput">cudnnSetConvolution2dDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created convolution descriptor object into
                                 a 2D correlation. This function assumes that the tensor and filter descriptors
                                 correspond to the forward convolution path and checks if their settings are valid. That
                                 same convolution descriptor can be reused in the backward path provided it corresponds
                                 to the same layer. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolution2dDescriptor(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             pad_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             pad_w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             u,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             v,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             dilation_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             dilation_w,
    cudnnConvolutionMode_t          mode,
    cudnnDataType_t                 computeType)</pre><div class="section" id="cudnnSetConvolution2dDescriptor__section_xz3_mk1_bjb"><a name="cudnnSetConvolution2dDescriptor__section_xz3_mk1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created convolution
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">pad_h</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Zero-padding height: number of rows of zeros implicitly
                                       concatenated onto the top and onto the bottom of input images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">pad_w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Zero-padding width: number of columns of zeros implicitly
                                       concatenated onto the left and onto the right of input images.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">u</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Vertical filter stride.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">v</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Horizontal filter stride.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dilation_h</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Filter height dilation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dilation_w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Filter width dilation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Selects between <samp class="ph codeph">CUDNN_CONVOLUTION</samp> and
                                       <samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">computeType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Compute precision.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetConvolution2dDescriptor__section_qqt_mk1_bjb"><a name="cudnnSetConvolution2dDescriptor__section_qqt_mk1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSetConvolution2dDescriptor__ul_a54_yfb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetConvolution2dDescriptor__ul_a54_yfb_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">convDesc</samp> is
                                             <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li">One of the parameters <samp class="ph codeph">pad_h</samp>,
                                             <samp class="ph codeph">pad_w</samp> is strictly negative.
                                          </li>
                                          <li class="li">One of the parameters <samp class="ph codeph">u</samp>, <samp class="ph codeph">v</samp> is
                                             negative or zero.
                                          </li>
                                          <li class="li">One of the parameters <samp class="ph codeph">dilation_h</samp>,
                                             <samp class="ph codeph">dilation_w</samp> is negative or zero.
                                          </li>
                                          <li class="li">The parameter <samp class="ph codeph">mode</samp> has an invalid enumerant
                                             value.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetConvolutionGroupCount"><a name="cudnnSetConvolutionGroupCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionGroupCount" name="cudnnSetConvolutionGroupCount" shape="rect">5.2.28.&nbsp;<kbd class="ph userinput">cudnnSetConvolutionGroupCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function allows the user to specify the number of groups to be used in the
                                 associated convolution.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionGroupCount(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             groupCount)</pre><div class="section" id="cudnnSetConvolutionGroupCount__section_mkt_tm1_bjb"><a name="cudnnSetConvolutionGroupCount__section_mkt_tm1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The group count was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid convolution descriptor was provided.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetConvolutionMathType"><a name="cudnnSetConvolutionMathType" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionMathType" name="cudnnSetConvolutionMathType" shape="rect">5.2.29.&nbsp;<kbd class="ph userinput">cudnnSetConvolutionMathType()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function allows the user to specify whether or not the use of tensor op is
                                 permitted in the library routines associated with a given convolution
                                 descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionMathType(
    cudnnConvolutionDescriptor_t    convDesc,
    cudnnMathType_t                 mathType)</pre><div class="section" id="cudnnSetConvolutionMathType__section_ihj_wm1_bjb"><a name="cudnnSetConvolutionMathType__section_ihj_wm1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The math type was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either an invalid convolution descriptor was provided or an invalid math
                                       type was specified.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetConvolutionNdDescriptor"><a name="cudnnSetConvolutionNdDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionNdDescriptor" name="cudnnSetConvolutionNdDescriptor" shape="rect">5.2.30.&nbsp;<kbd class="ph userinput">cudnnSetConvolutionNdDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created generic convolution descriptor
                                 object into a <samp class="ph codeph">Nd</samp> correlation. That same convolution descriptor can be
                                 reused in the backward path provided it corresponds to the same layer. The convolution
                                 computation will be done in the specified <samp class="ph codeph">dataType</samp>, which can be
                                 potentially different from the input/output tensors.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionNdDescriptor(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             arrayLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       padA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       filterStrideA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       dilationA[],
    cudnnConvolutionMode_t          mode,
    cudnnDataType_t                 dataType)</pre><div class="section" id="cudnnSetConvolutionNdDescriptor__section_en1_2n1_bjb"><a name="cudnnSetConvolutionNdDescriptor__section_en1_2n1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Handle to a previously created convolution
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">arrayLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Dimension of the convolution.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">padA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">arrayLength</samp> containing
                                       the zero-padding size for each dimension. For every dimension, the
                                       padding represents the number of extra zeros implicitly concatenated at
                                       the start and at the end of every element of that dimension.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">filterStrideA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">arrayLength</samp> containing
                                       the filter stride for each dimension. For every dimension, the filter
                                       stride represents the number of elements to slide to reach the next
                                       start of the filtering window of the next point.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dilationA</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">arrayLength</samp> containing
                                       the dilation factor for each dimension. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Selects between <samp class="ph codeph">CUDNN_CONVOLUTION</samp> and
                                       <samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">datatype</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Selects the data type in which the computation will be
                                       done.
                                       <div class="note note"><span class="notetitle">Note:</span><samp class="ph codeph">CUDNN_DATA_HALF</samp> in <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetConvolutionNdDescriptor" title="This function initializes a previously created generic convolution descriptor object into a Nd correlation. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer. The convolution computation will be done in the specified dataType, which can be potentially different from the input/output tensors." shape="rect">cudnnSetConvolutionNdDescriptor()</a></samp> with
                                          <samp class="ph codeph">HALF_CONVOLUTION_BWD_FILTER</samp> is not recommended
                                          as it is known to not be useful for any practical use case for
                                          training and will be considered to be blocked in a future cuDNN
                                          release. The use of <samp class="ph codeph">CUDNN_DATA_HALF</samp> for input
                                          tensors in <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetTensorNdDescriptor" title="This function initializes a previously created generic tensor descriptor object." shape="rect">cudnnSetTensorNdDescriptor()</a></samp> and <samp class="ph codeph">CUDNN_DATA_FLOAT</samp> in
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetConvolutionNdDescriptor" title="This function initializes a previously created generic convolution descriptor object into a Nd correlation. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer. The convolution computation will be done in the specified dataType, which can be potentially different from the input/output tensors." shape="rect">cudnnSetConvolutionNdDescriptor()</a></samp> with <samp class="ph codeph">HALF_CONVOLUTION_BWD_FILTER</samp> is
                                          recommended and is used with the automatic mixed precision (AMP)
                                          training in many well known deep learning frameworks.
                                       </div>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetConvolutionNdDescriptor__section_ask_2n1_bjb"><a name="cudnnSetConvolutionNdDescriptor__section_ask_2n1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSetConvolutionNdDescriptor__ul_idc_lgb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetConvolutionNdDescriptor__ul_idc_lgb_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">convDesc</samp> is
                                             <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">arrayLengthRequest</samp> is negative.
                                          </li>
                                          <li class="li">The enumerant <samp class="ph codeph">mode</samp> has an invalid value.
                                          </li>
                                          <li class="li">The enumerant <samp class="ph codeph">datatype</samp> has an invalid
                                             value.
                                          </li>
                                          <li class="li">One of the elements of <samp class="ph codeph">padA</samp> is strictly
                                             negative.
                                          </li>
                                          <li class="li">One of the elements of <samp class="ph codeph">strideA</samp> is negative or
                                             zero.
                                          </li>
                                          <li class="li">One of the elements of <samp class="ph codeph">dilationA</samp> is negative or
                                             zero.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnSetConvolutionNdDescriptor__ul_tdc_lgb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetConvolutionNdDescriptor__ul_tdc_lgb_s1b">
                                          <li class="li">The <samp class="ph codeph">arrayLengthRequest</samp> is greater than
                                             <samp class="ph codeph">CUDNN_DIM_MAX</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetConvolutionReorderType"><a name="cudnnSetConvolutionReorderType" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionReorderType" name="cudnnSetConvolutionReorderType" shape="rect">5.2.31.&nbsp;<kbd class="ph userinput">cudnnSetConvolutionReorderType()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function sets the convolution reorder type for the given convolution
                                 			descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionReorderType(
	cudnnConvolutionDescriptor_t convDesc, 
	cudnnReorderType_t reorderType);		</pre><div class="section" id="cudnnSetConvolutionReorderType__section_dwk_kp1_bjb"><a name="cudnnSetConvolutionReorderType__section_dwk_kp1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The convolution descriptor for which the reorder type
                                       							should be set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reorderType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Set the reorder type to this value. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnReorderType_t" shape="rect">cudnnReorderType_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetConvolutionReorderType__section_txy_kp1_bjb"><a name="cudnnSetConvolutionReorderType__section_txy_kp1_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The reorder type supplied is not supported.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">Reorder type is set successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="cudnn-cnn-train-so-library"><a name="cudnn-cnn-train-so-library" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cudnn-cnn-train-so-library" name="cudnn-cnn-train-so-library" shape="rect">6.&nbsp;<kbd class="ph userinput">cudnn_cnn_train.so</kbd> Library</a></h2>
                  <div class="body conbody">
                     <div class="abstract">This entity contains all routines related to convolutional neural networks needed
                        during training time. The <samp class="ph codeph">cudnn_cnn_train</samp> library depends on
                        <samp class="ph codeph">cudnn_ops_infer</samp>, <samp class="ph codeph">cudnn_ops_train</samp>, and
                        <samp class="ph codeph">cudnn_cnn_infer</samp>.   <span class="shortdesc"></span></div>
                     <p class="p">For the backend data and descriptor types, refer to the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a> section.
                     </p>
                  </div>
                  <div class="topic concept nested1" id="cudnn-cnn-train-so-data-types"><a name="cudnn-cnn-train-so-data-types" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-train-so-data-types" name="cudnn-cnn-train-so-data-types" shape="rect">6.1.&nbsp;Data Type References</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the data type references in the <samp class="ph codeph">cudnn_cnn_train.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnn-cnn-train-so-opaque"><a name="cudnn-cnn-train-so-opaque" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-train-so-opaque" name="cudnn-cnn-train-so-opaque" shape="rect">6.1.1.&nbsp;Pointer To Opaque Struct Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the pointers to the opaque struct types in the
                                 <samp class="ph codeph">cudnn_cnn_train.so</samp> library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnFusedOpsConstParamPack_t"><a name="cudnnFusedOpsConstParamPack_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsConstParamPack_t" name="cudnnFusedOpsConstParamPack_t" shape="rect">6.1.1.1.&nbsp;<kbd class="ph userinput">cudnnFusedOpsConstParamPack_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnFusedOpsConstParamPack_t</samp> is a pointer to an opaque structure
                                 		holding the description of the <samp class="ph codeph">cudnnFusedOps</samp> constant parameters. Use the
                                 		function <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateFusedOpsConstParamPack" title="This function creates an opaque structure to store the various problem size information, such as the shape, layout and the type of tensors, and the descriptors for convolution and activation, for the selected sequence of cudnnFusedOps computations." shape="rect">cudnnCreateFusedOpsConstParamPack()</a></samp> to create one
                                 		instance of this structure, and the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyFusedOpsConstParamPack" shape="rect">cudnnDestroyFusedOpsConstParamPack()</a></samp> to destroy a
                                 		previously-created descriptor. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFusedOpsPlan_t"><a name="cudnnFusedOpsPlan_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsPlan_t" name="cudnnFusedOpsPlan_t" shape="rect">6.1.1.2.&nbsp;<kbd class="ph userinput">cudnnFusedOpsPlan_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnFusedOpsPlan_t</samp> is a pointer to an opaque structure holding the
                                 		description of the <samp class="ph codeph">cudnnFusedOpsPlan</samp>. This descriptor contains the plan
                                 		information, including the problem type and size, which kernels should be run, and the
                                 		internal workspace partition. Use the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateFusedOpsPlan" title="This function creates the plan descriptor for the cudnnFusedOps computation. This descriptor contains the plan information, including the problem type and size, which kernels should be run, and the internal workspace partition." shape="rect">cudnnCreateFusedOpsPlan()</a></samp> to create one instance of this
                                 		structure, and the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyFusedOpsPlan" title="This function destroys the plan descriptor provided." shape="rect">cudnnDestroyFusedOpsPlan()</a></samp> to
                                 		destroy a previously-created descriptor. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFusedOpsVariantParamPack_t"><a name="cudnnFusedOpsVariantParamPack_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsVariantParamPack_t" name="cudnnFusedOpsVariantParamPack_t" shape="rect">6.1.1.3.&nbsp;<kbd class="ph userinput">cudnnFusedOpsVariantParamPack_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnFusedOpsVariantParamPack_t</samp> is a pointer to an opaque structure
                                 		holding the description of the <samp class="ph codeph">cudnnFusedOps</samp> variant parameters. Use the
                                 		function <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateFusedOpsVariantParamPack" title="This function creates the variant pack descriptor for the cudnnFusedOps computation." shape="rect">cudnnCreateFusedOpsVariantParamPack()</a></samp> to create one
                                 		instance of this structure, and the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyFusedOpsVariantParamPack" title="This function destroys a previously-created descriptor for cudnnFusedOps constant parameters." shape="rect">cudnnDestroyFusedOpsVariantParamPack()</a></samp> to destroy a
                                 		previously-created descriptor. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnn-cnn-train-so-struct-types"><a name="cudnn-cnn-train-so-struct-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-train-so-struct-types" name="cudnn-cnn-train-so-struct-types" shape="rect">6.1.2.&nbsp;Struct Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the struct types in the <samp class="ph codeph">cudnn_cnn_train.so</samp>
                                 library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnConvolutionBwdFilterAlgoPerf_t"><a name="cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdFilterAlgoPerf_t" name="cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">6.1.2.1.&nbsp;<kbd class="ph userinput">cudnnConvolutionBwdFilterAlgoPerf_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnConvolutionBwdFilterAlgoPerf_t</samp> is a structure containing
                                 performance results returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionBackwardFilterAlgorithm" shape="rect">cudnnFindConvolutionBackwardFilterAlgorithm()</a></samp> or heuristic results
                                 returned by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardFilterAlgorithm_v7" shape="rect">cudnnGetConvolutionBackwardFilterAlgorithm_v7()</a></samp>.
                                 <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnConvolutionBwdFilterAlgoPerf_t__section_mmj_zdr_2jb"><a name="cudnnConvolutionBwdFilterAlgoPerf_t__section_mmj_zdr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Data Members</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnConvolutionBwdFilterAlgo_t algo</samp></dt>
                                       <dd class="dd">The algorithm runs to obtain the associated performance metrics. </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnStatus_t status</samp></dt>
                                       <dd class="dd">If any error occurs during the workspace allocation or timing of
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>, this status will represent that error. Otherwise, this
                                          status will be the return status of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>.<a name="cudnnConvolutionBwdFilterAlgoPerf_t__ul_d3y_csz_r1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnConvolutionBwdFilterAlgoPerf_t__ul_d3y_csz_r1b">
                                             <li class="li"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp> if any error occurred
                                                during workspace allocation or if the provided workspace is
                                                insufficient.
                                             </li>
                                             <li class="li"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp> if any error
                                                occurred during timing calculations or workspace
                                                deallocation.
                                             </li>
                                             <li class="li">Otherwise, this will be the return status of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>.
                                             </li>
                                          </ul>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">float time</samp></dt>
                                       <dd class="dd">The execution time of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp> (in
                                          milliseconds). 
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">size_t memory</samp></dt>
                                       <dd class="dd">The workspace size (in bytes). </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnDeterminism_t determinism</samp></dt>
                                       <dd class="dd">The determinism of the algorithm.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">cudnnMathType_t mathType</samp></dt>
                                       <dd class="dd">The math type provided to the algorithm.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">int reserved[3]</samp></dt>
                                       <dd class="dd">Reserved space for future properties.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnn-cnn-train-so-enum-types"><a name="cudnn-cnn-train-so-enum-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-train-so-enum-types" name="cudnn-cnn-train-so-enum-types" shape="rect">6.1.3.&nbsp;Enumeration Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the enumeration types in the <samp class="ph codeph">cudnn_cnn_train.so</samp>
                                 library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnFusedOps_t"><a name="cudnnFusedOps_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOps_t" name="cudnnFusedOps_t" shape="rect">6.1.3.1.&nbsp;<kbd class="ph userinput">cudnnFusedOps_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">The <samp class="ph codeph">cudnnFusedOps_t</samp> type is an enumerated type to select a
                                    			specific sequence of computations to perform in the fused operations.</span></div>
                              <div class="section" id="cudnnFusedOps_t__section_ept_nqb_mwb"><a name="cudnnFusedOps_t__section_ept_nqb_mwb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Members and Descriptions</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS = 0</samp></dt>
                                       <dd class="dd">
                                          <p class="p">On a per-channel basis, it performs these operations in this order:
                                             									<samp class="ph codeph">scale</samp>, <samp class="ph codeph">add bias</samp>,
                                             									<samp class="ph codeph">activation</samp>, <samp class="ph codeph">convolution</samp>, and
                                             								generate <samp class="ph codeph">batchnorm</samp> statistics.
                                          </p>
                                          <div class="p">
                                             <div class="fig fignone" id="cudnnFusedOps_t__fig_fng_sjc_x3b"><a name="cudnnFusedOps_t__fig_fng_sjc_x3b" shape="rect">
                                                   <!-- --></a><span class="figcap">Figure 2. Operations Per Channel For
                                                   											<samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS</samp></span><br clear="none"></br><a name="cudnnFusedOps_t__image_hng_sjc_x3b" shape="rect">
                                                   <!-- --></a><div class="imageleft">
                                                   <embed class="image imageleft" id="cudnnFusedOps_t__image_hng_sjc_x3b" src="graphics/fused-op-block-diag-opcode0.svg" width="700"></embed>
                                                </div><br clear="none"></br></div>
                                          </div>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD = 1</samp></dt>
                                       <dd class="dd">
                                          <p class="p">On a per-channel basis, it performs these operations in this order:
                                             									<samp class="ph codeph">scale</samp>, <samp class="ph codeph">add bias</samp>,
                                             									<samp class="ph codeph">activation</samp>, convolution backward weights, and
                                             								generate <samp class="ph codeph">batchnorm</samp> statistics.
                                          </p>
                                          <div class="p">
                                             <div class="fig fignone" id="cudnnFusedOps_t__fig-fused-opcode1"><a name="cudnnFusedOps_t__fig-fused-opcode1" shape="rect">
                                                   <!-- --></a></div>
                                          </div>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING = 2</samp></dt>
                                       <dd class="dd">Computes the equivalent <samp class="ph codeph">scale</samp> and <samp class="ph codeph">bias</samp>
                                          							from <samp class="ph codeph">ySum</samp>, <samp class="ph codeph">ySqSum</samp> and learned
                                          								<samp class="ph codeph">scale</samp>, <samp class="ph codeph">bias</samp>. Optionally, update
                                          							running statistics and generate saved stats.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE = 3</samp></dt>
                                       <dd class="dd">Computes the equivalent <samp class="ph codeph">scale</samp> and <samp class="ph codeph">bias</samp>
                                          							from the learned running statistics and the learned
                                          								<samp class="ph codeph">scale</samp>, <samp class="ph codeph">bias</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FUSED_CONV_SCALE_BIAS_ADD_ACTIVATION = 4</samp></dt>
                                       <dd class="dd">On a per-channel basis, performs these operations in this order:
                                          								<samp class="ph codeph">convolution</samp>, <samp class="ph codeph">scale</samp>, <samp class="ph codeph">add
                                             								bias</samp>, element-wise addition with another tensor, and
                                          								<samp class="ph codeph">activation</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ADD_ACTIVATION_GEN_BITMASK =
                                             							5</samp></dt>
                                       <dd class="dd">On a per-channel basis, performs these operations in this order:
                                          								<samp class="ph codeph">scale</samp> and <samp class="ph codeph">bias</samp> on one tensor,
                                          								<samp class="ph codeph">scale</samp> and <samp class="ph codeph">bias</samp> on a second tensor,
                                          							element-wise addition of these two tensors, and on the resulting tensor
                                          							performs <samp class="ph codeph">activation</samp> and generates activation bit
                                          							mask.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FUSED_DACTIVATION_FORK_DBATCHNORM = 6</samp></dt>
                                       <dd class="dd">On a per-channel basis, performs these operations in this order:
                                          							backward activation, fork (meaning, write out gradient for the residual
                                          							branch), and backward batch norm.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFusedOpsConstParamLabel_t"><a name="cudnnFusedOpsConstParamLabel_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsConstParamLabel_t" name="cudnnFusedOpsConstParamLabel_t" shape="rect">6.1.3.2.&nbsp;<kbd class="ph userinput">cudnnFusedOpsConstParamLabel_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">The <samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp> is an enumerated type for the
                                 		selection of the type of the <samp class="ph codeph">cudnnFusedOps</samp> descriptor. For more
                                 		information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetFusedOpsConstParamPackAttribute" title="This function sets the descriptor pointed to by the param pointer input. The type of the descriptor to be set is indicated by the enum value of the paramLabel input." shape="rect">cudnnSetFusedOpsConstParamPackAttribute()</a></samp>.  <span class="shortdesc"></span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
	CUDNN_PARAM_XDESC                          = 0,
	CUDNN_PARAM_XDATA_PLACEHOLDER              = 1,
	CUDNN_PARAM_BN_MODE                        = 2,
	CUDNN_PARAM_BN_EQSCALEBIAS_DESC            = 3,
	CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER         = 4,
	CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER          = 5,
	CUDNN_PARAM_ACTIVATION_DESC                = 6,
	CUDNN_PARAM_CONV_DESC                      = 7,
	CUDNN_PARAM_WDESC                          = 8,
	CUDNN_PARAM_WDATA_PLACEHOLDER              = 9,
	CUDNN_PARAM_DWDESC                         = 10,
	CUDNN_PARAM_DWDATA_PLACEHOLDER             = 11,
	CUDNN_PARAM_YDESC                          = 12,
	CUDNN_PARAM_YDATA_PLACEHOLDER              = 13,
	CUDNN_PARAM_DYDESC                         = 14,
	CUDNN_PARAM_DYDATA_PLACEHOLDER             = 15,
	CUDNN_PARAM_YSTATS_DESC                    = 16,
	CUDNN_PARAM_YSUM_PLACEHOLDER               = 17,
	CUDNN_PARAM_YSQSUM_PLACEHOLDER             = 18,
	CUDNN_PARAM_BN_SCALEBIAS_MEANVAR_DESC      = 19,
	CUDNN_PARAM_BN_SCALE_PLACEHOLDER           = 20,
	CUDNN_PARAM_BN_BIAS_PLACEHOLDER            = 21,
	CUDNN_PARAM_BN_SAVED_MEAN_PLACEHOLDER      = 22,
	CUDNN_PARAM_BN_SAVED_INVSTD_PLACEHOLDER    = 23,
	CUDNN_PARAM_BN_RUNNING_MEAN_PLACEHOLDER    = 24,
	CUDNN_PARAM_BN_RUNNING_VAR_PLACEHOLDER     = 25,
	CUDNN_PARAM_ZDESC                          = 26,
	CUDNN_PARAM_ZDATA_PLACEHOLDER              = 27,
	CUDNN_PARAM_BN_Z_EQSCALEBIAS_DESC          = 28,
	CUDNN_PARAM_BN_Z_EQSCALE_PLACEHOLDER       = 29,
	CUDNN_PARAM_BN_Z_EQBIAS_PLACEHOLDER        = 30,
	CUDNN_PARAM_ACTIVATION_BITMASK_DESC        = 31,
	CUDNN_PARAM_ACTIVATION_BITMASK_PLACEHOLDER = 32,
	CUDNN_PARAM_DXDESC                         = 33,
	CUDNN_PARAM_DXDATA_PLACEHOLDER             = 34,
	CUDNN_PARAM_DZDESC                         = 35,
	CUDNN_PARAM_DZDATA_PLACEHOLDER             = 36,
	CUDNN_PARAM_BN_DSCALE_PLACEHOLDER          = 37,
	CUDNN_PARAM_BN_DBIAS_PLACEHOLDER           = 38,
	} cudnnFusedOpsConstParamLabel_t;</pre><div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_dhb_2wc_x3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_dhb_2wc_x3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 31. Legend For Tables in <samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e44039" rowspan="1" colspan="1">Short Form Used</th>
                                             <th class="entry" valign="top" width="50%" id="d54e44042" rowspan="1" colspan="1">Stands For</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44039" rowspan="1" colspan="1">Setter</td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44042" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetFusedOpsConstParamPackAttribute" title="This function sets the descriptor pointed to by the param pointer input. The type of the descriptor to be set is indicated by the enum value of the paramLabel input." shape="rect">cudnnSetFusedOpsConstParamPackAttribute()</a></samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44039" rowspan="1" colspan="1">Getter</td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44042" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFusedOpsConstParamPackAttribute" title="This function retrieves the values of the descriptor pointed to by the param pointer input. The type of the descriptor is indicated by the enum value of paramLabel input." shape="rect">cudnnGetFusedOpsConstParamPackAttribute()</a></samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44039" rowspan="1" colspan="1"><samp class="ph codeph">X_PointerPlaceHolder_t</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44042" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsPointerPlaceHolder_t" title="cudnnFusedOpsPointerPlaceHolder_t is an enumerated type used to select the alignment type of the cudnnFusedOps descriptor pointer." shape="rect">cudnnFusedOpsPointerPlaceHolder_t</a></samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44039" rowspan="1" colspan="1"><samp class="ph codeph">X_</samp> prefix in the <em class="ph i">Attribute</em> column
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44042" rowspan="1" colspan="1">Stands for <samp class="ph codeph">CUDNN_PARAM_</samp> in the enumerator
                                                								name
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_lfh_gyc_x3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_lfh_gyc_x3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 32. <samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS</samp> In
                                             						<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="4" valign="top" id="d54e44155" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS</samp>
                                                								in <samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="25%" id="d54e44166" rowspan="1" colspan="1">Attribute</th>
                                             <th class="entry" valign="top" width="25%" id="d54e44169" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="25%" id="d54e44172" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="25%" id="d54e44175" rowspan="1" colspan="1">Default Value After Creation</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_XDESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be
                                                									<samp class="ph codeph">xDesc</samp>, a pointer to a previously initialized
                                                									<samp class="ph codeph">cudnnTensorDescriptor_t</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Tensor descriptor describing the size, layout, and datatype of
                                                								the <samp class="ph codeph">x</samp> (input) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_XDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">xData</samp> pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_MODE</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics.
                                                <p class="p">As of cuDNN
                                                   									7.6.0, only <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp> and
                                                   										<samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp> are
                                                   									supported, meaning, scale, bias, and statistics are all
                                                   									per-channel.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BATCHNORM_PER_ACTIVATION</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALEBIAS_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Tensor descriptor describing the size, layout, and datatype of
                                                								the batchNorm equivalent scale and bias tensors. The shapes must
                                                								match the mode specified in <samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp>. If
                                                								set to <samp class="ph codeph">NULL</samp>, both scale and bias operation will
                                                								become a NOP.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes whether batchnorm equivalent scale pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the scale operation
                                                   									becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the bias operation
                                                   									becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_ACTIVATION_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes the activation operation.
                                                <p class="p">As of cuDNN 7.6.0, only activation modes of
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp> and
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp> are supported. If
                                                   									set to <samp class="ph codeph">NULL</samp> or if the activation mode is set to
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp>, then the
                                                   									activation in the op sequence becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_CONV_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes the convolution operation.</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_WDESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Filter descriptor describing the size, layout and datatype of the
                                                									<samp class="ph codeph">w</samp> (filter) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_WDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">w</samp> (filter) tensor pointer in
                                                								the <samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_YDESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the
                                                									<samp class="ph codeph">y</samp> (output) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_YDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">y</samp> (output) tensor pointer in
                                                								the <samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_YSTATS_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">cudnnTensorDescriptor_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the sum of
                                                									<samp class="ph codeph">y</samp> and sum of <samp class="ph codeph">y</samp> square tensors.
                                                								The shapes need to match the mode specified in
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp>.
                                                <p class="p">If set to
                                                   										<samp class="ph codeph">NULL</samp>, the <samp class="ph codeph">y</samp> statistics
                                                   									generation operation will become a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_YSUM_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes whether sum of <samp class="ph codeph">y</samp> pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, the <samp class="ph codeph">y</samp>
                                                   									statistics generation operation will become a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44166" rowspan="1" colspan="1"><samp class="ph codeph">X_YSQSUM_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44169" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44172" rowspan="1" colspan="1">Describes whether sum of <samp class="ph codeph">y</samp> square pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, the <samp class="ph codeph">y</samp>
                                                   									statistics generation operation will become a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e44155 d54e44175" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFusedOpsConstParamLabel_t__ul_ltb_sdd_x3b" shape="rect">
                                       <!-- --></a><ul class="ul" id="cudnnFusedOpsConstParamLabel_t__ul_ltb_sdd_x3b">
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp> is set to
                                          							<samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> needs to be <samp class="ph codeph">NULL</samp> as
                                          						well.
                                       </li>
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED</samp> or
                                          							<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> may not be <samp class="ph codeph">NULL</samp> and
                                          						need to be at least element-aligned or 16 bytes-aligned, respectively.
                                       </li>
                                    </ul>
                                 </div>
                              </div>
                              <div class="p">As of cuDNN 7.6.0, if the conditions in <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-fwd" shape="rect">Table 33</a> are met,
                                 			then the fully fused fast path will be triggered. Otherwise, a slower partially fused
                                 			path will be triggered. 
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-fwd" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-fwd" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 33. Conditions for Fully Fused Fast Path (Forward) for
                                             						<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e44774" rowspan="1" colspan="1">Parameter</th>
                                             <th class="entry" valign="top" width="50%" id="d54e44777" rowspan="1" colspan="1">Condition</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44774" rowspan="1" colspan="1">Device compute capability</td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44777" rowspan="1" colspan="1">Need to be one of <samp class="ph codeph">7.0</samp>, <samp class="ph codeph">7.2</samp> or
                                                									<samp class="ph codeph">7.5</samp>.
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44774" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_XDESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_XDATA_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44777" rowspan="1" colspan="1">Tensor is 4 dimensional
                                                <p class="p">Datatype is
                                                   										<samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Layout is
                                                   										<samp class="ph codeph">NHWC</samp> fully packed
                                                </p>
                                                <p class="p">Alignment is
                                                   										<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                                <p class="p">Tensors
                                                   										<samp class="ph codeph">C</samp> dimension is a multiple of 8.
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44774" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_BN_EQSCALEBIAS_DESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</samp></p>
                                                <p class="p"><samp class="ph codeph">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44777" rowspan="1" colspan="1">If either one of scale and bias operation is not turned into a
                                                									NOP:
                                                <p class="p">Tensor is 4 dimensional with shape 1xCx1x1</p>
                                                <p class="p">Datatype
                                                   									is <samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Layout is fully
                                                   									packed
                                                </p>
                                                <p class="p">Alignment is
                                                   									<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44774" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_CONV_DESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_WDESC</samp></p>
                                                <p class="p"><samp class="ph codeph">CUDNN_PARAM_WDATA_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44777" rowspan="1" colspan="1">Convolution descriptors mode needs to be
                                                									<samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp>.
                                                <p class="p">Convolution
                                                   									descriptors <samp class="ph codeph">dataType</samp> needs to be
                                                   										<samp class="ph codeph">CUDNN_DATA_FLOAT</samp>.
                                                </p>
                                                <p class="p">Convolution
                                                   									descriptors <samp class="ph codeph">dilationA</samp> is
                                                   									(1,1).
                                                </p>
                                                <p class="p">Convolution descriptors group count needs to be
                                                   										<samp class="ph codeph">1</samp>.
                                                </p>
                                                <p class="p">Convolution descriptors
                                                   										<samp class="ph codeph">mathType</samp> needs to be
                                                   										<samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                                                   										<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>.
                                                </p>
                                                <p class="p">Filter
                                                   									is in <samp class="ph codeph">NHWC</samp> layout
                                                </p>
                                                <p class="p">Filters data type is
                                                   										<samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Filters K dimension
                                                   									is a multiple of 32
                                                </p>
                                                <p class="p">Filter size RxS is either 1x1 or
                                                   									3x3
                                                </p>
                                                <p class="p">If filter size RxS is 1x1, convolution descriptors
                                                   										<samp class="ph codeph">padA</samp> needs to be (0,0) and
                                                   										<samp class="ph codeph">filterStrideA</samp> needs to be
                                                   									(1,1).
                                                </p>
                                                <p class="p">Filters alignment is
                                                   										<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44774" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_YDESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_YDATA_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44777" rowspan="1" colspan="1">Tensor is 4 dimensional
                                                <p class="p">Datatype is
                                                   										<samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Layout is
                                                   										<samp class="ph codeph">NHWC</samp> fully packed
                                                </p>
                                                <p class="p">Alignment is
                                                   										<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e44774" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_YSTATS_DESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_YSUM_PLACEHOLDER</samp></p>
                                                <p class="p"><samp class="ph codeph">CUDNN_PARAM_YSQSUM_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e44777" rowspan="1" colspan="1">If the generate statistics operation is not turned into a
                                                									NOP:
                                                <p class="p">Tensor is 4 dimensional with shape 1xKx1x1</p>
                                                <p class="p">Datatype
                                                   									is <samp class="ph codeph">CUDNN_DATA_FLOAT</samp></p>
                                                <p class="p">Layout is fully
                                                   									packed
                                                </p>
                                                <p class="p">Alignment is
                                                   									<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_alv_s4s_vhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_alv_s4s_vhb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 34. <samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="4" valign="top" id="d54e45018" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="30.839002267573694%" id="d54e45029" rowspan="1" colspan="1">Attribute</th>
                                             <th class="entry" valign="top" width="22.675736961451246%" id="d54e45032" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="23.80952380952381%" id="d54e45035" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="22.675736961451246%" id="d54e45038" rowspan="1" colspan="1">Default Value After Creation</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_XDESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be <samp class="ph codeph">xDesc</samp>, a pointer
                                                								to a previously initialized
                                                								<samp class="ph codeph">cudnnTensorDescriptor_t</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the <samp class="ph codeph">x</samp>
                                                								(input) tensor
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_XDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">xData</samp> pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_MODE</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics. 
                                                <p class="p">As of cuDNN
                                                   									7.6.0, only <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp> and
                                                   										<samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp> are
                                                   									supported, meaning, scale, bias, and statistics are all
                                                   									per-channel.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BATCHNORM_PER_ACTIVATION</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALEBIAS_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the batchNorm equivalent
                                                								scale and bias tensors. The shapes must match the mode specified in
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp>. If set to
                                                									<samp class="ph codeph">NULL</samp>, both scale and bias operation will become
                                                								a NOP. 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes whether batchnorm equivalent scale pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the scale operation
                                                   									becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the bias operation
                                                   									becomes a NOP. 
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_ACTIVATION_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes the activation operation. 
                                                <p class="p">As of cuDNN 7.6.0, only the activation mode of
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp> and
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp> is supported. If
                                                   									set to <samp class="ph codeph">NULL</samp> or if the activation mode is set to
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp>, then the
                                                   									activation in the op sequence becomes a NOP. 
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_CONV_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes the convolution operation.</td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_DWDESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Filter descriptor describing the size, layout and datatype of the
                                                									<samp class="ph codeph">dw</samp> (filter gradient output) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_DWDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">dw</samp> (filter gradient output) tensor pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_DYDESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the <samp class="ph codeph">dy</samp>
                                                								(gradient input) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45018 d54e45029" rowspan="1" colspan="1"><samp class="ph codeph">X_DYDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45032" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45018 d54e45035" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">dy</samp> (gradient input) tensor pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment *. 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45018 d54e45038" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFusedOpsConstParamLabel_t__ul_tlg_fnl_y3b" shape="rect">
                                       <!-- --></a><ul class="ul" id="cudnnFusedOpsConstParamLabel_t__ul_tlg_fnl_y3b">
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> needs to be <samp class="ph codeph">NULL</samp> as
                                          						well.
                                       </li>
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED</samp> or
                                          							<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> may not be <samp class="ph codeph">NULL</samp> and
                                          						needs to be at least element-aligned or 16 bytes-aligned, respectively.
                                       </li>
                                    </ul>
                                 </div>
                                 
                                 As of cuDNN 7.6.0, if the conditions in <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-bwd" shape="rect">Table 35</a> are met,
                                 			then the fully fused fast path will be triggered. Otherwise a slower partially fused
                                 			path will be triggered. 
                                 
                                 
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-bwd" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-bwd" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 35. Conditions for Fully Fused Fast Path (Backward) for
                                             						<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" id="d54e45513" rowspan="1" colspan="1">Parameter</th>
                                             <th class="entry" valign="top" id="d54e45516" rowspan="1" colspan="1">Condition</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" headers="d54e45513" rowspan="1" colspan="1">Device compute capability</td>
                                             <td class="entry" valign="top" headers="d54e45516" rowspan="1" colspan="1">Needs to be one of <samp class="ph codeph">7.0</samp>, <samp class="ph codeph">7.2</samp> or
                                                									<samp class="ph codeph">7.5</samp>.
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" headers="d54e45513" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_XDESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_XDATA_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" headers="d54e45516" rowspan="1" colspan="1">Tensor is 4 dimensional
                                                <p class="p">Datatype is
                                                   										<samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Layout is
                                                   										<samp class="ph codeph">NHWC</samp> fully packed
                                                </p>
                                                <p class="p">Alignment is
                                                   										<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                                <p class="p">Tensors
                                                   										<samp class="ph codeph">C</samp> dimension is a multiple of 8.
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" headers="d54e45513" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_BN_EQSCALEBIAS_DESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</samp></p>
                                                <p class="p"><samp class="ph codeph">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" headers="d54e45516" rowspan="1" colspan="1">If either one of scale and bias operation is not turned into a
                                                									NOP:
                                                <p class="p">Tensor is 4 dimensional with shape 1xCx1x1</p>
                                                <p class="p">Datatype
                                                   									is <samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Layout is fully
                                                   									packed
                                                </p>
                                                <p class="p">Alignment is
                                                   									<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" headers="d54e45513" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_CONV_DESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_DWDESC</samp></p>
                                                <p class="p"><samp class="ph codeph">CUDNN_PARAM_DWDATA_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" headers="d54e45516" rowspan="1" colspan="1">Convolution descriptors mode needs to be
                                                									<samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp>.
                                                <p class="p">Convolution
                                                   									descriptors dataType needs to be
                                                   										<samp class="ph codeph">CUDNN_DATA_FLOAT</samp>.
                                                </p>
                                                <p class="p">Convolution
                                                   									descriptors <samp class="ph codeph">dilationA</samp> is
                                                   									(1,1)
                                                </p>
                                                <p class="p">Convolution descriptors group count needs to be
                                                   										<samp class="ph codeph">1</samp>.
                                                </p>
                                                <p class="p">Convolution descriptors
                                                   										<samp class="ph codeph">mathType</samp> needs to be
                                                   										<samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                                                   										<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>.
                                                </p>
                                                <p class="p">Filter
                                                   									gradient is in <samp class="ph codeph">NHWC</samp> layout
                                                </p>
                                                <p class="p">Filter
                                                   									gradients data type is
                                                   									<samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Filter gradients
                                                   										<samp class="ph codeph">K</samp> dimension is a multiple of
                                                   									32.
                                                </p>
                                                <p class="p">Filter gradient size RxS is either 1x1 or 3x3</p>
                                                <p class="p">If
                                                   									filter gradient size RxS is 1x1, convolution descriptors
                                                   										<samp class="ph codeph">padA</samp> needs to be (0,0) and
                                                   										<samp class="ph codeph">filterStrideA</samp> needs to be
                                                   									(1,1).
                                                </p>
                                                <p class="p">Filter gradients alignment is
                                                   										<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" headers="d54e45513" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_DYDESC</samp><p class="p"><samp class="ph codeph">CUDNN_PARAM_DYDATA_PLACEHOLDER</samp></p>
                                             </td>
                                             <td class="entry" valign="top" headers="d54e45516" rowspan="1" colspan="1">Tensor is 4 dimensional
                                                <p class="p">Datatype is
                                                   										<samp class="ph codeph">CUDNN_DATA_HALF</samp></p>
                                                <p class="p">Layout is
                                                   										<samp class="ph codeph">NHWC</samp> fully packed
                                                </p>
                                                <p class="p">Alignment is
                                                   										<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp></p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_vp3_ljt_vhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_vp3_ljt_vhb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 36. <samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="4" valign="top" id="d54e45728" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="30.839002267573694%" id="d54e45739" rowspan="1" colspan="1">Attribute</th>
                                             <th class="entry" valign="top" width="22.675736961451246%" id="d54e45742" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="23.80952380952381%" id="d54e45745" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="22.675736961451246%" id="d54e45748" rowspan="1" colspan="1">Default Value After Creation</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_MODE</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics. 
                                                <p class="p">As of cuDNN
                                                   									7.6.0, only <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp> and
                                                   										<samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp> are
                                                   									supported, meaning, scale, bias and statistics are all
                                                   									per-channel.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BATCHNORM_PER_ACTIVATION</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_YSTATS_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">cudnnTensorDescriptor_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the sum of
                                                									<samp class="ph codeph">y</samp> and sum of <samp class="ph codeph">y</samp> square tensors.
                                                								The shapes need to match the mode specified in
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp>. 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_YSUM_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether sum of <samp class="ph codeph">y</samp> pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_YSQSUM_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether sum of <samp class="ph codeph">y</samp> square pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SCALEBIAS_MEANVAR_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">A common tensor descriptor describing the size, layout and datatype of the batchNorm
                                                								trained scale, bias and statistics tensors. The shapes need to match
                                                								the mode specified in <samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp> (similar
                                                								to the <samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> field in the
                                                									<samp class="ph codeph">cudnnBatchNormalization*</samp> API). 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether the batchNorm trained scale pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                                <p class="p">If
                                                   									the output of <samp class="ph codeph">BN_EQSCALE</samp> is not needed, then
                                                   									this is not needed and may be <samp class="ph codeph">NULL</samp>.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_BIAS_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether the batchNorm trained bias pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                                <p class="p">If
                                                   									neither output of <samp class="ph codeph">BN_EQSCALE</samp> or
                                                   										<samp class="ph codeph">BN_EQBIAS</samp> is needed, then this is not
                                                   									needed and may be <samp class="ph codeph">NULL</samp>.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SAVED_MEAN_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether the batchNorm saved mean pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p"> If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the computation for
                                                   									this output becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SAVED_INVSTD_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether the batchNorm saved inverse standard deviation pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the computation for
                                                   									this output becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_MEAN_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether the batchNorm running mean pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the computation for
                                                   									this output becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_VAR_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether the batchNorm running variance pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the computation for
                                                   									this output becomes a NOP. 
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALEBIAS_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the batchNorm equivalent
                                                								scale and bias tensors. The shapes need to match the mode specified
                                                								in <samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp>. 
                                                <p class="p">If neither output of
                                                   										<samp class="ph codeph">BN_EQSCALE</samp> or <samp class="ph codeph">BN_EQBIAS</samp> is
                                                   									needed, then this is not needed and may be
                                                   									<samp class="ph codeph">NULL</samp>.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether batchnorm equivalent scale pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p"> If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the computation for
                                                   									this output becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e45728 d54e45739" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45742" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e45728 d54e45745" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the computation for
                                                   									this output becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e45728 d54e45748" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_h3w_lnt_vhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_h3w_lnt_vhb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 37. <samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="4" valign="top" id="d54e46315" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="30.839002267573694%" id="d54e46326" rowspan="1" colspan="1">Attribute</th>
                                             <th class="entry" valign="top" width="22.675736961451246%" id="d54e46329" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="23.80952380952381%" id="d54e46332" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="22.675736961451246%" id="d54e46335" rowspan="1" colspan="1">Default Value After Creation</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_MODE</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics. 
                                                <p class="p">As of cuDNN
                                                   									7.6.0, only <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp> and
                                                   										<samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp> are
                                                   									supported, meaning, scale, bias and statistics are all
                                                   									per-channel.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BATCHNORM_PER_ACTIVATION</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SCALEBIAS_MEANVAR_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1"> A common tensor descriptor describing the size, layout and datatype of the batchNorm
                                                								trained scale, bias and statistics tensors. The shapes need to match
                                                								the mode specified in <samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp> (similar
                                                								to the <samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> field in the
                                                									<samp class="ph codeph">cudnnBatchNormalization*</samp> API). 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1"> Describes whether the batchNorm trained scale pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_BIAS_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1"> Describes whether the batchNorm trained bias pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.  
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_MEAN_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1">Describes whether the batchNorm running mean pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.  
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_VAR_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1">Describes whether the batchNorm running variance pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALEBIAS_DESC</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the batchNorm equivalent
                                                								scale and bias tensors. The shapes need to match the mode specified
                                                								in <samp class="ph codeph">CUDNN_PARAM_BN_MODE</samp>. 
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1">Describes whether batchnorm equivalent scale pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>. 
                                                <p class="p">
                                                   									If set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the computation
                                                   									for this output becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.839002267573694%" headers="d54e46315 d54e46326" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46329" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="23.80952380952381%" headers="d54e46315 d54e46332" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                									
                                                <p class="p">If set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the
                                                   									computation for this output becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="22.675736961451246%" headers="d54e46315 d54e46335" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_t5k_j3p_5lb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_t5k_j3p_5lb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 38. <samp class="ph codeph">CUDNN_FUSED_CONVOLUTION_SCALE_BIAS_ADD_RELU</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="4" valign="top" id="d54e46677" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_CONVOLUTION_SCALE_BIAS_ADD_RELU</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp><p class="p">This operation
                                                   									performs the following computation, where <samp class="ph codeph">*</samp>
                                                   									denotes convolution operator: <samp class="ph codeph">y=1(w*x)+2
                                                      									z+b</samp></p>
                                             </th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="25%" id="d54e46695" rowspan="1" colspan="1">Attribute</th>
                                             <th class="entry" valign="top" width="25%" id="d54e46698" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="25%" id="d54e46701" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="25%" id="d54e46704" rowspan="1" colspan="1">Default Value After Creation</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_XDESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be
                                                									<samp class="ph codeph">xDesc</samp>, a pointer to a previously initialized
                                                									<samp class="ph codeph">cudnnTensorDescriptor_t</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the
                                                									<samp class="ph codeph">x</samp> (input) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_XDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">xData</samp> pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_CONV_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes the convolution operation.</td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_WDESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Filter descriptor describing the size, layout and datatype of the
                                                									<samp class="ph codeph">w</samp> (filter) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_WDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">w</samp> (filter) tensor pointer in
                                                								the <samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment
                                                								<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALEBIAS_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the <sub class="ph sub">1</sub> scale
                                                								and bias tensors. The tensor should have shape (1,K,1,1), K is the
                                                								number of output features.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes whether batchnorm equivalent scale or <sub class="ph sub">1</sub> tensor pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then <sub class="ph sub">1</sub>
                                                   									scaling becomes an NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_ZDESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be <samp class="ph codeph">xDesc</samp>, a pointer
                                                								to a previously initialized
                                                								<samp class="ph codeph">cudnnTensorDescriptor_t</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the <samp class="ph codeph">z</samp>
                                                									tensor.
                                                <p class="p">If unset, then <samp class="ph codeph">z</samp> scale-add term
                                                   									becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_ZDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes whether <samp class="ph codeph">z</samp> tensor pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then <samp class="ph codeph">z</samp>
                                                   									scale-add term becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_BN_Z_EQSCALEBIAS_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the <sub class="ph sub">2</sub>
                                                									tensor.
                                                <p class="p">If set to <samp class="ph codeph">NULL</samp> then scaling for input
                                                   										<samp class="ph codeph">z</samp> becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULLPTR</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PARAM_BN_Z_EQSCALE_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes whether batchnorm z-equivalent scaling pointer in the
                                                									<samp class="ph codeph">VariantParamPack</samp> will be <samp class="ph codeph">NULL</samp>,
                                                								or if not, user promised pointer alignment <samp class="ph codeph">*</samp>.
                                                <p class="p">If
                                                   									set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the scaling for
                                                   									input z becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_ACTIVATION_DESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to a previously
                                                								initialized <samp class="ph codeph"><a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t*</a></samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes the activation operation.
                                                <p class="p">As of 7.6.0, only
                                                   									activation modes of <samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp> and
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp> are supported. If
                                                   									set to <samp class="ph codeph">NULL</samp> or if the activation mode is set to
                                                   										<samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp>, then the
                                                   									activation in the op sequence becomes a NOP.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_YDESC</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the <samp class="ph codeph">*param</samp> should be a pointer to
                                                								a previously initialized
                                                								<samp class="ph codeph">cudnnTensorDescriptor_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the
                                                									<samp class="ph codeph">y</samp> (output) tensor.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46695" rowspan="1" colspan="1"><samp class="ph codeph">X_YDATA_PLACEHOLDER</samp></td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46698" rowspan="1" colspan="1">In the setter, the<samp class="ph codeph"> *param </samp>should be a pointer to
                                                								a previously initialized<samp class="ph codeph">
                                                   								X_PointerPlaceHolder_t*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46701" rowspan="1" colspan="1">Describes whether<samp class="ph codeph"> y </samp>(output) tensor pointer in
                                                									the<samp class="ph codeph"> VariantParamPack </samp>will be
                                                									<samp class="ph codeph">NULL</samp>, or if not, user promised pointer
                                                									alignment<samp class="ph codeph"> *</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="25%" headers="d54e46677 d54e46704" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFusedOpsPointerPlaceHolder_t"><a name="cudnnFusedOpsPointerPlaceHolder_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsPointerPlaceHolder_t" name="cudnnFusedOpsPointerPlaceHolder_t" shape="rect">6.1.3.3.&nbsp;<kbd class="ph userinput">cudnnFusedOpsPointerPlaceHolder_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnFusedOpsPointerPlaceHolder_t</samp> is an enumerated type used to
                                    			select the alignment type of the <samp class="ph codeph">cudnnFusedOps</samp> descriptor
                                    			pointer.</span></div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsPointerPlaceHolder_t__table_jhf_p5l_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsPointerPlaceHolder_t__table_jhf_p5l_y3b" class="table" frame="border" border="1" rules="all">
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e47232" rowspan="1" colspan="1">Member</th>
                                             <th class="entry" valign="top" width="50%" id="d54e47235" rowspan="1" colspan="1">Description</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e47232" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_NULL = 0</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e47235" rowspan="1" colspan="1">Indicates that the pointer to the tensor in the
                                                									<samp class="ph codeph">variantPack</samp> will be
                                                								<samp class="ph codeph">NULL</samp>.
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e47232" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED = 1</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e47235" rowspan="1" colspan="1">Indicates that the pointer to the tensor in the
                                                									<samp class="ph codeph">variantPack</samp> will not be <samp class="ph codeph">NULL</samp>,
                                                								and will have element alignment.
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e47232" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_PTR_16B_ALIGNED = 2</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e47235" rowspan="1" colspan="1">Indicates that the pointer to the tensor in the
                                                									<samp class="ph codeph">variantPack</samp> will not be <samp class="ph codeph">NULL</samp>,
                                                								and will have 16 byte alignment.
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFusedOpsVariantParamLabel_t"><a name="cudnnFusedOpsVariantParamLabel_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsVariantParamLabel_t" name="cudnnFusedOpsVariantParamLabel_t" shape="rect">6.1.3.4.&nbsp;<kbd class="ph userinput">cudnnFusedOpsVariantParamLabel_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">The <samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp> is an enumerated type that
                                    			is used to set the buffer pointers. These buffer pointers can be changed in each
                                    			iteration. </span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
	CUDNN_PTR_XDATA                              = 0,
	CUDNN_PTR_BN_EQSCALE                         = 1,
	CUDNN_PTR_BN_EQBIAS                          = 2,
	CUDNN_PTR_WDATA                              = 3,
	CUDNN_PTR_DWDATA                             = 4,
	CUDNN_PTR_YDATA                              = 5,
	CUDNN_PTR_DYDATA                             = 6,
	CUDNN_PTR_YSUM                               = 7,
	CUDNN_PTR_YSQSUM                             = 8,
	CUDNN_PTR_WORKSPACE                          = 9,
	CUDNN_PTR_BN_SCALE                           = 10,
	CUDNN_PTR_BN_BIAS                            = 11,
	CUDNN_PTR_BN_SAVED_MEAN                      = 12,
	CUDNN_PTR_BN_SAVED_INVSTD                    = 13,
	CUDNN_PTR_BN_RUNNING_MEAN                    = 14,
	CUDNN_PTR_BN_RUNNING_VAR                     = 15,
	CUDNN_PTR_ZDATA                              = 16,
	CUDNN_PTR_BN_Z_EQSCALE                       = 17,
	CUDNN_PTR_BN_Z_EQBIAS                        = 18,
	CUDNN_PTR_ACTIVATION_BITMASK                 = 19,
	CUDNN_PTR_DXDATA                             = 20,
	CUDNN_PTR_DZDATA                             = 21,
	CUDNN_PTR_BN_DSCALE                          = 22,
	CUDNN_PTR_BN_DBIAS                           = 23,
	CUDNN_SCALAR_SIZE_T_WORKSPACE_SIZE_IN_BYTES  = 100,
	CUDNN_SCALAR_INT64_T_BN_ACCUMULATION_COUNT   = 101,
	CUDNN_SCALAR_DOUBLE_BN_EXP_AVG_FACTOR        = 102,
	CUDNN_SCALAR_DOUBLE_BN_EPSILON               = 103,
	} cudnnFusedOpsVariantParamLabel_t;</pre><div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_fms_fvl_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_fms_fvl_y3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 39. Legend For Tables in <samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e47335" rowspan="1" colspan="1">Short-Form Used</th>
                                             <th class="entry" valign="top" width="50%" id="d54e47338" rowspan="1" colspan="1">Stands For</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e47335" rowspan="1" colspan="1">Setter</td>
                                             <td class="entry" valign="top" width="50%" headers="d54e47338" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetFusedOpsVariantParamPackAttribute" title="This function sets the variable parameter pack descriptor." shape="rect">cudnnSetFusedOpsVariantParamPackAttribute()</a></samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e47335" rowspan="1" colspan="1">Getter</td>
                                             <td class="entry" valign="top" width="50%" headers="d54e47338" rowspan="1" colspan="1"><samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFusedOpsVariantParamPackAttribute" title="This function retrieves the settings of the variable parameter pack descriptor." shape="rect">cudnnGetFusedOpsVariantParamPackAttribute()</a></samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e47335" rowspan="1" colspan="1"><samp class="ph codeph">X_</samp> prefix in the <strong class="ph b">Attribute key</strong>
                                                								column
                                             </td>
                                             <td class="entry" valign="top" width="50%" headers="d54e47338" rowspan="1" colspan="1">Stands for <samp class="ph codeph">CUDNN_PTR_</samp> or
                                                									<samp class="ph codeph">CUDNN_SCALAR_</samp> in the enumerator name.
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_wbr_fvt_vhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_wbr_fvt_vhb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 40. <samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e47424" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS</samp>
                                                								in <samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="27.473958333333332%" id="d54e47435" rowspan="1" colspan="1">Attribute key</th>
                                             <th class="entry" valign="top" width="13.020833333333334%" id="d54e47438" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="13.020833333333334%" id="d54e47441" rowspan="1" colspan="1">I/O Type</th>
                                             <th class="entry" valign="top" width="33.46354166666667%" id="d54e47444" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="13.020833333333334%" id="d54e47447" rowspan="1" colspan="1">Default Value</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_XDATA</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">x</samp> (input) tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_XDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_WDATA</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">w</samp> (filter) tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_WDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_YDATA</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">y</samp> (output) tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_YDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_YSUM</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_YSUM_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_YSQSUM</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set <samp class="ph codeph">CUDNN_PARAM_YSQSUM_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_WORKSPACE</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be <samp class="ph codeph">NULL</samp> if the
                                                								workspace size requested is <samp class="ph codeph">0</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="27.473958333333332%" headers="d54e47424 d54e47435" rowspan="1" colspan="1"><samp class="ph codeph">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47438" rowspan="1" colspan="1"><samp class="ph codeph">size_t *</samp></td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47441" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.46354166666667%" headers="d54e47424 d54e47444" rowspan="1" colspan="1">Pointer to a <samp class="ph codeph">size_t</samp> value in host memory describing the user
                                                								allocated workspace size in bytes. The amount needs to be equal or
                                                								larger than the amount requested in
                                                									<samp class="ph codeph">cudnnMakeFusedOpsPlan</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="13.020833333333334%" headers="d54e47424 d54e47447" rowspan="1" colspan="1"><samp class="ph codeph">0</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFusedOpsVariantParamLabel_t__ul_ers_4yl_y3b" shape="rect">
                                       <!-- --></a><ul class="ul" id="cudnnFusedOpsVariantParamLabel_t__ul_ers_4yl_y3b">
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> needs to be <samp class="ph codeph">NULL</samp> as
                                          						well
                                       </li>
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED</samp> or
                                          							<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> may not be <samp class="ph codeph">NULL</samp> and
                                          						needs to be at least element-aligned or 16 bytes-aligned, respectively.
                                       </li>
                                    </ul>
                                 </div>
                                 <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_fdr_dwt_vhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_fdr_dwt_vhb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 41. <samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e47783" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="34.592680047225514%" id="d54e47794" rowspan="1" colspan="1">Attribute key</th>
                                             <th class="entry" valign="top" width="11.806375442739082%" id="d54e47797" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="11.806375442739082%" id="d54e47800" rowspan="1" colspan="1">I/O Type</th>
                                             <th class="entry" valign="top" width="29.988193624557262%" id="d54e47803" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="11.806375442739082%" id="d54e47806" rowspan="1" colspan="1">Default Value</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="34.592680047225514%" headers="d54e47783 d54e47794" rowspan="1" colspan="1"><samp class="ph codeph">X_XDATA</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47797" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47800" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="29.988193624557262%" headers="d54e47783 d54e47803" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">x</samp> (input) tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_XDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47806" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="34.592680047225514%" headers="d54e47783 d54e47794" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47797" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47800" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="29.988193624557262%" headers="d54e47783 d54e47803" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47806" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="34.592680047225514%" headers="d54e47783 d54e47794" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47797" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47800" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="29.988193624557262%" headers="d54e47783 d54e47803" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47806" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="34.592680047225514%" headers="d54e47783 d54e47794" rowspan="1" colspan="1"><samp class="ph codeph">X_DWDATA</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47797" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47800" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="29.988193624557262%" headers="d54e47783 d54e47803" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">dw</samp> (filter gradient output) tensor on device, need to
                                                								agree with previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_WDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47806" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="34.592680047225514%" headers="d54e47783 d54e47794" rowspan="1" colspan="1"><samp class="ph codeph">X_DYDATA</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47797" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47800" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="29.988193624557262%" headers="d54e47783 d54e47803" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">dy</samp> (gradient input) tensor on device, need to agree with
                                                								previously set <samp class="ph codeph">CUDNN_PARAM_YDATA_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47806" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="34.592680047225514%" headers="d54e47783 d54e47794" rowspan="1" colspan="1"><samp class="ph codeph">X_WORKSPACE</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47797" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47800" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="29.988193624557262%" headers="d54e47783 d54e47803" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be <samp class="ph codeph">NULL</samp> if the
                                                								workspace size requested is <samp class="ph codeph">0</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47806" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="34.592680047225514%" headers="d54e47783 d54e47794" rowspan="1" colspan="1"><samp class="ph codeph">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47797" rowspan="1" colspan="1"><samp class="ph codeph">size_t *</samp></td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47800" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="29.988193624557262%" headers="d54e47783 d54e47803" rowspan="1" colspan="1">Pointer to a <samp class="ph codeph">size_t</samp> value in host memory describing the user
                                                								allocated workspace size in bytes. The amount needs to be equal or
                                                								larger than the amount requested in
                                                									<samp class="ph codeph">cudnnMakeFusedOpsPlan</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.806375442739082%" headers="d54e47783 d54e47806" rowspan="1" colspan="1"><samp class="ph codeph">0</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFusedOpsVariantParamLabel_t__ul_k15_4zl_y3b" shape="rect">
                                       <!-- --></a><ul class="ul" id="cudnnFusedOpsVariantParamLabel_t__ul_k15_4zl_y3b">
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> needs to be <samp class="ph codeph">NULL</samp> as
                                          						well.
                                       </li>
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED</samp> or
                                          							<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> may not be <samp class="ph codeph">NULL</samp> and
                                          						needs to be at least element-aligned or 16 bytes-aligned, respectively.
                                       </li>
                                    </ul>
                                 </div>
                                 <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_jtz_dxt_vhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_jtz_dxt_vhb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 42. <samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e48082" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="33.84785005512679%" id="d54e48093" rowspan="1" colspan="1">Attribute key</th>
                                             <th class="entry" valign="top" width="11.025358324145534%" id="d54e48096" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="11.025358324145534%" id="d54e48099" rowspan="1" colspan="1">I/O Type</th>
                                             <th class="entry" valign="top" width="33.0760749724366%" id="d54e48102" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="11.025358324145534%" id="d54e48105" rowspan="1" colspan="1">Default Value</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_YSUM</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_YSUM_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_YSQSUM</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set <samp class="ph codeph">CUDNN_PARAM_YSQSUM_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SCALE</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set <samp class="ph codeph">CUDNN_PARAM_BN_SCALE_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_BIAS</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set <samp class="ph codeph">CUDNN_PARAM_BN_BIAS_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SAVED_MEAN</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_SAVED_MEAN_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SAVED_INVSTD</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_SAVED_INVSTD_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_MEAN</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input/output</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_RUNNING_MEAN_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_VAR</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input/output</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_RUNNING_VAR_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_INT64_T_BN_ACCUMULATION_COUNT</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">int64_t *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to a scalar value in <samp class="ph codeph">int64_t</samp> on host memory.
                                                <p class="p">This value
                                                   									should describe the number of tensor elements accumulated in the
                                                   									sum of <samp class="ph codeph">y</samp> and sum of <samp class="ph codeph">y</samp> square
                                                   									tensors.
                                                </p>
                                                <p class="p">For example, in the single GPU use case, if the
                                                   									mode is <samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp> or
                                                   										<samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp>, the
                                                   									value should be equal to N*H*W of the tensor from which the
                                                   									statistics are calculated.
                                                </p>
                                                <p class="p">In multi-GPU use case, if
                                                   									all-reduce has been performed on the sum of <samp class="ph codeph">y</samp>
                                                   									and sum of <samp class="ph codeph">y</samp> square tensors, this value should
                                                   									be the sum of the single GPU accumulation count on each of the
                                                   									GPUs.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">0</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE_BN_EXP_AVG_FACTOR</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">double *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to a scalar value in double on host memory.
                                                <p class="p">Factor used in the moving
                                                   									average computation. See
                                                   										<samp class="ph codeph">exponentialAverageFactor</samp> in
                                                   										<samp class="ph codeph">cudnnBatchNormalization*</samp> APIs.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE_BN_EPSILON</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">double *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to a scalar value in double on host memory.
                                                <p class="p">A conditioning constant used in
                                                   									the batch normalization formula. Its value should be equal to or
                                                   									greater than the value defined for
                                                   										<samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp> in
                                                   										<samp class="ph codeph">cudnn.h</samp>.
                                                </p>
                                                <p class="p">See
                                                   										<samp class="ph codeph">exponentialAverageFactor</samp> in
                                                   										<samp class="ph codeph">cudnnBatchNormalization*</samp> APIs.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_WORKSPACE</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be <samp class="ph codeph">NULL</samp> if the
                                                								workspace size requested is <samp class="ph codeph">0</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.84785005512679%" headers="d54e48082 d54e48093" rowspan="1" colspan="1"><samp class="ph codeph">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48096" rowspan="1" colspan="1"><samp class="ph codeph">size_t *</samp></td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48099" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.0760749724366%" headers="d54e48082 d54e48102" rowspan="1" colspan="1">Pointer to a <samp class="ph codeph">size_t</samp> value in host memory describing the user
                                                								allocated workspace size in bytes. The amount needs to be equal or
                                                								larger than the amount requested in
                                                									<samp class="ph codeph">cudnnMakeFusedOpsPlan</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.025358324145534%" headers="d54e48082 d54e48105" rowspan="1" colspan="1"><samp class="ph codeph">0</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFusedOpsVariantParamLabel_t__ul_rcs_phm_y3b" shape="rect">
                                       <!-- --></a><ul class="ul" id="cudnnFusedOpsVariantParamLabel_t__ul_rcs_phm_y3b">
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp> is set to
                                          							<samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> needs to be <samp class="ph codeph">NULL</samp> as
                                          						well.
                                       </li>
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED</samp> or
                                          							<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> may not be <samp class="ph codeph">NULL</samp> and
                                          						needs to be at least element-aligned or 16 bytes-aligned, respectively.
                                       </li>
                                    </ul>
                                 </div>
                                 <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_b3t_xxt_vhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_b3t_xxt_vhb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 43. <samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e48647" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="32.88439955106622%" id="d54e48658" rowspan="1" colspan="1">Attribute key</th>
                                             <th class="entry" valign="top" width="11.22334455667789%" id="d54e48661" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="11.22334455667789%" id="d54e48664" rowspan="1" colspan="1">I/O Type</th>
                                             <th class="entry" valign="top" width="33.44556677890011%" id="d54e48667" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="11.22334455667789%" id="d54e48670" rowspan="1" colspan="1">Default Value</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_SCALE</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set <samp class="ph codeph">CUDNN_PARAM_BN_SCALE_PLACEHOLDER
                                                   								</samp>attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_BIAS</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set <samp class="ph codeph">CUDNN_PARAM_BN_BIAS_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_MEAN</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">input/output</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_RUNNING_MEAN_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_RUNNING_VAR</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">input/output</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to sum of <samp class="ph codeph">y</samp> square tensor on device, need to agree with
                                                								previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_RUNNING_VAR_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQBIAS</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to agree with previously
                                                								set <samp class="ph codeph">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_DOUBLE_BN_EPSILON</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">double *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to a scalar value in double on host memory.
                                                <p class="p">A conditioning constant used in
                                                   									the batch normalization formula. Its value should be equal to or
                                                   									greater than the value defined for
                                                   										<samp class="ph codeph">CUDNN_BN_MIN_EPSILON</samp> in
                                                   										<samp class="ph codeph">cudnn.h</samp>.
                                                </p>
                                                <p class="p">See
                                                   										<samp class="ph codeph">exponentialAverageFactor</samp> in
                                                   										<samp class="ph codeph">cudnnBatchNormalization*</samp> APIs.
                                                </p>
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">0.0</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_WORKSPACE</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be <samp class="ph codeph">NULL</samp> if the
                                                								workspace size requested is <samp class="ph codeph">0</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="32.88439955106622%" headers="d54e48647 d54e48658" rowspan="1" colspan="1"><samp class="ph codeph">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48661" rowspan="1" colspan="1"><samp class="ph codeph">size_t *</samp></td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48664" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="33.44556677890011%" headers="d54e48647 d54e48667" rowspan="1" colspan="1">Pointer to a <samp class="ph codeph">size_t</samp> value in host memory describing the user
                                                								allocated workspace size in bytes. The amount needs to be equal or
                                                								larger than the amount requested in
                                                									<samp class="ph codeph">cudnnMakeFusedOpsPlan</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="11.22334455667789%" headers="d54e48647 d54e48670" rowspan="1" colspan="1"><samp class="ph codeph">0</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFusedOpsVariantParamLabel_t__ul_gpp_bmm_y3b" shape="rect">
                                       <!-- --></a><ul class="ul" id="cudnnFusedOpsVariantParamLabel_t__ul_gpp_bmm_y3b">
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> needs to be <samp class="ph codeph">NULL</samp> as
                                          						well.
                                       </li>
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED</samp> or
                                          							<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> may not be <samp class="ph codeph">NULL</samp> and
                                          						needs to be at least element-aligned or 16 bytes-aligned, respectively.
                                       </li>
                                    </ul>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_t5k_j3p_5lb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_t5k_j3p_5lb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 44. <samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE</samp> in
                                             						<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e49017" rowspan="1">For the attribute
                                                									<samp class="ph codeph">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE</samp> in
                                                									<samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e49028" rowspan="1" colspan="1">Attribute key</th>
                                             <th class="entry" valign="top" width="20%" id="d54e49031" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                             <th class="entry" valign="top" width="20%" id="d54e49034" rowspan="1" colspan="1">I/O Type</th>
                                             <th class="entry" valign="top" width="20%" id="d54e49037" rowspan="1" colspan="1">Description</th>
                                             <th class="entry" valign="top" width="20%" id="d54e49040" rowspan="1" colspan="1">Default Value</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_XDATA</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">x</samp> (image) tensor on device, need to
                                                								agree with previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_XDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_WDATA</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">w</samp> (filter) tensor on device, need to
                                                								agree with previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_WDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_EQSCALE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">alpha1</samp> or batchnorm equivalent scale
                                                								tensor on device; need to agree with previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_ZDATA</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">z</samp> ( tensor on device; Need to agree
                                                								with previously set <samp class="ph codeph">CUDNN_PARAM_YDATA_PLACEHOLDER</samp>
                                                								attribute <samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_Z_EQSCALE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">alpha2</samp>, equivalent scale tensor for
                                                									<samp class="ph codeph">z</samp>; Need to agree with previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_Z_EQSCALE_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_BN_Z_EQBIAS</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to
                                                								agree with previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_BN_Z_EQBIAS_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_YDATA</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">output</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to <samp class="ph codeph">y</samp> (output) tensor on device, need to
                                                								agree with previously set
                                                									<samp class="ph codeph">CUDNN_PARAM_YDATA_PLACEHOLDER</samp> attribute
                                                									<samp class="ph codeph">*</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_WORKSPACE</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be
                                                									<samp class="ph codeph">NULL</samp> if the workspace size requested is
                                                									<samp class="ph codeph">0</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">NULL</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49028" rowspan="1" colspan="1"><samp class="ph codeph">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49031" rowspan="1" colspan="1"><samp class="ph codeph">size_t *</samp></td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49034" rowspan="1" colspan="1">input</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49037" rowspan="1" colspan="1">Pointer to a <samp class="ph codeph">size_t</samp> value in host memory
                                                								describing the user allocated workspace size in bytes. The amount
                                                								needs to be equal or larger than the amount requested in
                                                									<samp class="ph codeph">cudnnMakeFusedOpsPlan</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="20%" headers="d54e49017 d54e49040" rowspan="1" colspan="1"><samp class="ph codeph">0</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFusedOpsVariantParamLabel_t__ul_ktv_blp_5lb" shape="rect">
                                       <!-- --></a><ul class="ul" id="cudnnFusedOpsVariantParamLabel_t__ul_ktv_blp_5lb">
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_NULL</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> needs to be <samp class="ph codeph">NULL</samp> as
                                          						well.
                                       </li>
                                       <li class="li">If the corresponding pointer placeholder in <samp class="ph codeph">ConstParamPack</samp>
                                          						is set to <samp class="ph codeph">CUDNN_PTR_ELEM_ALIGNED</samp> or
                                          							<samp class="ph codeph">CUDNN_PTR_16B_ALIGNED</samp>, then the device pointer in the
                                          							<samp class="ph codeph">VariantParamPack</samp> may not be <samp class="ph codeph">NULL</samp> and
                                          						needs to be at least element-aligned or 16 bytes-aligned, respectively.
                                       </li>
                                    </ul>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnn-cnn-train-so-api"><a name="cudnn-cnn-train-so-api" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-train-so-api" name="cudnn-cnn-train-so-api" shape="rect">6.2.&nbsp;API Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the API functions in the <samp class="ph codeph">cudnn_cnn_train.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnnCnnTrainVersionCheck"><a name="cudnnCnnTrainVersionCheck" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCnnTrainVersionCheck" name="cudnnCnnTrainVersionCheck" shape="rect">6.2.1.&nbsp;<kbd class="ph userinput">cudnnCnnTrainVersionCheck()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function checks whether the version of the <samp class="ph codeph">CnnTrain</samp> subset
                                 of the library is consistent with the other sub-libraries.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCnnTrainVersionCheck(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)</pre><div class="section" id="cudnnCnnTrainVersionCheck__section_zpy_xzc_z3b"><a name="cudnnCnnTrainVersionCheck__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The version is consistent with other sub-libraries.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_VERSION_MISMATCH</samp></dt>
                                    <dd class="dd">The version of <samp class="ph codeph">CnnTrain</samp> is not consistent with other
                                       sub-libraries. Users should check the installation and make sure all
                                       sub-component versions are consistent.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnConvolutionBackwardBias"><a name="cudnnConvolutionBackwardBias" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBackwardBias" name="cudnnConvolutionBackwardBias" shape="rect">6.2.2.&nbsp;<kbd class="ph userinput">cudnnConvolutionBackwardBias()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes the convolution function gradient with respect to the
                                 bias, which is the sum of every element belonging to the same feature map across all of
                                 the images of the input tensor. Therefore, the number of elements produced is equal to
                                 the number of features maps of the input tensor. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBackwardBias(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dbDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *db)</pre><div class="section" id="cudnnConvolutionBackwardBias__section_nfr_gb5_y3b"><a name="cudnnConvolutionBackwardBias__section_nfr_gb5_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dbDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">db</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">dbDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBackwardBias__section_z4l_hb5_y3b"><a name="cudnnConvolutionBackwardBias__section_z4l_hb5_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The operation was launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnConvolutionBackwardBias__ul_o4f_c3b_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardBias__ul_o4f_c3b_s1b">
                                          <li class="li">One of the parameters <samp class="ph codeph">n</samp>,
                                             <samp class="ph codeph">height</samp>, or <samp class="ph codeph">width</samp> of the
                                             output tensor is not 1.
                                          </li>
                                          <li class="li">The numbers of feature maps of the input tensor and output
                                             tensor differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors is
                                             different.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnConvolutionBackwardFilter"><a name="cudnnConvolutionBackwardFilter" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBackwardFilter" name="cudnnConvolutionBackwardFilter" shape="rect">6.2.3.&nbsp;<kbd class="ph userinput">cudnnConvolutionBackwardFilter()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function computes the convolution weight (filter) gradient of the tensor
                              <samp class="ph codeph">dy</samp>, where <samp class="ph codeph">y</samp> is the output of the forward convolution
                              in <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionForward" title="This function executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively." shape="rect">cudnnConvolutionForward()</a></samp>. It uses the specified
                              <samp class="ph codeph">algo</samp>, and returns the results in the output tensor <samp class="ph codeph">dw</samp>.
                              Scaling factors <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> can be used to scale the
                              computed result or accumulate with the current <samp class="ph codeph">dw</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBackwardFilter(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionBwdFilterAlgo_t     algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *dw)</pre><div class="section" id="cudnnConvolutionBackwardFilter__section_nks_qbv_y3b"><a name="cudnnConvolutionBackwardFilter__section_nks_qbv_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to
                                          blend the computation result with prior value in the output layer as
                                          follows:
                                          <pre xml:space="preserve">dstValue = alpha[0]*result + beta[0]*priorDstValue</pre></div>
                                       <p class="p">For more information, refer to <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#scaling-parameters" target="_blank" shape="rect">Scaling Parameters</a>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the
                                       backpropagation gradient tensor descriptor <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies which convolution algorithm
                                       should be used to compute the results. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBwdFilterAlgo_t" title="cudnnConvolutionBwdFilterAlgo_t is an enumerated type that exposes the different algorithms available to execute the backward filter convolution operation." shape="rect">cudnnConvolutionBwdFilterAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to be
                                       able to execute the specified algorithm. If no workspace is needed for a
                                       particular algorithm, that pointer can be <samp class="ph codeph">NIL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workSpace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter gradient
                                       descriptor. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dw</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       filter gradient descriptor <samp class="ph codeph">dwDesc</samp> that carries the
                                       result.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBackwardFilter__section_dky_lcv_y3b"><a name="cudnnConvolutionBackwardFilter__section_dky_lcv_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported configurations</h4>
                              <p class="p">This function supports the following combinations of data types for
                                 <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">convDesc</samp>, and
                                 <samp class="ph codeph">dwDesc</samp>. 
                              </p>
                              <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_atf_hjb_s1b" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_atf_hjb_s1b" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 45. Supported Configurations for
                                          <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp></span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="30.087527352297595%" id="d54e49957" rowspan="1" colspan="1">Data Type Configurations</th>
                                          <th class="entry" valign="top" width="34.9562363238512%" id="d54e49960" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, and
                                             <samp class="ph codeph">dwDesc</samp> Data Type
                                          </th>
                                          <th class="entry" valign="top" width="34.9562363238512%" id="d54e49971" rowspan="1" colspan="1"><samp class="ph codeph">convDesc</samp> Data Type
                                          </th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="30.087527352297595%" headers="d54e49957" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp> (only supported on
                                             architectures with true FP16 support, meaning, compute capability
                                             5.3 and later) 
                                          </td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49960" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49971" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="30.087527352297595%" headers="d54e49957" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49960" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49971" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="30.087527352297595%" headers="d54e49957" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49960" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_BFLOAT16</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49971" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="30.087527352297595%" headers="d54e49957" rowspan="1" colspan="1"><samp class="ph codeph">FLOAT_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49960" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49971" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="30.087527352297595%" headers="d54e49957" rowspan="1" colspan="1"><samp class="ph codeph">DOUBLE_CONFIG</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49960" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                          <td class="entry" valign="top" width="34.9562363238512%" headers="d54e49971" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBackwardFilter__section_xm1_lcv_y3b"><a name="cudnnConvolutionBackwardFilter__section_xm1_lcv_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported algorithms</h4>
                              <div class="note note"><span class="notetitle">Note:</span> Specifying a separate algorithm can cause changes in performance, support and
                                 computation determinism. Refer to the following table for an exhaustive list of
                                 algorithm options and their respective supported parameters and deterministic
                                 behavior.
                              </div>
                              <p class="p">The table below shows the list of the supported 2D and 3D convolutions. The 2D
                                 convolutions are described first, followed by the 3D convolutions. 
                              </p>
                              <div class="p">For the following terms, the short-form versions shown in the parentheses are used in
                                 the table below, for brevity: <a name="cudnnConvolutionBackwardFilter__ul_ly4_dgv_y3b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_ly4_dgv_y3b">
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0 <strong class="ph b">(_ALGO_0)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1 <strong class="ph b">(_ALGO_1)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3 <strong class="ph b">(_ALGO_3)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT <strong class="ph b">(_FFT)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT_TILING
                                          <strong class="ph b">(_FFT_TILING)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED
                                          <strong class="ph b">(_WINOGRAD_NONFUSED)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NCHW <strong class="ph b">(_NCHW)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NHWC <strong class="ph b">(_NHWC)</strong></samp></li>
                                    <li class="li"><samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C <strong class="ph b">(_NCHW_VECT_C)</strong></samp></li>
                                 </ul>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_vcd_y35_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_vcd_y35_y3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 46. Supported Algorithms for
                                             <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp> 2D Convolutions:
                                             <samp class="ph codeph">dwDesc: _NHWC</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e50162" rowspan="1">Filter descriptor <samp class="ph codeph">dwDesc:
                                                   _NHWC</samp> (refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a></samp>)
                                             </th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50177" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50180" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50183" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50189" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dxDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50194" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50198" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50162 d54e50177" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_0</samp> and <samp class="ph codeph">_ALGO_1</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50162 d54e50180" rowspan="1" colspan="1">&nbsp;</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50162 d54e50183" rowspan="1" colspan="1">NHWC HWC-packed.</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50162 d54e50189" rowspan="1" colspan="1">NHWC HWC-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50162 d54e50194" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50162 d54e50198" rowspan="1" colspan="1">&nbsp;</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_nc2_13v_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_nc2_13v_y3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 47. Supported Algorithms for
                                             <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp> 2D Convolutions:
                                             <samp class="ph codeph">dwDesc: _NCHW</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e50269" rowspan="1">Filter descriptor <samp class="ph codeph">dwDesc:
                                                   _NCHW</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50277" rowspan="1" colspan="1">Algo Name</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50280" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50283" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50289" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dxDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50294" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50298" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50277" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_0</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50280" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50283" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50289" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50294" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50298" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> greater than 0 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50277" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_1</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50280" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50283" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50289" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50294" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">TRUE_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50298" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> greater than 0 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50277" rowspan="1" colspan="1"><samp class="ph codeph">_FFT</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50280" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50283" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50289" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50294" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50298" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                                <p class="p"><samp class="ph codeph">xDesc</samp> feature
                                                   map height + 2 * <samp class="ph codeph">convDesc</samp> zero-padding
                                                   height must equal 256 or less
                                                </p>
                                                <p class="p"><samp class="ph codeph">xDesc</samp>
                                                   feature map width + 2 * <samp class="ph codeph">convDesc</samp>
                                                   zero-padding width must equal 256 or
                                                   less
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp> vertical and
                                                   horizontal filter stride must equal
                                                   1
                                                </p>
                                                <p class="p"><samp class="ph codeph">dwDesc</samp> filter height must be
                                                   greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   height
                                                </p>
                                                <p class="p"><samp class="ph codeph">dwDesc</samp> filter width must be
                                                   greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   width
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50277" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_3</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50280" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50283" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50289" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50294" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50298" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50277" rowspan="1" colspan="1"><samp class="ph codeph">_WINOGRAD_NONFUSED</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50280" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50283" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50289" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50294" rowspan="1" colspan="1"><samp class="ph codeph">TRUE_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50298" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp>
                                                   vertical and horizontal filter stride must equal
                                                   1
                                                </p>
                                                <p class="p"><samp class="ph codeph">dwDesc</samp> filter (height, width)
                                                   must be (3,3) or (5,5)
                                                </p>
                                                <p class="p">If <samp class="ph codeph">dwDesc</samp>
                                                   filter (height, width) is (5,5), then the data type config
                                                   <samp class="ph codeph">TRUE_HALF_CONFIG</samp> is not
                                                   supported.
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50277" rowspan="1" colspan="1"><samp class="ph codeph">_FFT_TILING</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50280" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50283" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50289" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50294" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50269 d54e50298" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> 1 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                                <p class="p"><samp class="ph codeph">dyDesc</samp> width
                                                   or height must equal 1 (the same dimension as in
                                                   <samp class="ph codeph">xDesc</samp>). The other dimension must be
                                                   less than or equal to 256, meaning, the largest 1D tile size
                                                   currently supported.
                                                </p>
                                                <p class="p"><samp class="ph codeph">convDesc</samp>
                                                   vertical and horizontal filter stride must equal
                                                   1
                                                </p>
                                                <p class="p"><samp class="ph codeph">dwDesc</samp> filter height must be
                                                   greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   height
                                                </p>
                                                <p class="p"><samp class="ph codeph">dwDesc</samp> filter width must be
                                                   greater than <samp class="ph codeph">convDesc</samp> zero-padding
                                                   width
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_ky2_gr5_y3b" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_ky2_gr5_y3b" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 48. Supported Algorithms for
                                             <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp> 3D Convolutions:
                                             <samp class="ph codeph">dwDesc: _NCHW</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e50652" rowspan="1">Filter descriptor <samp class="ph codeph">dwDesc:
                                                   _NCHW</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50660" rowspan="1" colspan="1">Algo Name (3D Convolutions)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50663" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50666" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50672" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dxDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50677" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50681" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50660" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_0</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50663" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50666" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCDHW_VECT_C</samp>.
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50672" rowspan="1" colspan="1"><a name="cudnnConvolutionBackwardFilter__ul_jzz_j1m_qtb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_jzz_j1m_qtb">
                                                   <li class="li">NCDHW CDHW-packed</li>
                                                   <li class="li">NCDHW W-packed</li>
                                                   <li class="li">NDHWC</li>
                                                </ul>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50677" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50681" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> greater than 0 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50660" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_1</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50663" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50666" rowspan="1" colspan="1">All except <samp class="ph codeph">_NCDHW_VECT_C</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50672" rowspan="1" colspan="1"><a name="cudnnConvolutionBackwardFilter__ul_qvq_m1m_qtb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_qvq_m1m_qtb">
                                                   <li class="li">NCDHW CDHW-packed</li>
                                                   <li class="li">NCDHW W-packed</li>
                                                   <li class="li">NDHWC</li>
                                                </ul>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50677" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50681" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> greater than 0 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50660" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_3</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50663" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50666" rowspan="1" colspan="1">NCDHW fully-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50672" rowspan="1" colspan="1">NCDHW fully-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50677" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOAT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">DOUBLE_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50652 d54e50681" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> greater than 0 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_rfv_15s_4nb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_rfv_15s_4nb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 49. Supported Algorithms for
                                             <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp> 3D Convolutions:
                                             <samp class="ph codeph">dwDesc: _NHWC</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="6" valign="top" id="d54e50869" rowspan="1">Filter descriptor <samp class="ph codeph">dwDesc:
                                                   _NHWC</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50877" rowspan="1" colspan="1">Algo Name (3D Convolutions)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50880" rowspan="1" colspan="1">Deterministic (Yes or No)</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50883" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">xDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50889" rowspan="1" colspan="1">Tensor Formats Supported for <samp class="ph codeph">dyDesc</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50894" rowspan="1" colspan="1">Data Type Configurations Supported</th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e50898" rowspan="1" colspan="1">Important</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50869 d54e50877" rowspan="1" colspan="1"><samp class="ph codeph">_ALGO_1</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50869 d54e50880" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50869 d54e50883" rowspan="1" colspan="1">NDHWC HWC-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50869 d54e50889" rowspan="1" colspan="1">NDHWC HWC-packed</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50869 d54e50894" rowspan="1" colspan="1"><samp class="ph codeph">PSEUDO_HALF_CONFIG</samp><p class="p"><samp class="ph codeph">PSEUDO_BFLOT16_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">FLOAT_CONFIG</samp></p>
                                                <p class="p"><samp class="ph codeph">TRUE_HALF_CONFIG</samp></p>
                                             </td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e50869 d54e50898" rowspan="1" colspan="1"><strong class="ph b">Dilation:</strong> greater than 0 for all
                                                dimensions
                                                <p class="p"><samp class="ph codeph">convDesc</samp> Group Count
                                                   Support: Greater than 0
                                                </p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnConvolutionBackwardFilter__section_jqt_tbv_y3b"><a name="cudnnConvolutionBackwardFilter__section_jqt_tbv_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The operation was launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnConvolutionBackwardFilter__ul_y5f_hjb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_y5f_hjb_s1b">
                                          <li class="li">At least one of the following is <samp class="ph codeph">NULL</samp>:
                                             <samp class="ph codeph">handle</samp>, <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">convDesc</samp>,
                                             <samp class="ph codeph">dwDesc</samp>, <samp class="ph codeph">xData</samp>,
                                             <samp class="ph codeph">dyData</samp>, <samp class="ph codeph">dwData</samp>,
                                             <samp class="ph codeph">alpha</samp>, or <samp class="ph codeph">beta</samp></li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dyDesc</samp> have a
                                             non-matching number of dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dwDesc</samp> have a
                                             non-matching number of dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> has fewer than three number of
                                             dimensions
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, and
                                             <samp class="ph codeph">dwDesc</samp> have a non-matching data type.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dwDesc</samp> have a
                                             non-matching number of input feature maps per image (or group in
                                             case of grouped convolutions).
                                          </li>
                                          <li class="li"><samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">dwDesc</samp> indicate an
                                             output channel count that isn't a multiple of group count (if
                                             group count has been set in <samp class="ph codeph">convDesc</samp>).
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionBackwardFilter__ul_dvf_hjb_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_dvf_hjb_s1b">
                                          <li class="li"><samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">dyDesc</samp> have negative
                                             tensor striding
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                             <samp class="ph codeph">dwDesc</samp> has a number of dimensions that is
                                             not 4 or 5
                                          </li>
                                          <li class="li">The chosen algo does not support the parameters provided; see
                                             above for exhaustive list of parameter support for each
                                             algo
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">An error occurs during the texture object creation associated with the
                                       filter data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateFusedOpsConstParamPack"><a name="cudnnCreateFusedOpsConstParamPack" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFusedOpsConstParamPack" name="cudnnCreateFusedOpsConstParamPack" shape="rect">6.2.4.&nbsp;<kbd class="ph userinput">cudnnCreateFusedOpsConstParamPack()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates an opaque structure to store the various problem size
                                 			information, such as the shape, layout and the type of tensors, and the descriptors for
                                 			convolution and activation, for the selected sequence of <samp class="ph codeph">cudnnFusedOps</samp>
                                 			computations.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFusedOpsConstParamPack(
	cudnnFusedOpsConstParamPack_t *constPack, 
	cudnnFusedOps_t ops);		</pre><div class="section" id="cudnnCreateFusedOpsConstParamPack__section_l4m_lyb_z3b"><a name="cudnnCreateFusedOpsConstParamPack__section_l4m_lyb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">constPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The opaque structure that is created by this function. For more information,
                                       							refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ops</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The specific sequence of computations to perform in the
                                       								<samp class="ph codeph">cudnnFusedOps</samp> computations, as defined in the
                                       							enumerant type <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOps_t" title="The cudnnFusedOps_t type is an enumerated type to select a specific sequence of computations to perform in the fused operations." shape="rect">cudnnFusedOps_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateFusedOpsConstParamPack__section_sth_pyb_z3b"><a name="cudnnCreateFusedOpsConstParamPack__section_sth_pyb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If either <samp class="ph codeph">constPack</samp> or <samp class="ph codeph">ops</samp> is
                                       								<samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">If the descriptor is created successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateFusedOpsPlan"><a name="cudnnCreateFusedOpsPlan" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFusedOpsPlan" name="cudnnCreateFusedOpsPlan" shape="rect">6.2.5.&nbsp;<kbd class="ph userinput">cudnnCreateFusedOpsPlan()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates the plan descriptor for the <samp class="ph codeph">cudnnFusedOps</samp>
                                 			computation. This descriptor contains the plan information, including the problem type
                                 			and size, which kernels should be run, and the internal workspace partition. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFusedOpsPlan(
	cudnnFusedOpsPlan_t *plan, 
	cudnnFusedOps_t ops);		</pre><div class="section" id="cudnnCreateFusedOpsPlan__section_bz1_13c_z3b"><a name="cudnnCreateFusedOpsPlan__section_bz1_13c_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">plan</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A pointer to the instance of the descriptor created by
                                       							this function.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ops</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The specific sequence of fused operations computations for which this plan
                                       							descriptor should be created. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOps_t" title="The cudnnFusedOps_t type is an enumerated type to select a specific sequence of computations to perform in the fused operations." shape="rect">cudnnFusedOps_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateFusedOpsPlan__section_vsv_t3c_z3b"><a name="cudnnCreateFusedOpsPlan__section_vsv_t3c_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If either the input <samp class="ph codeph">*plan</samp> is <samp class="ph codeph">NULL</samp> or
                                       							the <samp class="ph codeph">ops</samp> input is not a valid
                                       								<samp class="ph codeph">cudnnFusedOp</samp> enum.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The plan descriptor is created successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateFusedOpsVariantParamPack"><a name="cudnnCreateFusedOpsVariantParamPack" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFusedOpsVariantParamPack" name="cudnnCreateFusedOpsVariantParamPack" shape="rect">6.2.6.&nbsp;<kbd class="ph userinput">cudnnCreateFusedOpsVariantParamPack()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates the variant pack descriptor for the
                                 				<samp class="ph codeph">cudnnFusedOps</samp> computation.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFusedOpsVariantParamPack(
	cudnnFusedOpsVariantParamPack_t *varPack, 
	cudnnFusedOps_t ops);		</pre><div class="section" id="cudnnCreateFusedOpsVariantParamPack__section_kgg_1jc_z3b"><a name="cudnnCreateFusedOpsVariantParamPack__section_kgg_1jc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">varPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the descriptor created by this function. For more information,
                                       							refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsVariantParamPack_t" shape="rect">cudnnFusedOpsVariantParamPack_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ops</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The specific sequence of fused operations computations for
                                       							which this descriptor should be created.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateFusedOpsVariantParamPack__section_bt4_1jc_z3b"><a name="cudnnCreateFusedOpsVariantParamPack__section_bt4_1jc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor is successfully created.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If any input is invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyFusedOpsConstParamPack"><a name="cudnnDestroyFusedOpsConstParamPack" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFusedOpsConstParamPack" name="cudnnDestroyFusedOpsConstParamPack" shape="rect">6.2.7.&nbsp;<kbd class="ph userinput">cudnnDestroyFusedOpsConstParamPack()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function destroys a previously-created <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a></samp> structure. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFusedOpsConstParamPack(
	cudnnFusedOpsConstParamPack_t constPack);		</pre><div class="section" id="cudnnDestroyFusedOpsConstParamPack__section_yk1_4bd_z3b"><a name="cudnnDestroyFusedOpsConstParamPack__section_yk1_4bd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">constPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a></samp>
                                       							structure that should be destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyFusedOpsConstParamPack__section_svl_4bd_z3b"><a name="cudnnDestroyFusedOpsConstParamPack__section_svl_4bd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">If the descriptor is destroyed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">If the ops enum value is not supported or invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyFusedOpsPlan"><a name="cudnnDestroyFusedOpsPlan" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFusedOpsPlan" name="cudnnDestroyFusedOpsPlan" shape="rect">6.2.8.&nbsp;<kbd class="ph userinput">cudnnDestroyFusedOpsPlan()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys the plan descriptor provided.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFusedOpsPlan(
	cudnnFusedOpsPlan_t plan);		</pre><div class="section" id="cudnnDestroyFusedOpsPlan__section_vtx_ccd_z3b"><a name="cudnnDestroyFusedOpsPlan__section_vtx_ccd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">plan</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The descriptor that should be destroyed by this
                                       							function.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyFusedOpsPlan__section_ghj_dcd_z3b"><a name="cudnnDestroyFusedOpsPlan__section_ghj_dcd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">If either the plan descriptor is <samp class="ph codeph">NULL</samp> or the descriptor
                                       							is successfully destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyFusedOpsVariantParamPack"><a name="cudnnDestroyFusedOpsVariantParamPack" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFusedOpsVariantParamPack" name="cudnnDestroyFusedOpsVariantParamPack" shape="rect">6.2.9.&nbsp;<kbd class="ph userinput">cudnnDestroyFusedOpsVariantParamPack()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously-created descriptor for
                                 				<samp class="ph codeph">cudnnFusedOps</samp> constant parameters.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFusedOpsVariantParamPack(
	cudnnFusedOpsVariantParamPack_t varPack);		</pre><div class="section" id="cudnnDestroyFusedOpsVariantParamPack__section_ihd_ncd_z3b"><a name="cudnnDestroyFusedOpsVariantParamPack__section_ihd_ncd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">varPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The descriptor that should be destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyFusedOpsVariantParamPack__section_fcm_rcd_z3b"><a name="cudnnDestroyFusedOpsVariantParamPack__section_fcm_rcd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor is successfully destroyed.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindConvolutionBackwardFilterAlgorithm"><a name="cudnnFindConvolutionBackwardFilterAlgorithm" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardFilterAlgorithm" name="cudnnFindConvolutionBackwardFilterAlgorithm" shape="rect">6.2.10.&nbsp;<kbd class="ph userinput">cudnnFindConvolutionBackwardFilterAlgorithm()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function attempts all algorithms available for <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>. It will attempt both the
                              provided <samp class="ph codeph">convDesc mathType</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>
                              (assuming the two differ). <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardFilterAlgorithm(
cudnnHandle_t                          handle,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          xDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          dwDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
cudnnConvolutionBwdFilterAlgoPerf_t   *perfResults)</pre><div class="p">
                              <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> availability will only be
                                 tried with <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>, and returned as such.
                              </div>
                           </div>
                           <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned in
                              the user-allocated array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">cudnnConvolutionBwdFilterAlgoPerf_t</a></samp>. These metrics are written in a sorted fashion where the first element
                              has the lowest compute time. The total number of resulting algorithms can be queried
                              through the API <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardFilterAlgorithmMaxCount()</a></samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span><a name="cudnnFindConvolutionBackwardFilterAlgorithm__ul_u2b_t3h_z3b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithm__ul_u2b_t3h_z3b">
                                 <li class="li">This function is host blocking.</li>
                                 <li class="li">It is recommended to run this function prior to allocating layer data; doing
                                    otherwise may needlessly inhibit some algorithm options due to resource
                                    usage.
                                 </li>
                              </ul>
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardFilterAlgorithm__section_m1l_w3h_z3b"><a name="cudnnFindConvolutionBackwardFilterAlgorithm__section_m1l_w3h_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardFilterAlgorithm__section_r3x_w3h_z3b"><a name="cudnnFindConvolutionBackwardFilterAlgorithm__section_r3x_w3h_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardFilterAlgorithm__ul_o1g_g3b_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithm__ul_o1g_g3b_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dwDesc</samp> are not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dwDesc</samp> has fewer than 1 dimension.
                                          </li>
                                          <li class="li">Either <samp class="ph codeph">returnedCount</samp> or
                                             <samp class="ph codeph">perfResults</samp> is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">This function was unable to allocate memory to store sample input,
                                       filters and output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardFilterAlgorithm__ul_u1g_g3b_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithm__ul_u1g_g3b_s1b">
                                          <li class="li">The function was unable to allocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate sample input, filters and
                                             output.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindConvolutionBackwardFilterAlgorithmEx"><a name="cudnnFindConvolutionBackwardFilterAlgorithmEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardFilterAlgorithmEx" name="cudnnFindConvolutionBackwardFilterAlgorithmEx" shape="rect">6.2.11.&nbsp;<kbd class="ph userinput">cudnnFindConvolutionBackwardFilterAlgorithmEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function attempts all algorithms available for <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>. It will attempt both the
                              provided <samp class="ph codeph">convDesc mathType</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>
                              (assuming the two differ). <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardFilterAlgorithmEx(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdFilterAlgoPerf_t   *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *workSpace,
    size_t                                 workSpaceSizeInBytes)</pre><div class="p">
                              <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> availability will only be
                                 tried with <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>, and returned as such.
                              </div>
                           </div>
                           <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned in
                              the user-allocated array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">cudnnConvolutionBwdFilterAlgoPerf_t</a></samp>. These metrics are written in a sorted fashion where the first element
                              has the lowest compute time. The total number of resulting algorithms can be queried
                              through the API <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardFilterAlgorithmMaxCount()</a></samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardFilterAlgorithmEx__section_yhb_rsh_z3b"><a name="cudnnFindConvolutionBackwardFilterAlgorithmEx__section_yhb_rsh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dw</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       filter descriptor <samp class="ph codeph">dwDesc</samp>. The content of this tensor
                                       will be overwritten with arbitrary values.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory is a necessary workspace for
                                       some algorithms. The size of this workspace will determine the
                                       availability of algorithms. A <samp class="ph codeph">NIL</samp> pointer is considered
                                       a <samp class="ph codeph">workSpace</samp> of 0 bytes.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindConvolutionBackwardFilterAlgorithmEx__section_qkl_rsh_z3b"><a name="cudnnFindConvolutionBackwardFilterAlgorithmEx__section_qkl_rsh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_lgv_k3b_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_lgv_k3b_s1b">
                                          <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dwDesc</samp> are not allocated properly.
                                          </li>
                                          <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, or
                                             <samp class="ph codeph">dwDesc</samp> has fewer than 1 dimension.
                                          </li>
                                          <li class="li"><samp class="ph codeph">x</samp>, <samp class="ph codeph">dy</samp>, or <samp class="ph codeph">dw</samp>
                                             is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li">Either <samp class="ph codeph">returnedCount</samp> or
                                             <samp class="ph codeph">perfResults</samp> is <samp class="ph codeph">NIL</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_ugv_k3b_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_ugv_k3b_s1b">
                                          <li class="li">The function was unable to allocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate necessary timing
                                             objects.
                                          </li>
                                          <li class="li">The function was unable to deallocate sample input, filters and
                                             output.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFusedOpsExecute"><a name="cudnnFusedOpsExecute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsExecute" name="cudnnFusedOpsExecute" shape="rect">6.2.12.&nbsp;<kbd class="ph userinput">cudnnFusedOpsExecute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function executes the sequence of <samp class="ph codeph">cudnnFusedOps</samp>
                                 			operations.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnFusedOpsExecute(
	cudnnHandle_t handle, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsPlan_t plan, 
	cudnnFusedOpsVariantParamPack_t varPack);		</pre><div class="section" id="cudnnFusedOpsExecute__section_qdx_1x3_z3b"><a name="cudnnFusedOpsExecute__section_qdx_1x3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the cuDNN library context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">plan</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously-created and initialized plan
                                       							descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">varPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the descriptor to the variant parameters
                                       							pack.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFusedOpsExecute__section_ybm_bx3_z3b"><a name="cudnnFusedOpsExecute__section_ybm_bx3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If the type of <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOps_t" title="The cudnnFusedOps_t type is an enumerated type to select a specific sequence of computations to perform in the fused operations." shape="rect">cudnnFusedOps_t</a></samp> in the plan descriptor is
                                       							unsupported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount"><a name="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" name="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">6.2.13.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionBackwardFilterAlgorithmMaxCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the maximum number of algorithms which can be returned from
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionBackwardFilterAlgorithm" shape="rect">cudnnFindConvolutionBackwardFilterAlgorithm()</a></samp> and
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">cudnnGetConvolutionForwardAlgorithm_v7()</a></samp>. This is
                              the sum of all algorithms plus the sum of all algorithms with Tensor Core operations
                              supported for the current device.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardFilterAlgorithmMaxCount(
    cudnnHandle_t       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                 *count)</pre><div class="section" id="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount__section_zzs_g12_1jb"><a name="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount__section_zzs_g12_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">count</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The resulting maximum count of algorithms.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount__section_rk2_h12_1jb"><a name="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount__section_rk2_h12_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The provided handle is not allocated properly.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionBackwardFilterAlgorithm_v7"><a name="cudnnGetConvolutionBackwardFilterAlgorithm_v7" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardFilterAlgorithm_v7" name="cudnnGetConvolutionBackwardFilterAlgorithm_v7" shape="rect">6.2.14.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionBackwardFilterAlgorithm_v7()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function serves as a heuristic for obtaining the best suited algorithm for
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp> for the given layer
                              specifications. This function will return all algorithms (including
                              <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> and <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> versions
                              of algorithms where <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> may be available) sorted by
                              expected (based on internal heuristic) relative performance with fastest being index 0 of
                              <samp class="ph codeph">perfResults</samp>. For an exhaustive search for the fastest algorithm, use
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnFindConvolutionBackwardFilterAlgorithm" shape="rect">cudnnFindConvolutionBackwardFilterAlgorithm()</a></samp>. The
                              total number of resulting algorithms can be queried through the
                              <samp class="ph codeph">returnedAlgoCount</samp> variable. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardFilterAlgorithm_v7(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdFilterAlgoPerf_t   *perfResults)</pre><div class="section" id="cudnnGetConvolutionBackwardFilterAlgorithm_v7__section_xvv_5zd_1jb"><a name="cudnnGetConvolutionBackwardFilterAlgorithm_v7__section_xvv_5zd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionBackwardFilterAlgorithm_v7__section_kmg_vzd_1jb"><a name="cudnnGetConvolutionBackwardFilterAlgorithm_v7__section_kmg_vzd_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionBackwardFilterAlgorithm_v7__ul_f44_s3b_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardFilterAlgorithm_v7__ul_f44_s3b_s1b">
                                          <li class="li">One of the parameters <samp class="ph codeph">handle</samp>,
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                             <samp class="ph codeph">convDesc</samp>, <samp class="ph codeph">dwDesc</samp>,
                                             <samp class="ph codeph">perfResults</samp>,  or
                                             <samp class="ph codeph">returnedAlgoCount</samp> is
                                             <samp class="ph codeph">NULL</samp>.
                                          </li>
                                          <li class="li">The numbers of feature maps of the input tensor and output
                                             tensor differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or
                                             the filter are different.
                                          </li>
                                          <li class="li"><samp class="ph codeph">requestedAlgoCount</samp> is less than or equal to
                                             0.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetConvolutionBackwardFilterWorkspaceSize"><a name="cudnnGetConvolutionBackwardFilterWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardFilterWorkspaceSize" name="cudnnGetConvolutionBackwardFilterWorkspaceSize" shape="rect">6.2.15.&nbsp;<kbd class="ph userinput">cudnnGetConvolutionBackwardFilterWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the amount of GPU memory workspace the user needs to allocate to
                              be able to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp> with the
                              specified algorithm. The workspace allocated will then be passed to the routine
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter()</a></samp>. The specified
                              algorithm can be the result of the call to <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetConvolutionBackwardFilterAlgorithm_v7" shape="rect">cudnnGetConvolutionBackwardFilterAlgorithm_v7()</a></samp> or can be chosen
                              arbitrarily by the user. Note that not every algorithm is available for every configuration
                              of the input tensor and/or every configuration of the convolution
                              descriptor. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardFilterWorkspaceSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       dwDesc,
    cudnnConvolutionBwdFilterAlgo_t     algo,
    size_t                             *sizeInBytes)</pre><div class="section" id="cudnnGetConvolutionBackwardFilterWorkspaceSize__section_mgr_n12_1jb"><a name="cudnnGetConvolutionBackwardFilterWorkspaceSize__section_mgr_n12_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized input differential
                                       tensor descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">convDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies the chosen convolution algorithm.
                                       
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to
                                       execute a forward convolution with the specified
                                       <samp class="ph codeph">algo</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetConvolutionBackwardFilterWorkspaceSize__section_a5b_412_1jb"><a name="cudnnGetConvolutionBackwardFilterWorkspaceSize__section_a5b_412_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetConvolutionBackwardFilterWorkspaceSize__ul_cyh_w3b_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardFilterWorkspaceSize__ul_cyh_w3b_s1b">
                                          <li class="li">The numbers of feature maps of the input tensor and output
                                             tensor differ.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or
                                             the filter are different.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The combination of the tensor descriptors, filter descriptor and
                                       convolution descriptor is not supported for the specified
                                       algorithm.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetFusedOpsConstParamPackAttribute"><a name="cudnnGetFusedOpsConstParamPackAttribute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFusedOpsConstParamPackAttribute" name="cudnnGetFusedOpsConstParamPackAttribute" shape="rect">6.2.16.&nbsp;<kbd class="ph userinput">cudnnGetFusedOpsConstParamPackAttribute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves the values of the descriptor pointed to by the
                                 				<samp class="ph codeph">param</samp> pointer input. The type of the descriptor is indicated by the
                                 			enum value of <samp class="ph codeph">paramLabel</samp> input.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFusedOpsConstParamPackAttribute(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsConstParamPack_t constPack,
	cudnnFusedOpsConstParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *param,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *isNULL);		</pre><div class="section" id="cudnnGetFusedOpsConstParamPackAttribute__section_mzz_hr2_1jb"><a name="cudnnGetFusedOpsConstParamPackAttribute__section_mzz_hr2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">constPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The opaque <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a></samp>
                                       							structure that contains the various problem size information, such as
                                       							the shape, layout and the type of tensors, and the descriptors for
                                       							convolution and activation, for the selected sequence of <a class="xref" href="index.html#cudnnFusedOps_t" title="The cudnnFusedOps_t type is an enumerated type to select a specific sequence of computations to perform in the fused operations." shape="rect">cudnnFusedOps_t</a> computations.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paramLabel</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Several types of descriptors can be retrieved by this getter function. The
                                       								<samp class="ph codeph">param</samp> input points to the descriptor itself, and
                                       							this input indicates the type of the descriptor pointed to by the
                                       								<samp class="ph codeph">param</samp> input. The <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a></samp> enumerant
                                       							type enables the selection of the type of the descriptor. Refer to the
                                       								<samp class="ph codeph">param</samp> description below.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">param</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to the host memory associated with the descriptor that should
                                       							be retrieved. The type of this descriptor depends on the value of
                                       								<samp class="ph codeph">paramLabel</samp>. For the given
                                       								<samp class="ph codeph">paramLabel</samp>, if the associated value inside the
                                       								<samp class="ph codeph">constPack</samp> is set to <samp class="ph codeph">NULL</samp> or by
                                       							default <samp class="ph codeph">NULL</samp>, then cuDNN will copy the value or the
                                       							opaque structure in the <samp class="ph codeph">constPack</samp> to the host memory
                                       							buffer pointed to by <samp class="ph codeph">param</samp>. For more information, see
                                       							the table in <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">isNULL</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Users must pass a pointer to an integer in the host
                                       							memory in this field. If the value in the <samp class="ph codeph">constPack</samp>
                                       							associated with the given <samp class="ph codeph">paramLabel</samp> is by default
                                       								<samp class="ph codeph">NULL</samp> or previously set by the user to
                                       								<samp class="ph codeph">NULL</samp>, then cuDNN will write a non-zero value to the
                                       							location pointed by is <samp class="ph codeph">isNULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetFusedOpsConstParamPackAttribute__section_s2q_3r2_1jb"><a name="cudnnGetFusedOpsConstParamPackAttribute__section_s2q_3r2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor values are retrieved successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If either <samp class="ph codeph">constPack</samp>, <samp class="ph codeph">param</samp> or
                                       								<samp class="ph codeph">isNULL</samp> is <samp class="ph codeph">NULL</samp>; or if
                                       								<samp class="ph codeph">paramLabel</samp> is invalid.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetFusedOpsVariantParamPackAttribute"><a name="cudnnGetFusedOpsVariantParamPackAttribute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFusedOpsVariantParamPackAttribute" name="cudnnGetFusedOpsVariantParamPackAttribute" shape="rect">6.2.17.&nbsp;<kbd class="ph userinput">cudnnGetFusedOpsVariantParamPackAttribute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves the settings of the variable parameter pack
                                 			descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFusedOpsVariantParamPackAttribute(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsVariantParamPack_t varPack,
	cudnnFusedOpsVariantParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);		</pre><div class="section" id="cudnnGetFusedOpsVariantParamPackAttribute__section_rdy_w52_1jb"><a name="cudnnGetFusedOpsVariantParamPackAttribute__section_rdy_w52_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">varPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the <samp class="ph codeph">cudnnFusedOps</samp> variant
                                       							parameter pack (<samp class="ph codeph">varPack</samp>) descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paramLabel</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Type of the buffer pointer parameter (in the <samp class="ph codeph">varPack</samp>
                                       							descriptor). For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a></samp>. The
                                       							retrieved descriptor values vary according to this type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ptr</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the host or device memory where the retrieved value is written
                                       							by this function. The data type of the pointer, and the host/device
                                       							memory location, depend on the <samp class="ph codeph">paramLabel</samp> input
                                       							selection. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsVariantParamLabel_t" title="The cudnnFusedOpsVariantParamLabel_t is an enumerated type that is used to set the buffer pointers. These buffer pointers can be changed in each iteration." shape="rect">cudnnFusedOpsVariantParamLabel_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetFusedOpsVariantParamPackAttribute__section_qnf_x52_1jb"><a name="cudnnGetFusedOpsVariantParamPackAttribute__section_qnf_x52_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor values are retrieved successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If either <samp class="ph codeph">varPack</samp> or <samp class="ph codeph">ptr</samp> is
                                       								<samp class="ph codeph">NULL</samp>, or if <samp class="ph codeph">paramLabel</samp> is set to
                                       							invalid value.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnMakeFusedOpsPlan"><a name="cudnnMakeFusedOpsPlan" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMakeFusedOpsPlan" name="cudnnMakeFusedOpsPlan" shape="rect">6.2.18.&nbsp;<kbd class="ph userinput">cudnnMakeFusedOpsPlan()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function determines the optimum kernel to execute, and the workspace size the
                              		user should allocate, prior to the actual execution of the fused operations by <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsExecute" title="This function executes the sequence of cudnnFusedOps operations." shape="rect">cudnnFusedOpsExecute()</a></samp>.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnMakeFusedOpsPlan(
	cudnnHandle_t handle,
	cudnnFusedOpsPlan_t plan,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsConstParamPack_t constPack,
	size_t *workspaceSizeInBytes); 		</pre><div class="section" id="cudnnMakeFusedOpsPlan__section_jp2_t4k_1jb"><a name="cudnnMakeFusedOpsPlan__section_jp2_t4k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the cuDNN library context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">plan</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously-created and initialized plan
                                       							descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">constPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the descriptor to the const parameters
                                       							pack.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The amount of workspace size the user should allocate for
                                       							the execution of this plan.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnMakeFusedOpsPlan__section_qrq_t4k_1jb"><a name="cudnnMakeFusedOpsPlan__section_qrq_t4k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If any of the inputs is <samp class="ph codeph">NULL</samp>, or if the type of <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOps_t" title="The cudnnFusedOps_t type is an enumerated type to select a specific sequence of computations to perform in the fused operations." shape="rect">cudnnFusedOps_t</a></samp> in the
                                       								<samp class="ph codeph">constPack</samp> descriptor is unsupported.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function executed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetFusedOpsConstParamPackAttribute"><a name="cudnnSetFusedOpsConstParamPackAttribute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFusedOpsConstParamPackAttribute" name="cudnnSetFusedOpsConstParamPackAttribute" shape="rect">6.2.19.&nbsp;<kbd class="ph userinput">cudnnSetFusedOpsConstParamPackAttribute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function sets the descriptor pointed to by the <samp class="ph codeph">param</samp>
                                 			pointer input. The type of the descriptor to be set is indicated by the enum value of
                                 			the <span class="keyword apiname">paramLabel</span> input.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFusedOpsConstParamPackAttribute(
	cudnnFusedOpsConstParamPack_t constPack,
	cudnnFusedOpsConstParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *param);		</pre><div class="section" id="cudnnSetFusedOpsConstParamPackAttribute__section_yjc_mjh_bjb"><a name="cudnnSetFusedOpsConstParamPackAttribute__section_yjc_mjh_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">constPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The opaque <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a></samp>
                                       							structure that contains the various problem size information, such as
                                       							the shape, layout and the type of tensors, the descriptors for
                                       							convolution and activation, and settings for operations such as
                                       							convolution and activation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paramLabel</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Several types of descriptors can be set by this setter function. The
                                       								<samp class="ph codeph">param</samp> input points to the descriptor itself, and
                                       							this input indicates the type of the descriptor pointed to by the
                                       								<samp class="ph codeph">param</samp> input. The <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a></samp> enumerant
                                       							type enables the selection of the type of the descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">param</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to the host memory, associated with the specific descriptor.
                                       							The type of the descriptor depends on the value of
                                       								<samp class="ph codeph">paramLabel</samp>. For more information, refer to the
                                       							table in <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a></samp>.
                                       <p class="p">If this pointer is set to <samp class="ph codeph">NULL</samp>, then
                                          								the cuDNN library will record as such. If not, then the values
                                          								pointed to by this pointer (meaning, the value or the opaque
                                          								structure underneath) will be copied into the
                                          									<samp class="ph codeph">constPack</samp> during
                                          									<samp class="ph codeph">cudnnSetFusedOpsConstParamPackAttribute()</samp>
                                          								operation.
                                       </p>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetFusedOpsConstParamPackAttribute__section_wp5_njh_bjb"><a name="cudnnSetFusedOpsConstParamPackAttribute__section_wp5_njh_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor is set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If <samp class="ph codeph">constPack</samp> is <samp class="ph codeph">NULL</samp>, or if
                                       								<samp class="ph codeph">paramLabel</samp> or the ops setting for
                                       								<samp class="ph codeph">constPack</samp> is invalid.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetFusedOpsVariantParamPackAttribute"><a name="cudnnSetFusedOpsVariantParamPackAttribute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFusedOpsVariantParamPackAttribute" name="cudnnSetFusedOpsVariantParamPackAttribute" shape="rect">6.2.20.&nbsp;<kbd class="ph userinput">cudnnSetFusedOpsVariantParamPackAttribute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function sets the variable parameter pack descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFusedOpsVariantParamPackAttribute(
	cudnnFusedOpsVariantParamPack_t varPack,
	cudnnFusedOpsVariantParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);		</pre><div class="section" id="cudnnSetFusedOpsVariantParamPackAttribute__section_yzy_zvh_bjb"><a name="cudnnSetFusedOpsVariantParamPackAttribute__section_yzy_zvh_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">varPack</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the <samp class="ph codeph">cudnnFusedOps</samp> variant
                                       							parameter pack (<samp class="ph codeph">varPack</samp>) descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paramLabel</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Type to which the buffer pointer parameter (in the <samp class="ph codeph">varPack</samp>
                                       							descriptor) is set by this function. For more information, refer to
                                       									<samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ptr</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer, to the host or device memory, to the value to which the descriptor
                                       							parameter is set. The data type of the pointer, and the host/device
                                       							memory location, depend on the <samp class="ph codeph">paramLabel</samp> input
                                       							selection. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnFusedOpsVariantParamLabel_t" title="The cudnnFusedOpsVariantParamLabel_t is an enumerated type that is used to set the buffer pointers. These buffer pointers can be changed in each iteration." shape="rect">cudnnFusedOpsVariantParamLabel_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetFusedOpsVariantParamPackAttribute__section_l5j_1wh_bjb"><a name="cudnnSetFusedOpsVariantParamPackAttribute__section_l5j_1wh_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If <samp class="ph codeph">varPack</samp> is <samp class="ph codeph">NULL</samp> or if
                                       								<samp class="ph codeph">paramLabel</samp> is set to an unsupported value.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was set successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="cudnn-adv-infer-so-library"><a name="cudnn-adv-infer-so-library" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cudnn-adv-infer-so-library" name="cudnn-adv-infer-so-library" shape="rect">7.&nbsp;<kbd class="ph userinput">cudnn_adv_infer.so</kbd> Library</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">This entity contains all other features and algorithms. This includes RNNs, CTC
                           loss, and multi-head attention. The <samp class="ph codeph">cudnn_adv_infer</samp> library depends on
                           <samp class="ph codeph">cudnn_ops_infer</samp>.</span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="cudnn-adv-infer-so-data-types"><a name="cudnn-adv-infer-so-data-types" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-adv-infer-so-data-types" name="cudnn-adv-infer-so-data-types" shape="rect">7.1.&nbsp;Data Type References</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the data type references in the <samp class="ph codeph">cudnn_adv_infer.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnn-adv-infer-so-opaque"><a name="cudnn-adv-infer-so-opaque" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-adv-infer-so-opaque" name="cudnn-adv-infer-so-opaque" shape="rect">7.1.1.&nbsp;Pointer To Opaque Struct Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the pointers to the opaque struct types in the
                                 <samp class="ph codeph">cudnn_adv_infer.so</samp> library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnAttnDescriptor_t"><a name="cudnnAttnDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAttnDescriptor_t" name="cudnnAttnDescriptor_t" shape="rect">7.1.1.1.&nbsp;<kbd class="ph userinput">cudnnAttnDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnAttnDescriptor_t</samp> is a pointer to an opaque structure
                                    			holding parameters of the multi-head attention layer such as:</span></div>
                              <div class="p"><a name="cudnnAttnDescriptor_t__ul_wwx_jkb_x3b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnAttnDescriptor_t__ul_wwx_jkb_x3b">
                                    <li class="li">weight and bias tensor shapes (vector lengths before and after linear
                                       					projections)
                                    </li>
                                    <li class="li">parameters that can be set in advance and do not change when invoking functions
                                       					to evaluate forward responses and gradients (number of attention heads, softmax
                                       					smoothing/sharpening coefficient)
                                    </li>
                                    <li class="li">other settings that are necessary to compute temporary buffer sizes.</li>
                                 </ul>
                              </div>
                              <p class="p">Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateAttnDescriptor" title="This function creates one instance of an opaque attention descriptor object by allocating the host memory for it and initializing all descriptor fields. The function writes NULL to attnDesc when the attention descriptor object cannot be allocated." shape="rect">cudnnCreateAttnDescriptor()</a></samp> function to create an
                                 			instance of the attention descriptor object and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyAttnDescriptor" title="This function destroys the attention descriptor object and releases its memory. The attnDesc argument can be NULL. Invoking cudnnDestroyAttnDescriptor() with a NULL argument is a no operation (NOP)." shape="rect">cudnnDestroyAttnDescriptor()</a></samp> to delete the previously created
                                 			descriptor. Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetAttnDescriptor" shape="rect">cudnnSetAttnDescriptor()</a></samp> function to
                                 			configure the descriptor.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnPersistentRNNPlan_t"><a name="cudnnPersistentRNNPlan_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPersistentRNNPlan_t" name="cudnnPersistentRNNPlan_t" shape="rect">7.1.1.2.&nbsp;<kbd class="ph userinput">cudnnPersistentRNNPlan_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc">This function is deprecated starting in cuDNN 8.0.0.</span></div>
                              <p class="p"><samp class="ph codeph">cudnnPersistentRNNPlan_t</samp> is a pointer to an opaque structure holding a
                                 plan to execute a dynamic persistent RNN. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreatePersistentRNNPlan" shape="rect">cudnnCreatePersistentRNNPlan()</a></samp> is used to create and
                                 initialize one instance. 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNDataDescriptor_t"><a name="cudnnRNNDataDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNDataDescriptor_t" name="cudnnRNNDataDescriptor_t" shape="rect">7.1.1.3.&nbsp;<kbd class="ph userinput">cudnnRNNDataDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNDataDescriptor_t</samp> is a pointer to an opaque structure holding
                                 the description of an RNN data set. The function <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateRNNDataDescriptor" title="This function creates a RNN data descriptor object by allocating the memory needed to hold its opaque structure." shape="rect">cudnnCreateRNNDataDescriptor()</a></samp> is used to create one instance, and
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDataDescriptor" title="This function initializes a previously created RNN data descriptor object. This data structure is intended to support the unpacked (padded) layout for input and output of extended RNN inference and training functions. A packed (unpadded) layout is also supported for backward compatibility." shape="rect">cudnnSetRNNDataDescriptor()</a></samp> must be used to
                                 initialize this instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNDescriptor_t"><a name="cudnnRNNDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNDescriptor_t" name="cudnnRNNDescriptor_t" shape="rect">7.1.1.4.&nbsp;<kbd class="ph userinput">cudnnRNNDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNDescriptor_t</samp> is a pointer to an opaque structure holding the
                                 description of an RNN operation. <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateRNNDescriptor" title="This function creates a generic RNN descriptor object by allocating the memory needed to hold its opaque structure." shape="rect">cudnnCreateRNNDescriptor()</a></samp>
                                 is used to create one instance. <span class="shortdesc"></span></div>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSeqDataDescriptor_t"><a name="cudnnSeqDataDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSeqDataDescriptor_t" name="cudnnSeqDataDescriptor_t" shape="rect">7.1.1.5.&nbsp;<kbd class="ph userinput">cudnnSeqDataDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnSeqDataDescriptor_t</samp> is a pointer to an opaque structure
                                    			holding parameters of the sequence data container or buffer. The sequence data container
                                    			is used to store fixed size vectors defined by the <samp class="ph codeph">VECT</samp> dimension.
                                    			Vectors are arranged in additional three dimensions: <samp class="ph codeph">TIME</samp>,
                                    				<samp class="ph codeph">BATCH</samp> and <samp class="ph codeph">BEAM</samp>.</span></div>
                              <p class="p">The <samp class="ph codeph">TIME</samp> dimension is used to bundle vectors into sequences of vectors.
                                 			The actual sequences can be shorter than the <samp class="ph codeph">TIME</samp> dimension, therefore,
                                 			additional information is needed about each sequence length and how unused (padding)
                                 			vectors should be saved.
                              </p>
                              <p class="p">It is assumed that the sequence data container is fully packed. The
                                 			<samp class="ph codeph">TIME</samp>, <samp class="ph codeph">BATCH</samp> and <samp class="ph codeph">BEAM</samp> dimensions can
                                 			be in any order when vectors are traversed in the ascending order of addresses. Six data
                                 			layouts (permutation of <samp class="ph codeph">TIME</samp>, <samp class="ph codeph">BATCH</samp> and
                                 				<samp class="ph codeph">BEAM</samp>) are possible.
                              </p>
                              <div class="p">The <samp class="ph codeph">cudnnSeqDataDescriptor_t</samp> object holds the following parameters:<a name="cudnnSeqDataDescriptor_t__ul_yhv_lfn_y3b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnSeqDataDescriptor_t__ul_yhv_lfn_y3b">
                                    <li class="li">data type used by vectors</li>
                                    <li class="li"><samp class="ph codeph">TIME</samp>, <samp class="ph codeph">BATCH</samp>, <samp class="ph codeph">BEAM</samp> and
                                       						<samp class="ph codeph">VECT </samp>dimensions
                                    </li>
                                    <li class="li">data layout</li>
                                    <li class="li">the length of each sequence along the <samp class="ph codeph">TIME</samp> dimension
                                    </li>
                                    <li class="li">an optional value to be copied to output padding vectors</li>
                                 </ul>
                              </div>
                              <p class="p">Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateSeqDataDescriptor" title="This function creates one instance of an opaque sequence data descriptor object by allocating the host memory for it and initializing all descriptor fields. The function writes NULL to seqDataDesc when the sequence data descriptor object cannot be allocated." shape="rect">cudnnCreateSeqDataDescriptor()</a></samp> function to create one
                                 			instance of the sequence data descriptor object and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroySeqDataDescriptor" title="This function destroys the sequence data descriptor object and releases its memory. The seqDataDesc argument can be NULL. Invoking cudnnDestroySeqDataDescriptor() with a NULL argument is a no operation (NOP)." shape="rect">cudnnDestroySeqDataDescriptor()</a></samp> to delete a previously created
                                 			descriptor. Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSeqDataDescriptor" title="This function initializes a previously created sequence data descriptor object. In the most simplified view, this descriptor defines dimensions (dimA) and the data layout (axes) of a four-dimensional tensor." shape="rect">cudnnSetSeqDataDescriptor()</a></samp> function
                                 			to configure the descriptor.
                              </p>
                              <p class="p">This descriptor is used by multi-head attention API functions.</p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnn-adv-infer-so-enum-types"><a name="cudnn-adv-infer-so-enum-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-adv-infer-so-enum-types" name="cudnn-adv-infer-so-enum-types" shape="rect">7.1.2.&nbsp;Enumeration Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the enumeration types in the <samp class="ph codeph">cudnn_adv_infer.so</samp>
                                 library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnDirectionMode_t"><a name="cudnnDirectionMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDirectionMode_t" name="cudnnDirectionMode_t" shape="rect">7.1.2.1.&nbsp;<kbd class="ph userinput">cudnnDirectionMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnDirectionMode_t</samp> is an enumerated type used to specify the
                                 recurrence pattern in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp> routines. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnDirectionMode_t__section_qy2_l2r_2jb"><a name="cudnnDirectionMode_t__section_qy2_l2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp></dt>
                                       <dd class="dd">The network iterates recurrently from the first input to the last.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp></dt>
                                       <dd class="dd">Each layer of the network iterates recurrently from the first input to
                                          the last and separately from the last input to the first. The outputs of
                                          the two are concatenated at each iteration giving the output of the
                                          layer.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnForwardMode_t"><a name="cudnnForwardMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnForwardMode_t" name="cudnnForwardMode_t" shape="rect">7.1.2.2.&nbsp;<kbd class="ph userinput">cudnnForwardMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnForwardMode_t</samp> is an enumerated type to specify inference or
                                    training mode in RNN API. This parameter allows the cuDNN library to tune more precisely
                                    the size of the workspace buffer that could be different in inference and training
                                    regimens.</span></div>
                              <div class="section" id="cudnnForwardMode_t__section_pzn_ndr_2jb"><a name="cudnnForwardMode_t__section_pzn_ndr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FWD_MODE_INFERENCE</samp></dt>
                                       <dd class="dd">Selects the inference mode.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_FWD_MODE_TRAINING</samp></dt>
                                       <dd class="dd">Selects the training mode.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnMultiHeadAttnWeightKind_t"><a name="cudnnMultiHeadAttnWeightKind_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnWeightKind_t" name="cudnnMultiHeadAttnWeightKind_t" shape="rect">7.1.2.3.&nbsp;<kbd class="ph userinput">cudnnMultiHeadAttnWeightKind_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnMultiHeadAttnWeightKind_t</samp> is an enumerated type that specifies a
                                 		group of weights or biases in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetMultiHeadAttnWeights" shape="rect">cudnnGetMultiHeadAttnWeights()</a></samp> function. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnMultiHeadAttnWeightKind_t__section_rdp_gfr_2jb"><a name="cudnnMultiHeadAttnWeightKind_t__section_rdp_gfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_Q_WEIGHTS</samp></dt>
                                       <dd class="dd">Selects the input projection weights for <samp class="ph codeph">queries</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_K_WEIGHTS</samp></dt>
                                       <dd class="dd">Selects the input projection weights for <samp class="ph codeph">keys</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_V_WEIGHTS</samp></dt>
                                       <dd class="dd">Selects the input projection weights for <samp class="ph codeph">values</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_O_WEIGHTS</samp></dt>
                                       <dd class="dd">Selects the output projection weights.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_Q_BIASES</samp></dt>
                                       <dd class="dd">Selects the input projection biases for <samp class="ph codeph">queries</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_K_BIASES</samp></dt>
                                       <dd class="dd">Selects the input projection biases for <samp class="ph codeph">keys</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_V_BIASES</samp></dt>
                                       <dd class="dd">Selects the input projection biases for <samp class="ph codeph">values</samp>.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_MH_ATTN_O_BIASES</samp></dt>
                                       <dd class="dd">Selects the output projection biases.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNBiasMode_t"><a name="cudnnRNNBiasMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBiasMode_t" name="cudnnRNNBiasMode_t" shape="rect">7.1.2.4.&nbsp;<kbd class="ph userinput">cudnnRNNBiasMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNBiasMode_t</samp> is an enumerated type used to specify the number
                                 of bias vectors for RNN functions. Refer to the description of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNMode_t" shape="rect">cudnnRNNMode_t</a></samp> enumerated type for the
                                 equations for each cell type based on the bias mode. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnRNNBiasMode_t__section_bly_qfr_2jb"><a name="cudnnRNNBiasMode_t__section_bly_qfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_NO_BIAS</samp></dt>
                                       <dd class="dd">Applies RNN cell formulas that do not use biases.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp></dt>
                                       <dd class="dd">Applies RNN cell formulas that use one input bias vector in the input
                                          GEMM.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></dt>
                                       <dd class="dd">Applies RNN cell formulas that use two bias vectors.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp></dt>
                                       <dd class="dd">Applies RNN cell formulas that use one recurrent bias vector in the
                                          recurrent GEMM.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNClipMode_t"><a name="cudnnRNNClipMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNClipMode_t" name="cudnnRNNClipMode_t" shape="rect">7.1.2.5.&nbsp;<kbd class="ph userinput">cudnnRNNClipMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNClipMode_t</samp> is an enumerated type used to select the LSTM cell
                                 clipping mode. It is used with <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNSetClip" shape="rect">cudnnRNNSetClip()</a></samp>,
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNGetClip" shape="rect">cudnnRNNGetClip()</a></samp> functions, and internally within
                                 LSTM cells.  <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnRNNClipMode_t__section_syz_rfr_2jb"><a name="cudnnRNNClipMode_t__section_syz_rfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_CLIP_NONE</samp></dt>
                                       <dd class="dd">Disables LSTM cell clipping.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_CLIP_MINMAX</samp></dt>
                                       <dd class="dd">Enables LSTM cell clipping.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNDataLayout_t"><a name="cudnnRNNDataLayout_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNDataLayout_t" name="cudnnRNNDataLayout_t" shape="rect">7.1.2.6.&nbsp;<kbd class="ph userinput">cudnnRNNDataLayout_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNDataLayout_t</samp> is an enumerated type used to select the RNN
                                 data layout. It is used in the API calls <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDataDescriptor" title="This function retrieves a previously created RNN data descriptor object." shape="rect">cudnnGetRNNDataDescriptor()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDataDescriptor" title="This function initializes a previously created RNN data descriptor object. This data structure is intended to support the unpacked (padded) layout for input and output of extended RNN inference and training functions. A packed (unpadded) layout is also supported for backward compatibility." shape="rect">cudnnSetRNNDataDescriptor()</a></samp>.
                                 <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnRNNDataLayout_t__section_hth_tfr_2jb"><a name="cudnnRNNDataLayout_t__section_hth_tfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED</samp></dt>
                                       <dd class="dd">Data layout is padded, with outer stride from one time-step to the
                                          next.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_PACKED</samp></dt>
                                       <dd class="dd">The sequence length is sorted and packed as in the basic RNN API.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED</samp></dt>
                                       <dd class="dd">Data layout is padded, with outer stride from one batch to the
                                          next.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNInputMode_t"><a name="cudnnRNNInputMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNInputMode_t" name="cudnnRNNInputMode_t" shape="rect">7.1.2.7.&nbsp;<kbd class="ph userinput">cudnnRNNInputMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNInputMode_t</samp> is an enumerated type used to specify the
                                 behavior of the first layer in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp> routines.  <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnRNNInputMode_t__section_xlt_5fr_2jb"><a name="cudnnRNNInputMode_t__section_xlt_5fr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_LINEAR_INPUT</samp></dt>
                                       <dd class="dd">A biased matrix multiplication is performed at the input of the first
                                          recurrent layer.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SKIP_INPUT</samp></dt>
                                       <dd class="dd">No operation is performed at the input of the first recurrent layer. If
                                          <samp class="ph codeph">CUDNN_SKIP_INPUT</samp> is used the leading dimension of
                                          the input tensor must be equal to the hidden state size of the
                                          network.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNMode_t"><a name="cudnnRNNMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNMode_t" name="cudnnRNNMode_t" shape="rect">7.1.2.8.&nbsp;<kbd class="ph userinput">cudnnRNNMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnRNNMode_t</samp> is an enumerated type used to specify the type of
                                 		network used in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining</a></samp>,
                                 				<samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData</a></samp>
                                 		and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights</a></samp> routines.  <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnRNNMode_t__section_fmg_wfr_2jb"><a name="cudnnRNNMode_t__section_fmg_wfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_RELU</samp></dt>
                                       <dd class="dd">
                                          <p class="p">A single-gate recurrent neural network with a ReLU activation
                                             								function.
                                          </p>
                                          <p class="p">In the forward pass, the output 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 for a given iteration can be computed from the
                                             								recurrent input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo fontfamily="Times New Roman" lspace="0px" rspace="0px">-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and the previous layer input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								, given the matrices <samp class="ph codeph">W</samp>,
                                             									<samp class="ph codeph">R</samp> and the bias vectors, where 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi>ReLU</mi>
                                                   <mtext>&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mi>x</mi>
                                                   <mo>)</mo>
                                                   <mtext>&nbsp;</mtext>
                                                   <mo>=</mo>
                                                   <mtext>&nbsp;</mtext>
                                                   <mi>max</mi>
                                                   <mtext>&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mi>x, 0</mi>
                                                   <mo>)</mo>
                                                </mrow>
                                             </math>
                                             								.
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp> (default mode), then the
                                             								following equation with biases 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>W</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>R</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 applies: 
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>=</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mi>ReLU</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <msub>
                                                         <mi>W</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>x</mi>
                                                         <mi>t</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>R</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>h</mi>
                                                         <mrow>
                                                            <mi>t</mi>
                                                            <mo>-</mo>
                                                            <mn>1</mn>
                                                         </mrow>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>b</mi>
                                                         <mi>Wi</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>b</mi>
                                                         <mi>Ri</mi>
                                                      </msub>
                                                   </mrow>
                                                   <mo>)</mo>
                                                </mrow>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in <samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp> or
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>, then the following
                                             								equation with bias 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 applies: 
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>=</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mi>ReLU</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <msub>
                                                         <mi>W</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>x</mi>
                                                         <mi>t</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>R</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>h</mi>
                                                         <mrow>
                                                            <mi>t</mi>
                                                            <mo>-</mo>
                                                            <mn>1</mn>
                                                         </mrow>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>b</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                   </mrow>
                                                   <mo>)</mo>
                                                </mrow>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is <samp class="ph codeph">CUDNN_RNN_NO_BIAS</samp>,
                                             								then the following equation applies: 
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>=</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mi>ReLU</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <msub>
                                                         <mi>W</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>x</mi>
                                                         <mi>t</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>R</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>h</mi>
                                                         <mrow>
                                                            <mi>t</mi>
                                                            <mo>-</mo>
                                                            <mn>1</mn>
                                                         </mrow>
                                                      </msub>
                                                   </mrow>
                                                   <mo>)</mo>
                                                </mrow>
                                             </math>
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_TANH</samp></dt>
                                       <dd class="dd">
                                          <p class="p">A single-gate recurrent neural network with a <samp class="ph codeph">tanh</samp>
                                             								activation function.
                                          </p>
                                          <p class="p">In the forward pass, the output 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 for a given iteration can be computed from the
                                             								recurrent input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo fontfamily="Times New Roman" lspace="0px" rspace="0px">-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and the previous layer input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								, given the matrices <samp class="ph codeph">W</samp>,
                                             									<samp class="ph codeph">R</samp> and the bias vectors, and where
                                             									<samp class="ph codeph">tanh</samp> is the hyperbolic tangent function. 
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp> (default mode), then the
                                             								following equation with biases 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>W</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>R</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 applies:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>=</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mi>tanh</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <msub>
                                                         <mi>W</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>x</mi>
                                                         <mi>t</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>R</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>h</mi>
                                                         <mrow>
                                                            <mi>t</mi>
                                                            <mo>-</mo>
                                                            <mn>1</mn>
                                                         </mrow>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>b</mi>
                                                         <mi>Wi</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>b</mi>
                                                         <mi>Ri</mi>
                                                      </msub>
                                                   </mrow>
                                                   <mo>)</mo>
                                                </mrow>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in <samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp> or
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>, then the following
                                             								equation with bias 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 applies:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>=</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mi>tanh</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <msub>
                                                         <mi>W</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>x</mi>
                                                         <mi>t</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>R</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>h</mi>
                                                         <mrow>
                                                            <mi>t</mi>
                                                            <mo>-</mo>
                                                            <mn>1</mn>
                                                         </mrow>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>b</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                   </mrow>
                                                   <mo>)</mo>
                                                </mrow>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is <samp class="ph codeph">CUDNN_RNN_NO_BIAS</samp>,
                                             								then the following equation applies:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>=</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mi>tanh</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <msub>
                                                         <mi>W</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>x</mi>
                                                         <mi>t</mi>
                                                      </msub>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>+</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <msub>
                                                         <mi>R</mi>
                                                         <mi>i</mi>
                                                      </msub>
                                                      <msub>
                                                         <mi>h</mi>
                                                         <mrow>
                                                            <mi>t</mi>
                                                            <mo>-</mo>
                                                            <mn>1</mn>
                                                         </mrow>
                                                      </msub>
                                                   </mrow>
                                                   <mo>)</mo>
                                                </mrow>
                                             </math>
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_LSTM</samp></dt>
                                       <dd class="dd">
                                          <p class="p">A four-gate Long Short-Term Memory (LSTM) network with no peephole
                                             								connections.
                                          </p>
                                          <p class="p">In the forward pass, the output 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and cell output 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>c</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 for a given iteration can be computed from the
                                             								recurrent input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo fontfamily="Times New Roman" lspace="0px" rspace="0px">-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								, the cell input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>c</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo fontfamily="Times New Roman" lspace="0px" rspace="0px">-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and the previous layer input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								, given the matrices <samp class="ph codeph">W</samp>,
                                             									<samp class="ph codeph">R</samp> and the bias vectors. 
                                          </p>
                                          <div class="p">In addition, the following applies:<a name="cudnnRNNMode_t__ul_ybz_jhb_nhb" shape="rect">
                                                <!-- --></a><ul class="ul" id="cudnnRNNMode_t__ul_ybz_jhb_nhb">
                                                <li class="li liexpand">
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mrow>
                                                         <mo></mo>
                                                      </mrow>
                                                   </math>
                                                   										 is the sigmoid operator such that: 
                                                   											
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mrow>
                                                         <mo></mo>
                                                         <mo>(</mo>
                                                         <mi>x</mi>
                                                         <mo>)</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mo>=</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mn>1</mn>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mo>/</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mo>(</mo>
                                                         <mrow>
                                                            <mn>1</mn>
                                                            <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                            <mo>+</mo>
                                                            <msup>
                                                               <mi>e</mi>
                                                               <mrow>
                                                                  <mo>-</mo>
                                                                  <mi>x</mi>
                                                               </mrow>
                                                            </msup>
                                                            <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         </mrow>
                                                         <mo>)</mo>
                                                      </mrow>
                                                   </math>
                                                   										,
                                                </li>
                                                <li class="li liexpand">
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mo></mo>
                                                   </math>
                                                   										 represents a point-wise multiplication, 
                                                </li>
                                                <li class="li liexpand"><samp class="ph codeph">tanh</samp> is the hyperbolic tangent function,
                                                   										and
                                                </li>
                                                <li class="li liexpand">
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mrow>
                                                         <msub>
                                                            <mi>i</mi>
                                                            <mi>t</mi>
                                                         </msub>
                                                         <mo>,</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <msub>
                                                            <mi>f</mi>
                                                            <mi>t</mi>
                                                         </msub>
                                                         <mo>,</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <msub>
                                                            <mi>o</mi>
                                                            <mi>t</mi>
                                                         </msub>
                                                         <mo>,</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <msub>
                                                            <mrow>
                                                               <mi>c</mi>
                                                               <mo lspace="0px" form="infix"></mo>
                                                            </mrow>
                                                            <mi>t</mi>
                                                         </msub>
                                                      </mrow>
                                                   </math>
                                                   										 represent the input, forget, output and new
                                                   										gates respectively. 
                                                </li>
                                             </ul>
                                          </div>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp> (default mode), then the
                                             								following equations with biases 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>W</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>R</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 apply:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wi</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Ri</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>f</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>f</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>f</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wf</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Rf</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>o</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>o</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>o</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wo</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Ro</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mrow>
                                                      <mi>c</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>c</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>c</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wc</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Rc</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>c</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>f</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>c</mi>
                                                   <mrow>
                                                      <mi>t</mi>
                                                      <mo>-</mo>
                                                      <mn>1</mn>
                                                   </mrow>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>+</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <msub>
                                                   <mrow>
                                                      <mi>c</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>h</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>o</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <msub>
                                                   <mi>c</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in <samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp> or
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>, then the following
                                             								equations with bias 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 apply:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>f</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>f</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>f</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>f</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>o</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>o</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>o</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>o</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mrow>
                                                      <mi>c</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>c</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>c</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>c</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>c</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>f</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>c</mi>
                                                   <mrow>
                                                      <mi>t</mi>
                                                      <mo>-</mo>
                                                      <mn>1</mn>
                                                   </mrow>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>+</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <msub>
                                                   <mrow>
                                                      <mi>c</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>h</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>o</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <msub>
                                                   <mi>c</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is <samp class="ph codeph">CUDNN_RNN_NO_BIAS</samp>,
                                             								then the following equations apply:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>f</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>f</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>f</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>o</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>o</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>o</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mrow>
                                                      <mi>c</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>c</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>c</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>c</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>f</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>c</mi>
                                                   <mrow>
                                                      <mi>t</mi>
                                                      <mo>-</mo>
                                                      <mn>1</mn>
                                                   </mrow>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>+</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <msub>
                                                   <mrow>
                                                      <mi>c</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>h</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>o</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <msub>
                                                   <mi>c</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_GRU</samp></dt>
                                       <dd class="dd">
                                          <p class="p">A three-gate network consisting of Gated Recurrent Units.</p>
                                          <p class="p">In the forward pass, the output 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 for a given iteration can be computed from the
                                             								recurrent input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo fontfamily="Times New Roman" lspace="0px" rspace="0px">-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and the previous layer input 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 given matrices <samp class="ph codeph">W</samp>, <samp class="ph codeph">R</samp>
                                             								and the bias vectors.
                                          </p>
                                          <div class="p">In addition, the following applies:<a name="cudnnRNNMode_t__ul_hxv_fcn_y3b" shape="rect">
                                                <!-- --></a><ul class="ul" id="cudnnRNNMode_t__ul_hxv_fcn_y3b">
                                                <li class="li liexpand">
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mrow>
                                                         <mo></mo>
                                                      </mrow>
                                                   </math>
                                                   										 is the sigmoid operator such that: 
                                                   											
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mrow>
                                                         <mo></mo>
                                                         <mo>(</mo>
                                                         <mi>x</mi>
                                                         <mo>)</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mo>=</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mn>1</mn>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mo>/</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <mo>(</mo>
                                                         <mrow>
                                                            <mn>1</mn>
                                                            <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                            <mo>+</mo>
                                                            <msup>
                                                               <mi>e</mi>
                                                               <mrow>
                                                                  <mo>-</mo>
                                                                  <mi>x</mi>
                                                               </mrow>
                                                            </msup>
                                                            <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         </mrow>
                                                         <mo>)</mo>
                                                      </mrow>
                                                   </math>
                                                   										,
                                                </li>
                                                <li class="li liexpand">
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mo></mo>
                                                   </math>
                                                   										 represents a point-wise multiplication, 
                                                </li>
                                                <li class="li liexpand"><samp class="ph codeph">tanh</samp> is the hyperbolic tangent function,
                                                   										and
                                                </li>
                                                <li class="li liexpand">
                                                   <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                      <mrow>
                                                         <msub>
                                                            <mi>i</mi>
                                                            <mi>t</mi>
                                                         </msub>
                                                         <mo>,</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <msub>
                                                            <mi>r</mi>
                                                            <mi>t</mi>
                                                         </msub>
                                                         <mo>,</mo>
                                                         <mo>,</mo>
                                                         <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         <msub>
                                                            <mrow>
                                                               <mi>h</mi>
                                                               <mo lspace="0px" form="infix"></mo>
                                                            </mrow>
                                                            <mi>t</mi>
                                                         </msub>
                                                      </mrow>
                                                   </math>
                                                   										 represent the input, reset, and new gates
                                                   										respectively. 
                                                </li>
                                             </ul>
                                          </div>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp> (default mode), then the
                                             								following equations with biases 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>W</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 and 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>R</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 apply:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wi</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Ru</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>r</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wr</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Rr</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>r</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo></mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t-1</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Rh</mi>
                                                   </msub>
                                                   <mo>)</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wh</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>h</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mo>1</mo>
                                                <mo>-</mo>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mo>)</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>+</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mrow>
                                                      <mi>t</mi>
                                                   </mrow>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                   </mrow>
                                                   <mi>t-1</mi>
                                                </msub>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in <samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp>, then the following
                                             								equations with bias 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 apply:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>r</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>r</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo></mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t-1</mi>
                                                   </msub>
                                                   <mo>)</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Wh</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>h</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mo>1</mo>
                                                <mo>-</mo>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mo>)</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>+</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mrow>
                                                      <mi>t</mi>
                                                   </mrow>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                   </mrow>
                                                   <mi>t-1</mi>
                                                </msub>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in <samp class="ph codeph">rnnDesc</samp> is
                                             									<samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>, then the following
                                             								equations with bias 
                                             									
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <msub>
                                                      <mi>b</mi>
                                                   </msub>
                                                </mrow>
                                             </math>
                                             								 apply:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>r</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>r</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo></mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t-1</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msub>
                                                      <mi>b</mi>
                                                      <mi>Rh</mi>
                                                   </msub>
                                                   <mo>)</mo>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>h</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mo>1</mo>
                                                <mo>-</mo>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mo>)</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>+</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mrow>
                                                      <mi>t</mi>
                                                   </mrow>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                   </mrow>
                                                   <mi>t-1</mi>
                                                </msub>
                                             </math>
                                          </p>
                                          <p class="p">If <samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp> in
                                             									<samp class="ph codeph">rnnDesc</samp> is <samp class="ph codeph">CUDNN_RNN_NO_BIAS</samp>,
                                             								then the following equations apply:
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>i</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>r</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>r</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mrow>
                                                         <mi>t</mi>
                                                         <mo>-</mo>
                                                         <mn>1</mn>
                                                      </mrow>
                                                   </msub>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>tanh</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <msub>
                                                      <mi>W</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>x</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <msub>
                                                      <mi>r</mi>
                                                      <mi>t</mi>
                                                   </msub>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo></mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <msub>
                                                      <mi>R</mi>
                                                      <mi>h</mi>
                                                   </msub>
                                                   <msub>
                                                      <mi>h</mi>
                                                      <mi>t-1</mi>
                                                   </msub>
                                                   <mo>)</mo>
                                                </mrow>
                                                <mo>)</mo>
                                             </math>
                                          </p>
                                          <p class="p">
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <msub>
                                                   <mi>h</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>=</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mo>1</mo>
                                                <mo>-</mo>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mi>t</mi>
                                                </msub>
                                                <mo>)</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                      <mo lspace="0px" form="infix"></mo>
                                                   </mrow>
                                                   <mi>t</mi>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>+</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <msub>
                                                   <mi>i</mi>
                                                   <mrow>
                                                      <mi>t</mi>
                                                   </mrow>
                                                </msub>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo></mo>
                                                <msub>
                                                   <mrow>
                                                      <mi>h</mi>
                                                   </mrow>
                                                   <mi>t-1</mi>
                                                </msub>
                                             </math>
                                          </p>
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRNNPaddingMode_t"><a name="cudnnRNNPaddingMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNPaddingMode_t" name="cudnnRNNPaddingMode_t" shape="rect">7.1.2.9.&nbsp;<kbd class="ph userinput">cudnnRNNPaddingMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnRNNPaddingMode_t</samp> is an enumerated type used to enable or
                                    disable the padded input/output.</span></div>
                              <div class="section" id="cudnnRNNPaddingMode_t__section_ylg_xfr_2jb"><a name="cudnnRNNPaddingMode_t__section_ylg_xfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_PADDED_IO_DISABLED</samp></dt>
                                       <dd class="dd">Disables the padded input/output.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNN_PADDED_IO_ENABLED </samp></dt>
                                       <dd class="dd">Enables the padded input/output.</dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSeqDataAxis_t"><a name="cudnnSeqDataAxis_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSeqDataAxis_t" name="cudnnSeqDataAxis_t" shape="rect">7.1.2.10.&nbsp;<kbd class="ph userinput">cudnnSeqDataAxis_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnSeqDataAxis_t</samp> is an enumerated type that indexes active
                                 		dimensions in the <samp class="ph codeph">dimA[]</samp> argument that is passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSeqDataDescriptor" title="This function initializes a previously created sequence data descriptor object. In the most simplified view, this descriptor defines dimensions (dimA) and the data layout (axes) of a four-dimensional tensor." shape="rect">cudnnSetSeqDataDescriptor()</a></samp> function to configure the sequence
                                 		data descriptor of type <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp>. <span class="shortdesc"></span></div>
                              <p class="p"><samp class="ph codeph">cudnnSeqDataAxis_t</samp> constants are also used in the <samp class="ph codeph">axis[]</samp>
                                 			argument of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSeqDataDescriptor" title="This function initializes a previously created sequence data descriptor object. In the most simplified view, this descriptor defines dimensions (dimA) and the data layout (axes) of a four-dimensional tensor." shape="rect">cudnnSetSeqDataDescriptor()</a></samp> call to
                                 			define the layout of the sequence data buffer in memory.
                              </p>
                              <p class="p">Refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSeqDataDescriptor" title="This function initializes a previously created sequence data descriptor object. In the most simplified view, this descriptor defines dimensions (dimA) and the data layout (axes) of a four-dimensional tensor." shape="rect">cudnnSetSeqDataDescriptor()</a></samp> for a detailed description
                                 			on how to use the <samp class="ph codeph">cudnnSeqDataAxis_t</samp> enumerated type.
                              </p>
                              <p class="p">The <samp class="ph codeph">CUDNN_SEQDATA_DIM_COUNT</samp> macro defines the number of constants in the
                                 				<samp class="ph codeph">cudnnSeqDataAxis_t</samp> enumerated type. This value is currently set to
                                 				<samp class="ph codeph">4</samp>.
                              </p>
                              <div class="section" id="cudnnSeqDataAxis_t__section_n1f_zfr_2jb"><a name="cudnnSeqDataAxis_t__section_n1f_zfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEQDATA_TIME_DIM</samp></dt>
                                       <dd class="dd">Identifies the <samp class="ph codeph">TIME</samp> (sequence length) dimension or
                                          							specifies the <samp class="ph codeph">TIME</samp> in the data layout.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEQDATA_BATCH_DIM</samp></dt>
                                       <dd class="dd">Identifies the <samp class="ph codeph">BATCH</samp> dimension or specifies the
                                          								<samp class="ph codeph">BATCH</samp> in the data layout.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEQDATA_BEAM_DIM</samp></dt>
                                       <dd class="dd">Identifies the <samp class="ph codeph">BEAM</samp> dimension or specifies the
                                          								<samp class="ph codeph">BEAM</samp> in the data layout.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SEQDATA_VECT_DIM</samp></dt>
                                       <dd class="dd">Identifies the <samp class="ph codeph">VECT</samp> (vector) dimension or specifies the
                                          								<samp class="ph codeph">VECT</samp> in the data layout.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnn-adv-infer-so-api"><a name="cudnn-adv-infer-so-api" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-adv-infer-so-api" name="cudnn-adv-infer-so-api" shape="rect">7.2.&nbsp;API Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the API functions in the <samp class="ph codeph">cudnn_adv_infer.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnnAdvInferVersionCheck"><a name="cudnnAdvInferVersionCheck" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAdvInferVersionCheck" name="cudnnAdvInferVersionCheck" shape="rect">7.2.1.&nbsp;<kbd class="ph userinput">cudnnAdvInferVersionCheck()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function checks to see whether the version of the AdvInfer subset of the
                                 library is consistent with the other sub-libraries.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnAdvInferVersionCheck(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)</pre><div class="section" id="cudnnAdvInferVersionCheck__section_zpy_xzc_z3b"><a name="cudnnAdvInferVersionCheck__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The version is consistent with other sub-libraries.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_VERSION_MISMATCH</samp></dt>
                                    <dd class="dd">The version of <samp class="ph codeph">AdvInfer</samp> is not consistent with other
                                       sub-libraries. Users should check the installation and make sure all
                                       sub-component versions are consistent.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBuildRNNDynamic"><a name="cudnnBuildRNNDynamic" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBuildRNNDynamic" name="cudnnBuildRNNDynamic" shape="rect">7.2.2.&nbsp;<kbd class="ph userinput">cudnnBuildRNNDynamic()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function compiles the RNN persistent code using CUDA runtime compilation
                                 library (NVRTC) when the <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> algo is
                                 selected. The code is tailored to the current GPU and specific hyperparameters
                                 (<samp class="ph codeph">miniBatch</samp>). This call is expected to be expensive in terms of
                                 runtime and should be invoked infrequently. Note that the
                                 <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> algo does not support variable
                                 length sequences within the batch.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnBuildRNNDynamic(
	cudnnHandle_t handle,
	cudnnRNNDescriptor_t rnnDesc,
	int32_t miniBatch);
</pre><div class="section" id="cudnnBuildRNNDynamic__section_zpy_xzc_z3b"><a name="cudnnBuildRNNDynamic__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">miniBatch</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The exact number of sequences in a batch.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBuildRNNDynamic__section_dt1_ynb_wlb"><a name="cudnnBuildRNNDynamic__section_dt1_ynb_wlb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The code was built and linked successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">
                                       <p class="p">A GPU/CUDA resource, such as a texture object, shared memory, or
                                          zero-copy memory is not available in the required size or there is a
                                          mismatch between the user resource and cuDNN internal resources. A
                                          resource mismatch may occur, for example, when calling
                                          <samp class="ph codeph">cudnnSetStream()</samp>. There could be a mismatch
                                          between the user provided CUDA stream and the internal CUDA events
                                          instantiated in the cuDNN handle when <samp class="ph codeph">cudnnCreate()</samp>
                                          was invoked.
                                       </p>
                                       <p class="p">This error status may not be correctable when it is related to
                                          texture dimensions, shared memory size, or zero-copy memory
                                          availability. If <samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp> is
                                          returned by <samp class="ph codeph">cudnnSetStream()</samp>, then it is typically
                                          correctable, however, it means that the cuDNN handle was created on
                                          one GPU and the user stream passed to this function is associated
                                          with another GPU.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING</samp></dt>
                                    <dd class="dd">The prerequisite runtime library could not be found.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The current hyper-parameters are invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateAttnDescriptor"><a name="cudnnCreateAttnDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateAttnDescriptor" name="cudnnCreateAttnDescriptor" shape="rect">7.2.3.&nbsp;<kbd class="ph userinput">cudnnCreateAttnDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates one instance of an opaque attention descriptor object by
                                 			allocating the host memory for it and initializing all descriptor fields. The function
                                 			writes <samp class="ph codeph">NULL</samp> to <samp class="ph codeph">attnDesc</samp> when the attention descriptor
                                 			object cannot be allocated.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateAttnDescriptor(cudnnAttnDescriptor_t *attnDesc);</pre><p class="p">Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetAttnDescriptor" shape="rect">cudnnSetAttnDescriptor()</a></samp> function to configure the
                              			attention descriptor and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroyAttnDescriptor" title="This function destroys the attention descriptor object and releases its memory. The attnDesc argument can be NULL. Invoking cudnnDestroyAttnDescriptor() with a NULL argument is a no operation (NOP)." shape="rect">cudnnDestroyAttnDescriptor()</a></samp> to
                              			destroy it and release the allocated memory.
                           </p>
                           <div class="section" id="cudnnCreateAttnDescriptor__section_syl_qwb_z3b"><a name="cudnnCreateAttnDescriptor__section_syl_qwb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Pointer where the address to the newly created attention
                                       							descriptor should be written.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateAttnDescriptor__section_gn4_swb_z3b"><a name="cudnnCreateAttnDescriptor__section_gn4_swb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was encountered
                                       								(<samp class="ph codeph">attnDesc=NULL</samp>).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The memory allocation failed.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreatePersistentRNNPlan"><a name="cudnnCreatePersistentRNNPlan" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreatePersistentRNNPlan" name="cudnnCreatePersistentRNNPlan" shape="rect">7.2.4.&nbsp;<kbd class="ph userinput">cudnnCreatePersistentRNNPlan()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnBuildRNNDynamic" title="This function compiles the RNN persistent code using CUDA runtime compilation library (NVRTC) when the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo is selected. The code is tailored to the current GPU and specific hyperparameters (miniBatch). This call is expected to be expensive in terms of runtime and should be invoked infrequently. Note that the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo does not support variable length sequences within the batch." shape="rect">cudnnBuildRNNDynamic()</a></samp> instead of
                              <samp class="ph codeph">cudnnCreatePersistentRNNPlan()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreatePersistentRNNPlan(
    cudnnRNNDescriptor_t        rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                   minibatch,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnDataType_t       dataType,
    cudnnPersistentRNNPlan_t   *plan)</pre><p class="p">This function creates a plan to execute persistent RNNs when using the
                              <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> algo. This plan is tailored to the
                              current GPU and RNN model hyperparameters. This function call is expected to be
                              expensive in terms of runtime and should be used infrequently. However, the user must
                              invoke <samp class="ph codeph">cudnnCreatePersistentRNNPlan()</samp> every time the number of input
                              vectors changes in a minibatch. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNDescriptor_t" shape="rect">cudnnRNNDescriptor_t</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></samp>, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnPersistentRNNPlan_t" title="This function is deprecated starting in cuDNN 8.0.0." shape="rect">cudnnPersistentRNNPlan_t</a></samp>.
                           </p>
                           <div class="section" id="cudnnCreatePersistentRNNPlan__section_vvc_vqh_jvb"><a name="cudnnCreatePersistentRNNPlan__section_vvc_vqh_jvb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">minibatch</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The exact number of vectors in a batch.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies data type for RNN weights/biases and input and
                                       output data.
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">plan</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Pointer to where the address to the newly created RNN
                                       persistent plan should be written.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreatePersistentRNNPlan__section_lgf_mkc_z3b"><a name="cudnnCreatePersistentRNNPlan__section_lgf_mkc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">
                                       <p class="p">A GPU/CUDA resource, such as a texture object, shared memory, or
                                          zero-copy memory is not available in the required size or there is a
                                          mismatch between the user resource and cuDNN internal resources. A
                                          resource mismatch may occur, for example, when calling
                                          <samp class="ph codeph">cudnnSetStream()</samp>. There could be a mismatch
                                          between the user provided CUDA stream and the internal CUDA events
                                          instantiated in the cuDNN handle when <samp class="ph codeph">cudnnCreate()</samp>
                                          was invoked.
                                       </p>
                                       <p class="p">This error status may not be correctable when it is related to
                                          texture dimensions, shared memory size, or zero-copy memory
                                          availability. If <samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp> is
                                          returned by <samp class="ph codeph">cudnnSetStream()</samp>, then it is typically
                                          correctable, however, it means that the cuDNN handle was created on
                                          one GPU and the user stream passed to this function is associated
                                          with another GPU.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING</samp></dt>
                                    <dd class="dd">A prerequisite runtime library cannot be found.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The current hyperparameters are invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateRNNDataDescriptor"><a name="cudnnCreateRNNDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateRNNDataDescriptor" name="cudnnCreateRNNDataDescriptor" shape="rect">7.2.5.&nbsp;<kbd class="ph userinput">cudnnCreateRNNDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates a RNN data descriptor object by allocating the memory
                                 needed to hold its opaque structure. </span></div><pre xml:space="preserve">
cudnnStatus_t cudnnCreateRNNDataDescriptor(
    cudnnRNNDataDescriptor_t *RNNDataDesc)
</pre><div class="section" id="cudnnCreateRNNDataDescriptor__section_ffn_drh_jvb"><a name="cudnnCreateRNNDataDescriptor__section_ffn_drh_jvb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">RNNDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Pointer to where the address to the newly created RNN
                                       data descriptor should be written.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateRNNDataDescriptor__section_dyh_wkc_z3b"><a name="cudnnCreateRNNDataDescriptor__section_dyh_wkc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The RNN data descriptor object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">RNNDataDesc</samp> argument is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateRNNDescriptor"><a name="cudnnCreateRNNDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateRNNDescriptor" name="cudnnCreateRNNDescriptor" shape="rect">7.2.6.&nbsp;<kbd class="ph userinput">cudnnCreateRNNDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates a generic RNN descriptor object by allocating the memory
                                 needed to hold its opaque structure.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateRNNDescriptor(
    cudnnRNNDescriptor_t    *rnnDesc)</pre><div class="section" id="cudnnCreateRNNDescriptor__section_ll3_krh_jvb"><a name="cudnnCreateRNNDescriptor__section_ll3_krh_jvb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Pointer to where the address to the newly created RNN
                                       descriptor should be written.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateRNNDescriptor__section_qr5_1lc_z3b"><a name="cudnnCreateRNNDescriptor__section_qr5_1lc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">rnnDesc</samp> argument is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The resources could not be allocated.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateSeqDataDescriptor"><a name="cudnnCreateSeqDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateSeqDataDescriptor" name="cudnnCreateSeqDataDescriptor" shape="rect">7.2.7.&nbsp;<kbd class="ph userinput">cudnnCreateSeqDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates one instance of an opaque sequence data descriptor object
                                 			by allocating the host memory for it and initializing all descriptor fields. The
                                 			function writes <samp class="ph codeph">NULL</samp> to <samp class="ph codeph">seqDataDesc</samp> when the sequence
                                 			data descriptor object cannot be allocated.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateSeqDataDescriptor(cudnnSeqDataDescriptor_t *seqDataDesc);	</pre><p class="p">Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSeqDataDescriptor" title="This function initializes a previously created sequence data descriptor object. In the most simplified view, this descriptor defines dimensions (dimA) and the data layout (axes) of a four-dimensional tensor." shape="rect">cudnnSetSeqDataDescriptor()</a></samp> function to configure the
                              			sequence data descriptor and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroySeqDataDescriptor" title="This function destroys the sequence data descriptor object and releases its memory. The seqDataDesc argument can be NULL. Invoking cudnnDestroySeqDataDescriptor() with a NULL argument is a no operation (NOP)." shape="rect">cudnnDestroySeqDataDescriptor()</a></samp> to destroy it and release the allocated memory.
                           </p>
                           <div class="section" id="cudnnCreateSeqDataDescriptor__section_owl_mlc_z3b"><a name="cudnnCreateSeqDataDescriptor__section_owl_mlc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Pointer where the address to the newly created sequence
                                       							data descriptor should be written.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateSeqDataDescriptor__section_ams_nlc_z3b"><a name="cudnnCreateSeqDataDescriptor__section_ams_nlc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor object was created successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was encountered
                                       								(<samp class="ph codeph">seqDataDesc=NULL</samp>).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The memory allocation failed.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyAttnDescriptor"><a name="cudnnDestroyAttnDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyAttnDescriptor" name="cudnnDestroyAttnDescriptor" shape="rect">7.2.8.&nbsp;<kbd class="ph userinput">cudnnDestroyAttnDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys the attention descriptor object and releases its memory.
                                 			The <samp class="ph codeph">attnDesc </samp>argument can be <samp class="ph codeph">NULL</samp>. Invoking
                                 				<samp class="ph codeph">cudnnDestroyAttnDescriptor()</samp> with a <samp class="ph codeph">NULL</samp> argument
                                 			is a no operation (NOP).</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyAttnDescriptor(cudnnAttnDescriptor_t attnDesc);</pre><p class="p">The <samp class="ph codeph">cudnnDestroyAttnDescriptor()</samp> function is not able to detect if the
                              				<samp class="ph codeph">attnDesc </samp> argument holds a valid address. Undefined behavior will
                              			occur in case of passing an invalid pointer, not returned by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateAttnDescriptor" title="This function creates one instance of an opaque attention descriptor object by allocating the host memory for it and initializing all descriptor fields. The function writes NULL to attnDesc when the attention descriptor object cannot be allocated." shape="rect">cudnnCreateAttnDescriptor()</a></samp> function, or in the double
                              			deletion scenario of a valid address.
                           </p>
                           <div class="section" id="cudnnDestroyAttnDescriptor__section_tvk_n1d_z3b"><a name="cudnnDestroyAttnDescriptor__section_tvk_n1d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Pointer to the attention descriptor object to be
                                       							destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyAttnDescriptor__section_klt_41d_z3b"><a name="cudnnDestroyAttnDescriptor__section_klt_41d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyPersistentRNNPlan"><a name="cudnnDestroyPersistentRNNPlan" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyPersistentRNNPlan" name="cudnnDestroyPersistentRNNPlan" shape="rect">7.2.9.&nbsp;<kbd class="ph userinput">cudnnDestroyPersistentRNNPlan()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function destroys a previously created persistent RNN plan object. Invoking
                              <samp class="ph codeph">cudnnDestroyPersistentRNNPlan()</samp> with the <samp class="ph codeph">NULL</samp>
                              argument is a no operation (NOP).
                           </p><pre xml:space="preserve">cudnnStatus_t cudnnDestroyPersistentRNNPlan(
    cudnnPersistentRNNPlan_t plan)</pre><p class="p">The <samp class="ph codeph">cudnnDestroyPersistentRNNPlan()</samp> function is not able to detect if
                              the <samp class="ph codeph">plan</samp> argument holds a valid address. Undefined behavior will occur
                              in cases of passing an invalid pointer, not returned by the
                              <samp class="ph codeph">cudnnCreatePersistentRNNPlan()</samp> function, or in the double deletion
                              scenario of a valid address.
                           </p>
                           <div class="section" id="cudnnDestroyPersistentRNNPlan__section_it3_rrh_jvb"><a name="cudnnDestroyPersistentRNNPlan__section_it3_rrh_jvb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">plan</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Pointer to the RNN persistent plan object to be
                                       destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyPersistentRNNPlan__section_d4r_1dd_z3b"><a name="cudnnDestroyPersistentRNNPlan__section_d4r_1dd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyRNNDataDescriptor"><a name="cudnnDestroyRNNDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyRNNDataDescriptor" name="cudnnDestroyRNNDataDescriptor" shape="rect">7.2.10.&nbsp;<kbd class="ph userinput">cudnnDestroyRNNDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created RNN data descriptor object. Invoking
                                 <samp class="ph codeph">cudnnDestroyRNNDataDescriptor()</samp> with the <samp class="ph codeph">NULL</samp>
                                 argument is a no operation (NOP).</span></div><pre xml:space="preserve">
cudnnStatus_t cudnnDestroyRNNDataDescriptor(
    cudnnRNNDataDescriptor_t RNNDataDesc)
</pre><p class="p">The <samp class="ph codeph">cudnnDestroyRNNDataDescriptor()</samp> function is not able to detect if
                              the <samp class="ph codeph">RNNDataDesc</samp> argument holds a valid address. Undefined behavior will
                              occur in cases of passing an invalid pointer, not returned by the
                              <samp class="ph codeph">cudnnCreateRNNDataDescriptor()</samp> function, or in the double deletion
                              scenario of a valid address.
                           </p>
                           <div class="section" id="cudnnDestroyRNNDataDescriptor__section_xf1_yrh_jvb"><a name="cudnnDestroyRNNDataDescriptor__section_xf1_yrh_jvb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">RNNDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Pointer to the RNN data descriptor object to be
                                       destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyRNNDataDescriptor__section_u3f_kdd_z3b"><a name="cudnnDestroyRNNDataDescriptor__section_u3f_kdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The RNN data descriptor object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyRNNDescriptor"><a name="cudnnDestroyRNNDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyRNNDescriptor" name="cudnnDestroyRNNDescriptor" shape="rect">7.2.11.&nbsp;<kbd class="ph userinput">cudnnDestroyRNNDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a previously created RNN descriptor object. Invoking
                                 <samp class="ph codeph">cudnnDestroyRNNDescriptor()</samp> with the <samp class="ph codeph">NULL</samp> argument
                                 is a no operation (NOP).</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyRNNDescriptor(
    cudnnRNNDescriptor_t rnnDesc)</pre><p class="p">The <samp class="ph codeph">cudnnDestroyRNNDescriptor()</samp> function is not able to detect if
                              the<samp class="ph codeph"> rnnDesc</samp> argument holds a valid address. Undefined behavior will
                              occur in cases of passing an invalid pointer, not returned by the
                              <samp class="ph codeph">cudnnCreateRNNDescriptor()</samp> function, or in the double deletion
                              scenario of a valid address.
                           </p>
                           <div class="section" id="cudnnDestroyRNNDescriptor__section_j4m_csh_jvb"><a name="cudnnDestroyRNNDescriptor__section_j4m_csh_jvb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Pointer to the RNN descriptor object to be destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyRNNDescriptor__section_ppd_mdd_z3b"><a name="cudnnDestroyRNNDescriptor__section_ppd_mdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroySeqDataDescriptor"><a name="cudnnDestroySeqDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroySeqDataDescriptor" name="cudnnDestroySeqDataDescriptor" shape="rect">7.2.12.&nbsp;<kbd class="ph userinput">cudnnDestroySeqDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys the sequence data descriptor object and releases its
                                 			memory. The <samp class="ph codeph">seqDataDesc</samp> argument can be <samp class="ph codeph">NULL</samp>. Invoking
                                 				<samp class="ph codeph">cudnnDestroySeqDataDescriptor()</samp> with a <samp class="ph codeph">NULL</samp>
                                 			argument is a no operation (NOP).</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroySeqDataDescriptor(cudnnSeqDataDescriptor_t seqDataDesc);
</pre><p class="p">The <samp class="ph codeph">cudnnDestroySeqDataDescriptor()</samp> function is not able to detect if the
                              				<samp class="ph codeph">seqDataDesc</samp> argument holds a valid address. Undefined behavior will
                              			occur in case of passing an invalid pointer, not returned by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateSeqDataDescriptor" title="This function creates one instance of an opaque sequence data descriptor object by allocating the host memory for it and initializing all descriptor fields. The function writes NULL to seqDataDesc when the sequence data descriptor object cannot be allocated." shape="rect">cudnnCreateSeqDataDescriptor()</a></samp> function, or in the double
                              			deletion scenario of a valid address.
                           </p>
                           <div class="section" id="cudnnDestroySeqDataDescriptor__section_gqw_sdd_z3b"><a name="cudnnDestroySeqDataDescriptor__section_gqw_sdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Pointer to the sequence data descriptor object to be
                                       							destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroySeqDataDescriptor__section_nby_tdd_z3b"><a name="cudnnDestroySeqDataDescriptor__section_nby_tdd_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was destroyed successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindRNNForwardInferenceAlgorithmEx"><a name="cudnnFindRNNForwardInferenceAlgorithmEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNForwardInferenceAlgorithmEx" name="cudnnFindRNNForwardInferenceAlgorithmEx" shape="rect">7.2.13.&nbsp;<kbd class="ph userinput">cudnnFindRNNForwardInferenceAlgorithmEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function attempts all available cuDNN algorithms for <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference()</a></samp>, using user-allocated GPU memory.
                              It outputs the parameters that influence the performance of the algorithm to a
                              user-allocated array of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter
                              metrics are written in sorted fashion where the first element has the lowest compute
                              time. 
                           </p><pre xml:space="preserve">
cudnnStatus_t cudnnFindRNNForwardInferenceAlgorithmEx(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                    findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *returnedAlgoCount,
    cudnnAlgorithmPerformance_t    *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes)</pre><div class="section" id="cudnnFindRNNForwardInferenceAlgorithmEx__section_cf4_kp3_z3b"><a name="cudnnFindRNNForwardInferenceAlgorithmEx__section_cf4_kp3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the
                                       RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                       input to each recurrent iteration (one descriptor per iteration). The
                                       first dimension (batch size) of the tensors may decrease from element
                                       <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                       increase. Each tensor descriptor must have the same second dimension
                                       (vector length).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">xDesc</samp>. The data are expected
                                       to be packed contiguously with the first element of iteration
                                       <samp class="ph codeph">n+1</samp> following directly from the last element of
                                       iteration <samp class="ph codeph">n</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_bsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_bsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_dsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_dsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). The second dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_fsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_fsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">xDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>. The data are expected to be
                                       packed contiguously with the first element of iteration
                                       <samp class="ph codeph">n+1</samp> following directly from the last element of
                                       iteration <samp class="ph codeph">n</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final hidden state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_isf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_isf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final cell state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">findIntensity</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>.This input was previously unused in versions prior to
                                          7.2.0. It is used in cuDNN 7.2.0 and later versions to control the
                                          overall runtime of the RNN find algorithms, by selecting the
                                          percentage of a large Cartesian product space to be searched. 
                                       </p>
                                       <div class="p"><a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gyf_fh1_l2b">
                                             <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range
                                                (0,1.] will set a percentage of the entire RNN search space
                                                to search. When <samp class="ph codeph">findIntensity</samp> is set to
                                                1.0, a full search is performed over all RNN parameters. 
                                             </li>
                                             <li class="li liexpand">When <samp class="ph codeph">findIntensity</samp> is set to 0.0f, a quick,
                                                minimal search is performed. This setting has the best
                                                runtime. However, in this case the parameters returned by
                                                this function will not correspond to the best performance of
                                                the algorithm; a longer search might discover better
                                                parameters. This option will execute up to three instances
                                                of the configured RNN problem. Runtime will vary
                                                proportionally to RNN problem size, as it will in the other
                                                cases, hence no guarantee of an explicit time bound can be
                                                given. 
                                             </li>
                                             <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range
                                                [-1.,0) sets a percentage of a reduced Cartesian product
                                                space to be searched. This reduced search space has been
                                                heuristically selected to have good performance. The setting
                                                of -1.0 represents a full search over this reduced search
                                                space. 
                                             </li>
                                             <li class="li liexpand">Values outside the range [-1,1] are truncated to the range
                                                [-1,1], and then interpreted as per the above. 
                                             </li>
                                             <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2
                                                and later versions is equivalent to the behavior of this
                                                function in versions prior to cuDNN 7.2.0. 
                                             </li>
                                             <li class="li liexpand">This function times the single RNN executions over large
                                                parameter spaces - one execution per parameter combination.
                                                The times returned by this function are latencies. 
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindRNNForwardInferenceAlgorithmEx__section_hzb_mp3_z3b"><a name="cudnnFindRNNForwardInferenceAlgorithmEx__section_hzb_mp3_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_ksf_sf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_ksf_sf3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp> or <samp class="ph codeph">cyDesc</samp>, or one
                                             of the descriptors in <samp class="ph codeph">xDesc</samp> or
                                             <samp class="ph codeph">yDesc</samp> is invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">cxDesc</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp> or <samp class="ph codeph">cyDesc</samp> have
                                             incorrect strides or dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetAttnDescriptor"><a name="cudnnGetAttnDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAttnDescriptor" name="cudnnGetAttnDescriptor" shape="rect">7.2.14.&nbsp;<kbd class="ph userinput">cudnnGetAttnDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves settings from the previously created attention
                                 			descriptor. The user can assign <samp class="ph codeph">NULL</samp> to any pointer except
                                 				<samp class="ph codeph">attnDesc</samp> when the retrieved value is not needed.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetAttnDescriptor(
    cudnnAttnDescriptor_t attnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> *attnMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *nHeads,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> *smScaler,
    cudnnDataType_t *dataType,
    cudnnDataType_t *computePrec,
    cudnnMathType_t *mathType,
    cudnnDropoutDescriptor_t *attnDropoutDesc,
    cudnnDropoutDescriptor_t *postDropoutDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *qSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *kSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *vSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *qProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *kProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *vProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *oProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *qoMaxSeqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *kvMaxSeqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *maxBatchSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *maxBeamSize);
</pre><div class="section" id="cudnnGetAttnDescriptor__section_t55_jsj_z3b"><a name="cudnnGetAttnDescriptor__section_t55_jsj_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Attention descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the storage for binary attention flags.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nHeads</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the storage for the number of attention
                                       							heads.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">smScaler</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the storage for the softmax
                                       							smoothing/sharpening coefficient.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data type for attention weights, sequence data inputs,
                                       							and outputs.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">computePrec</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the storage for the compute precision.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mathType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. NVIDIA Tensor Core settings.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Descriptor of the dropout operation applied to the
                                       							softmax output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">postDropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Descriptor of the dropout operation applied to the
                                       							multi-head attention output.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">qSize</samp>, <samp class="ph codeph">kSize</samp>,
                                       							<samp class="ph codeph">vSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. <strong class="ph b">Q, K</strong>, and <strong class="ph b">V</strong> embedding vector lengths.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">qProjSize</samp>, <samp class="ph codeph">kProjSize</samp>,
                                       								<samp class="ph codeph">vProjSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. <strong class="ph b">Q, K</strong>, and <strong class="ph b">V</strong> embedding vector lengths after
                                       							input projections.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">oProjSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to store the output vector length after
                                       							projection.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">qoMaxSeqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Largest sequence length expected in sequence data
                                       							descriptors related to <strong class="ph b">Q, O, dQ, dO</strong> inputs and outputs.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">kvMaxSeqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Largest sequence length expected in sequence data
                                       							descriptors related to <strong class="ph b">K, V, dK, dV</strong> inputs and outputs.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxBatchSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Largest batch size expected in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> container.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxBeamSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Largest beam size expected in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> container.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetAttnDescriptor__section_cy4_ctj_z3b"><a name="cudnnGetAttnDescriptor__section_cy4_ctj_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">Requested attention descriptor fields were retrieved successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetMultiHeadAttnBuffers"><a name="cudnnGetMultiHeadAttnBuffers" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetMultiHeadAttnBuffers" name="cudnnGetMultiHeadAttnBuffers" shape="rect">7.2.15.&nbsp;<kbd class="ph userinput">cudnnGetMultiHeadAttnBuffers()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes weight, work, and reserve space buffer sizes used by the
                                 			following functions:</span></div>
                           <div class="p"><a name="cudnnGetMultiHeadAttnBuffers__ul_rwp_rw2_1jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetMultiHeadAttnBuffers__ul_rwp_rw2_1jb">
                                 <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp></li>
                                 <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp></li>
                                 <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardWeights" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its trainable parameters: projection weights and projection biases. If y=F(w) is a vector-valued function that represents the multi-head attention layer and it takes some vector of flatten weights or biases as an input (with all other parameters and inputs fixed), and outputs vector , then cudnnMultiHeadAttnBackwardWeights() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(w). The input is supplied via the dout argument." shape="rect">cudnnMultiHeadAttnBackwardWeights()</a></samp></li>
                              </ul>
                           </div><pre xml:space="preserve">cudnnStatus_t cudnnGetMultiHeadAttnBuffers(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	size_t *weightSizeInBytes,
	size_t *workSpaceSizeInBytes,
	size_t *reserveSpaceSizeInBytes);
</pre><div class="p">Assigning <samp class="ph codeph">NULL</samp> to the <samp class="ph codeph">reserveSpaceSizeInBytes</samp> argument
                              			indicates that the user does not plan to invoke multi-head attention gradient functions:
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp> and
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardWeights" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its trainable parameters: projection weights and projection biases. If y=F(w) is a vector-valued function that represents the multi-head attention layer and it takes some vector of flatten weights or biases as an input (with all other parameters and inputs fixed), and outputs vector , then cudnnMultiHeadAttnBackwardWeights() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(w). The input is supplied via the dout argument." shape="rect">cudnnMultiHeadAttnBackwardWeights()</a></samp>. This
                              			situation occurs in the inference mode.
                              <div class="note note"><span class="notetitle">Note:</span><samp class="ph codeph">NULL</samp> cannot be assigned to
                                 					<samp class="ph codeph">weightSizeInBytes</samp> and <samp class="ph codeph">workSpaceSizeInBytes</samp>
                                 				pointers.
                              </div>
                           </div>
                           <p class="p">The user must allocate weight, work, and reserve space buffer sizes in the GPU memory
                              			using <samp class="ph codeph">cudaMalloc()</samp> with the reported buffer sizes. The buffers can be
                              			also carved out from a larger chunk of allocated memory but the buffer addresses must be
                              			at least 16B aligned.
                           </p>
                           <p class="p">The work-space buffer is used for temporary storage. Its content can be discarded or modified
                              			after all GPU kernels launched by the corresponding API complete. The reserve-space
                              			buffer is used to transfer intermediate results from <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp> to <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp>, and from <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp> to <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardWeights" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its trainable parameters: projection weights and projection biases. If y=F(w) is a vector-valued function that represents the multi-head attention layer and it takes some vector of flatten weights or biases as an input (with all other parameters and inputs fixed), and outputs vector , then cudnnMultiHeadAttnBackwardWeights() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(w). The input is supplied via the dout argument." shape="rect">cudnnMultiHeadAttnBackwardWeights()</a></samp>. The content of the
                              			reserve-space buffer cannot be modified until all GPU kernels launched by the above
                              			three multi-head attention API functions finish.
                           </p>
                           <p class="p">All multi-head attention weight and bias tensors are stored in a single weight buffer. For
                              			speed optimizations, the cuDNN API may change tensor layouts and their relative
                              			locations in the weight buffer based on the provided attention parameters. Use the
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnGetMultiHeadAttnWeights" shape="rect">cudnnGetMultiHeadAttnWeights()</a></samp> function to
                              			obtain the start address and the shape of each weight or bias tensor.
                           </p>
                           <div class="section" id="cudnnGetMultiHeadAttnBuffers__section_vxg_cx2_1jb"><a name="cudnnGetMultiHeadAttnBuffers__section_vxg_cx2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized attention
                                       							descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum buffer size required to store all multi-head
                                       							attention trainable parameters.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum buffer size required to hold all temporary
                                       							surfaces used by the forward and gradient multi-head attention API
                                       							calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum buffer size required to store all intermediate
                                       							data exchanged between forward and backward (gradient) multi-head
                                       							attention functions. Set this parameter to <samp class="ph codeph">NULL</samp> in the
                                       							inference mode indicating that gradient API calls will not be
                                       							invoked.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetMultiHeadAttnBuffers__section_hnz_gx2_1jb"><a name="cudnnGetMultiHeadAttnBuffers__section_hnz_gx2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ARCH_MISMATCH</samp></dt>
                                    <dd class="dd">The GPU device does not support the input data type.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The requested buffer sizes were computed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetMultiHeadAttnWeights"><a name="cudnnGetMultiHeadAttnWeights" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetMultiHeadAttnWeights" name="cudnnGetMultiHeadAttnWeights" shape="rect">7.2.16.&nbsp;<kbd class="ph userinput">cudnnGetMultiHeadAttnWeights()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function obtains the shape of the weight or bias tensor. It also retrieves the
                              		start address of tensor data located in the <samp class="ph codeph">weight</samp> buffer. Use the
                              			<samp class="ph codeph">wKind</samp> argument to select a particular tensor. For more information,
                              		refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnWeightKind_t" shape="rect">cudnnMultiHeadAttnWeightKind_t</a></samp> for the
                              		description of the enumerant type. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetMultiHeadAttnWeights(
    cudnnHandle_t handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
    cudnnMultiHeadAttnWeightKind_t wKind,
    size_t weightSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *weights,
    cudnnTensorDescriptor_t wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **wAddr);
</pre><p class="p">Biases are used in the input and output projections when the
                              				<samp class="ph codeph">CUDNN_ATTN_ENABLE_PROJ_BIASES</samp> flag is set in the attention
                              			descriptor. Refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetAttnDescriptor" shape="rect">cudnnSetAttnDescriptor()</a></samp> for the
                              			description of flags to control projection biases.
                           </p>
                           <p class="p">When the corresponding weight or bias tensor does not exist, the function writes
                              				<samp class="ph codeph">NULL</samp> to the storage location pointed by <samp class="ph codeph">wAddr</samp> and
                              			returns zeros in the <samp class="ph codeph">wDesc</samp> tensor descriptor. The return status of the
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnGetMultiHeadAttnWeights" shape="rect">cudnnGetMultiHeadAttnWeights()</a></samp> function is
                              				<samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp> in this case.
                           </p>
                           <p class="p">The cuDNN <samp class="ph codeph">multiHeadAttention</samp> sample code demonstrates how to access multi-head
                              			attention weights. Although the buffer with weights and biases should be allocated in
                              			the GPU memory, the user can copy it to the host memory and invoke the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetMultiHeadAttnWeights" shape="rect">cudnnGetMultiHeadAttnWeights()</a></samp> function with the host weights
                              			address to obtain tensor pointers in the host memory. This scheme allows the user to
                              			inspect trainable parameters directly in the CPU memory.
                           </p>
                           <div class="section" id="cudnnGetMultiHeadAttnWeights__section_tmg_sx2_1jb"><a name="cudnnGetMultiHeadAttnWeights__section_tmg_sx2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously configured attention descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wKind</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant type to specify which weight or bias tensor
                                       							should be retrieved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Buffer size that stores all multi-head attention weights
                                       							and biases.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weights</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the <samp class="ph codeph">weight</samp> buffer in the host
                                       							or device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The descriptor specifying weight or bias tensor shape.
                                       							For weights, the <samp class="ph codeph">wDesc.dimA[]</samp> array has three elements:
                                       								<samp class="ph codeph">[nHeads, projected size, original size]</samp>. For
                                       							biases, the <samp class="ph codeph">wDesc.dimA[]</samp> array also has three elements:
                                       								<samp class="ph codeph">[nHeads, projected size, 1]</samp>. The
                                       								<samp class="ph codeph">wDesc.strideA[]</samp> array describes how tensor elements
                                       							are arranged in memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wAddr</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to a location where the start address of the
                                       							requested tensor should be written. When the corresponding projection is
                                       							disabled, the address written to <samp class="ph codeph">wAddr</samp> is
                                       								<samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetMultiHeadAttnWeights__section_g4g_xx2_1jb"><a name="cudnnGetMultiHeadAttnWeights__section_g4g_xx2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The weight tensor descriptor and the address of data in the device
                                       							memory were successfully retrieved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or incompatible input argument was encountered. For example,
                                       								<samp class="ph codeph">wKind</samp> did not have a valid value or
                                       								<samp class="ph codeph">weightSizeInBytes</samp> was too small.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNBackwardWeightsAlgorithmMaxCount"><a name="cudnnGetRNNBackwardWeightsAlgorithmMaxCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNBackwardWeightsAlgorithmMaxCount" name="cudnnGetRNNBackwardWeightsAlgorithmMaxCount" shape="rect">7.2.17.&nbsp;<kbd class="ph userinput">cudnnGetRNNBackwardWeightsAlgorithmMaxCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNBiasMode"><a name="cudnnGetRNNBiasMode" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNBiasMode" name="cudnnGetRNNBiasMode" shape="rect">7.2.18.&nbsp;<kbd class="ph userinput">cudnnGetRNNBiasMode()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDescriptor_v8" shape="rect">cudnnGetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNBiasMode()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnGetRNNBiasMode(
   cudnnRNNDescriptor_t   rnnDesc,
   cudnnRNNBiasMode_t     *biasMode)</pre><p class="p">This function retrieves the RNN bias mode that was configured by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNBiasMode" shape="rect">cudnnSetRNNBiasMode()</a></samp>. The default value of
                              <samp class="ph codeph">biasMode</samp> in <samp class="ph codeph">rnnDesc</samp> after <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateRNNDescriptor" title="This function creates a generic RNN descriptor object by allocating the memory needed to hold its opaque structure." shape="rect">cudnnCreateRNNDescriptor()</a></samp> is
                              <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>.
                           </p>
                           <div class="section" id="cudnnGetRNNBiasMode__section_mkr_4bf_1jb"><a name="cudnnGetRNNBiasMode__section_mkr_4bf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*biasMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN bias mode should be saved.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNBiasMode__section_dx1_pbf_1jb"><a name="cudnnGetRNNBiasMode__section_dx1_pbf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either the <samp class="ph codeph">rnnDesc</samp> or <samp class="ph codeph">*biasMode</samp> is
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">biasMode</samp> parameter was retrieved successfully.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNDataDescriptor"><a name="cudnnGetRNNDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNDataDescriptor" name="cudnnGetRNNDataDescriptor" shape="rect">7.2.19.&nbsp;<kbd class="ph userinput">cudnnGetRNNDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves a previously created RNN data descriptor
                                 object.</span></div><pre xml:space="preserve">
cudnnStatus_t cudnnGetRNNDataDescriptor(
    cudnnRNNDataDescriptor_t       RNNDataDesc,
    cudnnDataType_t                *dataType,
    cudnnRNNDataLayout_t           *layout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *maxSeqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *batchSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *vectorSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            arrayLengthRequested,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            seqLengthArray[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *paddingFill);
</pre><div class="section" id="cudnnGetRNNDataDescriptor__section_ill_5bf_1jb"><a name="cudnnGetRNNDataDescriptor__section_ill_5bf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">RNNDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the host memory location to store the datatype
                                       of the RNN data tensor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">layout</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the host memory location to store the memory
                                       layout of the RNN data tensor. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxSeqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The maximum sequence length within this RNN data tensor,
                                       including the padding vectors. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">batchSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of sequences within the mini-batch. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">vectorSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The vector length (meaning, embedding size) of the input
                                       or output tensor at each time-step. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">arrayLengthRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of elements that the user requested for
                                       <samp class="ph codeph">seqLengthArray</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLengthArray</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the host memory location to store the integer
                                       array describing the length (meaning, number of time-steps) of each
                                       sequence. This is allowed to be a <samp class="ph codeph">NULL</samp> pointer if
                                       <samp class="ph codeph">arrayLengthRequested</samp> is 0.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddingFill</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the host memory location to store the user
                                       defined symbol. The symbol should be interpreted as the same data type
                                       as the RNN data tensor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNDataDescriptor__section_uqv_5bf_1jb"><a name="cudnnGetRNNDataDescriptor__section_uqv_5bf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The parameters are fetched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Any one of these have occurred:
                                       <div class="p"><a name="cudnnGetRNNDataDescriptor__ul_g4k_bsr_h2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNDataDescriptor__ul_g4k_bsr_h2b">
                                             <li class="li">Any of <samp class="ph codeph">RNNDataDesc</samp>,
                                                <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                                <samp class="ph codeph">maxSeqLength</samp>,
                                                <samp class="ph codeph">batchSize</samp>, <samp class="ph codeph">vectorSize</samp>,
                                                or <samp class="ph codeph">paddingFill</samp> is <samp class="ph codeph">NULL</samp>. 
                                             </li>
                                             <li class="li"><samp class="ph codeph">seqLengthArray</samp> is <samp class="ph codeph">NULL</samp>
                                                while <samp class="ph codeph">arrayLengthRequested</samp> is greater than
                                                zero. 
                                             </li>
                                             <li class="li"><samp class="ph codeph">arrayLengthRequested</samp> is less than zero.
                                                
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNDescriptor_v6"><a name="cudnnGetRNNDescriptor_v6" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNDescriptor_v6" name="cudnnGetRNNDescriptor_v6" shape="rect">7.2.20.&nbsp;<kbd class="ph userinput">cudnnGetRNNDescriptor_v6()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDescriptor_v8" shape="rect">cudnnGetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNDescriptor_v6()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNDescriptor_v6(
	cudnnHandle_t handle,
	cudnnRNNDescriptor_t rnnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *hiddenSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *numLayers,
    cudnnDropoutDescriptor_t *dropoutDesc,
	cudnnRNNInputMode_t *inputMode,
	cudnnDirectionMode_t *direction,
	cudnnRNNMode_t *cellMode,
	cudnnRNNAlgo_t *algo,
	cudnnDataType_t *mathPrec) {
</pre><p class="p">This function retrieves RNN network parameters that were configured by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v6" shape="rect">cudnnSetRNNDescriptor_v6()</a></samp>. All pointers passed to the
                              function should be not-<samp class="ph codeph">NULL</samp> or <samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp>
                              is reported. The function does not check the validity of retrieved parameters.
                           </p>
                           <div class="section" id="cudnnGetRNNDescriptor_v6__section_ill_5bf_1jb"><a name="cudnnGetRNNDescriptor_v6__section_ill_5bf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hiddenSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the size of the hidden state should be
                                       stored (the same value is used in every RNN layer). 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">numLayers</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the number of RNN layers should be
                                       stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the handle to a previously configured
                                       dropout descriptor should be stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the mode of the first RNN layer should
                                       be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">direction</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN unidirectional/bidirectional mode
                                       should be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN cell type should be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN algorithm type should be
                                       stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mathPrec</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the math precision type should be
                                       stored.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNDescriptor_v6__section_uqv_5bf_1jb"><a name="cudnnGetRNNDescriptor_v6__section_uqv_5bf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">RNN parameters were successfully retrieved from the RNN descriptor.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one pointer passed to the function is
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNDescriptor_v8"><a name="cudnnGetRNNDescriptor_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNDescriptor_v8" name="cudnnGetRNNDescriptor_v8" shape="rect">7.2.21.&nbsp;<kbd class="ph userinput">cudnnGetRNNDescriptor_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function retrieves RNN network parameters that were configured by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>. The user can assign
                              <samp class="ph codeph">NULL</samp> to any pointer except <samp class="ph codeph">rnnDesc</samp> when the retrieved
                              value is not needed. The function does not check the validity of retrieved
                              parameters. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNDescriptor_v8(
	cudnnRNNDescriptor_t rnnDesc,
	cudnnRNNAlgo_t *algo,
	cudnnRNNMode_t *cellMode,
	cudnnRNNBiasMode_t *biasMode,
	cudnnDirectionMode_t *dirMode,
	cudnnRNNInputMode_t *inputMode,
	cudnnDataType_t *dataType,
	cudnnDataType_t *mathPrec,
	cudnnMathType_t *mathType,
	int32_t *inputSize,
	int32_t *hiddenSize,
	int32_t *projSize,
	int32_t *numLayers,
    cudnnDropoutDescriptor_t *dropoutDesc,
	uint32_t *auxFlags);
</pre><div class="section" id="cudnnGetRNNDescriptor_v8__section_drx_rln_y3b"><a name="cudnnGetRNNDescriptor_v8__section_drx_rln_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN algorithm type should be
                                       stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cellMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN cell type should be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">biasMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN bias mode <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBiasMode_t" shape="rect">cudnnRNNBiasMode_t</a></samp> should be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dirMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where RNN unidirectional/bidirectional mode
                                       should be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the mode of the first RNN layer should
                                       be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the data type of RNN weights/biases
                                       should be stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mathPrec</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the math precision type should be
                                       stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mathType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the preferred option for Tensor Cores
                                       are saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the RNN input vector size is
                                       stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hiddenSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the size of the hidden state should be
                                       stored (the same value is used in every RNN layer).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">projSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the LSTM cell output size after the
                                       recurrent projection is stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">numLayers</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the number of RNN layers should be
                                       stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to where the handle to a previously configured
                                       dropout descriptor should be stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">auxFlags</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to miscellaneous RNN options (flags) that do not
                                       require passing additional numerical values to configure.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNDescriptor_v8__section_bhm_sln_y3b"><a name="cudnnGetRNNDescriptor_v8__section_bhm_sln_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">RNN parameters were successfully retrieved from the RNN descriptor.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found (<samp class="ph codeph">rnnDesc</samp> was
                                       <samp class="ph codeph">NULL</samp>).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                                    <dd class="dd">The RNN descriptor was configured with the legacy <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v6" shape="rect">cudnnSetRNNDescriptor_v6()</a></samp> call.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNForwardInferenceAlgorithmMaxCount"><a name="cudnnGetRNNForwardInferenceAlgorithmMaxCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNForwardInferenceAlgorithmMaxCount" name="cudnnGetRNNForwardInferenceAlgorithmMaxCount" shape="rect">7.2.22.&nbsp;<kbd class="ph userinput">cudnnGetRNNForwardInferenceAlgorithmMaxCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNLinLayerBiasParams"><a name="cudnnGetRNNLinLayerBiasParams" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNLinLayerBiasParams" name="cudnnGetRNNLinLayerBiasParams" shape="rect">7.2.23.&nbsp;<kbd class="ph userinput">cudnnGetRNNLinLayerBiasParams()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWeightParams" title="This function is used to obtain the start address and shape of every RNN weight matrix and bias vector in each pseudo-layer within the recurrent network." shape="rect">cudnnGetRNNWeightParams()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNLinLayerBiasParams()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNLinLayerBiasParams(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       pseudoLayer,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       linLayerID,
    cudnnFilterDescriptor_t         linLayerBiasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           **linLayerBias)</pre><p class="p">This function is used to obtain a pointer and a descriptor of every RNN bias column
                              vector in each pseudo-layer within the recurrent network defined by
                              <samp class="ph codeph">rnnDesc</samp> and its input width specified in
                              <samp class="ph codeph">xDesc</samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNLinLayerBiasParams" shape="rect">cudnnGetRNNLinLayerBiasParams()</a></samp> function was
                              changed in cuDNN version 7.1.1 to match the behavior of <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNLinLayerMatrixParams" shape="rect">cudnnGetRNNLinLayerMatrixParams()</a></samp>.
                           </div>
                           <p class="p">The <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNLinLayerBiasParams" shape="rect">cudnnGetRNNLinLayerBiasParams()</a></samp> function returns the
                              RNN bias vector size in two dimensions: rows and columns. 
                           </p>
                           <div class="p">Due to historical reasons, the minimum number of dimensions in the filter descriptor is three.
                              In previous versions of the cuDNN library, the function returns the total number of
                              vector elements in <samp class="ph codeph">linLayerBiasDesc</samp> as follows:
                              <pre xml:space="preserve">filterDimA[0]=total_size, 
filterDimA[1]=1, 
filterDimA[2]=1</pre>For
                              more information, see the description of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFilterNdDescriptor" title="This function queries a previously initialized FilterNd descriptor object." shape="rect">cudnnGetFilterNdDescriptor()</a></samp> function.
                           </div>
                           <div class="p">In cuDNN 7.1.1, the format was changed to:
                              <pre xml:space="preserve">filterDimA[0]=1, 
filterDimA[1]=rows, 
filterDimA[2]=1 (number of columns)</pre>In
                              both cases, the <samp class="ph codeph">format</samp> field of the filter descriptor should be ignored
                              when retrieved by <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFilterNdDescriptor" title="This function queries a previously initialized FilterNd descriptor object." shape="rect">cudnnGetFilterNdDescriptor()</a></samp>. 
                           </div>
                           <div class="p">The RNN implementation in cuDNN uses two bias vectors before the cell non-linear function. Note
                              that the RNN implementation in cuDNN depends on the number of bias vectors before the
                              cell non-linear function. Refer to the equations in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNMode_t" shape="rect">cudnnRNNMode_t</a></samp> description, for the enumerant type based on
                              the value of <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBiasMode_t" shape="rect">cudnnRNNBiasMode_t</a></samp><samp class="ph codeph">biasMode</samp> in <samp class="ph codeph">rnnDesc</samp>. If nonexistent biases are
                              referenced by <samp class="ph codeph">linLayerID</samp>, then this function sets
                              <samp class="ph codeph">linLayerBiasDesc</samp> to a zeroed filter descriptor where:
                              <pre xml:space="preserve">filterDimA[0]=0, 
filterDimA[1]=0, and 
filterDimA[2]=2</pre> and sets
                              <samp class="ph codeph">linLayerBias</samp> to <samp class="ph codeph">NULL</samp>. Refer to the details for the
                              function parameter <samp class="ph codeph">linLayerID</samp> to determine the relevant values of
                              <samp class="ph codeph">linLayerID</samp> based on <samp class="ph codeph">biasMode</samp>.
                           </div>
                           <div class="section" id="cudnnGetRNNLinLayerBiasParams__section_lyv_fhf_1jb"><a name="cudnnGetRNNLinLayerBiasParams__section_lyv_fhf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">pseudoLayer</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The pseudo-layer to query. In unidirectional RNNs, a
                                       pseudo-layer is the same as a physical layer
                                       (<samp class="ph codeph">pseudoLayer=0</samp> is the RNN input layer,
                                       <samp class="ph codeph">pseudoLayer=1</samp> is the first hidden layer). In
                                       bidirectional RNNs, there are twice as many pseudo-layers in comparison
                                       to physical layers.<a name="cudnnGetRNNLinLayerBiasParams__ul_kf2_4hf_1jb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_kf2_4hf_1jb">
                                          <li class="li"><samp class="ph codeph">pseudoLayer=0</samp> refers to the forward part of the
                                             physical input layer
                                          </li>
                                          <li class="li"><samp class="ph codeph">pseudoLayer=1</samp> refers to the backward part of
                                             the physical input layer
                                          </li>
                                          <li class="li"><samp class="ph codeph">pseudoLayer=2</samp> is the forward part of the first
                                             hidden layer, and so on
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the input to
                                       one recurrent iteration (to retrieve the RNN input width).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">linLayerID</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. Linear ID index of the weight matrix. 
                                       </p>
                                       <div class="p">If <samp class="ph codeph">cellMode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                          <samp class="ph codeph">CUDNN_RNN_RELU</samp> or
                                          <samp class="ph codeph">CUDNN_RNN_TANH</samp>:<a name="cudnnGetRNNLinLayerBiasParams__ul_fhk_2fx_ngb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_fhk_2fx_ngb">
                                             <li class="li">Value <samp class="ph codeph">0</samp> references the weight matrix used
                                                in conjunction with the input from the previous layer or
                                                input to the RNN model.
                                             </li>
                                             <li class="li">Value <samp class="ph codeph">1</samp> references the weight matrix used
                                                in conjunction with the hidden state from the previous time
                                                step or the initial hidden state.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">If <samp class="ph codeph">cellMode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                          <samp class="ph codeph">CUDNN_LSTM</samp>:<a name="cudnnGetRNNLinLayerBiasParams__ul_c2t_5cq_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_c2t_5cq_wlb">
                                             <li class="li">Values <samp class="ph codeph">0</samp>, <samp class="ph codeph">1</samp>,
                                                <samp class="ph codeph">2</samp>, and <samp class="ph codeph">3</samp> reference
                                                weight matrices used in conjunction with the input from the
                                                previous layer or input to the RNN model.
                                             </li>
                                             <li class="li">Values <samp class="ph codeph">4</samp>, <samp class="ph codeph">5</samp>,
                                                <samp class="ph codeph">6</samp>, and <samp class="ph codeph">7</samp> reference
                                                weight matrices used in conjunction with the hidden state
                                                from the previous time step or the initial hidden
                                                state.
                                             </li>
                                             <li class="li">Value <samp class="ph codeph">8</samp> corresponds to the projection
                                                matrix, if enabled.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">Values and their LSTM gates:<a name="cudnnGetRNNLinLayerBiasParams__ul_nv1_wcq_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_nv1_wcq_wlb">
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">0</samp> and
                                                <samp class="ph codeph">4</samp> correspond to the input gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">1</samp> and
                                                <samp class="ph codeph">5</samp> correspond to the forget gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">2</samp> and
                                                <samp class="ph codeph">6</samp> correspond to the new cell state
                                                calculations with a hyperbolic tangent.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">3</samp> and
                                                <samp class="ph codeph">7</samp> correspond to the output gate.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">If <samp class="ph codeph">cellMode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                          <samp class="ph codeph">CUDNN_GRU</samp>:<a name="cudnnGetRNNLinLayerBiasParams__ul_lw5_xcq_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_lw5_xcq_wlb">
                                             <li class="li">Values <samp class="ph codeph">0</samp>, <samp class="ph codeph">1</samp>, and
                                                <samp class="ph codeph">2</samp> reference weight matrices used in
                                                conjunction with the input from the previous layer or input
                                                to the RNN model.
                                             </li>
                                             <li class="li">Values <samp class="ph codeph">3</samp>, <samp class="ph codeph">4</samp>, and
                                                <samp class="ph codeph">5</samp> reference weight matrices used in
                                                conjunction with the hidden state from the previous time
                                                step or the initial hidden state.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">Values and their GRU gates:<a name="cudnnGetRNNLinLayerBiasParams__ul_zwv_ycq_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_zwv_ycq_wlb">
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">0</samp> and
                                                <samp class="ph codeph">3</samp> correspond to the reset gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">1</samp> and
                                                <samp class="ph codeph">4</samp> references to the update gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">2</samp> and 5
                                                correspond to the new hidden state calculations with a
                                                hyperbolic tangent.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">linLayerBiasDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created filter descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">linLayerBias</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">linLayerBiasDesc</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNLinLayerBiasParams__section_cwg_ghf_1jb"><a name="cudnnGetRNNLinLayerBiasParams__section_cwg_ghf_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnGetRNNLinLayerBiasParams__ul_ycm_nf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_ycm_nf3_s1b">
                                          <li class="li">One of the following arguments is <samp class="ph codeph">NULL</samp>:
                                             <samp class="ph codeph">handle</samp>, <samp class="ph codeph">rnnDesc</samp>,
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">linLayerBiasDesc</samp>, or
                                             <samp class="ph codeph">linLayerBias</samp>.
                                          </li>
                                          <li class="li">A data type mismatch was detected between
                                             <samp class="ph codeph">rnnDesc</samp> and other descriptors.
                                          </li>
                                          <li class="li">Minimum requirement for the <samp class="ph codeph">w</samp> pointer alignment
                                             is not satisfied.
                                          </li>
                                          <li class="li">The value of <samp class="ph codeph">pseudoLayer</samp> or
                                             <samp class="ph codeph">linLayerID</samp> is out of range.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd">Some elements of the <samp class="ph codeph">linLayerBias</samp> vector are outside
                                       the <samp class="ph codeph">w</samp> buffer boundaries as specified by the
                                       <samp class="ph codeph">wDesc</samp> descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNLinLayerMatrixParams"><a name="cudnnGetRNNLinLayerMatrixParams" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNLinLayerMatrixParams" name="cudnnGetRNNLinLayerMatrixParams" shape="rect">7.2.24.&nbsp;<kbd class="ph userinput">cudnnGetRNNLinLayerMatrixParams()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0 . Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWeightParams" title="This function is used to obtain the start address and shape of every RNN weight matrix and bias vector in each pseudo-layer within the recurrent network." shape="rect">cudnnGetRNNWeightParams()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNLinLayerMatrixParams()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNLinLayerMatrixParams(
cudnnHandle_t                   handle,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       pseudoLayer,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       linLayerID,
cudnnFilterDescriptor_t         linLayerMatDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           **linLayerMat)</pre><p class="p">This function is used to obtain a pointer and a descriptor of every RNN 
                              weight matrix in each pseudo-layer within the recurrent network defined by 
                              <samp class="ph codeph">rnnDesc</samp> and its input width specified in <samp class="ph codeph">xDesc</samp>.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNLinLayerMatrixParams" shape="rect">cudnnGetRNNLinLayerMatrixParams()</a></samp> function was
                              enhanced in cuDNN version 7.1.1 without changing its prototype. Instead of reporting the
                              total number of elements in each weight matrix in the <samp class="ph codeph">linLayerMatDesc</samp>
                              filter descriptor, the function returns the matrix size as two dimensions: rows and
                              columns. Moreover, when a weight matrix does not exist, for example, due to
                              <samp class="ph codeph">CUDNN_SKIP_INPUT</samp> mode, the function returns <samp class="ph codeph">NULL</samp>
                              in <samp class="ph codeph">linLayerMat</samp> and all fields of <samp class="ph codeph">linLayerMatDesc</samp> are
                              zero.
                           </div>
                           <p class="p">The <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNLinLayerMatrixParams" shape="rect">cudnnGetRNNLinLayerMatrixParams()</a></samp> function returns
                              the RNN matrix size in two dimensions: rows and columns. This allows the user to easily
                              print and initialize RNN weight matrices. Elements in each weight matrix are arranged in
                              the row-major order. Due to historical reasons, the minimum number of dimensions in the
                              filter descriptor is three. In previous versions of the cuDNN library, the function
                              returned the total number of weights in <samp class="ph codeph">linLayerMatDesc</samp> as follows:
                              <samp class="ph codeph">filterDimA[0]=total_size</samp>, <samp class="ph codeph">filterDimA[1]=1</samp>,
                              <samp class="ph codeph">filterDimA[2]=1</samp> (see the description of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFilterNdDescriptor" title="This function queries a previously initialized FilterNd descriptor object." shape="rect">cudnnGetFilterNdDescriptor()</a></samp> function). In cuDNN 7.1.1, the
                              format was changed to: <samp class="ph codeph">filterDimA[0]=1</samp>,
                              <samp class="ph codeph">filterDimA[1]=rows</samp>, <samp class="ph codeph">filterDimA[2]=columns</samp>. In both
                              cases, the "format" field of the filter descriptor should be ignored when retrieved by
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetFilterNdDescriptor" title="This function queries a previously initialized FilterNd descriptor object." shape="rect">cudnnGetFilterNdDescriptor()</a></samp>.
                           </p>
                           <div class="section" id="cudnnGetRNNLinLayerMatrixParams__section_a3t_4dk_1jb"><a name="cudnnGetRNNLinLayerMatrixParams__section_a3t_4dk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">pseudoLayer</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The pseudo-layer to query. In unidirectional RNNs, a
                                       pseudo-layer is the same as a physical layer
                                       (<samp class="ph codeph">pseudoLayer=0</samp> is the RNN input layer,
                                       <samp class="ph codeph">pseudoLayer=1</samp> is the first hidden layer). In
                                       bidirectional RNNs, there are twice as many pseudo-layers in comparison
                                       to physical layers.<a name="cudnnGetRNNLinLayerMatrixParams__ul_kf2_4hf_1jb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_kf2_4hf_1jb">
                                          <li class="li"><samp class="ph codeph">pseudoLayer=0</samp> refers to the forward part of the
                                             physical input layer
                                          </li>
                                          <li class="li"><samp class="ph codeph">pseudoLayer=1</samp> refers to the backward part of
                                             the physical input layer
                                          </li>
                                          <li class="li"><samp class="ph codeph">pseudoLayer=2</samp> is the forward part of the first
                                             hidden layer, and so on
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the input to
                                       one recurrent iteration (to retrieve the RNN input width).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                          describing the weights for the RNN.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">linLayerID</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. The linear layer to obtain information about: <a name="cudnnGetRNNLinLayerMatrixParams__ul_ehk_2fx_ngb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_ehk_2fx_ngb">
                                             <li class="li">If <samp class="ph codeph">mode</samp> in <samp class="ph codeph">rnnDesc</samp> was set
                                                to <samp class="ph codeph">CUDNN_RNN_RELU</samp> or
                                                <samp class="ph codeph">CUDNN_RNN_TANH</samp>:<a name="cudnnGetRNNLinLayerMatrixParams__ul_fhk_2fx_ngb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_fhk_2fx_ngb">
                                                   <li class="li">Value 0 references the bias applied to the input
                                                      from the previous layer (relevant if
                                                      <samp class="ph codeph">biasMode</samp> in
                                                      <samp class="ph codeph">rnnDesc</samp> is
                                                      <samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp> or
                                                      <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>).
                                                   </li>
                                                   <li class="li">Value 1 references the bias applied to the recurrent
                                                      input (relevant if <samp class="ph codeph">biasMode</samp> in
                                                      <samp class="ph codeph">rnnDesc</samp> is
                                                      <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp> or
                                                      <samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>).
                                                   </li>
                                                </ul>
                                             </li>
                                             <li class="li">If <samp class="ph codeph">mode</samp> in <samp class="ph codeph">rnnDesc</samp> was set
                                                to <samp class="ph codeph">CUDNN_LSTM</samp>:<a name="cudnnGetRNNLinLayerMatrixParams__ul_ghk_2fx_ngb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_ghk_2fx_ngb">
                                                   <li class="li">Values of 0, 1, 2 and 3 reference bias applied to
                                                      the input from the previous layer (relevant if
                                                      <samp class="ph codeph">biasMode</samp> in
                                                      <samp class="ph codeph">rnnDesc</samp> is
                                                      <samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp> or
                                                      <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>).
                                                   </li>
                                                   <li class="li">Values of 4, 5, 6 and 7 reference bias applied to
                                                      the recurrent input (relevant if
                                                      <samp class="ph codeph">biasMode</samp> in
                                                      <samp class="ph codeph">rnnDesc</samp> is
                                                      <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp> or
                                                      <samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>).
                                                   </li>
                                                   <li class="li">Values and their associated gates:<a name="cudnnGetRNNLinLayerMatrixParams__ul_hhk_2fx_ngb" shape="rect">
                                                         <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_hhk_2fx_ngb">
                                                         <li class="li">Values 0 and 4 reference the input gate.</li>
                                                         <li class="li">Values 1 and 5 reference the forget gate.</li>
                                                         <li class="li">Values 2 and 6 reference the new memory
                                                            gate.
                                                         </li>
                                                         <li class="li">Values 3 and 7 reference the output gate.</li>
                                                      </ul>
                                                   </li>
                                                </ul>
                                             </li>
                                             <li class="li">If <samp class="ph codeph">mode</samp> in <samp class="ph codeph">rnnDesc</samp> was set
                                                to <samp class="ph codeph">CUDNN_GRU</samp>:<a name="cudnnGetRNNLinLayerMatrixParams__ul_ihk_2fx_ngb" shape="rect">
                                                   <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_ihk_2fx_ngb">
                                                   <li class="li">Values of 0, 1 and 2 reference bias applied to the
                                                      input from the previous layer (relevant if
                                                      <samp class="ph codeph">biasMode</samp> in
                                                      <samp class="ph codeph">rnnDesc</samp> is
                                                      <samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp> or
                                                      <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>).
                                                   </li>
                                                   <li class="li">Values of 3, 4 and 5 reference bias applied to the
                                                      recurrent input (relevant if
                                                      <samp class="ph codeph">biasMode</samp> in
                                                      <samp class="ph codeph">rnnDesc</samp> is
                                                      <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp> or
                                                      <samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>).
                                                   </li>
                                                   <li class="li">Values and their associated gates:<a name="cudnnGetRNNLinLayerMatrixParams__ul_jhk_2fx_ngb" shape="rect">
                                                         <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_jhk_2fx_ngb">
                                                         <li class="li">Values 0 and 3 reference the reset gate.</li>
                                                         <li class="li">Values 1 and 4 reference the update gate.</li>
                                                         <li class="li">Values 2 and 5 reference the new memory
                                                            gate.
                                                         </li>
                                                      </ul>
                                                   </li>
                                                </ul>
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">For more information on modes and bias modes, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNMode_t" shape="rect">cudnnRNNMode_t</a></samp>. 
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">linLayerMatDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created filter descriptor. When
                                       the weight matrix does not exist, the returned filer descriptor has all
                                       fields set to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">linLayerMat</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">linLayerMatDesc</samp>. When the weight matrix does
                                       not exist, the returned pointer is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNLinLayerMatrixParams__section_jl2_pdk_1jb"><a name="cudnnGetRNNLinLayerMatrixParams__section_jl2_pdk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnGetRNNLinLayerMatrixParams__ul_bss_jf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_bss_jf3_s1b">
                                          <li class="li">One of the following arguments is <samp class="ph codeph">NULL</samp>:
                                             <samp class="ph codeph">handle</samp>, <samp class="ph codeph">rnnDesc</samp>,
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">linLayerMatDesc</samp>, or
                                             <samp class="ph codeph">linLayerMat</samp>.
                                          </li>
                                          <li class="li">A data type mismatch was detected between
                                             <samp class="ph codeph">rnnDesc</samp> and other descriptors.
                                          </li>
                                          <li class="li">Minimum requirement for the <samp class="ph codeph">w</samp> pointer alignment
                                             is not satisfied.
                                          </li>
                                          <li class="li">The value of <samp class="ph codeph">pseudoLayer</samp> or
                                             <samp class="ph codeph">linLayerID</samp> is out of range.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd">Some elements of the <samp class="ph codeph">linLayerMat</samp> vector are outside the
                                       <samp class="ph codeph">w</samp> buffer boundaries as specified by the
                                       <samp class="ph codeph">wDesc</samp> descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNMatrixMathType"><a name="cudnnGetRNNMatrixMathType" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNMatrixMathType" name="cudnnGetRNNMatrixMathType" shape="rect">7.2.25.&nbsp;<kbd class="ph userinput">cudnnGetRNNMatrixMathType()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDescriptor_v8" shape="rect">cudnnGetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNMatrixMathType()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNMatrixMathType(
	cudnnRNNDescriptor_t rnnDesc,
	cudnnMathType_t *mType);
</pre><p class="p">This function retrieves the preferred settings for NVIDIA Tensor Cores on NVIDIA Volta (SM 7.0) or higher GPUs. Refer to
                              the <samp class="ph codeph"><a class="xref" href="index.html#cudnnMathType_t" shape="rect">cudnnMathType_t</a></samp> description for more details.
                           </p>
                           <div class="section" id="cudnnGetRNNMatrixMathType__section_jbn_42k_1jb"><a name="cudnnGetRNNMatrixMathType__section_jbn_42k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Address where the preferred Tensor Core settings should
                                       be stored.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNMatrixMathType__section_ety_42k_1jb"><a name="cudnnGetRNNMatrixMathType__section_ety_42k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The requested RNN descriptor field was retrieved successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found (<samp class="ph codeph">rnnDesc</samp> or
                                       <samp class="ph codeph">mType</samp> was <samp class="ph codeph">NULL</samp>).
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNPaddingMode"><a name="cudnnGetRNNPaddingMode" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNPaddingMode" name="cudnnGetRNNPaddingMode" shape="rect">7.2.26.&nbsp;<kbd class="ph userinput">cudnnGetRNNPaddingMode()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDescriptor_v8" shape="rect">cudnnGetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNPaddingMode()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNPaddingMode(
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNPaddingMode_t       *paddingMode)</pre><p class="p">This function retrieves the RNN padding mode from the RNN descriptor.</p>
                           <div class="section" id="cudnnGetRNNPaddingMode__section_jbn_42k_1jb"><a name="cudnnGetRNNPaddingMode__section_jbn_42k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*paddingMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the host memory where the RNN padding mode is
                                       saved. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNPaddingMode__section_ety_42k_1jb"><a name="cudnnGetRNNPaddingMode__section_ety_42k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The RNN padding mode parameter was retrieved successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either the <samp class="ph codeph">rnnDesc</samp> or <samp class="ph codeph">*paddingMode</samp> is
                                       <samp class="ph codeph">NULL</samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNParamsSize"><a name="cudnnGetRNNParamsSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNParamsSize" name="cudnnGetRNNParamsSize" shape="rect">7.2.27.&nbsp;<kbd class="ph userinput">cudnnGetRNNParamsSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWeightSpaceSize" title="This function reports the required size of the weight space buffer in bytes. The weight space buffer holds all RNN weight matrices and bias vectors." shape="rect">cudnnGetRNNWeightSpaceSize()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNParamsSize()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNParamsSize(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    size_t                         *sizeInBytes,
    cudnnDataType_t                 dataType)</pre><p class="p">This function is used to query the amount of parameter space required to execute the RNN
                              described by <samp class="ph codeph">rnnDesc</samp> with input dimensions defined by
                              <samp class="ph codeph">xDesc</samp>.
                           </p>
                           <div class="section" id="cudnnGetRNNParamsSize__section_gmf_v2k_1jb"><a name="cudnnGetRNNParamsSize__section_gmf_v2k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the input to
                                       one recurrent iteration.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum amount of GPU memory needed as parameter space to
                                       be able to execute an RNN with the specified descriptor and input
                                       tensors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The data type of the parameters.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNParamsSize__section_ys4_v2k_1jb"><a name="cudnnGetRNNParamsSize__section_ys4_v2k_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnGetRNNParamsSize__ul_pg4_ff3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNParamsSize__ul_pg4_ff3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">The descriptor <samp class="ph codeph">xDesc</samp> is invalid.
                                          </li>
                                          <li class="li">The descriptor <samp class="ph codeph">xDesc</samp> is not fully packed.
                                          </li>
                                          <li class="li">The combination of <samp class="ph codeph">dataType</samp> and tensor
                                             descriptor data type is invalid.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The combination of the RNN descriptor and tensor descriptors is not
                                       supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNProjectionLayers"><a name="cudnnGetRNNProjectionLayers" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNProjectionLayers" name="cudnnGetRNNProjectionLayers" shape="rect">7.2.28.&nbsp;<kbd class="ph userinput">cudnnGetRNNProjectionLayers()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNDescriptor_v8" shape="rect">cudnnGetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNProjectionLayers()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNProjectionLayers(
    cudnnHandle_t           handle,
    cudnnRNNDescriptor_t    rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *recProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *outProjSize)</pre><p class="p">This function retrieves the current RNN projection parameters. By default, the projection
                              feature is disabled so invoking this function will yield <samp class="ph codeph">recProjSize</samp>
                              equal to <samp class="ph codeph">hiddenSize</samp> and <samp class="ph codeph">outProjSize</samp> set to zero. The
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNProjectionLayers" shape="rect">cudnnSetRNNProjectionLayers()</a></samp> method enables the
                              RNN projection.
                           </p>
                           <div class="section" id="cudnnGetRNNProjectionLayers__section_ank_ffk_1jb"><a name="cudnnGetRNNProjectionLayers__section_ank_ffk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">recProjSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer where the recurrent projection size should be
                                       stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">outProjSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer where the output projection size should be
                                       stored.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNProjectionLayers__section_nst_ffk_1jb"><a name="cudnnGetRNNProjectionLayers__section_nst_ffk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">RNN projection parameters were retrieved successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">A <samp class="ph codeph">NULL</samp> pointer was passed to the function.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNTempSpaceSizes"><a name="cudnnGetRNNTempSpaceSizes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNTempSpaceSizes" name="cudnnGetRNNTempSpaceSizes" shape="rect">7.2.29.&nbsp;<kbd class="ph userinput">cudnnGetRNNTempSpaceSizes()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes the work and reserve space buffer sizes based on the RNN
                                 network geometry stored in <samp class="ph codeph">rnnDesc</samp>, designated usage (inference or
                                 training) defined by the <samp class="ph codeph">fMode</samp> argument, and the current RNN data
                                 dimensions (<samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>) retrieved from
                                 <samp class="ph codeph">xDesc</samp>. When RNN data dimensions change, the
                                 <samp class="ph codeph">cudnnGetRNNTempSpaceSizes()</samp> must be called again because RNN
                                 temporary buffer sizes are not monotonic.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNTempSpaceSizes(
	cudnnHandle_t handle,
	cudnnRNNDescriptor_t rnnDesc,
	cudnnForwardMode_t fMode,
    cudnnRNNDataDescriptor_t xDesc,
	size_t *workSpaceSize,
	size_t *reserveSpaceSize);
</pre><p class="p">The user can assign <samp class="ph codeph">NULL</samp> to <samp class="ph codeph">workSpaceSize</samp> or
                              <samp class="ph codeph">reserveSpaceSize</samp> pointers when the corresponding value is not
                              needed.
                           </p>
                           <div class="section" id="cudnnGetRNNTempSpaceSizes__section_drx_rln_y3b"><a name="cudnnGetRNNTempSpaceSizes__section_drx_rln_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">fMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies whether temporary buffers are used in inference
                                       or training modes. The reserve-space buffer is not used during
                                       inference. Therefore, the returned size of the reserve space buffer will
                                       be zero when the <samp class="ph codeph">fMode</samp> argument is
                                       <samp class="ph codeph">CUDNN_FWD_MODE_INFERENCE</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A single RNN data descriptor that specifies current RNN
                                       data dimensions: <samp class="ph codeph">maxSeqLength</samp> and
                                       <samp class="ph codeph">batchSize</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum amount of GPU memory in bytes needed as a
                                       workspace buffer. The workspace buffer is not used to pass intermediate
                                       results between APIs but as a temporary read/write buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum amount of GPU memory in bytes needed as the
                                       reserve-space buffer. The reserve space buffer is used to pass
                                       intermediate results from <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> to RNN <samp class="ph codeph">BackwardData</samp> and
                                       <samp class="ph codeph">BackwardWeights</samp> routines that compute first order
                                       derivatives with respect to RNN inputs or trainable weight and
                                       biases.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNTempSpaceSizes__section_bhm_sln_y3b"><a name="cudnnGetRNNTempSpaceSizes__section_bhm_sln_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">RNN temporary buffer sizes were computed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was detected.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">An incompatible or unsupported combination of input arguments was
                                       detected.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNTrainingReserveSize"><a name="cudnnGetRNNTrainingReserveSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNTrainingReserveSize" name="cudnnGetRNNTrainingReserveSize" shape="rect">7.2.30.&nbsp;<kbd class="ph userinput">cudnnGetRNNTrainingReserveSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNTempSpaceSizes" title="This function computes the work and reserve space buffer sizes based on the RNN network geometry stored in rnnDesc, designated usage (inference or training) defined by the fMode argument, and the current RNN data dimensions (maxSeqLength, batchSize) retrieved from xDesc. When RNN data dimensions change, the cudnnGetRNNTempSpaceSizes() must be called again because RNN temporary buffer sizes are not monotonic." shape="rect">cudnnGetRNNTempSpaceSizes()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNTrainingReserveSize()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNTrainingReserveSize(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    size_t                         *sizeInBytes)</pre><p class="p">This function is used to query the amount of reserved space required for training the RNN
                              described by <samp class="ph codeph">rnnDesc</samp> with input dimensions defined by
                              <samp class="ph codeph">xDesc</samp>. The same reserved space buffer must be passed to
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp>, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp>. Each of these calls overwrites the
                              contents of the reserved space, however it can safely be backed up and restored between
                              calls if reuse of the memory is desired.
                           </p>
                           <div class="section" id="cudnnGetRNNTrainingReserveSize__section_pcr_mfk_1jb"><a name="cudnnGetRNNTrainingReserveSize__section_pcr_mfk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the RNN. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of tensor descriptors describing the input to
                                       each recurrent iteration (one descriptor per iteration). The first
                                       dimension (batch size) of the tensors may decrease from element
                                       <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                       increase. Each tensor descriptor must have the same second dimension
                                       (vector length).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum amount of GPU memory needed as reserve space to
                                       be able to train an RNN with the specified descriptor and input
                                       tensors.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNTrainingReserveSize__section_xq1_nfk_1jb"><a name="cudnnGetRNNTrainingReserveSize__section_xq1_nfk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met: <a name="cudnnGetRNNTrainingReserveSize__ul_gxd_cf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNTrainingReserveSize__ul_gxd_cf3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors in <samp class="ph codeph">xDesc</samp> is
                                             invalid.
                                          </li>
                                          <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have inconsistent
                                             second dimensions, strides or data types.
                                          </li>
                                          <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have increasing first
                                             dimensions.
                                          </li>
                                          <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> are not fully
                                             packed.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The data types in tensors described by <samp class="ph codeph">xDesc</samp> are not
                                       supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNWeightParams"><a name="cudnnGetRNNWeightParams" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNWeightParams" name="cudnnGetRNNWeightParams" shape="rect">7.2.31.&nbsp;<kbd class="ph userinput">cudnnGetRNNWeightParams()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function is used to obtain the start address and shape of every RNN weight
                                 matrix and bias vector in each pseudo-layer within the recurrent network.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNWeightParams(
	cudnnHandle_t handle,
	cudnnRNNDescriptor_t rnnDesc,
	int32_t pseudoLayer,
	size_t weightSpaceSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *weightSpace,
	int32_t linLayerID,
    cudnnTensorDescriptor_t mDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **mAddr,
    cudnnTensorDescriptor_t bDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **bAddr);
</pre><div class="section" id="cudnnGetRNNWeightParams__section_l1g_xmn_y3b"><a name="cudnnGetRNNWeightParams__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">pseudoLayer</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The pseudo-layer to query. In unidirectional RNNs, a
                                       pseudo-layer is the same as a physical layer
                                       (<samp class="ph codeph">pseudoLayer=0</samp> is the RNN input layer,
                                       <samp class="ph codeph">pseudoLayer=1</samp> is the first hidden layer). In
                                       bidirectional RNNs, there are twice as many pseudo-layers in comparison
                                       to physical layers:<a name="cudnnGetRNNWeightParams__ul_vbp_drb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNWeightParams__ul_vbp_drb_wlb">
                                          <li class="li"><samp class="ph codeph">pseudoLayer=0</samp> refers to the forward direction
                                             sub-layer of the physical input layer
                                          </li>
                                          <li class="li"><samp class="ph codeph">pseudoLayer=1</samp> refers to the backward direction
                                             sub-layer of the physical input layer
                                          </li>
                                          <li class="li"><samp class="ph codeph">pseudoLayer=2</samp> is the forward direction
                                             sub-layer of the first hidden layer, and so on
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the weight space buffer in bytes.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the weight space buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">linLayerID</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. Weight matrix or bias vector linear ID index.
                                       </p>
                                       <div class="p">If <samp class="ph codeph">cellMode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                          <samp class="ph codeph">CUDNN_RNN_RELU</samp> or
                                          <samp class="ph codeph">CUDNN_RNN_TANH</samp>:<a name="cudnnGetRNNWeightParams__ul_l3d_hrb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNWeightParams__ul_l3d_hrb_wlb">
                                             <li class="li">Value <samp class="ph codeph">0</samp> references the weight matrix or
                                                bias vector used in conjunction with the input from the
                                                previous layer or input to the RNN model.
                                             </li>
                                             <li class="li">Value <samp class="ph codeph">1</samp> references the weight matrix or
                                                bias vector used in conjunction with the hidden state from
                                                the previous time step or the initial hidden state.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">If <samp class="ph codeph">cellMode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                          <samp class="ph codeph">CUDNN_LSTM</samp>:<a name="cudnnGetRNNWeightParams__ul_yfq_3rb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNWeightParams__ul_yfq_3rb_wlb">
                                             <li class="li">Values <samp class="ph codeph">0</samp>, <samp class="ph codeph">1</samp>,
                                                <samp class="ph codeph">2</samp> and <samp class="ph codeph">3</samp> reference
                                                weight matrices or bias vectors used in conjunction with the
                                                input from the previous layer or input to the RNN
                                                model.
                                             </li>
                                             <li class="li">Values <samp class="ph codeph">4</samp>, <samp class="ph codeph">5</samp>,
                                                <samp class="ph codeph">6</samp> and <samp class="ph codeph">7</samp> reference
                                                weight matrices or bias vectors used in conjunction with the
                                                hidden state from the previous time step or the initial
                                                hidden state.
                                             </li>
                                             <li class="li">Value <samp class="ph codeph">8</samp> corresponds to the projection
                                                matrix, if enabled (there is no bias in this
                                                operation).
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">Values and their LSTM gates:<a name="cudnnGetRNNWeightParams__ul_gx2_zsx_bnb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNWeightParams__ul_gx2_zsx_bnb">
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">0</samp> and
                                                <samp class="ph codeph">4</samp> correspond to the input gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">1</samp> and
                                                <samp class="ph codeph">5</samp> correspond to the forget gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">2</samp> and
                                                <samp class="ph codeph">6</samp> correspond to the new cell state
                                                calculations with hyperbolic tangent.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">3</samp> and
                                                <samp class="ph codeph">7</samp> correspond to the output gate.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">If <samp class="ph codeph">cellMode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                          <samp class="ph codeph">CUDNN_GRU</samp>:<a name="cudnnGetRNNWeightParams__ul_gdy_jrb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNWeightParams__ul_gdy_jrb_wlb">
                                             <li class="li">Values <samp class="ph codeph">0</samp>, <samp class="ph codeph">1</samp> and
                                                <samp class="ph codeph">2</samp> reference weight matrices or bias
                                                vectors used in conjunction with the input from the previous
                                                layer or input to the RNN model.
                                             </li>
                                             <li class="li">Values <samp class="ph codeph">3</samp>, <samp class="ph codeph">4</samp> and
                                                <samp class="ph codeph">5</samp> reference weight matrices or bias
                                                vectors used in conjunction with the hidden state from the
                                                previous time step or the initial hidden state.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">Values and their GRU gates:<a name="cudnnGetRNNWeightParams__ul_gld_mrb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnGetRNNWeightParams__ul_gld_mrb_wlb">
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">0</samp> and
                                                <samp class="ph codeph">3</samp> correspond to the reset gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">1</samp> and
                                                <samp class="ph codeph">4</samp> reference to the update gate.
                                             </li>
                                             <li class="li"><samp class="ph codeph">linLayerID</samp><samp class="ph codeph">2</samp> and
                                                <samp class="ph codeph">5</samp> correspond to the new hidden state
                                                calculations with hyperbolic tangent.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">For more information on modes and bias modes, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNMode_t" shape="rect">cudnnRNNMode_t</a></samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created tensor descriptor. The
                                       shape of the corresponding weight matrix is returned in this descriptor
                                       in the following format: <samp class="ph codeph">dimA[3] = {1, rows, cols}</samp>. The
                                       reported number of tensor dimensions is zero when the weight matrix does
                                       not exist. This situation occurs for input GEMM matrices of the first
                                       layer when <samp class="ph codeph">CUDNN_SKIP_INPUT</samp> is selected or for the LSTM
                                       projection matrix when the feature is disabled.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mAddr</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the beginning of the weight matrix within the
                                       weight space buffer. When the weight matrix does not exist, the returned
                                       address is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Handle to a previously created tensor descriptor. The
                                       shape of the corresponding bias vector is returned in this descriptor in
                                       the following format: <samp class="ph codeph">dimA[3] = {1, rows, 1}</samp>. The
                                       reported number of tensor dimensions is zero when the bias vector does
                                       not exist.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">bAddr</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the beginning of the bias vector within the
                                       weight space buffer. When the bias vector does not exist, the returned
                                       address is <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNWeightParams__section_zgs_xmn_y3b"><a name="cudnnGetRNNWeightParams__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was completed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was encountered. For example, the value of
                                       <samp class="ph codeph">pseudoLayer</samp> is out of range or
                                       <samp class="ph codeph">linLayerID</samp> is negative or larger than 8.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd">Some weight/bias elements are outside the weight space buffer
                                       boundaries.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                                    <dd class="dd">The RNN descriptor was configured with the legacy <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v6" shape="rect">cudnnSetRNNDescriptor_v6()</a></samp> call.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNWeightSpaceSize"><a name="cudnnGetRNNWeightSpaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNWeightSpaceSize" name="cudnnGetRNNWeightSpaceSize" shape="rect">7.2.32.&nbsp;<kbd class="ph userinput">cudnnGetRNNWeightSpaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function reports the required size of the weight space buffer in bytes. The
                                 weight space buffer holds all RNN weight matrices and bias vectors.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNWeightSpaceSize(
	cudnnHandle_t handle,
	cudnnRNNDescriptor_t rnnDesc,
	size_t *weightSpaceSize);
</pre><div class="section" id="cudnnGetRNNWeightSpaceSize__section_l1g_xmn_y3b"><a name="cudnnGetRNNWeightSpaceSize__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum size in bytes of GPU memory needed for all RNN
                                       trainable parameters.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNWeightSpaceSize__section_zgs_xmn_y3b"><a name="cudnnGetRNNWeightSpaceSize__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was encountered. For example, any input
                                       argument was <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                                    <dd class="dd">The RNN descriptor was configured with the legacy <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v6" shape="rect">cudnnSetRNNDescriptor_v6()</a></samp> call.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNWorkspaceSize"><a name="cudnnGetRNNWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNWorkspaceSize" name="cudnnGetRNNWorkspaceSize" shape="rect">7.2.33.&nbsp;<kbd class="ph userinput">cudnnGetRNNWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNTempSpaceSizes" title="This function computes the work and reserve space buffer sizes based on the RNN network geometry stored in rnnDesc, designated usage (inference or training) defined by the fMode argument, and the current RNN data dimensions (maxSeqLength, batchSize) retrieved from xDesc. When RNN data dimensions change, the cudnnGetRNNTempSpaceSizes() must be called again because RNN temporary buffer sizes are not monotonic." shape="rect">cudnnGetRNNTempSpaceSizes()</a></samp> instead of
                              <samp class="ph codeph">cudnnGetRNNWorkspaceSize()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNWorkspaceSize(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    size_t                         *sizeInBytes)</pre><p class="p">This function is used to query the amount of work space required to execute the RNN
                              described by <samp class="ph codeph">rnnDesc</samp> with input dimensions defined by
                              <samp class="ph codeph">xDesc</samp>.
                           </p>
                           <div class="section" id="cudnnGetRNNWorkspaceSize__section_lks_xfk_1jb"><a name="cudnnGetRNNWorkspaceSize__section_lks_xfk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. Workspace that is
                                       allocated, based on the size that this function provides, cannot be used
                                       for sequences longer than <samp class="ph codeph">seqLength</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. An array of tensor descriptors describing the input to
                                          each recurrent iteration (one descriptor per iteration). The first
                                          dimension (batch size) of the tensors may decrease from element
                                          <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                          increase. For example, if you have multiple time series in a batch,
                                          they can be different lengths. This dimension is the batch size for
                                          the particular iteration of the sequence, and so it should decrease
                                          when a sequence in the batch has been terminated. 
                                       </p>
                                       <p class="p">Each tensor descriptor must have the same second dimension (vector
                                          length).
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Minimum amount of GPU memory needed as workspace to be
                                       able to execute an RNN with the specified descriptor and input
                                       tensors.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetRNNWorkspaceSize__section_exd_yfk_1jb"><a name="cudnnGetRNNWorkspaceSize__section_exd_yfk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetRNNWorkspaceSize__ul_rlk_w23_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNWorkspaceSize__ul_rlk_w23_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors in <samp class="ph codeph">xDesc</samp> is
                                             invalid.
                                          </li>
                                          <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have inconsistent
                                             second dimensions, strides or data types.
                                          </li>
                                          <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have increasing first
                                             dimensions.
                                          </li>
                                          <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> are not fully
                                             packed.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The data types in tensors described by <samp class="ph codeph">xDesc</samp> are not
                                       supported. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetSeqDataDescriptor"><a name="cudnnGetSeqDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetSeqDataDescriptor" name="cudnnGetSeqDataDescriptor" shape="rect">7.2.34.&nbsp;<kbd class="ph userinput">cudnnGetSeqDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function retrieves settings from a previously created sequence data
                                 			descriptor. The user can assign <samp class="ph codeph">NULL</samp> to any pointer except
                                 				<samp class="ph codeph">seqDataDesc</samp> when the retrieved value is not needed. The
                                 				<samp class="ph codeph">nbDimsRequested</samp> argument applies to both <samp class="ph codeph">dimA[]</samp>
                                 			and <samp class="ph codeph">axes[]</samp> arrays. A positive value of <samp class="ph codeph">nbDimsRequested</samp>
                                 			or <samp class="ph codeph">seqLengthSizeRequested</samp> is ignored when the corresponding array,
                                 				<samp class="ph codeph">dimA[]</samp>, <samp class="ph codeph">axes[]</samp>, or
                                 				<samp class="ph codeph">seqLengthArray[]</samp> is <samp class="ph codeph">NULL</samp>.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetSeqDataDescriptor(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t seqDataDesc,
	cudnnDataType_t *dataType,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *nbDims,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> nbDimsRequested,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> dimA[],
	cudnnSeqDataAxis_t axes[],
	size_t *seqLengthArraySize,
	size_t seqLengthSizeRequested,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> seqLengthArray[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *paddingFill);
</pre><div class="p">The <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetSeqDataDescriptor" title="This function retrieves settings from a previously created sequence data descriptor. The user can assign NULL to any pointer except seqDataDesc when the retrieved value is not needed. The nbDimsRequested argument applies to both dimA[] and axes[] arrays. A positive value of nbDimsRequested or seqLengthSizeRequested is ignored when the corresponding array, dimA[], axes[], or seqLengthArray[] is NULL." shape="rect">cudnnGetSeqDataDescriptor()</a></samp> function does not report the
                              			actual strides in the sequence data buffer. Those strides can be handy in computing the
                              			offset to any sequence data element. The user must precompute strides based on the
                              				<samp class="ph codeph">axes[]</samp> and <samp class="ph codeph">dimA[]</samp> arrays reported by the
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnGetSeqDataDescriptor" title="This function retrieves settings from a previously created sequence data descriptor. The user can assign NULL to any pointer except seqDataDesc when the retrieved value is not needed. The nbDimsRequested argument applies to both dimA[] and axes[] arrays. A positive value of nbDimsRequested or seqLengthSizeRequested is ignored when the corresponding array, dimA[], axes[], or seqLengthArray[] is NULL." shape="rect">cudnnGetSeqDataDescriptor()</a></samp> function. Below is
                              			sample code that performs this
                              			task:<pre xml:space="preserve">// Array holding sequence data strides.
size_t strA[CUDNN_SEQDATA_DIM_COUNT] = {0};
 
// Compute strides from dimension and order arrays.
size_t stride = 1;
for (int i = nbDims - 1; i &gt;= 0; i--) {
	int j = int(axes[i]);
	if (unsigned(j) &lt; CUDNN_SEQDATA_DIM_COUNT-1 &amp;&amp; strA[j] == 0) {
   	strA[j] = stride;
   	stride *= dimA[j];
	} else {
	    fprintf(stderr, "ERROR: invalid axes[%d]=%d\n\n", i, j);
    	abort();
	}
}
</pre></div>
                           <div class="p">Now, the <samp class="ph codeph">strA[]</samp> array can be used to compute the index to any sequence
                              			data element, for
                              			example:<pre xml:space="preserve">// Using four indices (batch, beam, time, vect) with ranges already checked.
size_t base = strA[CUDNN_SEQDATA_BATCH_DIM] * batch
	        + strA[CUDNN_SEQDATA_BEAM_DIM]  * beam
       	 + strA[CUDNN_SEQDATA_TIME_DIM]  * time;
val = seqDataPtr[base + vect];
</pre></div>
                           <p class="p">The above code assumes that all four indices (<samp class="ph codeph">batch, beam, time, vect</samp>)
                              			are less than the corresponding value in the <samp class="ph codeph">dimA[]</samp> array. The sample
                              			code also omits the <samp class="ph codeph">strA[CUDNN_SEQDATA_VECT_DIM]</samp> stride because its
                              			value is always <samp class="ph codeph">1</samp>, meaning, elements of one vector occupy a contiguous
                              			block of memory.
                           </p>
                           <div class="section" id="cudnnGetSeqDataDescriptor__section_pzt_xgk_1jb"><a name="cudnnGetSeqDataDescriptor__section_pzt_xgk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Sequence data descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Data type used in the sequence data buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> The number of active dimensions in the
                                       								<samp class="ph codeph">dimA[]</samp> and <samp class="ph codeph">axes[]</samp> arrays.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDimsRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> The maximum number of consecutive elements that can be
                                       							written to <samp class="ph codeph">dimA[]</samp> and <samp class="ph codeph">axes[]</samp> arrays
                                       							starting from index zero. The recommended value for this argument is
                                       								<samp class="ph codeph">CUDNN_SEQDATA_DIM_COUNT</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dimA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Integer array holding sequence data dimensions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">axes[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataAxis_t" shape="rect">cudnnSeqDataAxis_t</a></samp> that defines
                                       							the layout of sequence data in memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLengthArraySize</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> The number of required elements in
                                       								<samp class="ph codeph">seqLengthArray[]</samp> to save all sequence lengths.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLengthSizeRequested</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> The maximum number of consecutive elements that can be
                                       							written to the <samp class="ph codeph">seqLengthArray[]</samp> array starting from
                                       							index zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLengthArray[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Integer array holding sequence lengths.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddingFill</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Pointer to a storage location of
                                       								<samp class="ph codeph">dataType</samp> with the fill value that should be written
                                       							to all padding vectors. Use <samp class="ph codeph">NULL</samp> when an explicit
                                       							initialization of output padding vectors was not requested.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetSeqDataDescriptor__section_yjb_fhk_1jb"><a name="cudnnGetSeqDataDescriptor__section_yjb_fhk_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">Requested sequence data descriptor fields were retrieved
                                       							successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">An inconsistent internal state was encountered.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnMultiHeadAttnForward"><a name="cudnnMultiHeadAttnForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnForward" name="cudnnMultiHeadAttnForward" shape="rect">7.2.35.&nbsp;<kbd class="ph userinput">cudnnMultiHeadAttnForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">The <samp class="ph codeph">cudnnMultiHeadAttnForward()</samp> function computes the forward
                              		responses of the multi-head attention layer. When <samp class="ph codeph">reserveSpaceSizeInBytes=0</samp>
                              		and <samp class="ph codeph">reserveSpace=NULL</samp>, the function operates in the inference mode in which
                              		backward (gradient) functions are not invoked, otherwise, the training mode is assumed. In
                              		the training mode, the reserve space is used to pass intermediate results from
                              			<samp class="ph codeph">cudnnMultiHeadAttnForward()</samp> to <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp> and from <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp> to <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardWeights" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its trainable parameters: projection weights and projection biases. If y=F(w) is a vector-valued function that represents the multi-head attention layer and it takes some vector of flatten weights or biases as an input (with all other parameters and inputs fixed), and outputs vector , then cudnnMultiHeadAttnBackwardWeights() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(w). The input is supplied via the dout argument." shape="rect">cudnnMultiHeadAttnBackwardWeights()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnMultiHeadAttnForward(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> currIdx,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> loWinIdx[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> hiWinIdx[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> devSeqLengthsQO[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> devSeqLengthsKV[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t qDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *queries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *residuals,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t kDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *keys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t vDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *values,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t oDesc,
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *out,
	size_t weightSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *weights,
	size_t workSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
	size_t reserveSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);
</pre><p class="p">In the inference mode, the <samp class="ph codeph">currIdx</samp> specifies the time-step or sequence
                              			index of the embedding vectors to be processed. In this mode, the user can perform one
                              			iteration for time-step zero (<samp class="ph codeph">currIdx=0</samp>), then update <strong class="ph b">Q, K, V</strong>
                              			vectors and the attention window, and execute the next step
                              			(<samp class="ph codeph">currIdx=1</samp>). The iterative process can be repeated for all
                              			time-steps.
                           </p>
                           <p class="p">When all <strong class="ph b">Q</strong> time-steps are available (for example, in the training mode or in the
                              			inference mode on the encoder side in self-attention),the user can assign a negative
                              			value to <samp class="ph codeph">currIdx </samp>and the <samp class="ph codeph">cudnnMultiHeadAttnForward()</samp>
                              			API will automatically sweep through all <strong class="ph b">Q</strong> time-steps.
                           </p>
                           <div class="p">The <samp class="ph codeph">loWinIdx[]</samp> and <samp class="ph codeph">hiWinIdx[]</samp> host arrays specify the
                              			attention window size for each <strong class="ph b">Q</strong> time-step. In a typical self-attention case, the
                              			user must include all previously visited embedding vectors but not the current or future
                              			vectors. In this situation, the user should
                              			set:<pre xml:space="preserve">currIdx=0: loWinIdx[0]=0; hiWinIdx[0]=0;  // initial time-step, no attention window
currIdx=1: loWinIdx[1]=0; hiWinIdx[1]=1;  // attention window spans one vector
currIdx=2: loWinIdx[2]=0; hiWinIdx[2]=2;  // attention window spans two vectors
(...)
</pre></div>
                           <p class="p">When <samp class="ph codeph">currIdx </samp>is negative in
                              			<samp class="ph codeph">cudnnMultiHeadAttnForward()</samp>, the <samp class="ph codeph">loWinIdx[]</samp> and
                              				<samp class="ph codeph">hiWinIdx[]</samp> arrays must be fully initialized for all time-steps.
                              			When <samp class="ph codeph">cudnnMultiHeadAttnForward()</samp> is invoked with
                              				<samp class="ph codeph">currIdx=0</samp>, <samp class="ph codeph">currIdx=1</samp>, <samp class="ph codeph">currIdx=2</samp>,
                              			etc., then the user can update <samp class="ph codeph">loWinIdx[currIdx]</samp> and
                              				<samp class="ph codeph">hiWinIdx[currIdx]</samp> elements only before invoking the forward
                              			response function. All other elements in the <samp class="ph codeph">loWinIdx[]</samp> and
                              				<samp class="ph codeph">hiWinIdx[]</samp> arrays will not be accessed. Any adaptive attention
                              			window scheme can be implemented that way.
                           </p>
                           <div class="p">Use the following settings when the attention window should be the maximum size, for
                              			example, in
                              			cross-attention:<pre xml:space="preserve">currIdx=0: loWinIdx[0]=0; hiWinIdx[0]=maxSeqLenK;
currIdx=1: loWinIdx[1]=0; hiWinIdx[1]=maxSeqLenK;
currIdx=2: loWinIdx[2]=0; hiWinIdx[2]=maxSeqLenK;
(...)
</pre></div>
                           <div class="p">The <samp class="ph codeph">maxSeqLenK</samp> value above should be equal to or larger than
                              				<samp class="ph codeph">dimA[CUDNN_SEQDATA_TIME_DIM]</samp> in the <samp class="ph codeph">kDesc</samp>
                              			descriptor. A good choice is to use <samp class="ph codeph">maxSeqLenK=INT_MAX</samp> from
                              				<samp class="ph codeph">limits.h</samp>. 
                              <div class="note note"><span class="notetitle">Note:</span> The actual length of any <strong class="ph b">K</strong> sequence defined
                                 				in <samp class="ph codeph">seqLengthArray[]</samp> in <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSeqDataDescriptor" title="This function initializes a previously created sequence data descriptor object. In the most simplified view, this descriptor defines dimensions (dimA) and the data layout (axes) of a four-dimensional tensor." shape="rect">cudnnSetSeqDataDescriptor()</a></samp> can be shorter than
                                 					<samp class="ph codeph">maxSeqLenK</samp>. The effective attention window span is computed
                                 				based on <samp class="ph codeph">seqLengthArray[]</samp> stored in the <strong class="ph b">K</strong> sequence
                                 				descriptor and indices held in <samp class="ph codeph">loWinIdx[]</samp> and
                                 					<samp class="ph codeph">hiWinIdx[]</samp> arrays.
                              </div>
                           </div>
                           <p class="p"><samp class="ph codeph">devSeqLengthsQO[]</samp> and <samp class="ph codeph">devSeqLengthsKV[]</samp> are pointers to
                              			device (not host) arrays with <strong class="ph b">Q, O</strong>, and <strong class="ph b">K, V</strong> sequence lengths. Note that
                              			the same information is also passed in the corresponding descriptors of type
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> on the host side. The
                              			need for extra device arrays comes from the asynchronous nature of cuDNN calls and
                              			limited size of the constant memory dedicated to GPU kernel arguments. When the
                              				<samp class="ph codeph">cudnnMultiHeadAttnForward()</samp> API returns, the sequence length arrays
                              			stored in the descriptors can be immediately modified for the next iteration. However,
                              			the GPU kernels launched by the forward call may not have started at this point. For
                              			this reason, copies of sequence arrays are needed on the device side to be accessed
                              			directly by GPU kernels. Those copies cannot be created inside the
                              				<samp class="ph codeph">cudnnMultiHeadAttnForward()</samp> function for very large <strong class="ph b">K, V</strong>
                              			inputs without the device memory allocation and CUDA stream synchronization.
                           </p>
                           <p class="p">To reduce the <samp class="ph codeph">cudnnMultiHeadAttnForward()</samp> API overhead,
                              				<samp class="ph codeph">devSeqLengthsQO[]</samp> and <samp class="ph codeph">devSeqLengthsKV[]</samp> device
                              			arrays are not validated to contain the same settings as
                              				<samp class="ph codeph">seqLengthArray[]</samp> in the sequence data descriptors.
                           </p>
                           <p class="p">Sequence lengths in the <samp class="ph codeph">kDesc</samp> and <samp class="ph codeph">vDesc</samp> descriptors should be
                              			the same. Similarly, sequence lengths in the <samp class="ph codeph">qDesc</samp> and
                              				<samp class="ph codeph">oDesc</samp> descriptors should match. The user can define six different
                              			data layouts in the <samp class="ph codeph">qDesc</samp>, <samp class="ph codeph">kDesc</samp>,
                              				<samp class="ph codeph">vDesc</samp> and <samp class="ph codeph">oDesc</samp> descriptors. Refer to the
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnSetSeqDataDescriptor" title="This function initializes a previously created sequence data descriptor object. In the most simplified view, this descriptor defines dimensions (dimA) and the data layout (axes) of a four-dimensional tensor." shape="rect">cudnnSetSeqDataDescriptor()</a></samp> function for the
                              			discussion of those layouts. All multi-head attention API calls require that the same
                              			layout is used in all sequence data descriptors.
                           </p>
                           <div class="p">In the transformer model, the multi-head attention block is tightly coupled with the layer
                              			normalization and residual connections. <samp class="ph codeph">cudnnMultiHeadAttnForward()</samp>
                              			does not encompass the layer normalization but it can be used to handle residual
                              			connections as depicted in the following figure.
                              <div class="fig fignone"><span class="figcap">Figure 3. Multi-Head Attention Block is Tightly Coupled with the Layer Normalization
                                    					and Residual Connections</span><img class="image" src="graphics/multiheadattnforward.png" alt="Multi-Head Attention Block is Tightly Coupled with the Layer Normalization and Residual Connections"></img></div>
                           </div>
                           <p class="p">Queries and residuals share the same <samp class="ph codeph">qDesc</samp> descriptor in
                              				<samp class="ph codeph">cudnnMultiHeadAttnForward()</samp>. When residual connections are
                              			disabled, the residuals pointer should be <samp class="ph codeph">NULL</samp>. When residual
                              			connections are enabled, the vector length in <samp class="ph codeph">qDesc</samp> should match the
                              			vector length specified in the <samp class="ph codeph">oDesc</samp> descriptor, so that a vector
                              			addition is feasible.
                           </p>
                           <p class="p">The <samp class="ph codeph">queries</samp>, <samp class="ph codeph">keys</samp>, and <samp class="ph codeph">values</samp> pointers
                              			are not allowed to be <samp class="ph codeph">NULL</samp>, even when <strong class="ph b">K</strong> and <strong class="ph b">V</strong> are the
                              			same inputs or <strong class="ph b">Q, K, V</strong> are the same inputs.
                           </p>
                           <div class="section" id="cudnnMultiHeadAttnForward__section_igv_tsl_1jb"><a name="cudnnMultiHeadAttnForward__section_igv_tsl_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized attention descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">currIdx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Time-step in queries to process. When the
                                       								<samp class="ph codeph">currIdx</samp> argument is negative, all <strong class="ph b">Q</strong>
                                       							time-steps are processed. When <samp class="ph codeph">currIdx</samp> is zero or
                                       							positive, the forward response is computed for the selected time-step
                                       							only. The latter input can be used in inference mode only, to process
                                       							one time-step while updating the next attention window and <strong class="ph b">Q, R, K,
                                          								V</strong> inputs in-between calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">loWinIdx[]</samp>, <samp class="ph codeph">hiWinIdx[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Two host integer arrays specifying the start and end
                                       							indices of the attention window for each <strong class="ph b">Q</strong> time-step. The start
                                       							index in <strong class="ph b">K, V</strong> sets is inclusive, and the end index is
                                       							exclusive.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">devSeqLengthsQO[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Device array specifying sequence lengths of query,
                                       							residual, and output sequence data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">devSeqLengthsKV[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Device array specifying sequence lengths of key and value
                                       							input data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">qDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the query and residual sequence data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">queries</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to queries data in the device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">residuals</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to residual data in device memory. Set this
                                       							argument to <samp class="ph codeph">NULL</samp> if no residual connections are
                                       							required.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">kDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the <samp class="ph codeph">keys</samp> sequence
                                       							data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">keys</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">keys</samp> data in device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">vDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the <samp class="ph codeph">values</samp> sequence
                                       							data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">values</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">values</samp> data in device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">oDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the multi-head attention output sequence
                                       							data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">out</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to device memory where the output response should
                                       							be written.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the weight buffer in bytes where all multi-head
                                       							attention trainable parameters are stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weights</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the weight buffer in device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the work-space buffer in bytes used for temporary
                                       							API storage.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Pointer to the work-space buffer in device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the reserve-space buffer in bytes used for data
                                       							exchange between forward and backward (gradient) API calls. This
                                       							parameter should be zero in the inference mode and non-zero in the
                                       							training mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Pointer to the reserve-space buffer in device
                                       							memory. This argument should be <samp class="ph codeph">NULL</samp> in inference mode
                                       							and <samp class="ph codeph">non-NULL</samp> in the training mode.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnMultiHeadAttnForward__section_sln_jtl_1jb"><a name="cudnnMultiHeadAttnForward__section_sln_jtl_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">No errors were detected while processing API input arguments and
                                       							launching GPU kernels.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or incompatible input argument was encountered. Some examples
                                       								include:<a name="cudnnMultiHeadAttnForward__ul_kkd_ltl_1jb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnMultiHeadAttnForward__ul_kkd_ltl_1jb">
                                          <li class="li">a required input pointer was <samp class="ph codeph">NULL</samp></li>
                                          <li class="li"><samp class="ph codeph">currIdx</samp> was out of bound
                                          </li>
                                          <li class="li">the descriptor value for <samp class="ph codeph">attention</samp>,
                                             										<samp class="ph codeph">query</samp>, <samp class="ph codeph">key</samp>,
                                             										<samp class="ph codeph">value</samp>, and <samp class="ph codeph">output</samp> were
                                             									incompatible with one another
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The process of launching a GPU kernel returned an error, or an earlier
                                       							kernel did not complete successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">An inconsistent internal state was encountered.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A requested option or a combination of input arguments is not
                                       							supported.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">Insufficient amount of shared memory to launch a GPU kernel.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNForward"><a name="cudnnRNNForward" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForward" name="cudnnRNNForward" shape="rect">7.2.36.&nbsp;<kbd class="ph userinput">cudnnRNNForward()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This routine computes the forward response of the recurrent neural network
                                 described by <samp class="ph codeph">rnnDesc</samp> with inputs in <samp class="ph codeph">x</samp>,
                                 <samp class="ph codeph">hx</samp>, <samp class="ph codeph">cx</samp>, and weights/biases in the
                                 <samp class="ph codeph">weightSpace</samp> buffer. RNN outputs are written to <samp class="ph codeph">y</samp>,
                                 <samp class="ph codeph">hy</samp>, and <samp class="ph codeph">cy</samp> buffers. Locations of
                                 <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, <samp class="ph codeph">hx</samp>, <samp class="ph codeph">cx</samp>,
                                 <samp class="ph codeph">hy</samp>, and <samp class="ph codeph">cy</samp> signals in the multi-layer RNN model
                                 are shown in the following figure. Note that internal RNN signals between time-steps and
                                 between layers are not exposed to the user.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNForward(
    cudnnHandle_t handle,
    cudnnRNNDescriptor_t rnnDesc,
    cudnnForwardMode_t fwdMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> int32_t devSeqLengths[],
    cudnnRNNDataDescriptor_t xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *x,
    cudnnRNNDataDescriptor_t yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *y,
    cudnnTensorDescriptor_t hDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *hy,
    cudnnTensorDescriptor_t cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *cy,
    size_t weightSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *weightSpace,
    size_t workSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
    size_t reserveSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);
</pre><div class="p">
                              <div class="fig fignone" id="cudnnRNNForward__fig_js4_vl5_kmb"><a name="cudnnRNNForward__fig_js4_vl5_kmb" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 4. Locations of x, y, hx, cx, hy, and cy Signals in the Multi-Layer RNN
                                    Model</span><br clear="none"></br><a name="cudnnRNNForward__image_tny_hl2_yz" shape="rect">
                                    <!-- --></a><div class="imageleft"><img class="image imageleft" id="cudnnRNNForward__image_tny_hl2_yz" src="graphics/cudnnRNNForward-locations.png" alt="Locations of x, y, hx, cx, hy, and cy Signals in the Multi-Layer RNN Model"></img></div><br clear="none"></br></div>
                           </div>
                           <p class="p">The next figure depicts data flow when the RNN model is bidirectional. In this mode each
                              RNN physical layer consists of two consecutive pseudo-layers, each with its own weights,
                              biases, the initial hidden state <samp class="ph codeph">hx</samp>, and for LSTM, also the initial
                              cell state <samp class="ph codeph">cx</samp>. Even pseudo-layers 0, 2, 4 process input vectors from
                              left to right or in the forward (<samp class="ph codeph">F</samp>) direction. Odd pseudo-layers 1, 3,
                              5 process input vectors from right to left or in the reverse (<samp class="ph codeph">R</samp>)
                              direction. Two successive pseudo-layers operate on the same input vectors, just in a
                              different order. Pseudo-layers 0 and 1 access the original sequences stored in the
                              <samp class="ph codeph">x</samp> buffer. Outputs of <samp class="ph codeph">F</samp> and <samp class="ph codeph">R</samp>
                              cells are concatenated so vectors fed to the next two pseudo-layers have lengths of 2x
                              <samp class="ph codeph">hiddenSize</samp> or 2x <samp class="ph codeph">projSize</samp>. Input GEMMs in
                              subsequent pseudo-layers adjust vector lengths to 1x <samp class="ph codeph">hiddenSize</samp>.
                           </p>
                           <div class="p">
                              <div class="fig fignone" id="cudnnRNNForward__fig_urg_dm5_kmb"><a name="cudnnRNNForward__fig_urg_dm5_kmb" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 5. Data Flow when the RNN Model is Bidirectional</span><br clear="none"></br><a name="cudnnRNNForward__image_vrg_dm5_kmb" shape="rect">
                                    <!-- --></a><div class="imageleft"><img class="image imageleft" id="cudnnRNNForward__image_vrg_dm5_kmb" src="graphics/cudnnRNNForward-flow.png" alt="Data Flow when the RNN Model is Bidirectional"></img></div><br clear="none"></br></div>
                           </div>
                           <p class="p">When the <samp class="ph codeph">fwdMode</samp> parameter is set to
                              <samp class="ph codeph">CUDNN_FWD_MODE_TRAINING</samp>, the <samp class="ph codeph">cudnnRNNForward()</samp>
                              function stores intermediate data required to compute first order derivatives in the
                              reserve space buffer. Work and reserve space buffer sizes should be computed by the
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNTempSpaceSizes" title="This function computes the work and reserve space buffer sizes based on the RNN network geometry stored in rnnDesc, designated usage (inference or training) defined by the fMode argument, and the current RNN data dimensions (maxSeqLength, batchSize) retrieved from xDesc. When RNN data dimensions change, the cudnnGetRNNTempSpaceSizes() must be called again because RNN temporary buffer sizes are not monotonic." shape="rect">cudnnGetRNNTempSpaceSizes()</a></samp> function with the
                              same <samp class="ph codeph">fwdMode</samp> setting as used in the <samp class="ph codeph">cudnnRNNForward()</samp>
                              call.
                           </p>
                           <p class="p">The same layout type must be specified in <samp class="ph codeph">xDesc</samp> and
                              <samp class="ph codeph">yDesc</samp> descriptors. The same sequence lengths must be configured in
                              <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> and in the device array
                              <samp class="ph codeph">devSeqLengths</samp>. Starting in cuDNN 8.9.1, the
                              <samp class="ph codeph">devSeqLengths</samp> parameter is no longer required and can be set to
                              <samp class="ph codeph">NULL</samp>. The variable sequence length array is transferred
                              automatically to GPU memory by the <samp class="ph codeph">cudnnRNNForward()</samp> function.
                           </p>
                           <p class="p">The <samp class="ph codeph">cudnnRNNForward()</samp> function does not verify that sequence lengths
                              stored in <samp class="ph codeph">devSeqLengths</samp> in GPU memory are the same as in
                              <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> descriptors in CPU memory.
                              Sequence length arrays from <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp>
                              descriptors are checked for consistency, however.
                           </p>
                           <div class="section" id="cudnnRNNForward__section_l1g_xmn_y3b"><a name="cudnnRNNForward__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">fwdMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies inference or training mode
                                       (<samp class="ph codeph">CUDNN_FWD_MODE_INFERENCE</samp> and
                                       <samp class="ph codeph">CUDNN_FWD_MODE_TRAINING</samp>). In the training mode,
                                       additional data is stored in the reserve space buffer. This information
                                       is used in the backward pass to compute derivatives.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">devSeqLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A copy of <samp class="ph codeph">seqLengthArray</samp> from
                                       <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> RNN data
                                       descriptor. The <samp class="ph codeph">devSeqLengths</samp> array must be stored in
                                       GPU memory as it is accessed asynchronously by GPU kernels, possibly
                                       after the <samp class="ph codeph">cudnnRNNForward()</samp> function exists. In cuDNN
                                       8.9.1 and later versions, <samp class="ph codeph">devSeqLengths</samp> should be
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized descriptor corresponding to the
                                       RNN model primary input. The <samp class="ph codeph">dataType</samp>,
                                       <samp class="ph codeph">layout</samp>, <samp class="ph codeph">maxSeqLength</samp>,
                                       <samp class="ph codeph">batchSize</samp>, and <samp class="ph codeph">seqLengthArray</samp> must
                                       match that of <samp class="ph codeph">yDesc</samp>. The parameter
                                       <samp class="ph codeph">vectorSize</samp> must match the
                                       <samp class="ph codeph">inputSize</samp> argument passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> function.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">xDesc</samp>. The vectors are expected to be
                                       arranged in memory according to the layout specified by
                                       <samp class="ph codeph">xDesc</samp>. The elements in the tensor (including
                                       padding vectors) must be densely packed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                       <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                       <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>, and
                                       <samp class="ph codeph">seqLengthArray</samp> must match that of
                                       <samp class="ph codeph">xDesc</samp>. The parameter <samp class="ph codeph">vectorSize</samp>
                                       depends on whether LSTM projection is enabled and whether the network is
                                       bi-directional. Specifically:<a name="cudnnRNNForward__ul_zpv_zsb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForward__ul_zpv_zsb_wlb">
                                          <li class="li">For uni-directional models, the parameter
                                             <samp class="ph codeph">vectorSize</samp> must match the
                                             <samp class="ph codeph">hiddenSize</samp> argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>. If the
                                             LSTM projection is enabled, the <samp class="ph codeph">vectorSize</samp> must
                                             be the same as the <samp class="ph codeph">projSize</samp> argument passed to
                                             <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                          </li>
                                          <li class="li">For bi-directional models, if the RNN <samp class="ph codeph">cellMode</samp>
                                             is <samp class="ph codeph">CUDNN_LSTM</samp> and the projection feature is
                                             enabled, the parameter <samp class="ph codeph">vectorSize</samp> must be 2x
                                             the <samp class="ph codeph">projSize</samp> argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>. Otherwise,
                                             it should be 2x the <samp class="ph codeph">hiddenSize</samp> value.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">yDesc</samp>. The vectors are expected to be
                                       laid out in memory according to the layout specified by
                                       <samp class="ph codeph">yDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A tensor descriptor describing the initial or final
                                          hidden state of RNN. Hidden state data are fully packed. The first
                                          dimension of the tensor depends on the <samp class="ph codeph">dirMode</samp>
                                          argument passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> function.<a name="cudnnRNNForward__ul_tgf_dtb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForward__ul_tgf_dtb_wlb">
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp>, then the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp>, then the first
                                                dimension should be double the <samp class="ph codeph">numLayers</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter described in <samp class="ph codeph">xDesc</samp>. The third dimension
                                          depends on whether RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and
                                          whether the LSTM projection is enabled. Specifically:<a name="cudnnRNNForward__ul_gvv_ftb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForward__ul_gvv_ftb_wlb">
                                             <li class="li">If RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM
                                                projection is enabled, the third dimension must match the
                                                <samp class="ph codeph">projSize</samp> argument passed to the
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNProjectionLayers" shape="rect">cudnnSetRNNProjectionLayers()</a></samp> call.
                                             </li>
                                             <li class="li">Otherwise, the third dimension must match the
                                                <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> call used to initialize
                                                <samp class="ph codeph">rnnDesc</samp>.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU buffer with the RNN initial hidden
                                       state. Data dimensions are described by the <samp class="ph codeph">hDesc</samp>
                                       tensor descriptor. If a <samp class="ph codeph">NULL</samp> pointer is passed, the
                                       initial hidden state of the network will be initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the GPU buffer where the final RNN hidden
                                       state should be stored. Data dimensions are described by the
                                       <samp class="ph codeph">hDesc</samp> tensor descriptor. If a <samp class="ph codeph">NULL</samp>
                                       pointer is passed, the final hidden state of the network will not be
                                       saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. For LSTM networks only. A tensor descriptor describing
                                          the initial or final cell state for LSTM networks only. Cell state
                                          data are fully packed. The first dimension of the tensor depends on
                                          the <samp class="ph codeph">dirMode</samp> argument passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> call.<a name="cudnnRNNForward__ul_kvk_ktb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForward__ul_kvk_ktb_wlb">
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp> argument
                                                passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second tensor dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> call.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. For LSTM networks only. Pointer to the GPU buffer with the
                                       initial LSTM state data. Data dimensions are described by the
                                       <samp class="ph codeph">cDesc</samp> tensor descriptor. If a <samp class="ph codeph">NULL</samp>
                                       pointer is passed, the initial cell state of the network will be
                                       initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. For LSTM networks only. Pointer to the GPU buffer where
                                       final LSTM state data should be stored. Data dimensions are described by
                                       the <samp class="ph codeph">cDesc</samp> tensor descriptor. If a <samp class="ph codeph">NULL</samp>
                                       pointer is passed, the final LSTM cell state will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided weight-space
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Address of the weight space buffer in GPU memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided workspace
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the workspace buffer in GPU memory to
                                       store temporary data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the reserve-space
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the reserve-space buffer in GPU
                                       memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNForward__section_zgs_xmn_y3b"><a name="cudnnRNNForward__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">No errors were detected while processing API input arguments and
                                       launching GPU kernels.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNForward__ul_qt3_ttb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForward__ul_qt3_ttb_wlb">
                                          <li class="li">variable sequence length input is passed while
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is
                                             specified
                                          </li>
                                          <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is requested
                                             on pre-Pascal devices
                                          </li>
                                          <li class="li">the 'double' floating point type is used for input/output and
                                             the <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> algo
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or incompatible input argument was encountered. For
                                       example:<a name="cudnnRNNForward__ul_rhc_vtb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForward__ul_rhc_vtb_wlb">
                                          <li class="li">some input descriptors are <samp class="ph codeph">NULL</samp></li>
                                          <li class="li">at least one of the settings in <samp class="ph codeph">rnnDesc</samp>,
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">hDesc</samp>, or <samp class="ph codeph">cDesc</samp>
                                             descriptors is invalid
                                          </li>
                                          <li class="li"><samp class="ph codeph">weightSpaceSize</samp>,
                                             <samp class="ph codeph">workSpaceSize</samp>, or
                                             <samp class="ph codeph">reserveSpaceSize</samp> is too small
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The process of launching a GPU kernel returned an error, or an earlier
                                       kernel did not complete successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate CPU memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNForwardInference"><a name="cudnnRNNForwardInference" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardInference" name="cudnnRNNForwardInference" shape="rect">7.2.37.&nbsp;<kbd class="ph userinput">cudnnRNNForwardInference()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNForwardInference()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNForwardInference(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes)</pre><p class="p">This routine executes the recurrent neural network described by <samp class="ph codeph">rnnDesc</samp>
                              with inputs <samp class="ph codeph">x</samp>, <samp class="ph codeph">hx</samp>, and <samp class="ph codeph">cx</samp>, weights
                              <samp class="ph codeph">w</samp> and outputs <samp class="ph codeph">y</samp>, <samp class="ph codeph">hy</samp>, and
                              <samp class="ph codeph">cy</samp>. <samp class="ph codeph">workspace</samp> is required for intermediate
                              storage. This function does not store intermediate data required for training;
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp> should be used for
                              that purpose.
                           </p>
                           <div class="section" id="cudnnRNNForwardInference__section_ahx_wwr_1jb"><a name="cudnnRNNForwardInference__section_ahx_wwr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the RNN. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of <samp class="ph codeph">seqLength</samp> fully packed tensor
                                       descriptors. Each descriptor in the array should have three dimensions
                                       that describe the input data format to one recurrent iteration (one
                                       descriptor per RNN time-step). The first dimension (batch size) of the
                                       tensors may decrease from iteration <samp class="ph codeph">n</samp> to iteration
                                       <samp class="ph codeph">n+1</samp> but may not increase. Each tensor descriptor
                                       must have the same second dimension (RNN input vector length,
                                       <samp class="ph codeph">inputSize</samp>). The third dimension of each tensor
                                       should be 1. Input data are expected to be arranged in the column-major
                                       order so strides in <samp class="ph codeph">xDesc</samp> should be set as follows:
                                       <pre xml:space="preserve">strideA[0]=inputSize, strideA[1]=1, strideA[2]=1</pre></dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the array of
                                       tensor descriptors <samp class="ph codeph">xDesc</samp>. The input vectors are
                                       expected to be packed contiguously with the first vector of iteration
                                       (time-step) <samp class="ph codeph">n+1</samp> following directly from the last vector
                                       of iteration <samp class="ph codeph">n</samp>. In other words, input vectors for all
                                       RNN time-steps should be packed in the contiguous block of GPU memory
                                       with no gaps between the vectors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_bsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_bsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_dsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_dsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). The second dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_fsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_fsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">xDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>. The data are expected to be
                                       packed contiguously with the first element of iteration
                                       <samp class="ph codeph">n+1</samp> following directly from the last element of
                                       iteration <samp class="ph codeph">n</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_gsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_gsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final hidden state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_isf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_isf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final cell state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNForwardInference__section_dn3_xwr_1jb"><a name="cudnnRNNForwardInference__section_dn3_xwr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNForwardInference__ul_ksf_sf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_ksf_sf3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp>, <samp class="ph codeph">cyDesc</samp> or one of
                                             the descriptors in <samp class="ph codeph">xDesc</samp>, or
                                             <samp class="ph codeph">yDesc</samp> is invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">cxDesc</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp>, or <samp class="ph codeph">cyDesc</samp> have
                                             incorrect strides or dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPersistentRNNPlan" title="This function has been deprecated in cuDNN 8.0." shape="rect">cudnnSetPersistentRNNPlan()</a></samp> was not
                                       called prior to the current function when
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> was selected in the
                                       RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNForwardInferenceEx"><a name="cudnnRNNForwardInferenceEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardInferenceEx" name="cudnnRNNForwardInferenceEx" shape="rect">7.2.38.&nbsp;<kbd class="ph userinput">cudnnRNNForwardInferenceEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNForwardInferenceEx()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNForwardInferenceEx(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  kDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *keys,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *cAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  iDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *iAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  qDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *queries,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *workSpace,
    size_t                          workSpaceSizeInBytes)
</pre><p class="p">This routine is the extended version of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference()</a></samp> function. The
                              <samp class="ph codeph">cudnnRNNForwardTrainingEx()</samp> function allows the user to use an
                              unpacked (padded) layout for input <samp class="ph codeph">x</samp> and output <samp class="ph codeph">y</samp>. In
                              the unpacked layout, each sequence in the mini-batch is considered to be of fixed
                              length, specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the
                              <samp class="ph codeph">nth</samp> sequence in the mini-batch, is composed of a valid segment,
                              specified by the <samp class="ph codeph">seqLengthArray[n]</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>, and a padding segment to make the combined
                              sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                           </p>
                           <p class="p">With an unpacked layout, both sequence major (meaning, time major) and batch major are
                              supported. For backward compatibility, the packed sequence major layout is supported.
                              However, similar to the non-extended function <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference()</a></samp>, the sequences in the mini-batch
                              need to be sorted in descending order according to length.
                           </p>
                           <div class="section" id="cudnnRNNForwardInferenceEx__section_sp5_zjs_1jb"><a name="cudnnRNNForwardInferenceEx__section_sp5_zjs_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN Data descriptor. The
                                       <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                       <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>, and
                                       <samp class="ph codeph">seqLengthArray</samp> need to match that of
                                       <samp class="ph codeph">yDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">xDesc</samp>. The vectors are expected to be
                                       laid out in memory according to the layout specified by
                                       <samp class="ph codeph">xDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInferenceEx__ul_bsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_bsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter described in <samp class="ph codeph">xDesc</samp>. The third dimension
                                          depends on whether RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and
                                          whether LSTM projection is enabled. Specifically:<a name="cudnnRNNForwardInferenceEx__ul_mgv_1px_h2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_mgv_1px_h2b">
                                             <li class="li">If RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM
                                                projection is enabled, the third dimension must match the
                                                <samp class="ph codeph">recProjSize</samp> argument passed to
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNProjectionLayers" shape="rect">cudnnSetRNNProjectionLayers()</a></samp> call used to set <samp class="ph codeph">rnnDesc</samp>. 
                                             </li>
                                             <li class="li">Otherwise, the third dimension must match the
                                                <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                                <samp class="ph codeph">rnnDesc</samp>.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInferenceEx__ul_dsf_sf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_dsf_sf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. 
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                          <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                          <samp class="ph codeph">maxSeqLength</samp> , <samp class="ph codeph">batchSize</samp>, and
                                          <samp class="ph codeph">seqLengthArray</samp> must match that of
                                          <samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dxDesc</samp>. The
                                          parameter <samp class="ph codeph">vectorSize</samp> depends on whether RNN mode is
                                          <samp class="ph codeph">CUDNN_LSTM</samp> and whether LSTM projection is
                                          enabled and whether the network is bidirectional. Specifically:<a name="cudnnRNNForwardInferenceEx__ul_jrn_wpx_h2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_jrn_wpx_h2b">
                                             <li class="li">For uni-directional network, if the RNN mode is
                                                <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM projection is
                                                enabled, the parameter <samp class="ph codeph">vectorSize</samp> must
                                                match the <samp class="ph codeph">recProjSize</samp> argument passed to
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNProjectionLayers" shape="rect">cudnnSetRNNProjectionLayers()</a></samp> call used to set <samp class="ph codeph">rnnDesc</samp>.
                                                If the network is bidirectional, then multiply the value by
                                                2. 
                                             </li>
                                             <li class="li">Otherwise, for a uni-directional network, the parameter
                                                <samp class="ph codeph">vectorSize</samp> must match the
                                                <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                                <samp class="ph codeph">rnnDesc</samp>. If the network is
                                                bidirectional, then multiply the value by 2.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">yDesc</samp>. The vectors are expected to be
                                       laid out in memory according to the layout specified by
                                       <samp class="ph codeph">yDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                       hidden state of the RNN. The descriptor must be set exactly the same way
                                       as <samp class="ph codeph">hxDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final hidden state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                       state for LSTM networks. The descriptor must be set exactly the same way
                                       as <samp class="ph codeph">cxDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final cell state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">kDesc</samp></dt>
                                    <dd class="dd">Reserved. User may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">keys</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cAttn</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">iDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">iAttn</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">qDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">queries</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNForwardInferenceEx__section_jy2_1ks_1jb"><a name="cudnnRNNForwardInferenceEx__section_jy2_1ks_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNForwardInferenceEx__ul_jkd_wrx_h2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_jkd_wrx_h2b">
                                          <li class="li">Variable sequence length input is passed in while
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used. 
                                          </li>
                                          <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used on
                                             pre-Pascal devices. 
                                          </li>
                                          <li class="li">Double input/output is used for
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>. 
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNForwardInferenceEx__ul_ksf_sf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_ksf_sf3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors in <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp>, or <samp class="ph codeph">cyDesc</samp> is
                                             invalid, or has incorrect strides or dimensions. 
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPersistentRNNPlan" title="This function has been deprecated in cuDNN 8.0." shape="rect">cudnnSetPersistentRNNPlan()</a></samp> was not
                                       called prior to the current function when
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> was selected in the
                                       RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNGetClip"><a name="cudnnRNNGetClip" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNGetClip" name="cudnnRNNGetClip" shape="rect">7.2.39.&nbsp;<kbd class="ph userinput">cudnnRNNGetClip()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNGetClip_v8" title="Retrieves the current LSTM cell clipping parameters, and stores them in the arguments provided. The user can assign NULL to any pointer except rnnDesc when the retrieved value is not needed. The function does not check the validity of retrieved parameters." shape="rect">cudnnRNNGetClip_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNGetClip()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNGetClip(
    cudnnHandle_t               handle,
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNClipMode_t          *clipMode,
    cudnnNanPropagation_t       *clipNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      *lclip,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      *rclip);
</pre><p class="p">Retrieves the current LSTM cell clipping parameters, and stores them in the arguments
                              provided. 
                           </p>
                           <div class="section" id="cudnnRNNGetClip__section_crb_kft_1jb"><a name="cudnnRNNGetClip__section_crb_kft_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*clipMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the location where the retrieved
                                       <samp class="ph codeph">clipMode</samp> is stored. The <samp class="ph codeph">clipMode</samp>
                                       can be <samp class="ph codeph">CUDNN_RNN_CLIP_NONE</samp> in which case no LSTM cell
                                       state clipping is being performed; or
                                       <samp class="ph codeph">CUDNN_RNN_CLIP_MINMAX</samp>, in which case the cell state
                                       activation to other units are being clipped.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*lclip</samp>, <samp class="ph codeph">*rclip</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointers to the location where the retrieved LSTM cell
                                       clipping range <samp class="ph codeph">[lclip, rclip]</samp> is stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">*clipNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the location where the retrieved
                                       <samp class="ph codeph">clipNanOpt</samp> is stored. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNGetClip__section_e1m_kft_1jb"><a name="cudnnRNNGetClip__section_e1m_kft_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">If any of the pointer arguments provided are <samp class="ph codeph">NULL</samp>.
                                       
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNGetClip_v8"><a name="cudnnRNNGetClip_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNGetClip_v8" name="cudnnRNNGetClip_v8" shape="rect">7.2.40.&nbsp;<kbd class="ph userinput">cudnnRNNGetClip_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Retrieves the current LSTM cell clipping parameters, and stores them in the
                                 arguments provided. The user can assign <samp class="ph codeph">NULL</samp> to any pointer except
                                 <samp class="ph codeph">rnnDesc</samp> when the retrieved value is not needed. The function does
                                 not check the validity of retrieved parameters.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNGetClip_v8(
	cudnnRNNDescriptor_t rnnDesc,
	cudnnRNNClipMode_t *clipMode,
	cudnnNanPropagation_t *clipNanOpt,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> *lclip,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> *rclip);
</pre><div class="section" id="cudnnRNNGetClip_v8__section_l1g_xmn_y3b"><a name="cudnnRNNGetClip_v8__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">clipMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the location where the retrieved <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNClipMode_t" shape="rect">cudnnRNNClipMode_t</a></samp> value is stored. The
                                       <samp class="ph codeph">clipMode</samp> can be
                                       <samp class="ph codeph">CUDNN_RNN_CLIP_NONE</samp> in which case no LSTM cell
                                       state clipping is being performed; or
                                       <samp class="ph codeph">CUDNN_RNN_CLIP_MINMAX</samp>, in which case the cell state
                                       activation to other units are being clipped.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">clipNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the location where the retrieved <samp class="ph codeph"><a class="xref" href="index.html#cudnnNanPropagation_t" shape="rect">cudnnNanPropagation_t</a></samp> value is stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lclip</samp>, <samp class="ph codeph">rclip</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointers to the location where the retrieved LSTM cell
                                       clipping range <samp class="ph codeph">[lclip, rclip]</samp> is stored.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNGetClip_v8__section_zgs_xmn_y3b"><a name="cudnnRNNGetClip_v8__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">LSTM clipping parameters were successfully retrieved from the RNN
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found (<samp class="ph codeph">rnnDesc</samp> was
                                       <samp class="ph codeph">NULL</samp>).
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNSetClip"><a name="cudnnRNNSetClip" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNSetClip" name="cudnnRNNSetClip" shape="rect">7.2.41.&nbsp;<kbd class="ph userinput">cudnnRNNSetClip()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNSetClip_v8" shape="rect">cudnnRNNSetClip_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNSetClip()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNSetClip(
    cudnnHandle_t               handle,
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNClipMode_t          clipMode,
    cudnnNanPropagation_t       clipNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      lclip,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      rclip);
</pre><p class="p">Sets the LSTM cell clipping mode. The LSTM clipping is disabled by default. When enabled,
                              clipping is applied to all layers. This <samp class="ph codeph">cudnnRNNSetClip()</samp> function may
                              be called multiple times.  
                           </p>
                           <div class="section" id="cudnnRNNSetClip__section_kfk_5ft_1jb"><a name="cudnnRNNSetClip__section_kfk_5ft_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">clipMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enables or disables the LSTM cell clipping. When
                                       <samp class="ph codeph">clipMode</samp> is set to
                                       <samp class="ph codeph">CUDNN_RNN_CLIP_NONE</samp> no LSTM cell state clipping is
                                       performed. When <samp class="ph codeph">clipMode</samp> is
                                       <samp class="ph codeph">CUDNN_RNN_CLIP_MINMAX</samp> the cell state activation to
                                       other units is clipped.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lclip</samp>, <samp class="ph codeph">rclip</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The range <samp class="ph codeph">[lclip, rclip]</samp> to which the
                                       LSTM cell clipping should be set. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">clipNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. When set to <samp class="ph codeph">CUDNN_PROPAGATE_NAN</samp> (see the
                                       description for <samp class="ph codeph"><a class="xref" href="index.html#cudnnNanPropagation_t" shape="rect">cudnnNanPropagation_t</a></samp>), <samp class="ph codeph">NaN</samp> is propagated from the LSTM cell, or
                                       it can be set to one of the clipping range boundary values, instead of
                                       propagating. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNSetClip__section_ext_5ft_1jb"><a name="cudnnRNNSetClip__section_ext_5ft_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Returns this value if <samp class="ph codeph">lclip</samp> &gt; <samp class="ph codeph">rclip</samp>;
                                       or if either <samp class="ph codeph">lclip</samp> or <samp class="ph codeph">rclip</samp> is
                                       <samp class="ph codeph">NaN</samp>. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNSetClip_v8"><a name="cudnnRNNSetClip_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNSetClip_v8" name="cudnnRNNSetClip_v8" shape="rect">7.2.42.&nbsp;<kbd class="ph userinput">cudnnRNNSetClip_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">Sets the LSTM cell clipping mode. The LSTM clipping is disabled by default. When
                              enabled, clipping is applied to all layers. This <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNSetClip" shape="rect">cudnnRNNSetClip()</a></samp> function does not affect the work, reserve, and weight-space buffer sizes
                              and may be called multiple times. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNSetClip_v8(
	cudnnRNNDescriptor_t rnnDesc,
	cudnnRNNClipMode_t clipMode,
	cudnnNanPropagation_t clipNanOpt,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> lclip,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> rclip);
</pre><div class="section" id="cudnnRNNSetClip_v8__section_l1g_xmn_y3b"><a name="cudnnRNNSetClip_v8__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">clipMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enables or disables the LSTM cell clipping. When
                                       <samp class="ph codeph">clipMode</samp> is set to
                                       <samp class="ph codeph">CUDNN_RNN_CLIP_NONE</samp> no LSTM cell state clipping is
                                       performed. When <samp class="ph codeph">clipMode</samp> is
                                       <samp class="ph codeph">CUDNN_RNN_CLIP_MINMAX</samp> the cell state activation to
                                       other units is clipped.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">clipNanOpt</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. When set to <samp class="ph codeph">CUDNN_PROPAGATE_NAN</samp> (see the
                                       description for <samp class="ph codeph"><a class="xref" href="index.html#cudnnNanPropagation_t" shape="rect">cudnnNanPropagation_t</a></samp>), <samp class="ph codeph">NaN</samp> is propagated from the LSTM cell, or
                                       it can be set to one of the clipping range boundary values, instead of
                                       propagating.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">lclip</samp>, <samp class="ph codeph">rclip</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The range <samp class="ph codeph">[lclip, rclip]</samp> to which the
                                       LSTM cell clipping should be set.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNSetClip_v8__section_zgs_xmn_y3b"><a name="cudnnRNNSetClip_v8__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function completed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found, for example:<a name="cudnnRNNSetClip_v8__ul_w1p_55b_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNSetClip_v8__ul_w1p_55b_wlb">
                                          <li class="li"><samp class="ph codeph">rnnDesc</samp> was <samp class="ph codeph">NULL</samp></li>
                                          <li class="li"><samp class="ph codeph">lclip</samp> &gt; <samp class="ph codeph">rclip</samp></li>
                                          <li class="li">either <samp class="ph codeph">lclip</samp> or <samp class="ph codeph">rclip</samp> is
                                             <samp class="ph codeph">NaN</samp></li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetAttnDescriptor"><a name="cudnnSetAttnDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetAttnDescriptor" name="cudnnSetAttnDescriptor" shape="rect">7.2.43.&nbsp;<kbd class="ph userinput">cudnnSetAttnDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function configures a multi-head attention descriptor that was previously created
                              		using the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateAttnDescriptor" title="This function creates one instance of an opaque attention descriptor object by allocating the host memory for it and initializing all descriptor fields. The function writes NULL to attnDesc when the attention descriptor object cannot be allocated." shape="rect">cudnnCreateAttnDescriptor()</a></samp> function. The
                              		function sets attention parameters that are necessary to compute internal buffer sizes,
                              		dimensions of weight and bias tensors, or to select optimized code
                              		paths. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetAttnDescriptor(
	cudnnAttnDescriptor_t attnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> attnMode,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> nHeads,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> smScaler,
	cudnnDataType_t dataType,
	cudnnDataType_t computePrec,
	cudnnMathType_t mathType,
	cudnnDropoutDescriptor_t attnDropoutDesc,
	cudnnDropoutDescriptor_t postDropoutDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> qSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> kSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> vSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> qProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> kProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> vProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> oProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> qoMaxSeqLength,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> kvMaxSeqLength,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> maxBatchSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> maxBeamSize);
</pre><p class="p">Input sequence data descriptors in <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp> and
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardWeights" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its trainable parameters: projection weights and projection biases. If y=F(w) is a vector-valued function that represents the multi-head attention layer and it takes some vector of flatten weights or biases as an input (with all other parameters and inputs fixed), and outputs vector , then cudnnMultiHeadAttnBackwardWeights() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(w). The input is supplied via the dout argument." shape="rect">cudnnMultiHeadAttnBackwardWeights()</a></samp> functions
                              			are checked against the configuration parameters stored in the attention descriptor.
                              			Some parameters must match exactly while <samp class="ph codeph">max</samp> arguments such as
                              				<samp class="ph codeph">maxBatchSize</samp> or <samp class="ph codeph">qoMaxSeqLength</samp> establish upper
                              			limits for the corresponding dimensions.
                           </p>
                           <p class="p">The multi-head attention model can be described by the following equations:</p>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">h</mi>
                                       <mi>i</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <mfenced open="(" close=")">
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mrow>
                                                <mi>V</mi>
                                                <mo>,</mo>
                                                <mi>i</mi>
                                             </mrow>
                                          </msub>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                       </mrow>
                                    </mfenced>
                                    <mi>softmax</mi>
                                    <mfenced open="(" close=")">
                                       <mrow>
                                          <mi>smScaler</mi>
                                          <mfenced open="(" close=")">
                                             <mrow>
                                                <msup>
                                                   <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                                   <mi mathvariant="bold-italic" fontfamily="Times New Roman">T</mi>
                                                </msup>
                                                <msubsup>
                                                   <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                                   <mrow>
                                                      <mi>K</mi>
                                                      <mo>,</mo>
                                                      <mi>i</mi>
                                                   </mrow>
                                                   <mi>T</mi>
                                                </msubsup>
                                             </mrow>
                                          </mfenced>
                                          <mfenced open="(" close=")">
                                             <mrow>
                                                <msub>
                                                   <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                                   <mrow>
                                                      <mi>Q</mi>
                                                      <mo>,</mo>
                                                      <mi>i</mi>
                                                   </mrow>
                                                </msub>
                                                <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                             </mrow>
                                          </mfenced>
                                       </mrow>
                                    </mfenced>
                                    <mo>,</mo>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mi>for</mi>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mi>i</mi>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mo>=</mo>
                                    <mn>0</mn>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mn>...</mn>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mi>nHeads</mi>
                                    <mo>-</mo>
                                    <mn>1</mn>
                                 </mrow>
                              </math>
                           </p>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>MultiHeadAttn</mi>
                                    <mfenced open="(" close=")">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                          <mo>,</mo>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                          <mo>,</mo>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                          <mo>,</mo>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mi>Q</mi>
                                          </msub>
                                          <mo>,</mo>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mi>K</mi>
                                          </msub>
                                          <mo>,</mo>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mi>V</mi>
                                          </msub>
                                          <mo>,</mo>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mi>O</mi>
                                          </msub>
                                       </mrow>
                                    </mfenced>
                                    <mo>=</mo>
                                    <mrow>
                                       <munderover>
                                          <mo></mo>
                                          <mrow>
                                             <mi>i</mi>
                                             <mo>=</mo>
                                             <mn>0</mn>
                                          </mrow>
                                          <mrow>
                                             <mi>nHeads</mi>
                                             <mo>-</mo>
                                             <mn>1</mn>
                                          </mrow>
                                       </munderover>
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mrow>
                                                <mi>O</mi>
                                                <mo>,</mo>
                                                <mi>i</mi>
                                             </mrow>
                                          </msub>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">h</mi>
                                             <mi>i</mi>
                                          </msub>
                                       </mrow>
                                    </mrow>
                                 </mrow>
                              </math>
                           </p>
                           <div class="p">Where:<a name="cudnnSetAttnDescriptor__ul_ptk_4f5_1jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetAttnDescriptor__ul_ptk_4f5_1jb">
                                 <li class="li">
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi>nHeads</mi>
                                       </mrow>
                                    </math>
                                    					 is the number of independent attention heads that evaluate 
                                    						
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">h</mi>
                                             <mi>i</mi>
                                          </msub>
                                       </mrow>
                                    </math>
                                    					 vectors.
                                 </li>
                                 <li class="li">
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                       </mrow>
                                    </math>
                                    					 is a primary input, a single <samp class="ph codeph">query</samp> column
                                    					vector.
                                 </li>
                                 <li class="li">
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                          <mo>,</mo>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                       </mrow>
                                    </math>
                                    					 are two matrices of <samp class="ph codeph">key</samp> and
                                    						<samp class="ph codeph">value</samp> column vectors.
                                 </li>
                              </ul>
                           </div>
                           <p class="p">For simplicity, the above equations are presented using a single embedding vector 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                 </mrow>
                              </math>
                              			 but the cuDNN API can handle multiple 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                 </mrow>
                              </math>
                              			 candidates in the beam search scheme, process 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                 </mrow>
                              </math>
                              			 vectors from multiple sequences bundled into a batch, or automatically
                              			iterate through all embedding vectors (time-steps) of a sequence. Thus, in general, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                    <mo>,</mo>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                 </mrow>
                              </math>
                              			 inputs are tensors with additional pieces of information such as the
                              			active length of each sequence or how unused padding vectors should be saved.
                           </p>
                           <p class="p">In some publications, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>O</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 matrices are combined into one output projection matrix and 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">h</mi>
                                       <mi>i</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              			 vectors are merged explicitly into a single vector. This is an equivalent
                              			notation. In the cuDNN library, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>O</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 matrices are conceptually treated the same way as 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">Q</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">K</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 or 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">V</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 input projection weights. See the description of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetMultiHeadAttnWeights" shape="rect">cudnnGetMultiHeadAttnWeights()</a></samp> function for more
                              			details.
                           </p>
                           <p class="p">Weight matrices 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">Q</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">K</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">V</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 and 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>O</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 play similar roles, adjusting vector lengths in 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                    <mo>,</mo>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                 </mrow>
                              </math>
                              			 inputs and in the multi-head attention final output. The user can disable
                              			any or all projections by setting 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>qProjSize</mi>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>kProjSize</mi>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>vProjSize</mi>
                                 </mrow>
                              </math>
                              			 or 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>oProjSize</mi>
                                 </mrow>
                              </math>
                              			 arguments to zero.
                           </p>
                           <p class="p">Embedding vector sizes in 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">q</mi>
                                 </mrow>
                              </math>
                              			, 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                    <mo>,</mo>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                 </mrow>
                              </math>
                              			 and the vector lengths after projections need to be selected in such a way
                              			that matrix multiplications described above are feasible. Otherwise,
                              				<samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp> is returned by the
                              				<samp class="ph codeph">cudnnSetAttnDescriptor()</samp> function. All four weight matrices are
                              			used when it is desirable to maintain rank deficiency of 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>K</mi>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">Q</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                    <mo>=</mo>
                                    <msubsup>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>K</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                       <mi>T</mi>
                                    </msubsup>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi mathvariant="normal" fontfamily="Times New Roman">Q,</mi>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 or 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>OV</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                    <mo>=</mo>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>O</mi>
                                          <mo>,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                       <mrow>
                                          <mi>V</mi>
                                          <mo rspace="0px" separator="false">,</mo>
                                          <mi>i</mi>
                                       </mrow>
                                    </msub>
                                 </mrow>
                              </math>
                              			 matrices to eliminate one or more dimensions during linear transformations
                              			in each head. This is a form of feature extraction. In such cases, the projected sizes
                              			are smaller than the original vector lengths.
                           </p>
                           <div class="p">For each attention head, weight matrix sizes are defined as follows:<a name="cudnnSetAttnDescriptor__ul_t4z_1xy_1jb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetAttnDescriptor__ul_t4z_1xy_1jb">
                                 <li class="li">
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mrow>
                                                <mi mathvariant="normal" fontfamily="Times New Roman">Q</mi>
                                                <mo>,</mo>
                                                <mi>i</mi>
                                             </mrow>
                                          </msub>
                                       </mrow>
                                    </math>
                                    					 - size 
                                    						
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mfenced open="[" close="]">
                                             <mrow>
                                                <mi>qProjSize</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>x</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>qSize</mi>
                                             </mrow>
                                          </mfenced>
                                          <mo>,</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>i</mi>
                                          <mo>=</mo>
                                          <mi>O</mi>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo lspace="0px" form="infix">..</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>nHeads</mi>
                                          <mo>-</mo>
                                          <mn>1</mn>
                                       </mrow>
                                    </math>
                                 </li>
                                 <li class="li">
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mrow>
                                                <mi mathvariant="normal" fontfamily="Times New Roman">K</mi>
                                                <mo>,</mo>
                                                <mi>i</mi>
                                             </mrow>
                                          </msub>
                                       </mrow>
                                    </math>
                                    					 - size 
                                    						
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mfenced open="[" close="]">
                                             <mrow>
                                                <mi>kProjSize</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>x</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>kSize</mi>
                                             </mrow>
                                          </mfenced>
                                          <mo>,</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>i</mi>
                                          <mo>=</mo>
                                          <mn>0</mn>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo lspace="0px" form="infix">..</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>nHeads</mi>
                                          <mo>-</mo>
                                          <mn>1</mn>
                                          <mo>,</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>kProjSize</mi>
                                          <mo>=</mo>
                                          <mi>qProjSize</mi>
                                       </mrow>
                                    </math>
                                 </li>
                                 <li class="li">
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mrow>
                                                <mi mathvariant="normal" fontfamily="Times New Roman">V</mi>
                                                <mo>,</mo>
                                                <mi>i</mi>
                                             </mrow>
                                          </msub>
                                       </mrow>
                                    </math>
                                    					 - size 
                                    						
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mfenced open="[" close="]">
                                             <mrow>
                                                <mi>vProjSize</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>x</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>vSize</mi>
                                             </mrow>
                                          </mfenced>
                                          <mo>,</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>i</mi>
                                          <mo>=</mo>
                                          <mn>0</mn>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo lspace="0px" form="infix">..</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>nHeads</mi>
                                          <mo>-</mo>
                                          <mn>1</mn>
                                       </mrow>
                                    </math>
                                 </li>
                                 <li class="li">
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                             <mrow>
                                                <mi>O</mi>
                                                <mo>,</mo>
                                                <mi>i</mi>
                                             </mrow>
                                          </msub>
                                       </mrow>
                                    </math>
                                    					 - size 
                                    						
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mfenced open="[" close="]">
                                             <mrow>
                                                <mi>oProjSize</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>x</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mfenced open="(" close=")">
                                                   <mrow>
                                                      <mi>vProjSize</mi>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>&gt;</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mn>0</mn>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>?</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mi>vProjSize</mi>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>:</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mi>vSize</mi>
                                                   </mrow>
                                                </mfenced>
                                             </mrow>
                                          </mfenced>
                                          <mo>,</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>i</mi>
                                          <mo>=</mo>
                                          <mn>0</mn>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo lspace="0px" form="infix">..</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>nHeads</mi>
                                          <mo>-</mo>
                                          <mn>1</mn>
                                       </mrow>
                                    </math>
                                 </li>
                              </ul>
                           </div>
                           <p class="p">When the output projection is disabled 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mfenced open="(" close=")">
                                       <mrow>
                                          <mi>oProjSize</mi>
                                          <mo>=</mo>
                                          <mn>0</mn>
                                       </mrow>
                                    </mfenced>
                                 </mrow>
                              </math>
                              			, the output vector length is 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>nHead</mi>
                                    <msup>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">s&nbsp;</mi>
                                       <mo lspace="0px" rspace="0px">*</mo>
                                    </msup>
                                    <mtext>&nbsp;</mtext>
                                    <mfenced open="(" close=")">
                                       <mrow>
                                          <mi>vProjSize</mi>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>&gt;</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mn>0</mn>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>?</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>vProjSize</mi>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>:</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>vSize</mi>
                                       </mrow>
                                    </mfenced>
                                 </mrow>
                              </math>
                              			, meaning, the output is a concatenation of all 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi mathvariant="bold" fontfamily="Times New Roman">h</mi>
                                       <mi>i</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              			 vectors. In the alternative interpretation, a concatenated matrix 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                    <mi>O</mi>
                                 </msub>
                                 <mo>=</mo>
                                 <mfenced open="[" close="]">
                                    <mrow>
                                       <msub>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                          <mrow>
                                             <mi>O</mi>
                                             <mo>,</mo>
                                             <mn>0</mn>
                                          </mrow>
                                       </msub>
                                       <mo>,</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <msub>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                          <mrow>
                                             <mi>O</mi>
                                             <mo>,</mo>
                                             <mn>1</mn>
                                          </mrow>
                                       </msub>
                                       <mo>,</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <msub>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                          <mrow>
                                             <mi>O</mi>
                                             <mo>,</mo>
                                             <mn>2</mn>
                                          </mrow>
                                       </msub>
                                       <mo>,</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo lspace="0px" form="infix">...</mo>
                                    </mrow>
                                 </mfenced>
                              </math>
                              			 forms the identity matrix.
                           </p>
                           <p class="p">Softmax is a normalized, exponential vector function that takes and outputs vectors of
                              			the same size. The multi-head attention API utilizes softmax of the
                              				<samp class="ph codeph">CUDNN_SOFTMAX_ACCURATE</samp> type to reduce the likelihood of the
                              			floating-point overflow.
                           </p>
                           <p class="p">The <samp class="ph codeph">smScaler</samp> parameter is the softmax sharpening/smoothing coefficient.
                              			When <samp class="ph codeph">smScaler=1.0</samp>, softmax uses the natural exponential function
                              				<samp class="ph codeph">exp(x)</samp> or <samp class="ph codeph">2.7183<sup class="ph sup">*</sup></samp>. When
                              				<samp class="ph codeph">smScaler&lt;1.0</samp>, for example <samp class="ph codeph">smScaler=0.2</samp>, the
                              			function used by the softmax block will not grow as fast because
                              					<samp class="ph codeph">exp(0.2<sup class="ph sup">*</sup>x)  1.2214<sup class="ph sup">*</sup></samp>. 
                           </p>
                           <p class="p">The <samp class="ph codeph">smScaler</samp> parameter can be adjusted to process larger ranges of
                              			values fed to softmax. When the range is too large (or <samp class="ph codeph">smScaler</samp> is not
                              			sufficiently small for the given range), the output vector of the softmax block becomes
                              			categorical, meaning, one vector element is close to 1.0 and other outputs are zero or
                              			very close to zero. When this occurs, the Jacobian matrix of the softmax block is also
                              			close to zero so deltas are not back-propagated during training from output to input
                              			except through residual connections, if these connections are enabled. The user can set
                              				<samp class="ph codeph">smScaler</samp> to any positive floating-point value or even zero. The
                              				<samp class="ph codeph">smScaler</samp> parameter is not trainable.
                           </p>
                           <p class="p">The <samp class="ph codeph">qoMaxSeqLength</samp>, <samp class="ph codeph">kvMaxSeqLength</samp>,
                              				<samp class="ph codeph">maxBatchSize</samp>, and <samp class="ph codeph">maxBeamSize</samp> arguments declare
                              			the maximum sequence lengths, maximum batch size, and maximum beam size respectively, in
                              			the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> containers. The actual
                              			dimensions supplied to forward and backward (gradient) API functions should not exceed
                              			the <samp class="ph codeph">max</samp> limits. The <samp class="ph codeph">max</samp> arguments should be set
                              			carefully because too large values will result in excessive memory usage due to
                              			oversized work and reserve space buffers.
                           </p>
                           <p class="p">The <samp class="ph codeph">attnMode</samp> argument is treated as a binary mask where various on/off
                              			options are set. These options can affect the internal buffer sizes, enforce certain
                              			argument checks, select optimized code execution paths, or enable attention variants
                              			that do not require additional numerical arguments. An example of such options is the
                              			inclusion of biases in input and output projections.
                           </p>
                           <div class="p">The <samp class="ph codeph">attnDropoutDesc</samp> and <samp class="ph codeph">postDropoutDesc</samp> arguments are
                              			descriptors that define two dropout layers active in the training mode. The first
                              			dropout operation defined by <samp class="ph codeph">attnDropoutDesc</samp>, is applied directly to
                              			the softmax output. The second dropout operation, specified by
                              				<samp class="ph codeph">postDropoutDesc</samp>, alters the multi-head attention output, just
                              			before the point where residual connections are added.
                              <div class="note note"><span class="notetitle">Note:</span> The
                                 					<samp class="ph codeph">cudnnSetAttnDescriptor()</samp> function performs a shallow copy of
                                 					<samp class="ph codeph">attnDropoutDesc</samp> and <samp class="ph codeph">postDropoutDesc</samp>, meaning,
                                 				the addresses of both dropout descriptors are stored in the attention descriptor and
                                 				not the entire structure. Therefore, the user should keep dropout descriptors during
                                 				the entire life of the attention descriptor.
                              </div>
                           </div>
                           <div class="section" id="cudnnSetAttnDescriptor__section_qy2_1dz_1jb"><a name="cudnnSetAttnDescriptor__section_qy2_1dz_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <dl class="dl">
                                 <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                 <dd class="dd"><em class="ph i">Output</em>. Attention descriptor to be configured.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">attnMode</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Enables various attention options that do not require
                                    						additional numerical values. See the table below for the list of supported
                                    						flags. The user should assign a preferred set of bitwise
                                    							<samp class="ph codeph">OR-ed</samp> flags to this argument.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">nHeads</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Number of attention heads.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">smScaler</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Softmax smoothing (<samp class="ph codeph">1.0 &gt;= smScaler &gt;= 0.0</samp>) or
                                    						sharpening (<samp class="ph codeph">smScaler &gt; 1.0</samp>) coefficient. Negative values
                                    						are not accepted.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Data type used to represent attention inputs, attention
                                    						weights and attention outputs.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">computePrec</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Compute precision.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">mathType</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. NVIDIA Tensor Core settings.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">attnDropoutDesc</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Descriptor of the dropout operation applied to the softmax
                                    						output. See the table below for a list of unsupported features.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">postDropoutDesc</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Descriptor of the dropout operation applied to the multi-head
                                    						attention output, just before the point where residual connections are
                                    						added. See the table below for a list of unsupported features.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">qSize</samp>, <samp class="ph codeph">kSize</samp>, <samp class="ph codeph">vSize</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                       </mrow>
                                    </math>
                                    						, 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                          <mo>,</mo>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                       </mrow>
                                    </math>
                                    						 embedding vector lengths.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">qProjSize</samp>, <samp class="ph codeph">kProjSize</samp>,
                                    							<samp class="ph codeph">vProjSize</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                       </mrow>
                                    </math>
                                    						, 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                          <mo>,</mo>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                       </mrow>
                                    </math>
                                    						 embedding vector lengths after input projections. Use zero to
                                    						disable the corresponding projection.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">oProjSize</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. The 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">h</mi>
                                             <mi>i</mi>
                                          </msub>
                                       </mrow>
                                    </math>
                                    						 vector length after the output projection. Use zero to disable
                                    						this projection.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">qoMaxSeqLength</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Largest sequence length expected in sequence data descriptors
                                    						related to 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                       </mrow>
                                    </math>
                                    						, 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">O</mi>
                                       </mrow>
                                    </math>
                                    						, 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">dQ</mi>
                                       </mrow>
                                    </math>
                                    						 and 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">dO</mi>
                                       </mrow>
                                    </math>
                                    						 inputs and outputs.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">kvMaxSeqLength</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Largest sequence length expected in sequence data descriptors
                                    						related to 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                          <mo>,</mo>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                       </mrow>
                                    </math>
                                    						, 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">dK</mi>
                                       </mrow>
                                    </math>
                                    						 and 
                                    							
                                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                                       <mrow>
                                          <mi mathvariant="bold" fontfamily="Times New Roman">dV</mi>
                                       </mrow>
                                    </math>
                                    						 inputs and outputs.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">maxBatchSize</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Largest batch size expected in any <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> container.
                                 </dd>
                                 <dt class="dt dltermexpand"><samp class="ph codeph">maxBeamSize</samp></dt>
                                 <dd class="dd"><em class="ph i">Input</em>. Largest beam size expected in any <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> container.
                                 </dd>
                              </dl>
                           </div>
                           <div class="section" id="cudnnSetAttnDescriptor__section_qgj_jfz_1jb"><a name="cudnnSetAttnDescriptor__section_qgj_jfz_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported <samp class="ph codeph">attnMode</samp> flags
                              </h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTN_QUERYMAP_ALL_TO_ONE</samp></dt>
                                    <dd class="dd">Forward declaration of mapping between 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                          </mrow>
                                       </math>
                                       							 and 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                             <mo>,</mo>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                          </mrow>
                                       </math>
                                       							 vectors when the beam size is greater than one in the 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                          </mrow>
                                       </math>
                                       							 input. Multiple 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                          </mrow>
                                       </math>
                                       							 vectors from the same beam bundle map to the same 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                             <mo>,</mo>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                          </mrow>
                                       </math>
                                       							 vectors. This means that beam sizes in the 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                             <mo>,</mo>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                          </mrow>
                                       </math>
                                       							 sets are equal to one.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTN_QUERYMAP_ONE_TO_ONE</samp></dt>
                                    <dd class="dd">Forward declaration of mapping between 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                          </mrow>
                                       </math>
                                       							 and 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                             <mo>,</mo>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                          </mrow>
                                       </math>
                                       							 vectors when the beam size is greater than one in the 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                          </mrow>
                                       </math>
                                       							 input. Multiple 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                          </mrow>
                                       </math>
                                       							 vectors from the same beam bundle map to different 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                             <mo>,</mo>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                          </mrow>
                                       </math>
                                       							 vectors. This requires beam sizes in 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                             <mo>,</mo>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">V</mi>
                                          </mrow>
                                       </math>
                                       							 sets to be the same as in the 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                          </mrow>
                                       </math>
                                       							 input.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTN_DISABLE_PROJ_BIASES</samp></dt>
                                    <dd class="dd">Use no biases in the attention input and output projections.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTN_ENABLE_PROJ_BIASES</samp></dt>
                                    <dd class="dd">Use extra biases in the attention input and output projections. In this
                                       							case the projected 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mover>
                                                <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                                <mo></mo>
                                             </mover>
                                          </mrow>
                                       </math>
                                       							 vectors are computed as 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mover>
                                                <msub>
                                                   <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                                   <mi>i</mi>
                                                </msub>
                                                <mo></mo>
                                             </mover>
                                             <mo>=</mo>
                                             <msub>
                                                <mi mathvariant="bold" fontfamily="Times New Roman">W</mi>
                                                <mrow>
                                                   <mi>K</mi>
                                                   <mo>,</mo>
                                                   <mi>i</mi>
                                                </mrow>
                                             </msub>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                             <mo lspace="2px" rspace="2px">+</mo>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">b</mi>
                                             <mo lspace="2px" rspace="2px">*</mo>
                                             <msub>
                                                <mfenced open="[" close="]">
                                                   <mrow>
                                                      <mn>1</mn>
                                                      <mo>,</mo>
                                                      <mn>1</mn>
                                                      <mo>,</mo>
                                                      <mo lspace="0px" rspace="0px">...,</mo>
                                                      <mn>1</mn>
                                                   </mrow>
                                                </mfenced>
                                                <mrow>
                                                   <mn>1</mn>
                                                   <mo lspace="2px" rspace="2px"></mo>
                                                   <mi>n</mi>
                                                </mrow>
                                             </msub>
                                          </mrow>
                                       </math>
                                       							, where 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>n</mi>
                                          </mrow>
                                       </math>
                                       							 is the number of columns in the 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                          </mrow>
                                       </math>
                                       							 matrix. In other words, the same column vector 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">b</mi>
                                          </mrow>
                                       </math>
                                       							 is added to all columns of 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                          </mrow>
                                       </math>
                                       							 after the weight matrix multiplication.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetAttnDescriptor__section_tyj_mhz_1jb"><a name="cudnnSetAttnDescriptor__section_tyj_mhz_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Supported combinations of <samp class="ph codeph">dataType</samp>,
                                 				<samp class="ph codeph">computePrec</samp>, and <samp class="ph codeph">mathType</samp></h4>
                              <div class="p">
                                 <div class="tablenoborder"><a name="cudnnSetAttnDescriptor__table_fcc_phz_1jb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetAttnDescriptor__table_fcc_phz_1jb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 50. Supported Combinations for <samp class="ph codeph">cudnnSetAttnDescriptor()</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="33.33333333333333%" id="d54e77699" rowspan="1" colspan="1"><samp class="ph codeph">dataType</samp></th>
                                             <th class="entry" valign="top" width="33.33333333333333%" id="d54e77703" rowspan="1" colspan="1"><samp class="ph codeph">computePrec</samp></th>
                                             <th class="entry" valign="top" width="33.33333333333333%" id="d54e77707" rowspan="1" colspan="1"><samp class="ph codeph">mathType</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77699" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77703" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77707" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DEFAULT_MATH</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77699" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77703" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77707" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>,
                                                										<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77699" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77703" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DATA_HALF</samp>, <samp class="ph codeph">CUDNN_DATA_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="33.33333333333333%" headers="d54e77707" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>,
                                                										<samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>,
                                                										<samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetAttnDescriptor__section_tnl_thz_1jb"><a name="cudnnSetAttnDescriptor__section_tnl_thz_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Unsupported features</h4>
                              <div class="p"><a name="cudnnSetAttnDescriptor__ol_q2z_thz_1jb" shape="rect">
                                    <!-- --></a><ol class="ol" id="cudnnSetAttnDescriptor__ol_q2z_thz_1jb">
                                    <li class="li">The <samp class="ph codeph">paddingFill</samp> argument in <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> is currently ignored
                                       						by all multi-head attention functions.
                                    </li>
                                 </ol>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetAttnDescriptor__section_b53_whz_1jb"><a name="cudnnSetAttnDescriptor__section_b53_whz_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The attention descriptor was configured successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was encountered. Some examples include:<a name="cudnnSetAttnDescriptor__ul_vbz_xhz_1jb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetAttnDescriptor__ul_vbz_xhz_1jb">
                                          <li class="li liexpand">post projection 
                                             										
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi mathvariant="bold" fontfamily="Times New Roman">Q</mi>
                                                </mrow>
                                             </math>
                                             									 and 
                                             										
                                             <math xmlns="http://www.w3.org/1998/Math/MathML">
                                                <mrow>
                                                   <mi mathvariant="bold" fontfamily="Times New Roman">K</mi>
                                                </mrow>
                                             </math>
                                             									 sizes were not equal
                                          </li>
                                          <li class="li liexpand"><samp class="ph codeph">dataType</samp>, <samp class="ph codeph">computePrec</samp>, or
                                             										<samp class="ph codeph">mathType</samp> were invalid
                                          </li>
                                          <li class="li liexpand">one or more of the following arguments were either negative or
                                             									zero: <samp class="ph codeph">nHeads</samp>, <samp class="ph codeph">qSize</samp>,
                                             										<samp class="ph codeph">kSize</samp>, <samp class="ph codeph">vSize</samp>,
                                             										<samp class="ph codeph">qoMaxSeqLength</samp>,
                                             										<samp class="ph codeph">kvMaxSeqLength</samp>,
                                             										<samp class="ph codeph">maxBatchSize</samp>,
                                             									<samp class="ph codeph">maxBeamSize</samp></li>
                                          <li class="li liexpand">one or more of the following arguments were negative:
                                             										<samp class="ph codeph">qProjSize</samp>, <samp class="ph codeph">kProjSize</samp>,
                                             										<samp class="ph codeph">vProjSize</samp>, <samp class="ph codeph">smScaler</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A requested option or a combination of input arguments is not
                                       							supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetPersistentRNNPlan"><a name="cudnnSetPersistentRNNPlan" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetPersistentRNNPlan" name="cudnnSetPersistentRNNPlan" shape="rect">7.2.44.&nbsp;<kbd class="ph userinput">cudnnSetPersistentRNNPlan()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function sets the persistent RNN plan to be executed when using
                              <samp class="ph codeph">rnnDesc</samp> and <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>
                              algo.
                           </p><pre xml:space="preserve">cudnnStatus_t cudnnSetPersistentRNNPlan(
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnPersistentRNNPlan_t    plan)</pre><div class="section" id="cudnnSetPersistentRNNPlan__section_orp_yp3_bjb"><a name="cudnnSetPersistentRNNPlan__section_orp_yp3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The plan was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The algo selected in <samp class="ph codeph">rnnDesc</samp> is not
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNAlgorithmDescriptor"><a name="cudnnSetRNNAlgorithmDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNAlgorithmDescriptor" name="cudnnSetRNNAlgorithmDescriptor" shape="rect">7.2.45.&nbsp;<kbd class="ph userinput">cudnnSetRNNAlgorithmDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNBiasMode"><a name="cudnnSetRNNBiasMode" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNBiasMode" name="cudnnSetRNNBiasMode" shape="rect">7.2.46.&nbsp;<kbd class="ph userinput">cudnnSetRNNBiasMode()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnSetRNNBiasMode()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnSetRNNBiasMode(
   cudnnRNNDescriptor_t   rnnDesc, 
   cudnnRNNBiasMode_t     biasMode)</pre><p class="p">The <samp class="ph codeph">cudnnSetRNNBiasMode()</samp> function sets the number of bias vectors for a
                              previously created and initialized RNN descriptor. This function should be called to
                              enable the specified bias mode in an RNN. The default value of <samp class="ph codeph">biasMode</samp>
                              in <samp class="ph codeph">rnnDesc</samp> after <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateRNNDescriptor" title="This function creates a generic RNN descriptor object by allocating the memory needed to hold its opaque structure." shape="rect">cudnnCreateRNNDescriptor()</a></samp> is <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>.
                           </p>
                           <div class="section" id="cudnnSetRNNBiasMode__section_jsc_hs3_bjb"><a name="cudnnSetRNNBiasMode__section_jsc_hs3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output.</em> A previously created RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">biasMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Sets the number of bias vectors. For more information,
                                       refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBiasMode_t" shape="rect">cudnnRNNBiasMode_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetRNNBiasMode__section_ykm_hs3_bjb"><a name="cudnnSetRNNBiasMode__section_ykm_hs3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either the <samp class="ph codeph">rnnDesc</samp> is <samp class="ph codeph">NULL</samp> or
                                       <samp class="ph codeph">biasMode</samp> has an invalid enumerant value.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">biasMode</samp> was set successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Non-default bias mode (an enumerated type besides
                                       <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>) applied to an RNN algo other
                                       than <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNDataDescriptor"><a name="cudnnSetRNNDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNDataDescriptor" name="cudnnSetRNNDataDescriptor" shape="rect">7.2.47.&nbsp;<kbd class="ph userinput">cudnnSetRNNDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created RNN data descriptor object. This
                                 data structure is intended to support the unpacked (padded) layout for input and output
                                 of extended RNN inference and training functions. A packed (unpadded) layout is also
                                 supported for backward compatibility.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNDataDescriptor(
    cudnnRNNDataDescriptor_t       RNNDataDesc,
    cudnnDataType_t                dataType,
    cudnnRNNDataLayout_t           layout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            maxSeqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            batchSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            vectorSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      seqLengthArray[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *paddingFill);</pre><div class="section" id="cudnnSetRNNDataDescriptor__section_ijs_rs3_bjb"><a name="cudnnSetRNNDataDescriptor__section_ijs_rs3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">RNNDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. A previously created RNN descriptor. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNDataDescriptor_t" shape="rect">cudnnRNNDataDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The datatype of the RNN data tensor. For more information,
                                       refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">layout</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The memory layout of the RNN data tensor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxSeqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum sequence length within this RNN data tensor.
                                       In the unpacked (padded) layout, this should include the padding vectors
                                       in each sequence. In the packed (unpadded) layout, this should be equal
                                       to the greatest element in <samp class="ph codeph">seqLengthArray</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">batchSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The number of sequences within the mini-batch.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">vectorSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The vector length (embedding size) of the input or output
                                       tensor at each time-step.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLengthArray</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An integer array with <samp class="ph codeph">batchSize</samp> number of
                                       elements. Describes the length (number of time-steps) of each sequence.
                                       Each element in <samp class="ph codeph">seqLengthArray</samp> must be greater than or
                                       equal to 0 but less than or equal to <samp class="ph codeph">maxSeqLength</samp>. In
                                       the packed layout, the elements should be sorted in descending order,
                                       similar to the layout required by the non-extended RNN compute
                                       functions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddingFill</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A user-defined symbol for filling the padding position in
                                       RNN output. This is only effective when the descriptor is describing the
                                       RNN output, and the unpacked layout is specified. The symbol should be
                                       in the host memory, and is interpreted as the same data type as that of
                                       the RNN data tensor. If a <samp class="ph codeph">NULL</samp> pointer is passed in,
                                       then the padding position in the output will be undefined. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetRNNDataDescriptor__section_nlc_ss3_bjb"><a name="cudnnSetRNNDataDescriptor__section_nlc_ss3_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Any one of these have occurred:<a name="cudnnSetRNNDataDescriptor__ul_ljx_s5y_3xb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetRNNDataDescriptor__ul_ljx_s5y_3xb">
                                          <li class="li"><samp class="ph codeph">dataType</samp> is not one of
                                             <samp class="ph codeph">CUDNN_DATA_HALF</samp>,
                                             <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>,
                                             <samp class="ph codeph">CUDNN_DATA_DOUBLE</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">maxSeqLength</samp> is larger than 65535
                                             (0xffff).
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Any one of these have occurred:<a name="cudnnSetRNNDataDescriptor__ul_g4k_bsr_h2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetRNNDataDescriptor__ul_g4k_bsr_h2b">
                                          <li class="li"><samp class="ph codeph">RNNDataDesc</samp> is <samp class="ph codeph">NULL</samp>. 
                                          </li>
                                          <li class="li">Any one of <samp class="ph codeph">maxSeqLength</samp>,
                                             <samp class="ph codeph">batchSize</samp> or <samp class="ph codeph">vectorSize</samp> is
                                             less than or equal to zero. 
                                          </li>
                                          <li class="li">An element of <samp class="ph codeph">seqLengthArray</samp> is less than zero
                                             or greater than <samp class="ph codeph">maxSeqLength</samp>. 
                                          </li>
                                          <li class="li">Layout is not one of
                                             <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED</samp>,<samp class="ph codeph">
                                                CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_PACKED</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED</samp>.
                                             
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The allocation of internal array storage has failed. </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNDescriptor_v6"><a name="cudnnSetRNNDescriptor_v6" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNDescriptor_v6" name="cudnnSetRNNDescriptor_v6" shape="rect">7.2.48.&nbsp;<kbd class="ph userinput">cudnnSetRNNDescriptor_v6()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnSetRNNDescriptor_v6()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNDescriptor_v6(
	cudnnHandle_t                    handle,
	cudnnRNNDescriptor_t             rnnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        hiddenSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        numLayers,
	cudnnDropoutDescriptor_t         dropoutDesc,
	cudnnRNNInputMode_t              inputMode,
	cudnnDirectionMode_t             direction,
	cudnnRNNMode_t                   mode,
	cudnnRNNAlgo_t                   algo,
	cudnnDataType_t                  mathPrec)</pre><p class="p">This function initializes a previously created RNN descriptor object.</p>
                           <div class="note note"><span class="notetitle">Note:</span> Larger networks, for example, longer sequences or more layers, are expected to be more
                              efficient than smaller networks.
                           </div>
                           <div class="section" id="cudnnSetRNNDescriptor_v6__section_htz_dwj_bjb"><a name="cudnnSetRNNDescriptor_v6__section_htz_dwj_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hiddenSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the internal hidden state for each layer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">numLayers</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of stacked layers.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created and initialized dropout
                                       descriptor. Dropout will be applied between layers, for example, a
                                       single layer network will have no dropout applied.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the behavior at the input to the first
                                       layer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">direction</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the recurrence pattern, for example,
                                       bidirectional.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the type of RNN to compute.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies which RNN algorithm should be used to compute
                                       the results.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mathPrec</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Math precision. This parameter is used for controlling the
                                       math precision in RNN. The following applies:<a name="cudnnSetRNNDescriptor_v6__ul_xp2_3wj_bjb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetRNNDescriptor_v6__ul_xp2_3wj_bjb">
                                          <li class="li">For the input/output in FP16, the parameter
                                             <samp class="ph codeph">mathPrec</samp> can be
                                             <samp class="ph codeph">CUDNN_DATA_HALF</samp> or
                                             <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>.
                                          </li>
                                          <li class="li">For the input/output in FP32, the parameter
                                             <samp class="ph codeph">mathPrec</samp> can only be
                                             <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>.
                                          </li>
                                          <li class="li">For the input/output in FP64, double type, the parameter
                                             <samp class="ph codeph">mathPrec</samp> can only be
                                             <samp class="ph codeph">CUDNN_DATA_DOUBLE</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetRNNDescriptor_v6__section_xw3_2wj_bjb"><a name="cudnnSetRNNDescriptor_v6__section_xw3_2wj_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The object was set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either at least one of the parameters <samp class="ph codeph">hiddenSize</samp> or
                                       <samp class="ph codeph">numLayers</samp> was zero or negative, one of
                                       <samp class="ph codeph">inputMode</samp>, <samp class="ph codeph">direction</samp>,
                                       <samp class="ph codeph">mode</samp>, <samp class="ph codeph">algo</samp> or
                                       <samp class="ph codeph">dataType</samp> has an invalid enumerant value,
                                       <samp class="ph codeph">dropoutDesc</samp> is an invalid dropout descriptor or
                                       <samp class="ph codeph">rnnDesc</samp> has not been created correctly. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNDescriptor_v8"><a name="cudnnSetRNNDescriptor_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNDescriptor_v8" name="cudnnSetRNNDescriptor_v8" shape="rect">7.2.49.&nbsp;<kbd class="ph userinput">cudnnSetRNNDescriptor_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created RNN descriptor object. The RNN
                                 descriptor configured by <samp class="ph codeph">cudnnSetRNNDescriptor_v8()</samp> was enhanced to
                                 store all information needed to compute the total number of adjustable weights/biases in
                                 the RNN model.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNDescriptor_v8(
	cudnnRNNDescriptor_t rnnDesc,
	cudnnRNNAlgo_t algo,
	cudnnRNNMode_t cellMode,
	cudnnRNNBiasMode_t biasMode,
	cudnnDirectionMode_t dirMode,
	cudnnRNNInputMode_t inputMode,
	cudnnDataType_t dataType,
	cudnnDataType_t mathPrec,
	cudnnMathType_t mathType,
	int32_t inputSize,
	int32_t hiddenSize,
	int32_t projSize,
	int32_t numLayers,
    cudnnDropoutDescriptor_t dropoutDesc,
    uint32_t auxFlags);
</pre><div class="section" id="cudnnSetRNNDescriptor_v8__section_l1g_xmn_y3b"><a name="cudnnSetRNNDescriptor_v8__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. RNN algo (<samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>,
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>, or
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cellMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the RNN cell type in the entire model
                                       (<samp class="ph codeph">CUDNN_RNN_RELU</samp>, <samp class="ph codeph">CUDNN_RNN_TANH</samp>,
                                       <samp class="ph codeph">CUDNN_RNN_LSTM</samp>,
                                       <samp class="ph codeph">CUDNN_RNN_GRU</samp>).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">biasMode</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">Input</samp>. Sets the number of bias vectors
                                       (<samp class="ph codeph">CUDNN_RNN_NO_BIAS</samp>,
                                       <samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp>,
                                       <samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp>,
                                       <samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>). The two single bias
                                       settings are functionally the same for <samp class="ph codeph">RELU</samp>,
                                       <samp class="ph codeph">TANH</samp> and <samp class="ph codeph">LSTM</samp> cell types. For
                                       differences in GRU cells, see the description of
                                       <samp class="ph codeph">CUDNN_GRU</samp> in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNMode_t" shape="rect">cudnnRNNMode_t</a></samp> enumerated type.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dirMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the recurrence pattern:
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> or
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp>. In bidirectional RNNs, the
                                       hidden states passed between physical layers are concatenations of
                                       forward and backward hidden states.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies how the input to the RNN model is processed by
                                       the first layer. When <samp class="ph codeph">inputMode</samp> is
                                       <samp class="ph codeph">CUDNN_LINEAR_INPUT</samp>, original input vectors of size
                                       <samp class="ph codeph">inputSize</samp> are multiplied by the weight matrix to
                                       obtain vectors of <samp class="ph codeph">hiddenSize</samp>. When
                                       <samp class="ph codeph">inputMode</samp> is <samp class="ph codeph">CUDNN_SKIP_INPUT</samp>, the
                                       original input vectors to the first layer are used as is without
                                       multiplying them by the weight matrix.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies data type for RNN weights/biases and input and
                                       output data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mathPrec</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. This parameter is used to control the compute math
                                       precision in the RNN model. The following applies:<a name="cudnnSetRNNDescriptor_v8__ul_pbb_nyb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetRNNDescriptor_v8__ul_pbb_nyb_wlb">
                                          <li class="li">For the input/output in FP16, the parameter
                                             <samp class="ph codeph">mathPrec</samp> can be
                                             <samp class="ph codeph">CUDNN_DATA_HALF</samp> or
                                             <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>.
                                          </li>
                                          <li class="li">For the input/output in FP32, the parameter
                                             <samp class="ph codeph">mathPrec</samp> can only be
                                             <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>.
                                          </li>
                                          <li class="li">For the input/output in FP64, double type, the parameter
                                             <samp class="ph codeph">mathPrec</samp> can only be
                                             <samp class="ph codeph">CUDNN_DATA_DOUBLE</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mathType</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. Sets the preferred option to use NVIDIA Tensor Cores
                                          accelerators on Volta (SM 7.0) or higher GPU-s).<a name="cudnnSetRNNDescriptor_v8__ul_zd4_4yb_wlb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnSetRNNDescriptor_v8__ul_zd4_4yb_wlb">
                                             <li class="li">When <samp class="ph codeph">dataType</samp> is
                                                <samp class="ph codeph">CUDNN_DATA_HALF</samp>, the
                                                <samp class="ph codeph">mathType</samp> parameter can be
                                                <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> or
                                                <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>. The
                                                <samp class="ph codeph">ALLOW_CONVERSION</samp> setting is treated the
                                                same as <samp class="ph codeph">CUDNN_TENSOR_OP_MATH </samp>for this data
                                                type.
                                             </li>
                                             <li class="li">When <samp class="ph codeph">dataType</samp> is
                                                <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>, the
                                                <samp class="ph codeph">mathType</samp> parameter can be
                                                <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp> or
                                                <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>.
                                                When the latter settings are used, original weights and
                                                intermediate results will be down-converted to
                                                <samp class="ph codeph">CUDNN_DATA_HALF</samp> before they are used in
                                                another recursive iteration.
                                             </li>
                                             <li class="li">When <samp class="ph codeph">dataType</samp> is
                                                <samp class="ph codeph">CUDNN_DATA_DOUBLE</samp>, the
                                                <samp class="ph codeph">mathType</samp> parameter can be
                                                <samp class="ph codeph">CUDNN_DEFAULT_MATH</samp>.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">This option has an advisory status meaning Tensor Cores may not be
                                          always utilized, for example, due to specific GEMM dimensions
                                          restrictions.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the input vector in the RNN model. When the
                                       <samp class="ph codeph">inputMode=CUDNN_SKIP_INPUT</samp>, the
                                       <samp class="ph codeph">inputSize</samp> should match the
                                       <samp class="ph codeph">hiddenSize</samp> value.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hiddenSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the hidden state vector in the RNN model. The same
                                       hidden size is used in all RNN layers.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">projSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the LSTM cell output after the recurrent
                                       projection. This value should not be larger than
                                       <samp class="ph codeph">hiddenSize</samp>. It is legal to set
                                       <samp class="ph codeph">projSize</samp> equal to <samp class="ph codeph">hiddenSize</samp>,
                                       however, in this case, the recurrent projection feature is disabled. The
                                       recurrent projection is an additional matrix multiplication in the LSTM
                                       cell to project hidden state vectors <samp class="ph codeph">h<sub class="ph sub">t</sub></samp> into
                                       smaller vectors <samp class="ph codeph">r<sub class="ph sub">t</sub></samp><samp class="ph codeph"> =
                                          W<sub class="ph sub">r</sub></samp><samp class="ph codeph">h<sub class="ph sub">t</sub></samp>, where
                                       <samp class="ph codeph">W<sub class="ph sub">r</sub></samp> is a rectangular matrix with
                                       <samp class="ph codeph">projSize</samp> rows and <samp class="ph codeph">hiddenSize</samp>
                                       columns. When the recurrent projection is enabled, the output of the
                                       LSTM cell (both to the next layer and unrolled in-time) is
                                       <samp class="ph codeph">r<sub class="ph sub">t</sub></samp> instead of
                                       <samp class="ph codeph">h<sub class="ph sub">t</sub></samp>. The recurrent projection can be
                                       enabled for LSTM cells and <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>
                                       only.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">numLayers</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of stacked, physical layers in the deep RNN model.
                                       When <samp class="ph codeph">dirMode= CUDNN_BIDIRECTIONAL</samp>, the physical layer
                                       consists of two pseudo-layers corresponding to forward and backward
                                       directions.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dropoutDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created and initialized dropout
                                       descriptor. Dropout operation will be applied between physical layers. A
                                       single layer network will have no dropout applied. Dropout is used in
                                       the training mode only.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">auxFlags</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. This argument is used to pass miscellaneous switches that
                                       do not require additional numerical values to configure the
                                       corresponding feature. In future cuDNN releases, this parameter will be
                                       used to extend the RNN functionality without adding new API functions
                                       (applicable options should be bitwise OR-ed). Currently, this parameter
                                       is used to enable or disable padded input/output
                                       (<samp class="ph codeph">CUDNN_RNN_PADDED_IO_DISABLED</samp>,
                                       <samp class="ph codeph">CUDNN_RNN_PADDED_IO_ENABLED</samp>). When the padded I/O
                                       is enabled, layouts
                                       <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED</samp> and
                                       <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED</samp> are
                                       permitted in RNN data descriptors.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetRNNDescriptor_v8__section_zgs_xmn_y3b"><a name="cudnnSetRNNDescriptor_v8__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The RNN descriptor was configured successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was detected.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The dimensions of the bias tensor refer to an amount of data that is
                                       incompatible with the output tensor dimensions or the
                                       <samp class="ph codeph">dataType</samp> of the two tensor descriptors are
                                       different.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">An incompatible or unsupported combination of input arguments was
                                       detected.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNMatrixMathType"><a name="cudnnSetRNNMatrixMathType" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNMatrixMathType" name="cudnnSetRNNMatrixMathType" shape="rect">7.2.50.&nbsp;<kbd class="ph userinput">cudnnSetRNNMatrixMathType()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnSetRNNMatrixMathType()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNMatrixMathType(
    cudnnRNNDescriptor_t    rnnDesc,
    cudnnMathType_t         mType)</pre><p class="p">This function sets the preferred option to use NVIDIA Tensor Cores accelerators on Volta
                              GPUs (SM 7.0 or higher). When the <samp class="ph codeph">mType</samp> parameter is
                              <samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp>, inference and training RNN APIs will attempt
                              use Tensor Cores when weights/biases are of type <samp class="ph codeph">CUDNN_DATA_HALF</samp> or
                              <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>. When RNN weights/biases are stored in the
                              <samp class="ph codeph">CUDNN_DATA_FLOAT</samp> format, the original weights and intermediate
                              results will be down-converted to <samp class="ph codeph">CUDNN_DATA_HALF</samp> before they are used
                              in another recursive iteration.
                           </p>
                           <div class="section" id="cudnnSetRNNMatrixMathType__section_ul4_tfc_cjb"><a name="cudnnSetRNNMatrixMathType__section_ul4_tfc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">mType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A preferred compute option when performing RNN GEMMs
                                       (general matrix-matrix multiplications). This option has an advisory
                                       status meaning that Tensor Cores may not be utilized, for example, due
                                       to specific GEMM dimensions.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetRNNMatrixMathType__section_ks1_5fc_cjb"><a name="cudnnSetRNNMatrixMathType__section_ks1_5fc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The preferred compute option for the RNN network was set
                                       successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input parameter was detected.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNPaddingMode"><a name="cudnnSetRNNPaddingMode" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNPaddingMode" name="cudnnSetRNNPaddingMode" shape="rect">7.2.51.&nbsp;<kbd class="ph userinput">cudnnSetRNNPaddingMode()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnSetRNNPaddingMode()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNPaddingMode(
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNPaddingMode_t       paddingMode)</pre><p class="p">This function enables or disables the padded RNN input/output for a previously created
                              and initialized RNN descriptor. This information is required before calling the
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNTrainingReserveSize" shape="rect">cudnnGetRNNTrainingReserveSize()</a></samp> functions, to determine
                              whether additional workspace and training reserve space is needed. By default, the
                              padded RNN input/output is not enabled.
                           </p>
                           <div class="section" id="cudnnSetRNNPaddingMode__section_rxh_1gc_cjb"><a name="cudnnSetRNNPaddingMode__section_rxh_1gc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddingMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enables or disables the padded input/output. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNPaddingMode_t" title="cudnnRNNPaddingMode_t is an enumerated type used to enable or disable the padded input/output." shape="rect">cudnnRNNPaddingMode_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetRNNPaddingMode__section_tzs_1gc_cjb"><a name="cudnnSetRNNPaddingMode__section_tzs_1gc_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">paddingMode</samp> was set successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Either the <samp class="ph codeph">rnnDesc</samp> is <samp class="ph codeph">NULL</samp> or
                                       <samp class="ph codeph">paddingMode</samp> has an invalid enumerant value. 
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetRNNProjectionLayers"><a name="cudnnSetRNNProjectionLayers" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNProjectionLayers" name="cudnnSetRNNProjectionLayers" shape="rect">7.2.52.&nbsp;<kbd class="ph userinput">cudnnSetRNNProjectionLayers()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnSetRNNProjectionLayers()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNProjectionLayers(
    cudnnHandle_t           handle,
    cudnnRNNDescriptor_t    rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     recProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     outProjSize)</pre><p class="p">The <samp class="ph codeph">cudnnSetRNNProjectionLayers()</samp> function should be called to enable
                              the recurrent and/or output projection in a recursive neural network. The recurrent
                              projection is an additional matrix multiplication in the LSTM cell to project hidden
                              state vectors 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>h</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              into smaller vectors 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>r</mi>
                                       <mi>t</mi>
                                    </msub>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mo>=</mo>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <msub>
                                       <mi>W</mi>
                                       <mi>r</mi>
                                    </msub>
                                    <msub>
                                       <mi>h</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              , where 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>W</mi>
                                       <mi>r</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              is a rectangular matrix with <samp class="ph codeph">recProjSize</samp> rows and
                              <samp class="ph codeph">hiddenSize</samp> columns. When the recurrent projection is enabled, the
                              output of the LSTM cell (both to the next layer and unrolled in-time) is 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>r</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              instead of 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>h</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              . The dimensionality of 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>i</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              , 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>f</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              , 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>o</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              , and 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>c</mi>
                                       <mi>t</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              vectors used in conjunction with non-linear functions remains the same as
                              in the canonical LSTM cell. To make this possible, the shapes of matrices in the LSTM
                              formulas (refer to <a class="xref" href="index.html#cudnnRNNMode_t" shape="rect">cudnnRNNMode_t</a> type), such as 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>W</mi>
                                       <mi>i</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              in hidden RNN layers or 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>R</mi>
                                       <mi>i</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              in the entire network, become rectangular versus square in the canonical
                              LSTM mode. Obviously, the result of 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>R</mi>
                                       <mi>i</mi>
                                    </msub>
                                    <mo lspace="2px" rspace="2px">*</mo>
                                    <msub>
                                       <mi>W</mi>
                                       <mi>r</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              is a square matrix but it is rank deficient, reflecting the compression of
                              LSTM output. The recurrent projection is typically employed when the number of
                              independent (adjustable) weights in the RNN network with projection is smaller in
                              comparison to canonical LSTM for the same <samp class="ph codeph">hiddenSize</samp> value.
                           </p>
                           <p class="p">The recurrent projection can be enabled for LSTM cells and
                              <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp> only. The <samp class="ph codeph">recProjSize</samp>
                              parameter should be smaller than the <samp class="ph codeph">hiddenSize</samp> value. It is legal to
                              set <samp class="ph codeph">recProjSize</samp> equal to <samp class="ph codeph">hiddenSize</samp> but in that case
                              the recurrent projection feature is disabled.
                           </p>
                           <p class="p">The output projection is currently not implemented.</p>
                           <p class="p">For more information on the recurrent and output RNN projections, refer to the paper by
                              <a class="xref" href="https://arxiv.org/abs/1402.1128" target="_blank" shape="rect">Hasim
                                 Sak, et al.: Long Short-Term Memory Based Recurrent Neural Network Architectures For
                                 Large Vocabulary Speech Recognition</a>.
                           </p>
                           <div class="section" id="cudnnSetRNNProjectionLayers__section_icd_g3c_cjb"><a name="cudnnSetRNNProjectionLayers__section_icd_g3c_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN library
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">recProjSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The size of the LSTM cell output after the recurrent
                                       projection. This value should not be larger than
                                       <samp class="ph codeph">hiddenSize</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">outProjSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. This parameter should be zero.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetRNNProjectionLayers__section_tc4_g3c_cjb"><a name="cudnnSetRNNProjectionLayers__section_tc4_g3c_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">RNN projection parameters were set successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was detected (for example,
                                       <samp class="ph codeph">NULL</samp> handles, negative values for projection
                                       parameters).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Projection applied to RNN algo other than
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>, cell type other than
                                       <samp class="ph codeph">CUDNN_LSTM</samp>, <samp class="ph codeph">recProjSize</samp> larger
                                       than <samp class="ph codeph">hiddenSize</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetSeqDataDescriptor"><a name="cudnnSetSeqDataDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetSeqDataDescriptor" name="cudnnSetSeqDataDescriptor" shape="rect">7.2.53.&nbsp;<kbd class="ph userinput">cudnnSetSeqDataDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function initializes a previously created sequence data descriptor object.
                                 			In the most simplified view, this descriptor defines dimensions (<samp class="ph codeph">dimA</samp>)
                                 			and the data layout (<samp class="ph codeph">axes</samp>) of a four-dimensional tensor. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetSeqDataDescriptor(
	cudnnSeqDataDescriptor_t seqDataDesc,
    cudnnDataType_t dataType,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> nbDims,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> dimA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataAxis_t axes[],
	size_t seqLengthArraySize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> seqLengthArray[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *paddingFill);
</pre><div class="p">All four dimensions of the sequence data descriptor have unique identifiers that can be used to
                              			index the <samp class="ph codeph">dimA[]</samp>
                              			array:<pre xml:space="preserve">CUDNN_SEQDATA_TIME_DIM
CUDNN_SEQDATA_BATCH_DIM
CUDNN_SEQDATA_BEAM_DIM
CUDNN_SEQDATA_VECT_DIM
</pre></div>
                           <p class="p">For example, to express information that vectors in our sequence data buffer are five
                              			elements long, we need to assign <samp class="ph codeph">dimA[CUDNN_SEQDATA_VECT_DIM]=5</samp> in the
                              				<samp class="ph codeph">dimA[]</samp> array.
                           </p>
                           <p class="p">The number of active dimensions in the <samp class="ph codeph">dimA[]</samp> and
                              				<samp class="ph codeph">axes[]</samp> arrays is defined by the <samp class="ph codeph">nbDims</samp> argument.
                              			Currently, the value of this argument should be four. The actual size of the
                              				<samp class="ph codeph">dimA[]</samp> and <samp class="ph codeph">axes[]</samp> arrays should be declared using
                              			the <samp class="ph codeph">CUDNN_SEQDATA_DIM_COUNT</samp> macro.
                           </p>
                           <p class="p">The <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> container is treated as a
                              			collection of fixed length vectors that form sequences, similarly to words (vectors of
                              			characters) constructing sentences. The <samp class="ph codeph">TIME</samp> dimension spans the
                              			sequence length. Different sequences are bundled together in a batch. A
                              				<samp class="ph codeph">BATCH</samp> may be a group of individual sequences or beams. A
                              				<samp class="ph codeph">BEAM</samp> is a cluster of alternative sequences or candidates. When
                              			thinking about the beam, consider a translation task from one language to another. You
                              			may want to keep around and experiment with several translated versions of the original
                              			sentence before selecting the best one. The number of candidates kept around is the
                              				<samp class="ph codeph">BEAM</samp> size.
                           </p>
                           <p class="p">Every sequence can have a different length, even within the same beam, so vectors toward
                              			the end of the sequence can be just padding. The <samp class="ph codeph">paddingFill</samp> argument
                              			specifies how the padding vectors should be written in output sequence data buffers. The
                              				<samp class="ph codeph">paddingFill</samp> argument points to one value of type
                              				<samp class="ph codeph">dataType</samp> that should be copied to all elements in padding vectors.
                              			Currently, the only supported value for <samp class="ph codeph">paddingFill</samp> is
                              				<samp class="ph codeph">NULL</samp> which means this option should be ignored. In this case,
                              			elements of the padding vectors in output buffers will have undefined values.
                           </p>
                           <div class="p">It is assumed that a non-empty sequence always starts from the time index zero. The
                              				<samp class="ph codeph">seqLengthArray[]</samp> must specify all sequence lengths in the container
                              			so the total size of this array should be <samp class="ph codeph">dimA[CUDNN_SEQDATA_BATCH_DIM] *
                                 				dimA[CUDNN_SEQDATA_BEAM_DIM]</samp>. Each element of the
                              				<samp class="ph codeph">seqLengthArray[]</samp> array should have a non-negative value, less than
                              			or equal to <samp class="ph codeph">dimA[CUDNN_SEQDATA_TIME_DIM</samp>; the maximum sequence length.
                              			Elements in <samp class="ph codeph">seqLengthArray[]</samp> are always arranged in the same
                              			batch-major order, meaning, when considering <samp class="ph codeph">BEAM</samp> and
                              				<samp class="ph codeph">BATCH</samp> dimensions, <samp class="ph codeph">BATCH</samp> is the outer or the slower
                              			changing index when we traverse the array in ascending order of the addresses. Using a
                              			simple example, the <samp class="ph codeph">seqLengthArray[]</samp> array should hold sequence lengths
                              			in the following
                              			order:<pre xml:space="preserve">{batch_idx=0, beam_idx=0}
{batch_idx=0, beam_idx=1}
{batch_idx=1, beam_idx=0}
{batch_idx=1, beam_idx=1}
{batch_idx=2, beam_idx=0}
{batch_idx=2, beam_idx=1}
</pre>when
                              				<samp class="ph codeph">dimA[CUDNN_SEQDATA_BATCH_DIM]=3</samp> and
                              				<samp class="ph codeph">dimA[CUDNN_SEQDATA_BEAM_DIM]=2</samp>.
                           </div>
                           <div class="p">Data stored in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataDescriptor_t" title="cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding parameters of the sequence data container or buffer. The sequence data container is used to store fixed size vectors defined by the VECT dimension. Vectors are arranged in additional three dimensions: TIME, BATCH and BEAM." shape="rect">cudnnSeqDataDescriptor_t</a></samp> container must
                              			comply with the following constraints:<a name="cudnnSetSeqDataDescriptor__ul_wcq_fkc_cjb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetSeqDataDescriptor__ul_wcq_fkc_cjb">
                                 <li class="li">All data is fully packed. There are no unused spaces or gaps between individual
                                    					vector elements or consecutive vectors.
                                 </li>
                                 <li class="li">The most inner dimension of the container is the vector. In other words, the
                                    					first contiguous group of <samp class="ph codeph">dimA[CUDNN_SEQDATA_VECT_DIM]</samp> elements
                                    					belongs to the first vector, followed by elements of the second vector, and so
                                    					on.
                                 </li>
                              </ul>
                           </div>
                           <div class="p">The <samp class="ph codeph">axes</samp> argument in the <samp class="ph codeph">cudnnSetSeqDataDescriptor()</samp> function
                              			is a bit more complicated. This array should have the same capacity as
                              				<samp class="ph codeph">dimA[]</samp>. The <samp class="ph codeph">axes[]</samp> array specifies the actual data
                              			layout in the GPU memory. In this function, the layout is described in the following
                              			way: as we move from one element of a vector to another in memory by incrementing the
                              			element pointer, what is the order of <samp class="ph codeph">VECT</samp>, <samp class="ph codeph">TIME</samp>,
                              				<samp class="ph codeph">BATCH</samp>, and <samp class="ph codeph">BEAM</samp> dimensions that we encounter. Let
                              			us assume that we want to define the following data layout:
                              <div class="fig fignone"><span class="figcap">Figure 6. Data Layout Example for <samp class="ph codeph">cudnnSetSeqDataDescriptor()</samp></span><img class="image" src="graphics/cudnnSetSeqDataDescriptor.png" alt="Data Layout Example for cudnnSetSeqDataDescriptor()"></img></div>
                              
                              that corresponds to tensor
                              			dimensions:<pre xml:space="preserve">int dimA[CUDNN_SEQDATA_DIM_COUNT];
dimA[CUDNN_SEQDATA_TIME_DIM]  = 4;
dimA[CUDNN_SEQDATA_BATCH_DIM] = 3;
dimA[CUDNN_SEQDATA_BEAM_DIM]  = 2;
dimA[CUDNN_SEQDATA_VECT_DIM]  = 5;
</pre></div>
                           <div class="p">Now, lets initialize the <samp class="ph codeph">axes[]</samp> array. Note that the most inner
                              			dimension is described by the last active element of <samp class="ph codeph">axes[]</samp>. There is
                              			only one valid configuration here as we always traverse a full vector first. Thus, we
                              			need to write <samp class="ph codeph">CUDNN_SEQDATA_VECT_DIM</samp> in the last active element of
                              				<samp class="ph codeph">axes[]</samp>.<pre xml:space="preserve">cudnnSeqDataAxis_t axes[CUDNN_SEQDATA_DIM_COUNT];
axes[3] = CUDNN_SEQDATA_VECT_DIM;   // 3 = nbDims-1
</pre></div>
                           <div class="p">Now, lets work on the remaining three elements of <samp class="ph codeph">axes[]</samp>. When we reach
                              			the end of the first vector, we jump to the next beam,
                              			therefore:<pre xml:space="preserve">axes[2] = CUDNN_SEQDATA_BEAM_DIM;</pre></div>
                           <div class="p">When we approach the end of the second vector, we move to the next batch,
                              			therefore:<pre xml:space="preserve">axes[1] = CUDNN_SEQDATA_BATCH_DIM;</pre></div>
                           <div class="p">The last (outermost) dimension is
                              			<samp class="ph codeph">TIME</samp>:<pre xml:space="preserve">axes[0] = CUDNN_SEQDATA_TIME_DIM;</pre></div>
                           <p class="p">The four values of the <samp class="ph codeph">axes[]</samp> array fully describe the data layout
                              			depicted in the figure.
                           </p>
                           <p class="p">The sequence data descriptor allows the user to select <samp class="ph codeph">3! = 6</samp> different
                              			data layouts or permutations of <samp class="ph codeph">BEAM</samp>, <samp class="ph codeph">BATCH</samp> and
                              				<samp class="ph codeph">TIME</samp> dimensions. The multi-head attention API supports all six
                              			layouts.
                           </p>
                           <div class="section" id="cudnnSetSeqDataDescriptor__section_mcq_44c_cjb"><a name="cudnnSetSeqDataDescriptor__section_mcq_44c_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqDataDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output.</em> Pointer to a previously created sequence data
                                       							descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dataType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Data type of the sequence data buffer
                                       								(<samp class="ph codeph">CUDNN_DATA_HALF</samp>, <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>
                                       							or <samp class="ph codeph">CUDNN_DATA_DOUBLE</samp>).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">nbDims</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Must be <samp class="ph codeph">4</samp>. The number of active
                                       							dimensions in <samp class="ph codeph">dimA[]</samp> and <samp class="ph codeph">axes[]</samp>
                                       							arrays. Both arrays should be declared to contain at least
                                       								<samp class="ph codeph">CUDNN_SEQDATA_DIM_COUNT</samp> elements.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dimA[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Integer array specifying sequence data dimensions. Use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataAxis_t" shape="rect">cudnnSeqDataAxis_t</a></samp> enumerated type to index
                                       							all active <samp class="ph codeph">dimA[]</samp> elements.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">axes[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Array of <samp class="ph codeph"><a class="xref" href="index.html#cudnnSeqDataAxis_t" shape="rect">cudnnSeqDataAxis_t</a></samp> that defines
                                       							the layout of sequence data in memory. The first <samp class="ph codeph">nbDims</samp>
                                       							elements of <samp class="ph codeph">axes[]</samp> should be initialized with the
                                       							outermost dimension in <samp class="ph codeph">axes[0]</samp> and the innermost
                                       							dimension in <samp class="ph codeph">axes[nbDims-1]</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLengthArraySize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Number of elements in the sequence length array,
                                       								<samp class="ph codeph">seqLengthArray[]</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLengthArray[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> An integer array that defines all sequence lengths of the
                                       							container.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">paddingFill</samp></dt>
                                    <dd class="dd"><em class="ph i">Input.</em> Must be <samp class="ph codeph">NULL</samp>. Pointer to a value of
                                       								<samp class="ph codeph">dataType</samp> that is used to fill up output vectors
                                       							beyond the valid length of each sequence or <samp class="ph codeph">NULL</samp> to
                                       							ignore this setting.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetSeqDataDescriptor__section_imz_y4c_cjb"><a name="cudnnSetSeqDataDescriptor__section_imz_y4c_cjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">All input arguments were validated and the sequence data descriptor was
                                       							successfully updated.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid input argument was found. Some examples include:<a name="cudnnSetSeqDataDescriptor__ul_jnz_bpc_cjb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetSeqDataDescriptor__ul_jnz_bpc_cjb">
                                          <li class="li"><samp class="ph codeph">seqDataDesc=NULL</samp></li>
                                          <li class="li"><samp class="ph codeph">dateType</samp> was not a valid type of <samp class="ph codeph"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></samp></li>
                                          <li class="li"><samp class="ph codeph">nbDims</samp> was negative or zero
                                          </li>
                                          <li class="li"><samp class="ph codeph">seqLengthArraySize</samp> did not match the expected
                                             									length
                                          </li>
                                          <li class="li">some elements of <samp class="ph codeph">seqLengthArray[]</samp> were
                                             									invalid
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">An unsupported input argument was encountered. Some examples include:<a name="cudnnSetSeqDataDescriptor__ul_ycf_lpc_cjb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnSetSeqDataDescriptor__ul_ycf_lpc_cjb">
                                          <li class="li"><samp class="ph codeph">nbDims</samp> is not equal to <samp class="ph codeph">4</samp></li>
                                          <li class="li"><samp class="ph codeph">paddingFill</samp> is not <samp class="ph codeph">NULL</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">Failed to allocate storage for the sequence data descriptor object.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="cudnn-adv-train-so-library"><a name="cudnn-adv-train-so-library" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cudnn-adv-train-so-library" name="cudnn-adv-train-so-library" shape="rect">8.&nbsp;<kbd class="ph userinput">cudnn_adv_train.so</kbd> Library</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">This entity contains all the training counterparts of
                           <samp class="ph codeph">cudnn_adv_infer</samp>. The <samp class="ph codeph">cudnn_adv_train</samp> library
                           depends on <samp class="ph codeph">cudnn_ops_infer</samp>, <samp class="ph codeph">cudnn_ops_train</samp>, and
                           <samp class="ph codeph">cudnn_adv_infer</samp>.</span></div>
                     <p class="p"></p>
                  </div>
                  <div class="topic concept nested1" id="cudnn-adv-train-so-data-types"><a name="cudnn-adv-train-so-data-types" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-adv-train-so-data-types" name="cudnn-adv-train-so-data-types" shape="rect">8.1.&nbsp;Data Type References</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the data type references in the <samp class="ph codeph">cudnn_adv_train.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnn-adv-train-so-enum-types"><a name="cudnn-adv-train-so-enum-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-adv-train-so-enum-types" name="cudnn-adv-train-so-enum-types" shape="rect">8.1.1.&nbsp;Enumeration Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the enumeration types in the <samp class="ph codeph">cudnn_adv_train.so</samp>
                                 library.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnLossNormalizationMode_t"><a name="cudnnLossNormalizationMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLossNormalizationMode_t" name="cudnnLossNormalizationMode_t" shape="rect">8.1.1.1.&nbsp;<kbd class="ph userinput">cudnnLossNormalizationMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnLossNormalizationMode_t</samp> is an enumerated type that controls the
                                 input normalization mode for a loss function. This type can be used with <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptorEx" shape="rect">cudnnSetCTCLossDescriptorEx()</a></samp>. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnLossNormalizationMode_t__section_qjc_dfr_2jb"><a name="cudnnLossNormalizationMode_t__section_qjc_dfr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_NONE</samp></dt>
                                       <dd class="dd">The input <samp class="ph codeph">probs</samp> of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLoss" title="This function returns the CTC costs and gradients, given the probabilities and labels." shape="rect">cudnnCTCLoss()</a></samp> function is expected to be the
                                          normalized probability, and the output <samp class="ph codeph">gradients</samp> is the
                                          gradient of loss with respect to the unnormalized probability.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_SOFTMAX</samp></dt>
                                       <dd class="dd">The input <samp class="ph codeph">probs</samp> of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLoss" title="This function returns the CTC costs and gradients, given the probabilities and labels." shape="rect">cudnnCTCLoss()</a></samp> function is expected to be the
                                          unnormalized activation from the previous layer, and the output
                                          <samp class="ph codeph">gradients</samp> is the gradient with respect to the
                                          activation. Internally the probability is computed by softmax
                                          normalization.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnWgradMode_t"><a name="cudnnWgradMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnWgradMode_t" name="cudnnWgradMode_t" shape="rect">8.1.1.2.&nbsp;<kbd class="ph userinput">cudnnWgradMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnWgradMode_t</samp> is an enumerated type that selects how buffers
                                 		holding gradients of the loss function, computed with respect to trainable parameters, are
                                 		updated. Currently, this type is used by the <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardWeights" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its trainable parameters: projection weights and projection biases. If y=F(w) is a vector-valued function that represents the multi-head attention layer and it takes some vector of flatten weights or biases as an input (with all other parameters and inputs fixed), and outputs vector , then cudnnMultiHeadAttnBackwardWeights() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(w). The input is supplied via the dout argument." shape="rect">cudnnMultiHeadAttnBackwardWeights()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to all trainable parameters: weights and biases. If o = [y, hy, cy] = F(w) is a vector-valued function that represents the multi-layer RNN model and it takes some vector of &#34;flatten&#34; weights or biases as input (with all other data inputs constant), and outputs vector , then cudnnRNNBackwardWeights_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(w). The input is supplied via the dy, dhy, and dcy arguments in the cudnnRNNBackwardData_v8() function." shape="rect">cudnnRNNBackwardWeights_v8()</a></samp> functions
                                 		only. <span class="shortdesc"></span></div>
                              <div class="section" id="cudnnWgradMode_t__section_igg_3gr_2jb"><a name="cudnnWgradMode_t__section_igg_3gr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_WGRAD_MODE_ADD</samp></dt>
                                       <dd class="dd">A weight gradient component corresponding to a new batch of inputs is
                                          							added to previously evaluated weight gradients. Before using this mode,
                                          							the buffer holding weight gradients should be initialized to zero.
                                          							Alternatively, the first API call outputting to an uninitialized buffer
                                          							should use the <samp class="ph codeph">CUDNN_WGRAD_MODE_SET</samp> option.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_WGRAD_MODE_SET</samp></dt>
                                       <dd class="dd">A weight gradient component, corresponding to a new batch of inputs,
                                          							overwrites previously stored weight gradients in the output buffer.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnn-adv-train-so-api"><a name="cudnn-adv-train-so-api" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-adv-train-so-api" name="cudnn-adv-train-so-api" shape="rect">8.2.&nbsp;API Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the API functions in the <samp class="ph codeph">cudnn_adv_train.so</samp>
                              library.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnnAdvTrainVersionCheck"><a name="cudnnAdvTrainVersionCheck" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAdvTrainVersionCheck" name="cudnnAdvTrainVersionCheck" shape="rect">8.2.1.&nbsp;<kbd class="ph userinput">cudnnAdvTrainVersionCheck()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function checks whether the version of the <samp class="ph codeph">AdvTrain</samp> subset
                                 of the library is consistent with the other sub-libraries.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnAdvTrainVersionCheck(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)</pre><div class="section" id="cudnnAdvTrainVersionCheck__section_zpy_xzc_z3b"><a name="cudnnAdvTrainVersionCheck__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The version is consistent with other sub-libraries.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_VERSION_MISMATCH</samp></dt>
                                    <dd class="dd">The version of <samp class="ph codeph">AdvTrain</samp> is not consistent with other
                                       sub-libraries. Users should check the installation and make sure all
                                       sub-component versions are consistent.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCreateCTCLossDescriptor"><a name="cudnnCreateCTCLossDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateCTCLossDescriptor" name="cudnnCreateCTCLossDescriptor" shape="rect">8.2.2.&nbsp;<kbd class="ph userinput">cudnnCreateCTCLossDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function creates a CTC loss function descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateCTCLossDescriptor(
    cudnnCTCLossDescriptor_t* ctcLossDesc)</pre><div class="section" id="cudnnCreateCTCLossDescriptor__section_vxq_2xb_z3b"><a name="cudnnCreateCTCLossDescriptor__section_vxq_2xb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. CTC loss descriptor to be set. For more information,
                                       refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCreateCTCLossDescriptor__section_zlb_fxb_z3b"><a name="cudnnCreateCTCLossDescriptor__section_zlb_fxb_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">CTC loss descriptor passed to the function is invalid.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">Memory allocation for this CTC loss descriptor failed.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCTCLoss"><a name="cudnnCTCLoss" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCTCLoss" name="cudnnCTCLoss" shape="rect">8.2.3.&nbsp;<kbd class="ph userinput">cudnnCTCLoss()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the CTC costs and gradients, given the probabilities and
                                 labels. </span></div><pre xml:space="preserve">cudnnStatus_t cudnnCTCLoss(
    cudnnHandle_t                        handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      probsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *probs,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          hostLabels[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          hostLabelLengths[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          hostInputLengths[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *costs,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      gradientsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *gradients,
    cudnnCTCLossAlgo_t                   algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnCTCLossDescriptor_t     ctcLossDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *workspace,
    size_t                              *workSpaceSizeInBytes)
</pre><div class="p">
                              <div class="note note"><span class="notetitle">Note:</span> This function can have an inconsistent interface depending on the <samp class="ph codeph"><a class="xref" href="index.html#cudnnLossNormalizationMode_t" shape="rect">cudnnLossNormalizationMode_t</a></samp> chosen (bound to the
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a></samp> with
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptorEx" shape="rect">cudnnSetCTCLossDescriptorEx()</a></samp>). For the
                                 <samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_NONE</samp>, this function has an
                                 inconsistent interface, for example, the probs input is probability normalized by
                                 softmax, but the gradients output is with respect to the unnormalized activation.
                                 However, for <samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_SOFTMAX</samp>, the function has a
                                 consistent interface; all values are normalized by softmax.
                              </div>
                           </div>
                           <div class="section" id="cudnnCTCLoss__section_kz3_xmc_z3b"><a name="cudnnCTCLoss__section_kz3_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">probsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized probabilities tensor
                                       descriptor. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">probs</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized probabilities tensor.
                                       These input probabilities are normalized by softmax.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hostLabels</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized labels list, in CPU
                                       memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hostLabelLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized lengths list in CPU
                                       memory, to walk the above labels list.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hostInputLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized list of the lengths of
                                       the timing steps in each batch, in CPU memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">costs</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the computed costs of CTC.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradientsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized gradient tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradients</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the computed gradients of CTC. These computed
                                       gradient outputs are with respect to the unnormalized activation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies the chosen CTC loss algorithm.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossAlgo_t" shape="rect">cudnnCTCLossAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized CTC loss descriptor.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to GPU memory of a workspace needed to be able to
                                       execute the specified algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Amount of GPU memory needed as workspace to be able to
                                       execute the CTC loss computation with the specified
                                       <samp class="ph codeph">algo</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCTCLoss__section_xs5_xmc_z3b"><a name="cudnnCTCLoss__section_xs5_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnCTCLoss__ul_zpd_lg3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnCTCLoss__ul_zpd_lg3_s1b">
                                          <li class="li">The dimensions of <samp class="ph codeph">probsDesc</samp> do not match the
                                             dimensions of <samp class="ph codeph">gradientsDesc</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">inputLengths</samp> do not agree with the first
                                             dimension of <samp class="ph codeph">probsDesc</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">workSpaceSizeInBytes</samp> is not
                                             sufficient.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">labelLengths</samp> is greater than 255.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A compute or data type other than <samp class="ph codeph">FLOAT</samp> was chosen, or
                                       an unknown algorithm type was chosen.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnCTCLoss_v8"><a name="cudnnCTCLoss_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCTCLoss_v8" name="cudnnCTCLoss_v8" shape="rect">8.2.4.&nbsp;<kbd class="ph userinput">cudnnCTCLoss_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the CTC costs and gradients, given the probabilities and labels.
                              Many CTC API functions were updated in v8 with the <samp class="ph codeph">_v8</samp> suffix to support
                              CUDA graphs. Label and input data is now passed in GPU memory, and <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a></samp> should be set using <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptor_v8" title="Many CTC API functions are updated in cuDNN version 8.0.0 to support CUDA graphs. In order to do so, a new parameter is needed, maxLabelLength. Now that label and input data are assumed to be in GPU memory, this information is not otherwise readily available." shape="rect">cudnnSetCTCLossDescriptor_v8()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCTCLoss_v8(
    cudnnHandle_t                        handle,
    cudnnCTCLossAlgo_t                   algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnCTCLossDescriptor_t     ctcLossDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      probsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *probs,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          labels[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          labelLengths[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          inputLengths[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *costs,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      gradientsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *gradients,
    size_t                              *workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *workspace)</pre><div class="p">
                              <div class="note note"><span class="notetitle">Note:</span>  This function can have an inconsistent interface depending on the <samp class="ph codeph"><a class="xref" href="index.html#cudnnLossNormalizationMode_t" shape="rect">cudnnLossNormalizationMode_t</a></samp> chosen (bound to the
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a></samp> with
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptorEx" shape="rect">cudnnSetCTCLossDescriptorEx()</a></samp>). For the
                                 <samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_NONE</samp>, this function has an
                                 inconsistent interface, for example, the probs input is probability normalized by
                                 softmax, but the gradients output is with respect to the unnormalized activation.
                                 However, for <samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_SOFTMAX</samp>, the function has a
                                 consistent interface; all values are normalized by softmax.
                              </div>
                           </div>
                           <div class="section" id="cudnnCTCLoss_v8__section_kz3_xmc_z3b"><a name="cudnnCTCLoss_v8__section_kz3_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies the chosen CTC loss algorithm.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossAlgo_t" shape="rect">cudnnCTCLossAlgo_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized CTC loss descriptor.
                                       To use this <samp class="ph codeph">_v8</samp> function, this descriptor must be set
                                       using <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptor_v8" title="Many CTC API functions are updated in cuDNN version 8.0.0 to support CUDA graphs. In order to do so, a new parameter is needed, maxLabelLength. Now that label and input data are assumed to be in GPU memory, this information is not otherwise readily available." shape="rect">cudnnSetCTCLossDescriptor_v8()</a></samp>.
                                       For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">probsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized probabilities tensor
                                       descriptor. For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">probs</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized probabilities tensor.
                                       These input probabilities are normalized by softmax.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">labels</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized labels list, in GPU
                                       memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">labelLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized lengths list in GPU
                                       memory, to walk the above labels list.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized list of the lengths of
                                       the timing steps in each batch, in GPU memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">costs</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the computed costs of CTC.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradientsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized gradient tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradients</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the computed gradients of CTC. These computed
                                       gradient outputs are with respect to the unnormalized activation.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to GPU memory of a workspace needed to be able to
                                       execute the specified algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Amount of GPU memory needed as a workspace to be able to
                                       execute the CTC loss computation with the specified
                                       <samp class="ph codeph">algo</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnCTCLoss_v8__section_xs5_xmc_z3b"><a name="cudnnCTCLoss_v8__section_xs5_xmc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnCTCLoss_v8__ul_zpd_lg3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnCTCLoss_v8__ul_zpd_lg3_s1b">
                                          <li class="li">The dimensions of <samp class="ph codeph">probsDesc</samp> do not match the
                                             dimensions of <samp class="ph codeph">gradientsDesc</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">inputLengths</samp> do not agree with the first
                                             dimension of <samp class="ph codeph">probsDesc</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">workSpaceSizeInBytes</samp> is not
                                             sufficient.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">labelLengths</samp> is greater than 256.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A compute or data type other than <samp class="ph codeph">FLOAT</samp> was chosen, or
                                       an unknown algorithm type was chosen.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnDestroyCTCLossDescriptor"><a name="cudnnDestroyCTCLossDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyCTCLossDescriptor" name="cudnnDestroyCTCLossDescriptor" shape="rect">8.2.5.&nbsp;<kbd class="ph userinput">cudnnDestroyCTCLossDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function destroys a CTC loss function descriptor object.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyCTCLossDescriptor(
    cudnnCTCLossDescriptor_t 	ctcLossDesc)</pre><div class="section" id="cudnnDestroyCTCLossDescriptor__section_iqd_w1d_z3b"><a name="cudnnDestroyCTCLossDescriptor__section_iqd_w1d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. CTC loss function descriptor to be destroyed.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnDestroyCTCLossDescriptor__section_odt_w1d_z3b"><a name="cudnnDestroyCTCLossDescriptor__section_odt_w1d_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindRNNBackwardDataAlgorithmEx"><a name="cudnnFindRNNBackwardDataAlgorithmEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNBackwardDataAlgorithmEx" name="cudnnFindRNNBackwardDataAlgorithmEx" shape="rect">8.2.6.&nbsp;<kbd class="ph userinput">cudnnFindRNNBackwardDataAlgorithmEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function attempts all available cuDNN algorithms for <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp>, using user-allocated GPU memory. It
                              outputs the parameters that influence the performance of the algorithm to a
                              user-allocated array of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter
                              metrics are written in sorted fashion where the first element has the lowest compute
                              time.
                           </p><pre xml:space="preserve">
cudnnStatus_t cudnnFindRNNBackwardDataAlgorithmEx(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t       rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dhyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *dhy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dcyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *dcy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t    wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dhxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dhx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dcxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dcx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                      findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              *returnedAlgoCount,
    cudnnAlgorithmPerformance_t      *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *workspace,
    size_t                           workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *reserveSpace,
    size_t                           reserveSpaceSizeInBytes)</pre><div class="section" id="cudnnFindRNNBackwardDataAlgorithmEx__section_xmn_jwh_z3b"><a name="cudnnFindRNNBackwardDataAlgorithmEx__section_xmn_jwh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the
                                       RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). The second dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_xgb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_xgb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">dyDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the gradient at the output from each recurrent iteration (one
                                          descriptor per iteration). The second dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_zgb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_zgb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          second dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">dxDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradients at the final hidden state of the RNN. The first dimension
                                          of the tensor depends on the <samp class="ph codeph">direction</samp> argument
                                          used to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_bhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_bhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dhyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradients at the final hidden state of the network will
                                       be initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradients at the final cell state of the RNN. The first dimension of
                                          the tensor depends on the <samp class="ph codeph">direction</samp> argument used
                                          to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_chb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_chb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dcyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradients at the final cell state of the network will be
                                       initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_ehb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_ehb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_fhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_fhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                       gradient at the input of each recurrent iteration (one descriptor per
                                       iteration). The first dimension (batch size) of the tensors may decrease
                                       from element <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may
                                       not increase. Each tensor descriptor must have the same second dimension
                                       (vector length).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">dxDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradient at the initial hidden state of the RNN. The first dimension
                                          of the tensor depends on the <samp class="ph codeph">direction</samp> argument
                                          used to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_hhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_hhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dhxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradient at the hidden input of the network will not be
                                       set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradient at the initial cell state of the RNN. The first dimension
                                          of the tensor depends on the <samp class="ph codeph">direction</samp> argument
                                          used to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_jhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_jhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dcxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradient at the cell input of the network will not be
                                       set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">findIntensity</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>.This input was previously unused in versions prior to cuDNN
                                       7.2.0. It is used in cuDNN 7.2.0 and later versions to control the
                                       overall runtime of the RNN find algorithms, by selecting the percentage
                                       of a large Cartesian product space to be searched. <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_gyf_fh1_l2b">
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range (0,1.]
                                             will set a percentage of the entire RNN search space to search.
                                             When <samp class="ph codeph">findIntensity</samp> is set to 1.0, a full search
                                             is performed over all RNN parameters. 
                                          </li>
                                          <li class="li liexpand">When <samp class="ph codeph">findIntensity</samp> is set to
                                             <samp class="ph codeph">0.0f</samp>, a quick, minimal search is performed.
                                             This setting has the best runtime. However, in this case the
                                             parameters returned by this function will not correspond to the
                                             best performance of the algorithm; a longer search might
                                             discover better parameters. This option will execute up to three
                                             instances of the configured RNN problem. Runtime will vary
                                             proportionally to RNN problem size, as it will in the other
                                             cases, hence no guarantee of an explicit time bound can be
                                             given. 
                                          </li>
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range [-1.,0)
                                             sets a percentage of a reduced Cartesian product space to be
                                             searched. This reduced search space has been heuristically
                                             selected to have good performance. The setting of -1.0
                                             represents a full search over this reduced search space. 
                                          </li>
                                          <li class="li liexpand">Values outside the range [-1,1] are truncated to the range
                                             [-1,1], and then interpreted as per the above. 
                                          </li>
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2 and
                                             later versions is equivalent to the behavior of this function in
                                             versions prior to cuDNN 7.2.0. 
                                          </li>
                                          <li class="li liexpand">This function times the single RNN executions over large
                                             parameter spaces - one execution per parameter combination. The
                                             times returned by this function are latencies. 
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve
                                       space for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindRNNBackwardDataAlgorithmEx__section_b41_kwh_z3b"><a name="cudnnFindRNNBackwardDataAlgorithmEx__section_b41_kwh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_khb_1g3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_khb_1g3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">dhxDesc</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">dcxDesc</samp>,
                                             <samp class="ph codeph">dhyDesc</samp>, or <samp class="ph codeph">dcyDesc</samp> or one
                                             of the descriptors in <samp class="ph codeph">yDesc, dxdesc, dydesc</samp> is
                                             invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">dxDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                             <samp class="ph codeph">dhxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">cxDesc</samp>,
                                             <samp class="ph codeph">dcxDesc</samp>, <samp class="ph codeph">dhyDesc</samp>, or
                                             <samp class="ph codeph">dcyDesc</samp> has incorrect strides or
                                             dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindRNNBackwardWeightsAlgorithmEx"><a name="cudnnFindRNNBackwardWeightsAlgorithmEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNBackwardWeightsAlgorithmEx" name="cudnnFindRNNBackwardWeightsAlgorithmEx" shape="rect">8.2.7.&nbsp;<kbd class="ph userinput">cudnnFindRNNBackwardWeightsAlgorithmEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function attempts all available cuDNN algorithms for <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp>, using user-allocated GPU memory. It
                              outputs the parameters that influence the performance of the algorithm to a
                              user-allocated array of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter
                              metrics are written in sorted fashion where the first element has the lowest compute
                              time. 
                           </p><pre xml:space="preserve">
cudnnStatus_t cudnnFindRNNBackwardWeightsAlgorithmEx(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t       rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                      findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              *returnedAlgoCount,
    cudnnAlgorithmPerformance_t      *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *workspace,
    size_t                           workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t    dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *reserveSpace,
    size_t                           reserveSpaceSizeInBytes)</pre><div class="section" id="cudnnFindRNNBackwardWeightsAlgorithmEx__section_mv3_mzh_z3b"><a name="cudnnFindRNNBackwardWeightsAlgorithmEx__section_mv3_mzh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the RNN. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                       input to each recurrent iteration (one descriptor per iteration). The
                                       first dimension (batch size) of the tensors may decrease from element
                                       <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                       increase. Each tensor descriptor must have the same second dimension
                                       (vector length).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_qjf_2g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_qjf_2g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). The second dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_ujf_2g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_ujf_2g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">dyDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">findIntensity</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>.This input was previously unused in versions prior to cuDNN
                                       7.2.0. It is used in cuDNN 7.2.0 and later versions to control the
                                       overall runtime of the RNN find algorithms, by selecting the percentage
                                       of a large Cartesian product space to be searched. <a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_gyf_fh1_l2b">
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range (0,1.]
                                             will set a percentage of the entire RNN search space to search.
                                             When <samp class="ph codeph">findIntensity</samp> is set to 1.0, a full search
                                             is performed over all RNN parameters. 
                                          </li>
                                          <li class="li liexpand">When <samp class="ph codeph">findIntensity</samp> is set to 0.0f, a quick,
                                             minimal search is performed. This setting has the best runtime.
                                             However, in this case the parameters returned by this function
                                             will not correspond to the best performance of the algorithm; a
                                             longer search might discover better parameters. This option will
                                             execute up to three instances of the configured RNN problem.
                                             Runtime will vary proportionally to RNN problem size, as it will
                                             in the other cases, hence no guarantee of an explicit time bound
                                             can be given. 
                                          </li>
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range [-1.,0)
                                             sets a percentage of a reduced Cartesian product space to be
                                             searched. This reduced search space has been heuristically
                                             selected to have good performance. The setting of -1.0
                                             represents a full search over this reduced search space. 
                                          </li>
                                          <li class="li liexpand">Values outside the range [-1,1] are truncated to the range
                                             [-1,1], and then interpreted as per the above. 
                                          </li>
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2 and
                                             later versions is equivalent to the behavior of this function in
                                             versions prior to cuDNN 7.2.0. 
                                          </li>
                                          <li class="li liexpand">This function times the single RNN executions over large
                                             parameter spaces - one execution per parameter combination. The
                                             times returned by this function are latencies. 
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the gradients of the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dw</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       filter descriptor <samp class="ph codeph">dwDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a reserve space
                                       for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindRNNBackwardWeightsAlgorithmEx__section_c15_mzh_z3b"><a name="cudnnFindRNNBackwardWeightsAlgorithmEx__section_c15_mzh_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_yjf_2g3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_yjf_2g3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">dwDesc</samp> or one of the descriptors in
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> is
                                             invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">yDesc</samp>, or
                                             <samp class="ph codeph">dwDesc</samp> have incorrect strides or
                                             dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnFindRNNForwardTrainingAlgorithmEx"><a name="cudnnFindRNNForwardTrainingAlgorithmEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNForwardTrainingAlgorithmEx" name="cudnnFindRNNForwardTrainingAlgorithmEx" shape="rect">8.2.8.&nbsp;<kbd class="ph userinput">cudnnFindRNNForwardTrainingAlgorithmEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p">This function attempts all available cuDNN algorithms for <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp>, using user-allocated GPU memory. It
                              outputs the parameters that influence the performance of the algorithm to a
                              user-allocated array of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter
                              metrics are written in sorted fashion where the first element has the lowest compute
                              time. 
                           </p><pre xml:space="preserve">cudnnStatus_t cudnnFindRNNForwardTrainingAlgorithmEx(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                    findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *returnedAlgoCount,
    cudnnAlgorithmPerformance_t    *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><div class="section" id="cudnnFindRNNForwardTrainingAlgorithmEx__section_dxf_d53_z3b"><a name="cudnnFindRNNForwardTrainingAlgorithmEx__section_dxf_d53_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                       input to each recurrent iteration (one descriptor per iteration). The
                                       first dimension (batch size) of the tensors may decrease from element
                                       <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                       increase. Each tensor descriptor must have the same second dimension
                                       (vector length).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the RNN. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_hqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_hqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_kqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_kqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). The second dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_mqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_mqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">xDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_oqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_oqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final hidden state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_qqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_qqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final cell state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">findIntensity</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>.This input was previously unused in versions prior to cuDNN
                                       7.2.0. It is used in cuDNN 7.2.0 and later versions to control the
                                       overall runtime of the RNN find algorithms, by selecting the percentage
                                       of a large Cartesian product space to be searched. <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_gyf_fh1_l2b">
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range (0,1.]
                                             will set a percentage of the entire RNN search space to search.
                                             When <samp class="ph codeph">findIntensity</samp> is set to 1.0, a full search
                                             is performed over all RNN parameters. 
                                          </li>
                                          <li class="li liexpand">When <samp class="ph codeph">findIntensity</samp> is set to 0.0f, a quick,
                                             minimal search is performed. This setting has the best runtime.
                                             However, in this case the parameters returned by this function
                                             will not correspond to the best performance of the algorithm; a
                                             longer search might discover better parameters. This option will
                                             execute up to three instances of the configured RNN problem.
                                             Runtime will vary proportionally to RNN problem size, as it will
                                             in the other cases, hence no guarantee of an explicit time bound
                                             can be given. 
                                          </li>
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> within the range [-1.,0)
                                             sets a percentage of a reduced Cartesian product space to be
                                             searched. This reduced search space has been heuristically
                                             selected to have good performance. The setting of -1.0
                                             represents a full search over this reduced search space. 
                                          </li>
                                          <li class="li liexpand">Values outside the range [-1,1] are truncated to the range
                                             [-1,1], and then interpreted as per the above. 
                                          </li>
                                          <li class="li liexpand">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2 and
                                             later versions is equivalent to the behavior of this function in
                                             versions prior to cuDNN 7.2.0. 
                                          </li>
                                          <li class="li liexpand">This function times the single RNN executions over large
                                             parameter spaces - one execution per parameter combination. The
                                             times returned by this function are latencies. 
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum number of elements to be stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">returnedAlgoCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The number of output elements stored in
                                       <samp class="ph codeph">perfResults</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">perfResults</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. A user-allocated array to store performance metrics
                                       sorted ascending by compute time.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve
                                       space for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnFindRNNForwardTrainingAlgorithmEx__section_yt5_d53_z3b"><a name="cudnnFindRNNForwardTrainingAlgorithmEx__section_yt5_d53_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_rqb_wf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_rqb_wf3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp>, or <samp class="ph codeph">cyDesc</samp> or one
                                             of the descriptors in <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp> is invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">cxDesc</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp>, or <samp class="ph codeph">cyDesc</samp> have
                                             incorrect strides or dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetCTCLossDescriptor"><a name="cudnnGetCTCLossDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCTCLossDescriptor" name="cudnnGetCTCLossDescriptor" shape="rect">8.2.9.&nbsp;<kbd class="ph userinput">cudnnGetCTCLossDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the configuration of the passed CTC loss function
                                 descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCTCLossDescriptor(
    cudnnCTCLossDescriptor_t         ctcLossDesc,
    cudnnDataType_t*                 compType)
</pre><div class="section" id="cudnnGetCTCLossDescriptor__section_bhr_wf2_1jb"><a name="cudnnGetCTCLossDescriptor__section_bhr_wf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. CTC loss function descriptor passed, from which to
                                       retrieve the configuration.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">compType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Compute type associated with this CTC loss function
                                       descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetCTCLossDescriptor__section_mlc_xf2_1jb"><a name="cudnnGetCTCLossDescriptor__section_mlc_xf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Input <samp class="ph codeph">ctcLossDesc</samp> descriptor passed is invalid.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetCTCLossDescriptorEx"><a name="cudnnGetCTCLossDescriptorEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCTCLossDescriptorEx" name="cudnnGetCTCLossDescriptorEx" shape="rect">8.2.10.&nbsp;<kbd class="ph userinput">cudnnGetCTCLossDescriptorEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the configuration of the passed CTC loss function
                                 descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCTCLossDescriptorEx(
    cudnnCTCLossDescriptor_t         ctcLossDesc,
    cudnnDataType_t                 *compType,
    cudnnLossNormalizationMode_t    *normMode,
    cudnnNanPropagation_t           *gradMode)
</pre><div class="section" id="cudnnGetCTCLossDescriptorEx__section_bhr_wf2_1jb"><a name="cudnnGetCTCLossDescriptorEx__section_bhr_wf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. CTC loss function descriptor passed, from which to
                                       retrieve the configuration.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">compType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Compute type associated with this CTC loss function
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Input normalization type for this CTC loss function
                                       descriptor. For more information, see <samp class="ph codeph"><a class="xref" href="index.html#cudnnLossNormalizationMode_t" shape="rect">cudnnLossNormalizationMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. NaN propagation type for this CTC loss function
                                       descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetCTCLossDescriptorEx__section_mlc_xf2_1jb"><a name="cudnnGetCTCLossDescriptorEx__section_mlc_xf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Input <samp class="ph codeph">ctcLossDesc</samp> descriptor passed is invalid.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetCTCLossDescriptor_v8"><a name="cudnnGetCTCLossDescriptor_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCTCLossDescriptor_v8" name="cudnnGetCTCLossDescriptor_v8" shape="rect">8.2.11.&nbsp;<kbd class="ph userinput">cudnnGetCTCLossDescriptor_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function returns the configuration of the passed CTC loss function
                                 descriptor.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCTCLossDescriptor_v8(
    cudnnCTCLossDescriptor_t         ctcLossDesc,
    cudnnDataType_t                 *compType,
    cudnnLossNormalizationMode_t    *normMode,
    cudnnNanPropagation_t           *gradMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             *maxLabelLength)
</pre><div class="section" id="cudnnGetCTCLossDescriptor_v8__section_bhr_wf2_1jb"><a name="cudnnGetCTCLossDescriptor_v8__section_bhr_wf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. CTC loss function descriptor passed, from which to
                                       retrieve the configuration.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">compType</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Compute type associated with this CTC loss function
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Input normalization type for this CTC loss function
                                       descriptor. For more information, see <samp class="ph codeph"><a class="xref" href="index.html#cudnnLossNormalizationMode_t" shape="rect">cudnnLossNormalizationMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. NaN propagation type for this CTC loss function
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxLabelLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. The max label length for this CTC loss function
                                       descriptor.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetCTCLossDescriptor_v8__section_mlc_xf2_1jb"><a name="cudnnGetCTCLossDescriptor_v8__section_mlc_xf2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Input <samp class="ph codeph">ctcLossDesc</samp> descriptor passed is invalid.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetCTCLossWorkspaceSize"><a name="cudnnGetCTCLossWorkspaceSize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCTCLossWorkspaceSize" name="cudnnGetCTCLossWorkspaceSize" shape="rect">8.2.12.&nbsp;<kbd class="ph userinput">cudnnGetCTCLossWorkspaceSize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the amount of GPU memory workspace the user needs to allocate to
                              be able to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLoss" title="This function returns the CTC costs and gradients, given the probabilities and labels." shape="rect">cudnnCTCLoss()</a></samp> with the specified algorithm.
                              The workspace allocated will then be passed to the routine <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLoss" title="This function returns the CTC costs and gradients, given the probabilities and labels." shape="rect">cudnnCTCLoss()</a></samp>.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCTCLossWorkspaceSize(
    cudnnHandle_t                        handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      probsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      gradientsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *labels,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *labelLengths,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *inputLengths,
    cudnnCTCLossAlgo_t                   algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnCTCLossDescriptor_t     ctcLossDesc,
    size_t                              *sizeInBytes)</pre><div class="section" id="cudnnGetCTCLossWorkspaceSize__section_yw3_1g2_1jb"><a name="cudnnGetCTCLossWorkspaceSize__section_yw3_1g2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">probsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized probabilities tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradientsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized gradient tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">labels</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized labels list.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">labelLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized lengths list, to walk
                                       the above labels list.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">inputLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to a previously initialized list of the lengths of
                                       the timing steps in each batch.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies the chosen CTC loss
                                       algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized CTC loss
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to
                                       execute the CTC loss computation with the specified
                                       <samp class="ph codeph">algo</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetCTCLossWorkspaceSize__section_zfs_1g2_1jb"><a name="cudnnGetCTCLossWorkspaceSize__section_zfs_1g2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetCTCLossWorkspaceSize__ul_jkx_hg3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetCTCLossWorkspaceSize__ul_jkx_hg3_s1b">
                                          <li class="li">The dimensions of <samp class="ph codeph">probsDesc</samp> do not match the
                                             dimensions of <samp class="ph codeph">gradientsDesc</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">inputLengths</samp> do not agree with the first
                                             dimension of <samp class="ph codeph">probsDesc</samp>.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">workSpaceSizeInBytes</samp> is not
                                             sufficient.
                                          </li>
                                          <li class="li">The <samp class="ph codeph">labelLengths</samp> is greater than 256.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A compute or data type other than <samp class="ph codeph">FLOAT</samp> was chosen, or
                                       an unknown algorithm type was chosen.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetCTCLossWorkspaceSize_v8"><a name="cudnnGetCTCLossWorkspaceSize_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCTCLossWorkspaceSize_v8" name="cudnnGetCTCLossWorkspaceSize_v8" shape="rect">8.2.13.&nbsp;<kbd class="ph userinput">cudnnGetCTCLossWorkspaceSize_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function returns the amount of GPU memory workspace the user needs to allocate to
                              be able to call <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLoss_v8" shape="rect">cudnnCTCLoss_v8()</a></samp> with the specified
                              algorithm. The workspace allocated will then be passed to the routine <samp class="ph codeph"><a class="xref" href="index.html#cudnnCTCLoss_v8" shape="rect">cudnnCTCLoss_v8()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCTCLossWorkspaceSize_v8(
    cudnnHandle_t                        handle,
    cudnnCTCLossAlgo_t                   algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnCTCLossDescriptor_t     ctcLossDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      probsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      gradientsDesc,
    size_t                              *sizeInBytes
</pre><div class="section" id="cudnnGetCTCLossWorkspaceSize_v8__section_yw3_1g2_1jb"><a name="cudnnGetCTCLossWorkspaceSize_v8__section_yw3_1g2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">algo</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerant that specifies the chosen CTC loss
                                       algorithm.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized CTC loss
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">probsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to the previously initialized probabilities tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradientsDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized gradient tensor
                                       descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to
                                       execute the CTC loss computation with the specified
                                       <samp class="ph codeph">algo</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnGetCTCLossWorkspaceSize_v8__section_zfs_1g2_1jb"><a name="cudnnGetCTCLossWorkspaceSize_v8__section_zfs_1g2_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The query was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnGetCTCLossWorkspaceSize_v8__ul_jkx_hg3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetCTCLossWorkspaceSize_v8__ul_jkx_hg3_s1b">
                                          <li class="li">The dimensions of <samp class="ph codeph">probsDesc</samp> do not match the
                                             dimensions of <samp class="ph codeph">gradientsDesc</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A compute or data type other than <samp class="ph codeph">FLOAT</samp> was chosen, or
                                       an unknown algorithm type was chosen.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNBackwardDataAlgorithmMaxCount"><a name="cudnnGetRNNBackwardDataAlgorithmMaxCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNBackwardDataAlgorithmMaxCount" name="cudnnGetRNNBackwardDataAlgorithmMaxCount" shape="rect">8.2.14.&nbsp;<kbd class="ph userinput">cudnnGetRNNBackwardDataAlgorithmMaxCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnGetRNNForwardTrainingAlgorithmMaxCount"><a name="cudnnGetRNNForwardTrainingAlgorithmMaxCount" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNForwardTrainingAlgorithmMaxCount" name="cudnnGetRNNForwardTrainingAlgorithmMaxCount" shape="rect">8.2.15.&nbsp;<kbd class="ph userinput">cudnnGetRNNForwardTrainingAlgorithmMaxCount()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function has been deprecated in cuDNN 8.0.</span></div>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnMultiHeadAttnBackwardData"><a name="cudnnMultiHeadAttnBackwardData" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnBackwardData" name="cudnnMultiHeadAttnBackwardData" shape="rect">8.2.16.&nbsp;<kbd class="ph userinput">cudnnMultiHeadAttnBackwardData()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes exact, first-order derivatives of the multi-head attention
                                 			block with respect to its inputs: <strong class="ph b">Q, K, V</strong>. If <strong class="ph b">y</strong>=<em class="ph i">F</em>(<strong class="ph b">x</strong>) is a
                                 			vector-valued function that represents the multi-head attention layer and it takes some
                                 			vector 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>w</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>n</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 			 as an input (with all other parameters and inputs constant), and outputs
                                 			vector 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>y</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>m</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 			, then <samp class="ph codeph">cudnnMultiHeadAttnBackwardData()</samp> computes the
                                 			result of 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msup>
                                          <mfenced open="(" close=")">
                                             <mrow>
                                                <msub>
                                                   <mrow>
                                                      <mo rspace="1px"></mo>
                                                      <mi>y</mi>
                                                   </mrow>
                                                   <mi>i</mi>
                                                </msub>
                                                <mo>/</mo>
                                                <mo rspace="1px"></mo>
                                                <msub>
                                                   <mi>x</mi>
                                                   <mi>j</mi>
                                                </msub>
                                             </mrow>
                                          </mfenced>
                                          <mi>T</mi>
                                       </msup>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 where 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 is the 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mn>1</mn>
                                    </mrow>
                                 </math>
                                 			 gradient of the loss function with respect to multi-head attention
                                 			outputs. The 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 gradient is back propagated through prior layers of the deep learning
                                 			model. 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>y</mi>
                                          <mi>i</mi>
                                       </msub>
                                       <mo>/</mo>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>x</mi>
                                          <mi>j</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 is the 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">n</mi>
                                    </mrow>
                                 </math>
                                 			 Jacobian matrix of <em class="ph i">F</em>(<strong class="ph b">x</strong>). The input is supplied via the
                                 				<samp class="ph codeph">dout </samp>argument and gradient results for <strong class="ph b">Q, K, V</strong> are written
                                 			to the <samp class="ph codeph">dqueries</samp>, <samp class="ph codeph">dkeys</samp>, and <samp class="ph codeph">dvalues</samp>
                                 			buffers.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnMultiHeadAttnBackwardData(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> loWinIdx[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> hiWinIdx[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> devSeqLengthsDQDO[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> devSeqLengthsDKDV[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t doDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dout,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t dqDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dqueries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *queries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t dkDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dkeys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *keys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t dvDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dvalues,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *values,
	size_t weightSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *weights,
	size_t workSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
	size_t reserveSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);
</pre><p class="p">The <samp class="ph codeph">cudnnMultiHeadAttnBackwardData()</samp> function does not output partial
                              			derivatives for residual connections because this result is equal to 
                              				
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi></mi>
                                       <mi>out</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              			. If the multi-head attention model enables residual connections sourced
                              			directly from <strong class="ph b">Q</strong>, then the <samp class="ph codeph">dout</samp> tensor needs to be added to
                              				<samp class="ph codeph">dqueries</samp> to obtain the correct result of the latter. This operation
                              			is demonstrated in the cuDNN <samp class="ph codeph">multiHeadAttention</samp> sample code.
                           </p>
                           <div class="p">The <samp class="ph codeph">cudnnMultiHeadAttnBackwardData()</samp> function must be invoked after
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp>. The
                              				<samp class="ph codeph">loWinIdx[]</samp>, <samp class="ph codeph">hiWinIdx[]</samp>, <samp class="ph codeph">queries</samp>,
                              				<samp class="ph codeph">keys</samp>, <samp class="ph codeph">values</samp>, <samp class="ph codeph">weights</samp>, and
                              				<samp class="ph codeph">reserveSpace</samp> arguments should be the same as in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp> call.
                              				<samp class="ph codeph">devSeqLengthsDQDO[]</samp> and <samp class="ph codeph">devSeqLengthsDKDV[]</samp> device
                              			arrays should contain the same start and end attention window indices as
                              				<samp class="ph codeph">devSeqLengthsQO[]</samp> and <samp class="ph codeph">devSeqLengthsKV[]</samp> arrays in
                              			the forward function invocation.
                              <div class="note note"><span class="notetitle">Note:</span><samp class="ph codeph">cudnnMultiHeadAttnBackwardData()</samp>
                                 				does not verify that sequence lengths stored in <samp class="ph codeph">devSeqLengthsDQDO[]</samp>
                                 				and <samp class="ph codeph">devSeqLengthsDKDV[]</samp> contain the same settings as
                                 					<samp class="ph codeph">seqLengthArray[]</samp> in the corresponding sequence data
                                 				descriptor.
                              </div>
                           </div>
                           <div class="section" id="cudnnMultiHeadAttnBackwardData__section_acr_cfl_1jb"><a name="cudnnMultiHeadAttnBackwardData__section_acr_cfl_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized attention descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">loWinIdx[]</samp>, <samp class="ph codeph">hiWinIdx[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Two host integer arrays specifying the start and end
                                       							indices of the attention window for each <strong class="ph b">Q</strong> time-step. The start
                                       							index in <strong class="ph b">K, V</strong> sets is inclusive, and the end index is
                                       							exclusive.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">devSeqLengthsDQDO[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Device array containing a copy of the sequence length
                                       							array from the <samp class="ph codeph">dqDesc</samp> or <samp class="ph codeph">doDesc</samp>
                                       							sequence data descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">devSeqLengthsDKDV[]</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Device array containing a copy of the sequence length
                                       							array from the <samp class="ph codeph">dkDesc</samp> or <samp class="ph codeph">dvDesc</samp>
                                       							sequence data descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">doDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi></mi>
                                                <mi>out</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                       							 gradients (vectors of partial derivatives of the loss
                                       							function with respect to the multi-head attention outputs).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dout</samp></dt>
                                    <dd class="dd">Pointer to 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi></mi>
                                                <mi>out</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                       							 gradient data in the device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dqDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for <samp class="ph codeph">queries</samp> and
                                       								<samp class="ph codeph">dqueries</samp> sequence data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dqueries</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Device pointer to gradients of the loss function computed
                                       							with respect to <samp class="ph codeph">queries</samp> vectors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">queries</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">queries</samp> data in the device memory. This is the
                                       							same input as in <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dkDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for <samp class="ph codeph">keys</samp> and
                                       								<samp class="ph codeph">dkeys</samp> sequence data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dkeys</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Device pointer to gradients of the loss function computed
                                       							with respect to <samp class="ph codeph">keys</samp> vectors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">keys</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">keys</samp> data in the device memory. This is the same
                                       							input as in <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dvDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for <samp class="ph codeph">values</samp> and
                                       								<samp class="ph codeph">dvalues</samp> sequence data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dvalues</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Device pointer to gradients of the loss function computed
                                       							with respect to <samp class="ph codeph">values</samp> vectors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">values</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">values</samp> data in the device memory. This is the
                                       							same input as in <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the <samp class="ph codeph">weight</samp> buffer in bytes where
                                       							all multi-head attention trainable parameters are stored.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weights</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Address of the <samp class="ph codeph">weight</samp> buffer in the
                                       							device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the work-space buffer in bytes used for temporary
                                       							API storage.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the work-space buffer in the device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the reserve-space buffer in bytes used for data
                                       							exchange between forward and backward (gradient) API calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address to the reserve-space buffer in the device
                                       							memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnMultiHeadAttnBackwardData__section_qqz_zhl_1jb"><a name="cudnnMultiHeadAttnBackwardData__section_qqz_zhl_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">No errors were detected while processing API input arguments and
                                       							launching GPU kernels.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or incompatible input argument was encountered.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The process of launching a GPU kernel returned an error, or an earlier
                                       							kernel did not complete successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">An inconsistent internal state was encountered.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A requested option or a combination of input arguments is not
                                       							supported.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">Insufficient amount of shared memory to launch a GPU kernel.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnMultiHeadAttnBackwardWeights"><a name="cudnnMultiHeadAttnBackwardWeights" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnBackwardWeights" name="cudnnMultiHeadAttnBackwardWeights" shape="rect">8.2.17.&nbsp;<kbd class="ph userinput">cudnnMultiHeadAttnBackwardWeights()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes exact, first-order derivatives of the multi-head attention
                                 			block with respect to its trainable parameters: projection weights and projection
                                 			biases. If <strong class="ph b">y</strong>=<em class="ph i">F</em>(<strong class="ph b">w</strong>) is a vector-valued function that represents the
                                 			multi-head attention layer and it takes some vector 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>x</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>n</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 			 of flatten weights or biases as an input (with all other parameters and
                                 			inputs fixed), and outputs vector 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>y</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>m</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 			, then <samp class="ph codeph">cudnnMultiHeadAttnBackwardWeights()</samp> computes the
                                 			result of 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msup>
                                          <mfenced open="(" close=")">
                                             <mrow>
                                                <msub>
                                                   <mrow>
                                                      <mo rspace="1px"></mo>
                                                      <mi>y</mi>
                                                   </mrow>
                                                   <mi>i</mi>
                                                </msub>
                                                <mo>/</mo>
                                                <mo rspace="1px"></mo>
                                                <msub>
                                                   <mi>x</mi>
                                                   <mi>j</mi>
                                                </msub>
                                             </mrow>
                                          </mfenced>
                                          <mi>T</mi>
                                       </msup>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 where 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 is the 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mn>1</mn>
                                    </mrow>
                                 </math>
                                 			 gradient of the loss function with respect to multi-head attention
                                 			outputs. The 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 gradient is back propagated through prior layers of the deep learning
                                 			model. 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>y</mi>
                                          <mi>i</mi>
                                       </msub>
                                       <mo>/</mo>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>x</mi>
                                          <mi>j</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 is the 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">n</mi>
                                    </mrow>
                                 </math>
                                 			 Jacobian matrix of <em class="ph i">F</em>(<strong class="ph b">w</strong>). The 
                                 				
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 			 input is supplied via the <samp class="ph codeph">dout</samp> argument.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnMultiHeadAttnBackwardWeights(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	cudnnWgradMode_t addGrad,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t qDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *queries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t kDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *keys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t vDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *values,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t doDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dout,
	size_t weightSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *weights,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dweights,
	size_t workSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
	size_t reserveSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);
</pre><p class="p">All gradient results with respect to weights and biases are written to the
                              				<samp class="ph codeph">dweights</samp> buffer. The size and the organization of the
                              				<samp class="ph codeph">dweights</samp> buffer is the same as the <samp class="ph codeph">weights</samp> buffer
                              			that holds multi-head attention weights and biases. The cuDNN
                              				<samp class="ph codeph">multiHeadAttention</samp> sample code demonstrates how to access those
                              			weights.
                           </p>
                           <p class="p">Gradient of the loss function with respect to weights or biases is typically computed
                              			over multiple batches. In such a case, partial results computed for each batch should be
                              			summed together. The <samp class="ph codeph">addGrad</samp> argument specifies if the gradients from
                              			the current batch should be added to previously computed results or the
                              				<samp class="ph codeph">dweights</samp> buffer should be overwritten with the new results.
                           </p>
                           <p class="p">The <samp class="ph codeph">cudnnMultiHeadAttnBackwardWeights()</samp> function should be invoked after
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp>. The
                              				<samp class="ph codeph">queries</samp>, <samp class="ph codeph">keys</samp>, <samp class="ph codeph">values</samp>,
                              				<samp class="ph codeph">weights</samp>, and <samp class="ph codeph">reserveSpace</samp> arguments should be the
                              			same as in <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward()</a></samp> and
                              					<samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp> calls. The
                              				<samp class="ph codeph">dout</samp> argument should be the same as in <samp class="ph codeph"><a class="xref" href="index.html#cudnnMultiHeadAttnBackwardData" title="This function computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector as an input (with all other parameters and inputs constant), and outputs vector , then cudnnMultiHeadAttnBackwardData() computes the result of where is the gradient of the loss function with respect to multi-head attention outputs. The gradient is back propagated through prior layers of the deep learning model. is the Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers." shape="rect">cudnnMultiHeadAttnBackwardData()</a></samp>.
                           </p>
                           <div class="section" id="cudnnMultiHeadAttnBackwardWeights__section_msq_v3l_1jb"><a name="cudnnMultiHeadAttnBackwardWeights__section_msq_v3l_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized attention descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">addGrad</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Weight gradient output mode.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">qDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the <samp class="ph codeph">query</samp> sequence
                                       							data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">queries</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">queries</samp> sequence data in the
                                       							device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">kDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the <samp class="ph codeph">keys</samp> sequence
                                       							data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">keys</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">keys</samp> sequence data in the
                                       							device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">vDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the <samp class="ph codeph">values</samp> sequence
                                       							data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">values</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to <samp class="ph codeph">values</samp> sequence data in the
                                       							device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">doDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Descriptor for the 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi></mi>
                                                <mi>out</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                       							 gradients (vectors of partial derivatives of the loss
                                       							function with respect to the multi-head attention outputs).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dout</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to 
                                       								
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi></mi>
                                                <mi>out</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                       							 gradient data in the device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the <samp class="ph codeph">weights</samp> and
                                       								<samp class="ph codeph">dweights</samp> buffers in bytes.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weights</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Address of the <samp class="ph codeph">weight</samp> buffer in the
                                       							device memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dweights</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Address of the weight gradient buffer in the device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the work-space buffer in bytes used for temporary
                                       							API storage.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the work-space buffer in the device
                                       							memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of the reserve-space buffer in bytes used for data
                                       							exchange between forward and backward (gradient) API calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address to the reserve-space buffer in the device
                                       							memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnMultiHeadAttnBackwardWeights__section_c2b_qjl_1jb"><a name="cudnnMultiHeadAttnBackwardWeights__section_c2b_qjl_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">No errors were detected while processing API input arguments and
                                       							launching GPU kernels.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or incompatible input argument was encountered.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The process of launching a GPU kernel returned an error, or an earlier
                                       							kernel did not complete successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">An inconsistent internal state was encountered.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">A requested option or a combination of input arguments is not
                                       							supported.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNBackwardData"><a name="cudnnRNNBackwardData" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardData" name="cudnnRNNBackwardData" shape="rect">8.2.18.&nbsp;<kbd class="ph userinput">cudnnRNNBackwardData()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNBackwardData()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNBackwardData(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dhyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dhy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dcyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dcy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dhxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dhx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dcxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dcx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">This routine executes the recurrent neural network described by <samp class="ph codeph">rnnDesc</samp>
                              with output gradients <samp class="ph codeph">dy</samp>, <samp class="ph codeph">dhy</samp>, and
                              <samp class="ph codeph">dhc</samp>, weights <samp class="ph codeph">w</samp> and input gradients
                              <samp class="ph codeph">dx</samp>, <samp class="ph codeph">dhx</samp>, and <samp class="ph codeph">dcx</samp>.
                              <samp class="ph codeph">workspace</samp> is required for intermediate storage. The data in
                              <samp class="ph codeph">reserveSpace</samp> must have previously been generated by <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp>. The same
                              <samp class="ph codeph">reserveSpace</samp> data must be used for future calls to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp> if they execute on the same input
                              data.
                           </p>
                           <div class="section" id="cudnnRNNBackwardData__section_qbh_tmr_1jb"><a name="cudnnRNNBackwardData__section_qbh_tmr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor. For more
                                       information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNDescriptor_t" shape="rect">cudnnRNNDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the RNN. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). For more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp>. The second
                                          dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                          argument used to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_xgb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_xgb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">dyDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the gradient at the output from each recurrent iteration (one
                                          descriptor per iteration). The second dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_zgb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_zgb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">dxDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">dyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradients at the final hidden state of the RNN. The first dimension
                                          of the tensor depends on the <samp class="ph codeph">direction</samp> argument
                                          used to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_bhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_bhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dhyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradients at the final hidden state of the network will
                                       be initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradients at the final cell state of the RNN. The first dimension of
                                          the tensor depends on the <samp class="ph codeph">direction</samp> argument used
                                          to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_chb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_chb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dcyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradients at the final cell state of the network will be
                                       initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN. For more information, refer to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_ehb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_ehb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the second dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_fhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_fhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the second dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                       gradient at the input of each recurrent iteration (one descriptor per
                                       iteration). The first dimension (batch size) of the tensors may decrease
                                       from element <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may
                                       not increase. Each tensor descriptor must have the same second dimension
                                       (vector length).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">dxDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradient at the initial hidden state of the RNN. The first dimension
                                          of the tensor depends on the <samp class="ph codeph">direction</samp> argument
                                          used to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_hhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_hhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dhxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradient at the hidden input of the network will not be
                                       set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradient at the initial cell state of the RNN. The first dimension
                                          of the tensor depends on the <samp class="ph codeph">direction</samp> argument
                                          used to initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_jhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_jhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dcxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradient at the cell input of the network will not be
                                       set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve
                                       space for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNBackwardData__section_gws_tmr_1jb"><a name="cudnnRNNBackwardData__section_gws_tmr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNBackwardData__ul_khb_1g3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_khb_1g3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">dhxDesc</samp>,
                                             <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">dcxDesc</samp>,
                                             <samp class="ph codeph">dhyDesc</samp>, or <samp class="ph codeph">dcyDesc</samp> or one
                                             of the descriptors in <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">dxdesc</samp>, <samp class="ph codeph">dydesc</samp> is
                                             invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">dxDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                             <samp class="ph codeph">dhxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">cxDesc</samp>,
                                             <samp class="ph codeph">dcxDesc</samp>, <samp class="ph codeph">dhyDesc</samp>, or
                                             <samp class="ph codeph">dcyDesc</samp> has incorrect strides or
                                             dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPersistentRNNPlan" title="This function has been deprecated in cuDNN 8.0." shape="rect">cudnnSetPersistentRNNPlan()</a></samp> was not
                                       called prior to the current function when
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> was selected in the
                                       RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">
                                       <p class="p">A GPU/CUDA resource, such as a texture object, shared memory, or
                                          zero-copy memory is not available in the required size or there is a
                                          mismatch between the user resource and cuDNN internal resources. A
                                          resource mismatch may occur, for example, when calling
                                          <samp class="ph codeph">cudnnSetStream()</samp>. There could be a mismatch
                                          between the user provided CUDA stream and the internal CUDA events
                                          instantiated in the cuDNN handle when <samp class="ph codeph">cudnnCreate()</samp>
                                          was invoked.
                                       </p>
                                       <p class="p">This error status may not be correctable when it is related to
                                          texture dimensions, shared memory size, or zero-copy memory
                                          availability. If <samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp> is
                                          returned by <samp class="ph codeph">cudnnSetStream()</samp>, then it is typically
                                          correctable, however, it means that the cuDNN handle was created on
                                          one GPU and the user stream passed to this function is associated
                                          with another GPU.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNBackwardData_v8"><a name="cudnnRNNBackwardData_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardData_v8" name="cudnnRNNBackwardData_v8" shape="rect">8.2.19.&nbsp;<kbd class="ph userinput">cudnnRNNBackwardData_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes exact, first-order derivatives of the RNN model with
                                 respect to its inputs: <samp class="ph codeph">x</samp>, <samp class="ph codeph">hx</samp> and for the LSTM cell
                                 typealso<samp class="ph codeph">cx</samp>. If <strong class="ph b">o</strong> = <strong class="ph b">[y, hy, cy] </strong>= <em class="ph i">F</em>(<strong class="ph b">x, hx,
                                    cx</strong>) = <em class="ph i">F</em>(<strong class="ph b">z</strong>) is a vector-valued function that represents the entire
                                 RNN model and it takes vectors <samp class="ph codeph">x</samp>(for all time-steps) and vectors
                                 <samp class="ph codeph">hx</samp>, <samp class="ph codeph">cx</samp> (for all layers) as inputs, concatenated
                                 into 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>z</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>n</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 (network weights and biases are assumed constant), and outputs vectors
                                 <samp class="ph codeph">y</samp>, <samp class="ph codeph">hy</samp>, <samp class="ph codeph">cy</samp> concatenated into a
                                 vector 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>o</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>m</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 , then <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp> computes the result of 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msup>
                                          <mfenced open="(" close=")">
                                             <mrow>
                                                <msub>
                                                   <mrow>
                                                      <mo rspace="1px"></mo>
                                                      <mi>o</mi>
                                                   </mrow>
                                                   <mi>i</mi>
                                                </msub>
                                                <mo>/</mo>
                                                <mo rspace="1px"></mo>
                                                <msub>
                                                   <mi>z</mi>
                                                   <mi>j</mi>
                                                </msub>
                                             </mrow>
                                          </mfenced>
                                          <mi>T</mi>
                                       </msup>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 where 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 is the 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mn>1</mn>
                                    </mrow>
                                 </math>
                                 gradient of the loss function with respect to all RNN outputs. The 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 gradient is back propagated through prior layers of the deep learning
                                 model, starting from the model output. 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>o</mi>
                                          <mi>i</mi>
                                       </msub>
                                       <mo>/</mo>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>z</mi>
                                          <mi>j</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 is the 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">n</mi>
                                    </mrow>
                                 </math>
                                 Jacobian matrix of <em class="ph i">F</em>(<strong class="ph b">z</strong>). The 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 input is supplied via the <samp class="ph codeph">dy</samp>, <samp class="ph codeph">dhy</samp>, and
                                 <samp class="ph codeph">dcy</samp> arguments and gradient results 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msup>
                                          <mfenced open="(" close=")">
                                             <mrow>
                                                <msub>
                                                   <mrow>
                                                      <mo rspace="1px"></mo>
                                                      <mi>o</mi>
                                                   </mrow>
                                                   <mi>i</mi>
                                                </msub>
                                                <mo>/</mo>
                                                <mo rspace="1px"></mo>
                                                <msub>
                                                   <mi>z</mi>
                                                   <mi>j</mi>
                                                </msub>
                                             </mrow>
                                          </mfenced>
                                          <mi>T</mi>
                                       </msup>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 are written to the <samp class="ph codeph">dx</samp>, <samp class="ph codeph">dhx</samp>, and
                                 <samp class="ph codeph">dcx</samp> buffers.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNBackwardData_v8(
    cudnnHandle_t handle,
    cudnnRNNDescriptor_t rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> int32_t devSeqLengths[],
    cudnnRNNDataDescriptor_t yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dy,
    cudnnRNNDataDescriptor_t xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dx,
    cudnnTensorDescriptor_t hDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dhy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dhx,
    cudnnTensorDescriptor_t cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dcy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dcx,
    size_t weightSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *weightSpace,
    size_t workSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
    size_t reserveSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);
</pre><p class="p">Locations of <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, <samp class="ph codeph">hx</samp>,
                              <samp class="ph codeph">cx</samp>, <samp class="ph codeph">hy</samp>, <samp class="ph codeph">cy</samp>, <samp class="ph codeph">dx</samp>,
                              <samp class="ph codeph">dy</samp>, <samp class="ph codeph">dhx</samp>, <samp class="ph codeph">dcx</samp>,
                              <samp class="ph codeph">dhy</samp>, and <samp class="ph codeph">dcy</samp> signals a multi-layer RNN model are
                              shown in the following figure. Note that internal RNN signals (between time-steps and
                              between layers) are not exposed by the <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp>
                              function.
                           </p>
                           <div class="p">
                              <div class="fig fignone" id="cudnnRNNBackwardData_v8__fig_js4_vl5_kmb"><a name="cudnnRNNBackwardData_v8__fig_js4_vl5_kmb" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 7. Locations of x, y, hx, cx, hy, cy, dx, dy, dhx, dcx, dhy, and dcy Signals a
                                    Multi-Layer RNN Model</span><br clear="none"></br><a name="cudnnRNNBackwardData_v8__image_tny_hl2_yz" shape="rect">
                                    <!-- --></a><div class="imageleft"><img class="image imageleft" id="cudnnRNNBackwardData_v8__image_tny_hl2_yz" src="graphics/cudnnRNNBackwardData-locations.png" alt="Locations of x, y, hx, cx, hy, cy, dx, dy, dhx, dcx, dhy, and dcy Signals a Multi-Layer RNN Model"></img></div><br clear="none"></br></div>
                           </div>
                           <p class="p">Memory addresses to the primary RNN output <samp class="ph codeph">y</samp>, the initial hidden state
                              <samp class="ph codeph">hx</samp>, and the initial cell state <samp class="ph codeph">cx</samp> (for LSTM only)
                              should point to the same data as in the preceding <samp class="ph codeph">cudnnRNNForward()</samp>
                              call. The <samp class="ph codeph">dy</samp> and <samp class="ph codeph">dx</samp> pointers cannot be
                              <samp class="ph codeph">NULL</samp>.
                           </p>
                           <p class="p">The <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp> function accepts any combination of
                              <samp class="ph codeph">dhy</samp>, <samp class="ph codeph">dhx</samp>, <samp class="ph codeph">dcy</samp>,
                              <samp class="ph codeph">dcx</samp> buffer addresses being <samp class="ph codeph">NULL</samp>. When
                              <samp class="ph codeph">dhy</samp> or <samp class="ph codeph">dcy</samp> are <samp class="ph codeph">NULL</samp>, it is
                              assumed that those inputs are zero. When <samp class="ph codeph">dhx</samp> or <samp class="ph codeph">dcx</samp>
                              pointers are <samp class="ph codeph">NULL</samp> then the corresponding results are not written by
                              <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp>.
                           </p>
                           <p class="p">When all <samp class="ph codeph">hx</samp>, <samp class="ph codeph">dhy</samp>, <samp class="ph codeph">dhx</samp> pointers are
                              <samp class="ph codeph">NULL</samp>, then the corresponding tensor descriptor
                              <samp class="ph codeph">hDesc</samp> can be <samp class="ph codeph">NULL</samp> too. The same rule applies to
                              the <samp class="ph codeph">cx</samp>, <samp class="ph codeph">dcy</samp>, <samp class="ph codeph">dcx</samp> pointers and the
                              <samp class="ph codeph">cDesc</samp> tensor descriptor.
                           </p>
                           <p class="p">The <samp class="ph codeph">cudnnRNNBackwardData_v8(</samp>) function allows the user to use padded
                              layouts for inputs <samp class="ph codeph">y</samp>, <samp class="ph codeph">dy</samp>, and output
                              <samp class="ph codeph">dx</samp>. In padded or unpacked layouts
                              (<samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED</samp>,
                              <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED)</samp> each sequence of
                              vectors in a mini-batch has a fixed length defined by the <samp class="ph codeph">maxSeqLength</samp>
                              argument in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDataDescriptor" title="This function initializes a previously created RNN data descriptor object. This data structure is intended to support the unpacked (padded) layout for input and output of extended RNN inference and training functions. A packed (unpadded) layout is also supported for backward compatibility." shape="rect">cudnnSetRNNDataDescriptor()</a></samp> function.
                              The term "unpacked" refers here to the presence of padding vectors, and not unused
                              address ranges between contiguous vectors.
                           </p>
                           <p class="p">Each padded, fixed-length sequence starts from a segment of valid vectors. The valid
                              vector count is stored in <samp class="ph codeph">seqLengthArray</samp> passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDataDescriptor" title="This function initializes a previously created RNN data descriptor object. This data structure is intended to support the unpacked (padded) layout for input and output of extended RNN inference and training functions. A packed (unpadded) layout is also supported for backward compatibility." shape="rect">cudnnSetRNNDataDescriptor()</a></samp>, such that <samp class="ph codeph">0 &lt;
                                 seqLengthArray[i] &lt;= maxSeqLength</samp> for all sequences in a mini-batch,
                              that is, for <samp class="ph codeph">i=0..batchSize-1</samp>. The remaining padding vectors make the
                              combined sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. Both sequence-major and
                              batch-major padded layouts are supported. 
                           </p>
                           <p class="p">In addition, a packed sequence-major layout:
                              <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_PACKED</samp> can be selected by the user.
                              In the latter layout, sequences of vectors in a mini-batch are sorted in the descending
                              order according to the sequence lengths. First, all vectors for time step zero are
                              stored. They are followed by vectors for time step one, and so on. This layout uses no
                              padding vectors.
                           </p>
                           <p class="p">The same layout type must be specified in <samp class="ph codeph">xDesc</samp> and
                              <samp class="ph codeph">yDesc</samp> descriptors.
                           </p>
                           <p class="p">Two host arrays named <samp class="ph codeph">seqLengthArray</samp> in <samp class="ph codeph">xDesc</samp> and
                              <samp class="ph codeph">yDesc</samp> RNN data descriptors must be the same. In addition, a copy of
                              <samp class="ph codeph">seqLengthArray</samp> in the device memory must be passed via the
                              <samp class="ph codeph">devSeqLengths</samp> argument. This array is supplied directly to GPU
                              kernels. Starting in cuDNN 8.9.1, the <samp class="ph codeph">devSeqLengths</samp> parameter is no
                              longer required and can be set to <samp class="ph codeph">NULL</samp>. The variable sequence length
                              array is transferred automatically to GPU memory by the
                              <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp> function.
                           </p>
                           <p class="p">The <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp> function does not verify that sequence
                              lengths stored in <samp class="ph codeph">devSeqLengths</samp> in GPU memory are the same as in
                              <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> descriptors in CPU memory.
                              Sequence length arrays from <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp>
                              descriptors are checked for consistency, however.
                           </p>
                           <p class="p">The <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp> function must be called after
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp>. The <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> function should be invoked with the
                              <samp class="ph codeph">fwdMode</samp> argument of type <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> set to <samp class="ph codeph">CUDNN_FWD_MODE_TRAINING</samp>.
                           </p>
                           <div class="section" id="cudnnRNNBackwardData_v8__section_l1g_xmn_y3b"><a name="cudnnRNNBackwardData_v8__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">devSeqLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A copy of <samp class="ph codeph">seqLengthArray</samp> from
                                       <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> RNN data
                                       descriptors. The <samp class="ph codeph">devSeqLengths</samp> array must be stored in
                                       GPU memory as it is accessed asynchronously by GPU kernels, possibly
                                       after the <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp> function exists. In
                                       cuDNN 8.9.1 and later versions, <samp class="ph codeph">devSeqLengths</samp> should be
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized descriptor corresponding to the
                                       RNN model primary output. The <samp class="ph codeph">dataType</samp>,
                                       <samp class="ph codeph">layout</samp>, <samp class="ph codeph">maxSeqLength</samp>,
                                       <samp class="ph codeph">batchSize</samp>, and <samp class="ph codeph">seqLengthArray</samp> need
                                       to match that of <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp>, <samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointers to GPU buffers holding the RNN model primary
                                       output and gradient deltas (gradient of the loss function with respect
                                       to <samp class="ph codeph">y</samp>). The <samp class="ph codeph">y</samp> output should be produced
                                       by the preceding <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp>
                                       call. The <samp class="ph codeph">y</samp> and <samp class="ph codeph">dy</samp> vectors are
                                       expected to be laid out in memory according to the layout specified by
                                       <samp class="ph codeph">yDesc</samp>. The elements in the tensor (including
                                       elements in padding vectors) must be densely packed. The
                                       <samp class="ph codeph">y</samp> and <samp class="ph codeph">dy</samp> arguments cannot be
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN data descriptor corresponding
                                       to the gradient of the loss function with respect to the RNN primary
                                       model input. The <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                       <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>, and
                                       <samp class="ph codeph">seqLengthArray</samp> must match that of
                                       <samp class="ph codeph">yDesc</samp>. The parameter <samp class="ph codeph">vectorSize</samp>
                                       must match the <samp class="ph codeph">inputSize</samp> argument passed to the
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>
                                       function.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory where back-propagated
                                       gradients of the loss function with respect to the RNN primary input
                                       <samp class="ph codeph">x</samp> should be stored. The vectors are expected to be
                                       arranged in memory according to the layout specified by
                                       <samp class="ph codeph">xDesc</samp>. The elements in the tensor (including
                                       padding vectors) must be densely packed. This argument cannot be
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A tensor descriptor describing the initial RNN hidden
                                          state hx and gradients of the loss function with respect to the
                                          initial of the final hidden state. Hidden state data and the
                                          corresponding gradients are fully packed. The first dimension of the
                                          tensor depends on the dirMode argument passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> function.<a name="cudnnRNNBackwardData_v8__ul_df2_dw5_kmb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData_v8__ul_df2_dw5_kmb">
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp>, then the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp>, then the first
                                                dimension should be double the <samp class="ph codeph">numLayers</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter described in <samp class="ph codeph">xDesc</samp>. The third dimension
                                          depends on whether RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and
                                          whether the LSTM projection is enabled. Specifically:<a name="cudnnRNNBackwardData_v8__ul_krt_tw5_kmb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData_v8__ul_krt_tw5_kmb">
                                             <li class="li">If RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM
                                                projection is enabled, the third dimension must match the
                                                <samp class="ph codeph">projSize</samp> argument passed to the
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> call.
                                             </li>
                                             <li class="li">Otherwise, the third dimension must match the
                                                <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> call used to initialize
                                                <samp class="ph codeph">rnnDesc</samp>.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp>, <samp class="ph codeph">dhy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Addresses of GPU buffers with the RNN initial hidden state
                                       <samp class="ph codeph">hx</samp> and gradient deltas <samp class="ph codeph">dhy</samp>. Data
                                       dimensions are described by the <samp class="ph codeph">hDesc</samp> tensor
                                       descriptor. If a <samp class="ph codeph">NULL</samp> pointer is passed in
                                       <samp class="ph codeph">hx</samp> or <samp class="ph codeph">dhy</samp> arguments, the
                                       corresponding buffer is assumed to contain all zeros.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the GPU buffer where first-order derivatives
                                       corresponding to initial hidden state variables should be stored. Data
                                       dimensions are described by the <samp class="ph codeph">hDesc</samp> tensor
                                       descriptor. If a <samp class="ph codeph">NULL</samp> pointer is assigned to
                                       <samp class="ph codeph">dhx</samp>, the back-propagated derivatives are not
                                       saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. For LSTM networks only. A tensor descriptor describing
                                          the initial cell state <samp class="ph codeph">cx</samp> and gradients of the loss
                                          function with respect to the initial of the final cell state. Cell
                                          state data are fully packed. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">dirMode</samp> argument passed to the
                                          <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> call.<a name="cudnnRNNBackwardData_v8__ul_t1v_ww5_kmb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardData_v8__ul_t1v_ww5_kmb">
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp>, then the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">dirMode</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp>, then the first
                                                dimension should be double the <samp class="ph codeph">numLayers</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp>.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second tensor dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor_v8" title="This function initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model." shape="rect">cudnnSetRNNDescriptor_v8()</a></samp> call.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp>, <samp class="ph codeph">dcy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. For LSTM networks only. Addresses of GPU buffers with the
                                       initial LSTM state data and gradient deltas <samp class="ph codeph">dcy</samp>. Data
                                       dimensions are described by the <samp class="ph codeph">cDesc</samp> tensor
                                       descriptor. If a <samp class="ph codeph">NULL</samp> pointer is passed in
                                       <samp class="ph codeph">cx</samp> or <samp class="ph codeph">dcy</samp> arguments, the
                                       corresponding buffer is assumed to contain all zeros.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. For LSTM networks only. Pointer to the GPU buffer where
                                       first-order derivatives corresponding to initial LSTM state variables
                                       should be stored. Data dimensions are described by the
                                       <samp class="ph codeph">cDesc</samp> tensor descriptor. If a <samp class="ph codeph">NULL</samp>
                                       pointer is assigned to <samp class="ph codeph">dcx</samp>, the back-propagated
                                       derivatives are not saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided weight-space
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Address of the weight space buffer in GPU memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided workspace
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the workspace buffer in GPU memory to
                                       store temporary data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the reserve-space
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the reserve-space buffer in GPU
                                       memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNBackwardData_v8__section_zgs_xmn_y3b"><a name="cudnnRNNBackwardData_v8__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">No errors were detected while processing API input arguments and
                                       launching GPU kernels.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNBackwardData_v8__ul_qt3_ttb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardData_v8__ul_qt3_ttb_wlb">
                                          <li class="li">variable sequence length input is passed while
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is
                                             specified
                                          </li>
                                          <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is requested
                                             on pre-Pascal devices
                                          </li>
                                          <li class="li">the 'double' floating point type is used for input/output and
                                             the <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> algo
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or incompatible input argument was encountered. For
                                       example:<a name="cudnnRNNBackwardData_v8__ul_rhc_vtb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardData_v8__ul_rhc_vtb_wlb">
                                          <li class="li">some input descriptors are <samp class="ph codeph">NULL</samp></li>
                                          <li class="li">settings in <samp class="ph codeph">rnnDesc</samp>, <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">hDesc</samp>, or
                                             <samp class="ph codeph">cDesc</samp> descriptors are invalid
                                          </li>
                                          <li class="li"><samp class="ph codeph">weightSpaceSize</samp>,
                                             <samp class="ph codeph">workSpaceSize</samp>, or
                                             <samp class="ph codeph">reserveSpaceSize</samp> is too small
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">
                                       <p class="p">A GPU/CUDA resource, such as a texture object, shared memory, or
                                          zero-copy memory is not available in the required size or there is a
                                          mismatch between the user resource and cuDNN internal resources. A
                                          resource mismatch may occur, for example, when calling
                                          <samp class="ph codeph">cudnnSetStream()</samp>. There could be a mismatch
                                          between the user provided CUDA stream and the internal CUDA events
                                          instantiated in the cuDNN handle when <samp class="ph codeph">cudnnCreate()</samp>
                                          was invoked.
                                       </p>
                                       <p class="p">This error status may not be correctable when it is related to
                                          texture dimensions, shared memory size, or zero-copy memory
                                          availability. If <samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp> is
                                          returned by <samp class="ph codeph">cudnnSetStream()</samp>, then it is typically
                                          correctable, however, it means that the cuDNN handle was created on
                                          one GPU and the user stream passed to this function is associated
                                          with another GPU.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The process of launching a GPU kernel returned an error, or an earlier
                                       kernel did not complete successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate CPU memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNBackwardDataEx"><a name="cudnnRNNBackwardDataEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardDataEx" name="cudnnRNNBackwardDataEx" shape="rect">8.2.20.&nbsp;<kbd class="ph userinput">cudnnRNNBackwardDataEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNBackwardDataEx()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNBackwardDataEx(
    cudnnHandle_t                     handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t        rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dcDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dcAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dhyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dhy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dcyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dcy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t     wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dhxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dhx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dcxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dcx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dkDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dkeys,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *workSpace,
    size_t                            workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *reserveSpace,
    size_t                            reserveSpaceSizeInBytes)
</pre><p class="p">This routine is the extended version of the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp>. This function
                              <samp class="ph codeph">cudnnRNNBackwardDataEx()</samp> allows the user to use an unpacked
                              (padded) layout for input <samp class="ph codeph">y</samp> and output <samp class="ph codeph">dx</samp>. 
                           </p>
                           <p class="p">In the unpacked layout, each sequence in the mini-batch is considered to be of fixed
                              length, specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the
                              <samp class="ph codeph">nth</samp> sequence in the mini-batch, is composed of a valid segment
                              specified by the <samp class="ph codeph">seqLengthArray[n]</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>; and a padding segment to make the combined
                              sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                           </p>
                           <p class="p">With the unpacked layout, both sequence major (meaning, time major) and batch major are
                              supported. For backward compatibility, the packed sequence major layout is supported.
                              However, similar to the non-extended function <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp>, the sequences in the mini-batch need
                              to be sorted in descending order according to length. 
                           </p>
                           <div class="section" id="cudnnRNNBackwardDataEx__section_fpp_vqr_1jb"><a name="cudnnRNNBackwardDataEx__section_fpp_vqr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created This function is deprecated
                                       starting in cuDNN 8.0.0. context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. Must match
                                       or be the exact same descriptor previously passed into <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">yDesc</samp>. The vectors are expected to be
                                       laid out in memory according to the layout specified by
                                       <samp class="ph codeph">yDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported. Must contain the exact same data previously produced by
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                       <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                       <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>,
                                       <samp class="ph codeph">vectorSize</samp>, and <samp class="ph codeph">seqLengthArray</samp>
                                       need to match the <samp class="ph codeph">yDesc</samp> previously passed to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">dyDesc</samp>. The vectors are expected to be
                                       laid out in memory according to the layout specified by
                                       <samp class="ph codeph">dyDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradients at the final hidden state of the RNN. The first dimension
                                          of the tensor depends on the <samp class="ph codeph">direction</samp> argument
                                          used to initialize <samp class="ph codeph">rnnDesc</samp>. Additionally: <a name="cudnnRNNBackwardDataEx__ul_bhb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_bhb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter in <samp class="ph codeph">xDesc</samp>. The third dimension depends on
                                          whether the RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and whether LSTM
                                          projection is enabled. Additionally: 
                                       </p>
                                       <div class="p"><a name="cudnnRNNBackwardDataEx__ul_v5c_4xy_h2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_v5c_4xy_h2b">
                                             <li class="li">If the RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM
                                                projection is enabled, the third dimension must match the
                                                <samp class="ph codeph">recProjSize</samp> argument passed to
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNProjectionLayers" shape="rect">cudnnSetRNNProjectionLayers()</a></samp> call used to set <samp class="ph codeph">rnnDesc</samp>. 
                                             </li>
                                             <li class="li">Otherwise, the third dimension must match the
                                                <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                                <samp class="ph codeph">rnnDesc</samp>. 
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dhyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradients at the final hidden state of the network will
                                       be initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the
                                          gradients at the final cell state of the RNN. The first dimension of
                                          the tensor depends on the <samp class="ph codeph">direction</samp> argument used
                                          to initialize <samp class="ph codeph">rnnDesc</samp>. Additionally: <a name="cudnnRNNBackwardDataEx__ul_chb_1g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_chb_1g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcy</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dcyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradients at the final cell state of the network will be
                                       initialized to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                       hidden state of the RNN. Must match or be the exact same descriptor
                                       previously passed into <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero. Must contain the exact same data previously passed into
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>, or
                                       be <samp class="ph codeph">NULL</samp> if <samp class="ph codeph">NULL</samp> was previously passed
                                       to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                       cell state for LSTM networks. Must match or be the exact same descriptor
                                       previously passed into <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero. Must contain the exact same data previously passed into
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>, or
                                       be <samp class="ph codeph">NULL</samp> if <samp class="ph codeph">NULL</samp> was previously passed
                                       to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                       <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                       <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>,
                                       <samp class="ph codeph">vectorSize</samp> and <samp class="ph codeph">seqLengthArray</samp> need
                                       to match that of <samp class="ph codeph">xDesc</samp> previously passed to
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">dxDesc</samp>. The vectors are expected to be
                                       laid out in memory according to the layout specified by
                                       <samp class="ph codeph">dxDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient
                                       at the initial hidden state of the RNN. The descriptor must be set
                                       exactly the same way as <samp class="ph codeph">dhyDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dhx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dhxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradient at the hidden input of the network will not be
                                       set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient
                                       at the initial cell state of the RNN. The descriptor must be set exactly
                                       the same way as <samp class="ph codeph">dcyDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dcx</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">dcxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the gradient at the cell input of the network will not be
                                       set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dkDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dkeys</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve
                                       space for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNBackwardDataEx__section_dl1_wqr_1jb"><a name="cudnnRNNBackwardDataEx__section_dl1_wqr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNBackwardDataEx__ul_j3f_hzy_h2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_j3f_hzy_h2b">
                                          <li class="li">Variable sequence length input is passed in while
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used. 
                                          </li>
                                          <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used on
                                             pre-Pascal devices. 
                                          </li>
                                          <li class="li">Double input/output is used for
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNBackwardDataEx__ul_khb_1g3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_khb_1g3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">dxdesc</samp>, <samp class="ph codeph">dydesc</samp>,
                                             <samp class="ph codeph">dhxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">cxDesc</samp>,
                                             <samp class="ph codeph">dcxDesc</samp>, <samp class="ph codeph">dhyDesc</samp>,  or
                                             <samp class="ph codeph">dcyDesc</samp> is invalid or has incorrect strides
                                             or dimensions. 
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPersistentRNNPlan" title="This function has been deprecated in cuDNN 8.0." shape="rect">cudnnSetPersistentRNNPlan()</a></samp> was not
                                       called prior to the current function when
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> was selected in the
                                       RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                                    <dd class="dd">
                                       <p class="p">A GPU/CUDA resource, such as a texture object, shared memory, or
                                          zero-copy memory is not available in the required size or there is a
                                          mismatch between the user resource and cuDNN internal resources. A
                                          resource mismatch may occur, for example, when calling
                                          <samp class="ph codeph">cudnnSetStream()</samp>. There could be a mismatch
                                          between the user provided CUDA stream and the internal CUDA events
                                          instantiated in the cuDNN handle when <samp class="ph codeph">cudnnCreate()</samp>
                                          was invoked.
                                       </p>
                                       <p class="p">This error status may not be correctable when it is related to
                                          texture dimensions, shared memory size, or zero-copy memory
                                          availability. If <samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp> is
                                          returned by <samp class="ph codeph">cudnnSetStream()</samp>, then it is typically
                                          correctable, however, it means that the cuDNN handle was created on
                                          one GPU and the user stream passed to this function is associated
                                          with another GPU.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNBackwardWeights"><a name="cudnnRNNBackwardWeights" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardWeights" name="cudnnRNNBackwardWeights" shape="rect">8.2.21.&nbsp;<kbd class="ph userinput">cudnnRNNBackwardWeights()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to all trainable parameters: weights and biases. If o = [y, hy, cy] = F(w) is a vector-valued function that represents the multi-layer RNN model and it takes some vector of &#34;flatten&#34; weights or biases as input (with all other data inputs constant), and outputs vector , then cudnnRNNBackwardWeights_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(w). The input is supplied via the dy, dhy, and dcy arguments in the cudnnRNNBackwardData_v8() function." shape="rect">cudnnRNNBackwardWeights_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNBackwardWeights()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNBackwardWeights(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">This routine accumulates weight gradients <samp class="ph codeph">dw</samp> from the recurrent neural
                              network described by <samp class="ph codeph">rnnDesc</samp> with inputs <samp class="ph codeph">x</samp>,
                              <samp class="ph codeph">hx</samp> and outputs <samp class="ph codeph">y</samp>. The mode of operation in this
                              case is additive, the weight gradients calculated will be added to those already
                              existing in <samp class="ph codeph">dw</samp>. <samp class="ph codeph">workspace</samp> is required for intermediate
                              storage. The data in <samp class="ph codeph">reserveSpace</samp> must have previously been generated
                              by <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp>.
                           </p>
                           <div class="section" id="cudnnRNNBackwardWeights__section_ufn_jtr_1jb"><a name="cudnnRNNBackwardWeights__section_ufn_jtr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand">rnnDesc</dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the
                                       RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                       input to each recurrent iteration (one descriptor per iteration). The
                                       first dimension (batch size) of the tensors may decrease from element
                                       <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                       increase. Each tensor descriptor must have the same second dimension
                                       (vector length).
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">xDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardWeights__ul_qjf_2g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeights__ul_qjf_2g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). The second dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardWeights__ul_ujf_2g3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeights__ul_ujf_2g3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">dyDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the gradients of the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dw</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       filter descriptor <samp class="ph codeph">dwDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a reserve space
                                       for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNBackwardWeights__section_jgx_jtr_1jb"><a name="cudnnRNNBackwardWeights__section_jgx_jtr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNBackwardWeights__ul_yjf_2g3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeights__ul_yjf_2g3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">dwDesc</samp> or one of the descriptors in
                                             <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">yDesc</samp> is
                                             invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">yDesc</samp>,
                                             <samp class="ph codeph">dwDesc</samp> have incorrect strides or
                                             dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNBackwardWeights_v8"><a name="cudnnRNNBackwardWeights_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardWeights_v8" name="cudnnRNNBackwardWeights_v8" shape="rect">8.2.22.&nbsp;<kbd class="ph userinput">cudnnRNNBackwardWeights_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function computes exact, first-order derivatives of the RNN model with
                                 respect to all trainable parameters: weights and biases. If <strong class="ph b">o</strong> = <strong class="ph b">[y, hy, cy]
                                    </strong>= <em class="ph i">F</em>(<strong class="ph b">w</strong>) is a vector-valued function that represents the multi-layer RNN
                                 model and it takes some vector 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>w</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>n</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 of "flatten" weights or biases as input (with all other data inputs
                                 constant), and outputs vector 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>o</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <msup>
                                          <mi></mi>
                                          <mi>m</mi>
                                       </msup>
                                    </mrow>
                                 </math>
                                 , then <samp class="ph codeph">cudnnRNNBackwardWeights_v8()</samp> computes the result of 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msup>
                                          <mfenced open="(" close=")">
                                             <mrow>
                                                <msub>
                                                   <mrow>
                                                      <mo rspace="1px"></mo>
                                                      <mi>o</mi>
                                                   </mrow>
                                                   <mi>i</mi>
                                                </msub>
                                                <mo>/</mo>
                                                <mo rspace="1px"></mo>
                                                <msub>
                                                   <mi>w</mi>
                                                   <mi>j</mi>
                                                </msub>
                                             </mrow>
                                          </mfenced>
                                          <mi>T</mi>
                                       </msup>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 where 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 is the 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mn>1</mn>
                                    </mrow>
                                 </math>
                                 gradient of the loss function with respect to all RNN outputs. The 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 gradient is back propagated through prior layers of the deep learning
                                 model, starting from the model output. 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>o</mi>
                                          <mi>i</mi>
                                       </msub>
                                       <mo>/</mo>
                                       <mo rspace="1px"></mo>
                                       <msub>
                                          <mi>w</mi>
                                          <mi>j</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 is the 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">m</mi>
                                       <mo lspace="2px" rspace="2px"></mo>
                                       <mi mathvariant="normal" fontfamily="Times New Roman">n</mi>
                                    </mrow>
                                 </math>
                                 Jacobian matrix of <em class="ph i">F</em>(<strong class="ph b">w</strong>). The 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msub>
                                          <mi></mi>
                                          <mi>out</mi>
                                       </msub>
                                    </mrow>
                                 </math>
                                 input is supplied via the <samp class="ph codeph">dy</samp>, <samp class="ph codeph">dhy</samp>, and
                                 <samp class="ph codeph">dcy</samp> arguments in the <samp class="ph codeph">cudnnRNNBackwardData_v8()</samp>
                                 function.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNBackwardWeights_v8(
    cudnnHandle_t handle,
    cudnnRNNDescriptor_t rnnDesc,
    cudnnWgradMode_t addGrad,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> int32_t devSeqLengths[],
    cudnnRNNDataDescriptor_t xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *x,
    cudnnTensorDescriptor_t hDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *hx,
    cudnnRNNDataDescriptor_t yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *y,
    size_t weightSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dweightSpace,
    size_t workSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
    size_t reserveSpaceSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);
</pre><p class="p">All gradient results 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msup>
                                       <mfenced open="(" close=")">
                                          <mrow>
                                             <msub>
                                                <mrow>
                                                   <mo rspace="1px"></mo>
                                                   <mi>o</mi>
                                                </mrow>
                                                <mi>i</mi>
                                             </msub>
                                             <mo>/</mo>
                                             <mo rspace="1px"></mo>
                                             <msub>
                                                <mi>w</mi>
                                                <mi>j</mi>
                                             </msub>
                                          </mrow>
                                       </mfenced>
                                       <mi>T</mi>
                                    </msup>
                                    <msub>
                                       <mi></mi>
                                       <mi>out</mi>
                                    </msub>
                                 </mrow>
                              </math>
                              with respect to weights and biases are written to the
                              <samp class="ph codeph">dweightSpace</samp> buffer. The size and the organization of the
                              <samp class="ph codeph">dweightSpace</samp> buffer is the same as the <samp class="ph codeph">weightSpace</samp>
                              buffer that holds RNN weights and biases.
                           </p>
                           <p class="p">Gradient of the loss function with respect to weights and biases is typically computed
                              over multiple mini-batches. In such a case, partial results computed for each mini-batch
                              should be aggregated. The <samp class="ph codeph">addGrad</samp> argument specifies if gradients from
                              the current mini-batch should be added to previously computed results
                              (<samp class="ph codeph">CUDNN_WGRAD_MODE_ADD</samp>) or the <samp class="ph codeph">dweightSpace</samp> buffer
                              should be overwritten with the new results (<samp class="ph codeph">CUDNN_WGRAD_MODE_SET</samp>).
                              Currently, the <samp class="ph codeph">cudnnRNNBackwardWeights_v8()</samp> function supports the
                              <samp class="ph codeph">CUDNN_WGRAD_MODE_ADD</samp> mode only so the <samp class="ph codeph">dweightSpace</samp>
                              buffer should be zeroed by the user before invoking the routine for the first time.
                           </p>
                           <p class="p">The same sequence lengths must be specified in the <samp class="ph codeph">xDesc</samp> descriptor and
                              in the device array <samp class="ph codeph">devSeqLengths</samp>. Starting in cuDNN 8.9.1, the
                              <samp class="ph codeph">devSeqLengths</samp> parameter is no longer required and can be set to
                              <samp class="ph codeph">NULL</samp>. The variable sequence length array is transferred
                              automatically to GPU memory by the<samp class="ph codeph">cudnnRNNBackwardWeights_v8()</samp>
                              function.
                           </p>
                           <p class="p">The <samp class="ph codeph">cudnnRNNBackwardWeights_v8()</samp> function should be invoked after
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp>.
                           </p>
                           <div class="section" id="cudnnRNNBackwardWeights_v8__section_l1g_xmn_y3b"><a name="cudnnRNNBackwardWeights_v8__section_l1g_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The current cuDNN context handle.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">addGrad</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Weight gradient output mode. For more details, see the
                                       description of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnWgradMode_t" shape="rect">cudnnWgradMode_t</a></samp>
                                       enumerated type. Currently, only the
                                       <samp class="ph codeph">CUDNN_WGRAD_MODE_ADD</samp> mode is supported by the
                                       <samp class="ph codeph">cudnnRNNBackwardWeights_v8()</samp> function.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">devSeqLengths</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A copy of <samp class="ph codeph">seqLengthArray</samp> from the
                                       <samp class="ph codeph">xDesc</samp> RNN data descriptor. The
                                       <samp class="ph codeph">devSeqLengths</samp> array must be stored in GPU memory as
                                       it is accessed asynchronously by GPU kernels, possibly after the
                                       <samp class="ph codeph">cudnnRNNBackwardWeights_v8()</samp> function exists. In
                                       cuDNN 8.9.1 and later versions, <samp class="ph codeph">devSeqLengths</samp> should be
                                       <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized descriptor corresponding to the
                                       RNN model input data. This is the same RNN data descriptor as used in
                                       the preceding <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> and
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp>
                                       calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU buffer with the primary RNN input. The
                                       same buffer address <samp class="ph codeph">x</samp> should be provided in prior
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> and
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp>
                                       calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A tensor descriptor describing the initial RNN hidden
                                       state. Hidden state data are fully packed. This is the same tensor
                                       descriptor as used in prior <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp> calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU buffer with the RNN initial hidden
                                       state. The same buffer address <samp class="ph codeph">hx</samp> should be provided in
                                       prior <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> and
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp>
                                       calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized descriptor corresponding to the
                                       RNN model output data. This is the same RNN data descriptor as used in
                                       prior <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> and
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector , then cudnnRNNBackwardData_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(z). The input is supplied via the dy, dhy, and dcy arguments and gradient results are written to the dx, dhx, and dcx buffers." shape="rect">cudnnRNNBackwardData_v8()</a></samp>
                                       calls.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Pointer to the GPU buffer with the primary RNN output as
                                       generated by the prior <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> call. Data in the <samp class="ph codeph">y</samp> buffer are
                                       described by the <samp class="ph codeph">yDesc</samp> descriptor. Elements in the
                                       <samp class="ph codeph">y</samp> tensor (including elements in padding vectors)
                                       must be densely packed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">weightSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided weight-space
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dweightSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Address of the weight space buffer in GPU memory.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided workspace
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the workspace buffer in GPU memory to
                                       store temporary data.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSize</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the reserve-space
                                       buffer.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Address of the reserve-space buffer in GPU
                                       memory.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNBackwardWeights_v8__section_zgs_xmn_y3b"><a name="cudnnRNNBackwardWeights_v8__section_zgs_xmn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">No errors were detected while processing API input arguments and
                                       launching GPU kernels.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or incompatible input argument was encountered. For
                                       example:<a name="cudnnRNNBackwardWeights_v8__ul_rhc_vtb_wlb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeights_v8__ul_rhc_vtb_wlb">
                                          <li class="li">some input descriptors are <samp class="ph codeph">NULL</samp></li>
                                          <li class="li">settings in <samp class="ph codeph">rnnDesc</samp>, <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp>, or <samp class="ph codeph">hDesc</samp>
                                             descriptors are invalid
                                          </li>
                                          <li class="li"><samp class="ph codeph">weightSpaceSize</samp>,
                                             <samp class="ph codeph">workSpaceSize</samp>, or
                                             <samp class="ph codeph">reserveSpaceSize</samp> values are too small
                                          </li>
                                          <li class="li">the <samp class="ph codeph">addGrad</samp> argument is not equal to
                                             <samp class="ph codeph">CUDNN_WGRAD_MODE_ADD</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The process of launching a GPU kernel returned an error, or an earlier
                                       kernel did not complete successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate CPU memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNBackwardWeightsEx"><a name="cudnnRNNBackwardWeightsEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardWeightsEx" name="cudnnRNNBackwardWeightsEx" shape="rect">8.2.23.&nbsp;<kbd class="ph userinput">cudnnRNNBackwardWeightsEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights_v8" title="This function computes exact, first-order derivatives of the RNN model with respect to all trainable parameters: weights and biases. If o = [y, hy, cy] = F(w) is a vector-valued function that represents the multi-layer RNN model and it takes some vector of &#34;flatten&#34; weights or biases as input (with all other data inputs constant), and outputs vector , then cudnnRNNBackwardWeights_v8() computes the result of where is the gradient of the loss function with respect to all RNN outputs. The gradient is back propagated through prior layers of the deep learning model, starting from the model output. is the Jacobian matrix of F(w). The input is supplied via the dy, dhy, and dcy arguments in the cudnnRNNBackwardData_v8() function." shape="rect">cudnnRNNBackwardWeights_v8()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNBackwardWeightsEX()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNBackwardWeightsEx(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t       rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t   xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *workSpace,
    size_t                           workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t    dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *reserveSpace,
    size_t                           reserveSpaceSizeInBytes)
</pre><p class="p">This routine is the extended version of the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp>. This function
                              <samp class="ph codeph">cudnnRNNBackwardWeightsEx()</samp> allows the user to use an unpacked
                              (padded) layout for input <samp class="ph codeph">x</samp> and output <samp class="ph codeph">dw</samp>. 
                           </p>
                           <p class="p">In the unpacked layout, each sequence in the mini-batch is considered to be of fixed
                              length, specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the
                              <samp class="ph codeph">nth</samp> sequence in the mini-batch, is composed of a valid segment
                              specified by the <samp class="ph codeph">seqLengthArray[n]</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>; and a padding segment to make the combined
                              sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                           </p>
                           <p class="p">With the unpacked layout, both sequence major (meaning, time major) and batch major are
                              supported. For backward compatibility, the packed sequence major layout is supported.
                              However, similar to the non-extended function <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp>, the sequences in the mini-batch
                              need to be sorted in descending order according to length. 
                           </p>
                           <div class="section" id="cudnnRNNBackwardWeightsEx__section_ewx_svr_1jb"><a name="cudnnRNNBackwardWeightsEx__section_ewx_svr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. Must match
                                       or be the exact same descriptor previously passed into <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptors in the array <samp class="ph codeph">xDesc</samp>. Must contain the exact
                                       same data previously passed into <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                       hidden state of the RNN. Must match or be the exact same descriptor
                                       previously passed into <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero. Must contain the exact same data previously passed into
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>, or
                                       be <samp class="ph codeph">NULL</samp> if <samp class="ph codeph">NULL</samp> was previously passed
                                       to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. Must match
                                       or be the exact same descriptor previously passed into <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>. Must contain the exact same
                                       data previously produced by <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx()</a></samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dwDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the gradients of the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">dw</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the
                                       filter descriptor <samp class="ph codeph">dwDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a reserve space
                                       for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNBackwardWeightsEx__section_qjh_tvr_1jb"><a name="cudnnRNNBackwardWeightsEx__section_qjh_tvr_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The function does not support the provided configuration.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNBackwardWeightsEx__ul_yjf_2g3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeightsEx__ul_yjf_2g3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">dwDesc</samp> is invalid, or has incorrect strides
                                             or dimensions. 
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNForwardTraining"><a name="cudnnRNNForwardTraining" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardTraining" name="cudnnRNNForwardTraining" shape="rect">8.2.24.&nbsp;<kbd class="ph userinput">cudnnRNNForwardTraining()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function is deprecated starting in cuDNN 8.0.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNForwardTraining()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNForwardTraining(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">This routine executes the recurrent neural network described by <samp class="ph codeph">rnnDesc</samp>
                              with inputs <samp class="ph codeph">x</samp>, <samp class="ph codeph">hx</samp>, and <samp class="ph codeph">cx</samp>, weights
                              <samp class="ph codeph">w</samp> and outputs <samp class="ph codeph">y</samp>, <samp class="ph codeph">hy</samp>, and
                              <samp class="ph codeph">cy</samp>. <samp class="ph codeph">workspace</samp> is required for intermediate
                              storage. <samp class="ph codeph">reserveSpace</samp> stores data required for training. The same
                              <samp class="ph codeph">reserveSpace</samp> data must be used for future calls to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a></samp> if these execute on the same input
                              data.
                           </p>
                           <div class="section" id="cudnnRNNForwardTraining__section_wlw_sps_1jb"><a name="cudnnRNNForwardTraining__section_wlw_sps_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">seqLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                       <samp class="ph codeph">seqLength</samp> must not exceed the value that was used
                                       in the <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetRNNWorkspaceSize" shape="rect">cudnnGetRNNWorkspaceSize()</a></samp>
                                       function for querying the workspace size required to execute the RNN. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. An array of <samp class="ph codeph">seqLength</samp> fully packed tensor
                                       descriptors. Each descriptor in the array should have three dimensions
                                       that describe the input data format to one recurrent iteration (one
                                       descriptor per RNN time-step). The first dimension (batch size) of the
                                       tensors may decrease from iteration element n to iteration element
                                       <samp class="ph codeph">n+1</samp> but may not increase. Each tensor descriptor
                                       must have the same second dimension (RNN input vector length,
                                       <samp class="ph codeph">inputSize</samp>). The third dimension of each tensor
                                       should be 1. Input vectors are expected to be arranged in the
                                       column-major order so strides in <samp class="ph codeph">xDesc</samp> should be set as
                                       follows:
                                       <pre xml:space="preserve">strideA[0]=inputSize, strideA[1]=1, strideA[2]=1</pre></dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the array of
                                       tensor descriptors <samp class="ph codeph">xDesc</samp>. The input vectors are
                                       expected to be packed contiguously with the first vector of iterations
                                       (time-step) <samp class="ph codeph">n+1</samp> following directly the last vector of
                                       iteration <samp class="ph codeph">n</samp>. In other words, input vectors for all RNN
                                       time-steps should be packed in the contiguous block of GPU memory with
                                       no gaps between the vectors.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_hqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_hqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_kqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_kqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing
                                          the output from each recurrent iteration (one descriptor per
                                          iteration). The second dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_mqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_mqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second
                                                dimension should match the <samp class="ph codeph">hiddenSize</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second
                                                dimension should match double the
                                                <samp class="ph codeph">hiddenSize</samp> argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                          first dimension of the tensor <samp class="ph codeph">n</samp> in
                                          <samp class="ph codeph">xDesc</samp>.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output
                                       tensor descriptor <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          hidden state of the RNN. The first dimension of the tensor depends
                                          on the <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_oqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_oqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final hidden state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cyDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                          cell state for LSTM networks. The first dimension of the tensor
                                          depends on the <samp class="ph codeph">direction</samp> argument used to
                                          initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_qqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_qqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final cell state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve
                                       space for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNForwardTraining__section_ylh_tps_1jb"><a name="cudnnRNNForwardTraining__section_ylh_tps_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">
                                       <p class="p">The function launched successfully.</p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">
                                       <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNForwardTraining__ul_rqb_wf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_rqb_wf3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc, cxDesc, wDesc,
                                                hyDesc, cyDesc</samp> or one of the descriptors in
                                             <samp class="ph codeph">xDesc, yDesc</samp> is invalid.
                                          </li>
                                          <li class="li">The descriptors in one of <samp class="ph codeph">xDesc, hxDesc, cxDesc, wDesc,
                                                yDesc, hyDesc, cyDesc</samp> have incorrect strides or
                                             dimensions.
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPersistentRNNPlan" title="This function has been deprecated in cuDNN 8.0." shape="rect">cudnnSetPersistentRNNPlan()</a></samp> was not
                                          called prior to the current function when
                                          <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> was selected in
                                          the RNN descriptor.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnRNNForwardTrainingEx"><a name="cudnnRNNForwardTrainingEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardTrainingEx" name="cudnnRNNForwardTrainingEx" shape="rect">8.2.25.&nbsp;<kbd class="ph userinput">cudnnRNNForwardTrainingEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function has been deprecated starting in cuDNN 8.0. Use <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForward" title="This routine computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the following figure. Note that internal RNN signals between time-steps and between layers are not exposed to the user." shape="rect">cudnnRNNForward()</a></samp> instead of
                              <samp class="ph codeph">cudnnRNNForwardTrainingEx()</samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNForwardTrainingEx(
    cudnnHandle_t                        handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t           rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t        wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       kDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *keys,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *cAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       iDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *iAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       qDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *queries,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *workSpace,
    size_t                               workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *reserveSpace,
    size_t                               reserveSpaceSizeInBytes);
</pre><p class="p">This routine is the extended version of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp> function. The
                              <samp class="ph codeph">cudnnRNNForwardTrainingEx()</samp> allows the user to use unpacked
                              (padded) layout for input <samp class="ph codeph">x</samp> and output <samp class="ph codeph">y</samp>. 
                           </p>
                           <p class="p">In the unpacked layout, each sequence in the mini-batch is considered to be of fixed
                              length, specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the
                              <samp class="ph codeph">nth</samp> sequence in the mini-batch, is composed of a valid segment
                              specified by the <samp class="ph codeph">seqLengthArray[n]</samp> in its corresponding
                              <samp class="ph codeph">RNNDataDescriptor</samp>; and a padding segment to make the combined
                              sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                           </p>
                           <p class="p">With the unpacked layout, both sequence major (meaning, time major) and batch major are
                              supported. For backward compatibility, the packed sequence major layout is supported.
                              However, similar to the non-extended function <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a></samp>, the sequences in the mini-batch
                              need to be sorted in descending order according to length. 
                           </p>
                           <div class="section" id="cudnnRNNForwardTrainingEx__section_o41_mbt_1jb"><a name="cudnnRNNForwardTrainingEx__section_o41_mbt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">handle</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">rnnDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">xDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A previously initialized RNN Data descriptor. The
                                       <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                       <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>, and
                                       <samp class="ph codeph">seqLengthArray</samp> need to match that of
                                       <samp class="ph codeph">yDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">x</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN
                                       data descriptor <samp class="ph codeph">xDesc</samp>. The input vectors are expected
                                       to be laid out in memory according to the layout specified by
                                       <samp class="ph codeph">xDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hxDesc</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          hidden state of the RNN. 
                                       </p>
                                       <div class="p">The first dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. Moreover: <a name="cudnnRNNForwardTrainingEx__ul_hqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_hqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> then the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> then the first
                                                dimension should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <div class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp>
                                          parameter in <samp class="ph codeph">xDesc</samp>. The third dimension depends on
                                          whether RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and whether
                                          <samp class="ph codeph">LSTM</samp> projection is enabled. Additionally: <a name="cudnnRNNForwardTrainingEx__ul_n2s_vfs_h2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_n2s_vfs_h2b">
                                             <li class="li">If RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and
                                                <samp class="ph codeph">LSTM</samp> projection is enabled, the third
                                                dimension must match the <samp class="ph codeph">recProjSize</samp>
                                                argument passed to <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNProjectionLayers" shape="rect">cudnnSetRNNProjectionLayers()</a></samp> call
                                                used to set <samp class="ph codeph">rnnDesc</samp>. 
                                             </li>
                                             <li class="li">Otherwise, the third dimension must match the
                                                <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                                <samp class="ph codeph">rnnDesc</samp>.
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial hidden state of the network will be initialized
                                       to zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cxDesc</samp></dt>
                                    <dd class="dd">
                                       <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial
                                          cell state for LSTM networks. 
                                       </p>
                                       <div class="p">The first dimension of the tensor depends on the
                                          <samp class="ph codeph">direction</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. Additionally: <a name="cudnnRNNForwardTrainingEx__ul_kqb_wf3_s1b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_kqb_wf3_s1b">
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first
                                                dimension should match the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                             <li class="li">If <samp class="ph codeph">direction</samp> is
                                                <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension
                                                should match double the <samp class="ph codeph">numLayers</samp>
                                                argument.
                                             </li>
                                          </ul>
                                       </div>
                                       <p class="p">The second dimension must match the first dimension of the tensors
                                          described in <samp class="ph codeph">xDesc</samp>. The third dimension must match
                                          the <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                          <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                                       </p>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cx</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the initial cell state of the network will be initialized to
                                       zero.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">wDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor
                                       describing the weights for the RNN.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">w</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                       descriptor <samp class="ph codeph">wDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">yDesc</samp></dt>
                                    <dd class="dd">
                                       <div class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                          <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                          <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>, and
                                          <samp class="ph codeph">seqLengthArray</samp> need to match that of
                                          <samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dxDesc</samp>. The
                                          parameter <samp class="ph codeph">vectorSize</samp> depends on whether the RNN
                                          mode is <samp class="ph codeph">CUDNN_LSTM</samp> and whether LSTM projection is
                                          enabled and whether the network is bidirectional. Specifically: <a name="cudnnRNNForwardTrainingEx__ul_zsr_v1y_h2b" shape="rect">
                                             <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_zsr_v1y_h2b">
                                             <li class="li">For a unidirectional network, if the RNN mode is
                                                <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM projection is
                                                enabled, the parameter <samp class="ph codeph">vectorSize</samp> must
                                                match the <samp class="ph codeph">recProjSize</samp> argument passed to
                                                <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNProjectionLayers" shape="rect">cudnnSetRNNProjectionLayers()</a></samp> call used to set <samp class="ph codeph">rnnDesc</samp>.
                                                If the network is bidirectional, then multiply the value by
                                                2. 
                                             </li>
                                             <li class="li">Otherwise, for unidirectional network, the parameter
                                                <samp class="ph codeph">vectorSize</samp> must match the
                                                <samp class="ph codeph">hiddenSize</samp> argument used to initialize
                                                <samp class="ph codeph">rnnDesc</samp>. If the network is
                                                bidirectional, then multiply the value by 2. 
                                             </li>
                                          </ul>
                                       </div>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">y</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the RNN data
                                       descriptor <samp class="ph codeph">yDesc</samp>. The input vectors are expected to be
                                       laid out in memory according to the layout specified by
                                       <samp class="ph codeph">yDesc</samp>. The elements in the tensor (including
                                       elements in the padding vector) must be densely packed, and no strides
                                       are supported.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final
                                       hidden state of the RNN. The descriptor must be set exactly the same as
                                       <samp class="ph codeph">hxDesc</samp>. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">hy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">hyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final hidden state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cyDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                       state for LSTM networks. The descriptor must be set exactly the same as
                                       <samp class="ph codeph">cxDesc</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cy</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                       descriptor <samp class="ph codeph">cyDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer
                                       is passed, the final cell state of the network will not be saved.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">kDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">keys</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">cAttn</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">iDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">iAttn</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">qDesc</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">queries</samp></dt>
                                    <dd class="dd">Reserved. Users may pass in <samp class="ph codeph">NULL</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workspace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for
                                       this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">workSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">workspace</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpace</samp></dt>
                                    <dd class="dd"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve
                                       space for this call.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">reserveSpaceSizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                       <samp class="ph codeph">reserveSpace</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnRNNForwardTrainingEx__section_ikl_mbt_1jb"><a name="cudnnRNNForwardTrainingEx__section_ikl_mbt_1jb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function launched successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNForwardTrainingEx__ul_v1c_d3s_h2b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_v1c_d3s_h2b">
                                          <li class="li">Variable sequence length input is passed in while <samp class="ph codeph">
                                                CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used. 
                                          </li>
                                          <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used on
                                             pre-Pascal devices. 
                                          </li>
                                          <li class="li">Double input/output is used for
                                             <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>. 
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the following conditions are met:<a name="cudnnRNNForwardTrainingEx__ul_rqb_wf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_rqb_wf3_s1b">
                                          <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                          </li>
                                          <li class="li">At least one of the descriptors <samp class="ph codeph">xDesc</samp>,
                                             <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">hxDesc</samp>,
                                             <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                             <samp class="ph codeph">hyDesc</samp>, and <samp class="ph codeph">cyDesc</samp> is
                                             invalid, or have incorrect strides or dimensions. 
                                          </li>
                                          <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                          </li>
                                          <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                                    <dd class="dd"><samp class="ph codeph"><a class="xref" href="index.html#cudnnSetPersistentRNNPlan" title="This function has been deprecated in cuDNN 8.0." shape="rect">cudnnSetPersistentRNNPlan()</a></samp> was not
                                       called prior to the current function when
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> was selected in the
                                       RNN descriptor.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">The function failed to launch on the GPU.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The function was unable to allocate memory.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetCTCLossDescriptor"><a name="cudnnSetCTCLossDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetCTCLossDescriptor" name="cudnnSetCTCLossDescriptor" shape="rect">8.2.26.&nbsp;<kbd class="ph userinput">cudnnSetCTCLossDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function sets a CTC loss function descriptor. See also the extended version
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptorEx" shape="rect">cudnnSetCTCLossDescriptorEx()</a></samp> to set the input
                              normalization mode.  <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetCTCLossDescriptor(
    cudnnCTCLossDescriptor_t        ctcLossDesc,
    cudnnDataType_t                 compType)</pre><div class="p">When the extended version <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptorEx" shape="rect">cudnnSetCTCLossDescriptorEx()</a></samp> is used
                              with <samp class="ph codeph">normMode</samp> set to <samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_NONE</samp> and
                              the <samp class="ph codeph">gradMode</samp> set to <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>, then it
                              is the same as the current function <samp class="ph codeph">cudnnSetCTCLossDescriptor()</samp>,
                              meaning:
                              <pre xml:space="preserve">cudnnSetCtcLossDescriptor(*) = cudnnSetCtcLossDescriptorEx(*, normMode=CUDNN_LOSS_NORMALIZATION_NONE, gradMode=CUDNN_NOT_PROPAGATE_NAN)</pre></div>
                           <div class="section" id="cudnnSetCTCLossDescriptor__section_enf_cjb_bjb"><a name="cudnnSetCTCLossDescriptor__section_enf_cjb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. CTC loss descriptor to be set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">compType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Compute type for this CTC loss function.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetCTCLossDescriptor__section_om4_cjb_bjb"><a name="cudnnSetCTCLossDescriptor__section_om4_cjb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the input parameters passed is invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetCTCLossDescriptorEx"><a name="cudnnSetCTCLossDescriptorEx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetCTCLossDescriptorEx" name="cudnnSetCTCLossDescriptorEx" shape="rect">8.2.27.&nbsp;<kbd class="ph userinput">cudnnSetCTCLossDescriptorEx()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function is an extension of <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptor" shape="rect">cudnnSetCTCLossDescriptor()</a></samp>. This function provides an additional interface <samp class="ph codeph">normMode</samp> to
                              set the input normalization mode for the CTC loss function, and <samp class="ph codeph">gradMode</samp> to
                              control the <samp class="ph codeph">NaN</samp> propagation type. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetCTCLossDescriptorEx(
    cudnnCTCLossDescriptor_t        ctcLossDesc,
    cudnnDataType_t                 compType,
    cudnnLossNormalizationMode_t    normMode,
    cudnnNanPropagation_t           gradMode)</pre><div class="p">When this function <samp class="ph codeph">cudnnSetCTCLossDescriptorEx()</samp> is used with
                              <samp class="ph codeph">normMode</samp> set to <samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_NONE</samp> and
                              the <samp class="ph codeph">gradMode</samp> set to <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>, then it
                              is the same as <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCTCLossDescriptor" shape="rect">cudnnSetCTCLossDescriptor()</a></samp>, meaning:
                              <pre xml:space="preserve">cudnnSetCtcLossDescriptor(*) = cudnnSetCtcLossDescriptorEx(*, normMode=CUDNN_LOSS_NORMALIZATION_NONE, gradMode=CUDNN_NOT_PROPAGATE_NAN)</pre></div>
                           <div class="section" id="cudnnSetCTCLossDescriptorEx__section_hxz_rjb_bjb"><a name="cudnnSetCTCLossDescriptorEx__section_hxz_rjb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. CTC loss descriptor to be set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">compType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Compute type for this CTC loss function.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Input normalization type for this CTC loss function. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnLossNormalizationMode_t" shape="rect">cudnnLossNormalizationMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. NaN propagation type for this CTC loss function. For
                                       <samp class="ph codeph">L</samp> the sequence length, <samp class="ph codeph">R</samp> the
                                       number of repeated letters in the sequence, and <samp class="ph codeph">T</samp> the
                                       length of sequential data, the following applies: when a sample with
                                       <samp class="ph codeph">L+R &gt; T</samp> is encountered during the gradient
                                       calculation, if <samp class="ph codeph">gradMode</samp> is set to
                                       <samp class="ph codeph">CUDNN_PROPAGATE_NAN</samp> (refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNanPropagation_t" shape="rect">cudnnNanPropagation_t</a></samp>), then the CTC loss
                                       function does not write to the gradient buffer for that sample. Instead,
                                       the current values, even not finite, are retained. If
                                       <samp class="ph codeph">gradMode</samp> is set to
                                       <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>, then the gradient for that
                                       sample is set to zero. This guarantees a finite gradient.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetCTCLossDescriptorEx__section_hhk_sjb_bjb"><a name="cudnnSetCTCLossDescriptorEx__section_hhk_sjb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of the input parameters passed is invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnSetCTCLossDescriptor_v8"><a name="cudnnSetCTCLossDescriptor_v8" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetCTCLossDescriptor_v8" name="cudnnSetCTCLossDescriptor_v8" shape="rect">8.2.28.&nbsp;<kbd class="ph userinput">cudnnSetCTCLossDescriptor_v8()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Many CTC API functions are updated in cuDNN version 8.0.0 to support CUDA graphs.
                                 In order to do so, a new parameter is needed, <samp class="ph codeph">maxLabelLength</samp>. Now that
                                 label and input data are assumed to be in GPU memory, this information is not otherwise
                                 readily available.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetCTCLossDescriptorEx(
    cudnnCTCLossDescriptor_t        ctcLossDesc,
    cudnnDataType_t                 compType,
    cudnnLossNormalizationMode_t    normMode,
    cudnnNanPropagation_t           gradMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             maxLabelLength)
</pre><div class="section" id="cudnnSetCTCLossDescriptor_v8__section_hxz_rjb_bjb"><a name="cudnnSetCTCLossDescriptor_v8__section_hxz_rjb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">ctcLossDesc</samp></dt>
                                    <dd class="dd"><em class="ph i">Output</em>. CTC loss descriptor to be set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">compType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Compute type for this CTC loss function.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">normMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Input normalization type for this CTC loss function. For
                                       more information, refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnLossNormalizationMode_t" shape="rect">cudnnLossNormalizationMode_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">gradMode</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. NaN propagation type for this CTC loss function. For
                                       <samp class="ph codeph">L</samp> the sequence length, <samp class="ph codeph">R</samp> the
                                       number of repeated letters in the sequence, and <samp class="ph codeph">T</samp> the
                                       length of sequential data, the following applies: when a sample with
                                       <samp class="ph codeph">L+R &gt; T</samp> is encountered during the gradient
                                       calculation, if <samp class="ph codeph">gradMode</samp> is set to
                                       <samp class="ph codeph">CUDNN_PROPAGATE_NAN</samp> (refer to <samp class="ph codeph"><a class="xref" href="index.html#cudnnNanPropagation_t" shape="rect">cudnnNanPropagation_t</a></samp>), then the CTC loss
                                       function does not write to the gradient buffer for that sample. Instead,
                                       the current values, even not finite, are retained. If
                                       <samp class="ph codeph">gradMode</samp> is set to
                                       <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>, then the gradient for that
                                       sample is set to zero. This guarantees a finite gradient.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">maxLabelLength</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The maximum label length from the labels data.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnSetCTCLossDescriptor_v8__section_hhk_sjb_bjb"><a name="cudnnSetCTCLossDescriptor_v8__section_hhk_sjb_bjb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The function returned successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">At least one of input parameters passed is invalid.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="cudnn-backend-api"><a name="cudnn-backend-api" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cudnn-backend-api" name="cudnn-backend-api" shape="rect">9.&nbsp;cuDNN Backend API</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc">This chapter documents the current implemented behavior of the
                           <samp class="ph codeph">cudnnBackend*</samp> API introduced in cuDNN version 8.x. Users specify
                           the computational case, set up an execution plan for it, and execute the computation via
                           numerous descriptors. The typical use pattern for a descriptor with attributes consists
                           of the following sequence of API calls:</span></div>
                     <div class="p"><a name="cudnn-backend-api__ol_kkf_dc3_gmb" shape="rect">
                           <!-- --></a><ol class="ol" id="cudnn-backend-api__ol_kkf_dc3_gmb">
                           <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendCreateDescriptor" title="This function allocates memory in the descriptor for a given descriptor type and at the location pointed by the descriptor." shape="rect">cudnnBackendCreateDescriptor()</a></samp> creates a
                              descriptor of a specified type.
                           </li>
                           <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp> sets the values of a
                              settable attribute for the descriptor. All required attributes must be set
                              before the next step.
                           </li>
                           <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> finalizes the
                              descriptor.
                           </li>
                           <li class="li"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> gets the values of an
                              attribute from a finalized descriptor.
                           </li>
                        </ol>
                     </div>
                     <p class="p">The enumeration type <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptorType_t" shape="rect">cudnnBackendDescriptorType_t</a></samp>
                        enumerates the list of valid cuDNN backend descriptor types. The enumeration type
                        <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> enumerates the
                        list of valid attributes. Each descriptor type in <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptorType_t" shape="rect">cudnnBackendDescriptorType_t</a></samp> has a disjoint subset of valid
                        attribute values of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp>. The
                        full description of each descriptor type and their attributes are specified in the
                        <samp class="ph codeph"><a class="xref" href="index.html#backend-descriptor-type" title="This section enumerates all valid attributes of various descriptors." shape="rect">Backend Descriptor Types</a></samp> section.
                     </p>
                  </div>
                  <div class="topic concept nested1" id="backend-data-type"><a name="backend-data-type" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#backend-data-type" name="backend-data-type" shape="rect">9.1.&nbsp;Data Type References</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the data type references for the cuDNN Backend API.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="backend-enumeration-types"><a name="backend-enumeration-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#backend-enumeration-types" name="backend-enumeration-types" shape="rect">9.1.1.&nbsp;Enumeration Types</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the enumeration types for the cuDNN Backend API.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendAttributeName_t"><a name="cudnnBackendAttributeName_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendAttributeName_t" name="cudnnBackendAttributeName_t" shape="rect">9.1.1.1.&nbsp;<kbd class="ph userinput">cudnnBackendAttributeName_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendAttributeName_t</samp> is an enumerated type that indicates the
                                 backend descriptor attributes that can be set or get using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> functions. The backend descriptor to
                                 which an attribute belongs is identified by the prefix of the attribute
                                 name. <span class="shortdesc"></span></div>
                              <div class="p"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_ATTR_POINTWISE_MODE                  = 0,
    CUDNN_ATTR_POINTWISE_MATH_PREC             = 1,
    CUDNN_ATTR_POINTWISE_NAN_PROPAGATION       = 2,
    CUDNN_ATTR_POINTWISE_RELU_LOWER_CLIP       = 3,
    CUDNN_ATTR_POINTWISE_RELU_UPPER_CLIP       = 4,
    CUDNN_ATTR_POINTWISE_RELU_LOWER_CLIP_SLOPE = 5,
    CUDNN_ATTR_POINTWISE_ELU_ALPHA             = 6,
    CUDNN_ATTR_POINTWISE_SOFTPLUS_BETA         = 7,
    CUDNN_ATTR_POINTWISE_SWISH_BETA            = 8,
    CUDNN_ATTR_POINTWISE_AXIS                  = 9,

    CUDNN_ATTR_CONVOLUTION_COMP_TYPE      = 100,
    CUDNN_ATTR_CONVOLUTION_CONV_MODE      = 101,
    CUDNN_ATTR_CONVOLUTION_DILATIONS      = 102,
    CUDNN_ATTR_CONVOLUTION_FILTER_STRIDES = 103,
    CUDNN_ATTR_CONVOLUTION_POST_PADDINGS  = 104,
    CUDNN_ATTR_CONVOLUTION_PRE_PADDINGS   = 105,
    CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS   = 106,

    CUDNN_ATTR_ENGINEHEUR_MODE            = 200,
    CUDNN_ATTR_ENGINEHEUR_OPERATION_GRAPH = 201,
    CUDNN_ATTR_ENGINEHEUR_RESULTS         = 202,
    CUDNN_ATTR_ENGINEHEUR_SM_COUNT_TARGET = 203,
 
    CUDNN_ATTR_ENGINECFG_ENGINE            = 300,
    CUDNN_ATTR_ENGINECFG_INTERMEDIATE_INFO = 301,
    CUDNN_ATTR_ENGINECFG_KNOB_CHOICES      = 302,

    CUDNN_ATTR_EXECUTION_PLAN_HANDLE                     = 400,
    CUDNN_ATTR_EXECUTION_PLAN_ENGINE_CONFIG              = 401,
    CUDNN_ATTR_EXECUTION_PLAN_WORKSPACE_SIZE             = 402,
    CUDNN_ATTR_EXECUTION_PLAN_COMPUTED_INTERMEDIATE_UIDS = 403,
    CUDNN_ATTR_EXECUTION_PLAN_RUN_ONLY_INTERMEDIATE_UIDS = 404,

    CUDNN_ATTR_INTERMEDIATE_INFO_UNIQUE_ID            = 500,
    CUDNN_ATTR_INTERMEDIATE_INFO_SIZE                 = 501,
    CUDNN_ATTR_INTERMEDIATE_INFO_DEPENDENT_DATA_UIDS  = 502,
    CUDNN_ATTR_INTERMEDIATE_INFO_DEPENDENT_ATTRIBUTES = 503,

    CUDNN_ATTR_KNOB_CHOICE_KNOB_TYPE  = 600,
    CUDNN_ATTR_KNOB_CHOICE_KNOB_VALUE = 601,
 
    CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA        = 700,
    CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA         = 701,
    CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_CONV_DESC    = 702,
    CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_W            = 703,
    CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_X            = 704,
    CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_Y            = 705,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA       = 706,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA        = 707,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_CONV_DESC   = 708,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_W           = 709,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DX          = 710,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DY          = 711,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA     = 712,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA      = 713,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_CONV_DESC = 714,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DW        = 715,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_X         = 716,
    CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DY        = 717,
    CUDNN_ATTR_OPERATION_POINTWISE_PW_DESCRIPTOR          = 750,
    CUDNN_ATTR_OPERATION_POINTWISE_XDESC                  = 751,
    CUDNN_ATTR_OPERATION_POINTWISE_BDESC                  = 752,
    CUDNN_ATTR_OPERATION_POINTWISE_YDESC                  = 753,
    CUDNN_ATTR_OPERATION_POINTWISE_ALPHA1                 = 754,
    CUDNN_ATTR_OPERATION_POINTWISE_ALPHA2                 = 755,
    CUDNN_ATTR_OPERATION_POINTWISE_DXDESC                 = 756,
    CUDNN_ATTR_OPERATION_POINTWISE_DYDESC                 = 757,
    CUDNN_ATTR_OPERATION_POINTWISE_TDESC                  = 758,

    CUDNN_ATTR_OPERATION_GENSTATS_MODE                    = 770,
    CUDNN_ATTR_OPERATION_GENSTATS_MATH_PREC               = 771,
    CUDNN_ATTR_OPERATION_GENSTATS_XDESC                   = 772,
    CUDNN_ATTR_OPERATION_GENSTATS_SUMDESC                 = 773,
    CUDNN_ATTR_OPERATION_GENSTATS_SQSUMDESC               = 774,

    CUDNN_ATTR_OPERATION_BN_FINALIZE_STATS_MODE                = 780,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_MATH_PREC                 = 781,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_Y_SUM_DESC                = 782,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_Y_SQ_SUM_DESC             = 783,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_SCALE_DESC                = 784,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_BIAS_DESC                 = 785,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_PREV_RUNNING_MEAN_DESC    = 786,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_PREV_RUNNING_VAR_DESC     = 787,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_UPDATED_RUNNING_MEAN_DESC = 788,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_UPDATED_RUNNING_VAR_DESC  = 789,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_SAVED_MEAN_DESC           = 790,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_SAVED_INV_STD_DESC        = 791,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_EQ_SCALE_DESC             = 792,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_EQ_BIAS_DESC              = 793,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_ACCUM_COUNT_DESC          = 794,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_EPSILON_DESC              = 795,
    CUDNN_ATTR_OPERATION_BN_FINALIZE_EXP_AVERATE_FACTOR_DESC   = 796,

    CUDNN_ATTR_OPERATIONGRAPH_HANDLE              = 800,
    CUDNN_ATTR_OPERATIONGRAPH_OPS                 = 801,
    CUDNN_ATTR_OPERATIONGRAPH_ENGINE_GLOBAL_COUNT = 802,
 
    CUDNN_ATTR_TENSOR_BYTE_ALIGNMENT       = 900,
    CUDNN_ATTR_TENSOR_DATA_TYPE            = 901,
    CUDNN_ATTR_TENSOR_DIMENSIONS           = 902,
    CUDNN_ATTR_TENSOR_STRIDES              = 903,
    CUDNN_ATTR_TENSOR_VECTOR_COUNT         = 904,
    CUDNN_ATTR_TENSOR_VECTORIZED_DIMENSION = 905,
    CUDNN_ATTR_TENSOR_UNIQUE_ID            = 906,
    CUDNN_ATTR_TENSOR_IS_VIRTUAL           = 907,
    CUDNN_ATTR_TENSOR_IS_BY_VALUE          = 908,
    CUDNN_ATTR_TENSOR_REORDERING_MODE      = 909,
    CUDNN_ATTR_TENSOR_RAGGED_OFFSET_DESC   = 910,

    CUDNN_ATTR_VARIANT_PACK_UNIQUE_IDS    = 1000,
    CUDNN_ATTR_VARIANT_PACK_DATA_POINTERS = 1001,
    CUDNN_ATTR_VARIANT_PACK_INTERMEDIATES = 1002,
    CUDNN_ATTR_VARIANT_PACK_WORKSPACE     = 1003,

    CUDNN_ATTR_LAYOUT_INFO_TENSOR_UID = 1100,
    CUDNN_ATTR_LAYOUT_INFO_TYPES      = 1101,

    CUDNN_ATTR_KNOB_INFO_TYPE          = 1200,
    CUDNN_ATTR_KNOB_INFO_MAXIMUM_VALUE = 1201,
    CUDNN_ATTR_KNOB_INFO_MINIMUM_VALUE = 1202,
    CUDNN_ATTR_KNOB_INFO_STRIDE        = 1203,

    CUDNN_ATTR_ENGINE_OPERATION_GRAPH = 1300,
    CUDNN_ATTR_ENGINE_GLOBAL_INDEX    = 1301,
    CUDNN_ATTR_ENGINE_KNOB_INFO       = 1302,
    CUDNN_ATTR_ENGINE_NUMERICAL_NOTE  = 1303,
    CUDNN_ATTR_ENGINE_LAYOUT_INFO     = 1304,
    CUDNN_ATTR_ENGINE_BEHAVIOR_NOTE   = 1305,
    CUDNN_ATTR_ENGINE_SM_COUNT_TARGET = 1306,

    CUDNN_ATTR_MATMUL_COMP_TYPE       = 1500,
   CUDNN_ATTR_MATMUL_PADDING_VALUE    = 1501,

    CUDNN_ATTR_OPERATION_MATMUL_ADESC                           = 1520,
    CUDNN_ATTR_OPERATION_MATMUL_BDESC                           = 1521,
    CUDNN_ATTR_OPERATION_MATMUL_CDESC                           = 1522,
    CUDNN_ATTR_OPERATION_MATMUL_DESC                            = 1523,
    CUDNN_ATTR_OPERATION_MATMUL_IRREGULARLY_STRIDED_BATCH_COUNT = 1524,
    CUDNN_ATTR_OPERATION_MATMUL_GEMM_M_OVERRIDE_DESC            = 1525,
    CUDNN_ATTR_OPERATION_MATMUL_GEMM_N_OVERRIDE_DESC            = 1526,
    CUDNN_ATTR_OPERATION_MATMUL_GEMM_K_OVERRIDE_DESC            = 1527,


    CUDNN_ATTR_REDUCTION_OPERATOR  = 1600,
    CUDNN_ATTR_REDUCTION_COMP_TYPE = 1601,

    CUDNN_ATTR_OPERATION_REDUCTION_XDESC = 1610,
    CUDNN_ATTR_OPERATION_REDUCTION_YDESC = 1611,
    CUDNN_ATTR_OPERATION_REDUCTION_DESC  = 1612,

    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_MATH_PREC        = 1620,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_MEAN_DESC        = 1621,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_INVSTD_DESC      = 1622,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_BN_SCALE_DESC    = 1623,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_X_DESC           = 1624,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_DY_DESC          = 1625,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_DBN_SCALE_DESC   = 1626,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_DBN_BIAS_DESC    = 1627,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_EQ_DY_SCALE_DESC = 1628,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_EQ_X_SCALE_DESC  = 1629,
    CUDNN_ATTR_OPERATION_BN_BWD_WEIGHTS_EQ_BIAS          = 1630,

    CUDNN_ATTR_RESAMPLE_MODE            = 1700,
    CUDNN_ATTR_RESAMPLE_COMP_TYPE       = 1701,
    CUDNN_ATTR_RESAMPLE_SPATIAL_DIMS    = 1702,
    CUDNN_ATTR_RESAMPLE_POST_PADDINGS   = 1703,
    CUDNN_ATTR_RESAMPLE_PRE_PADDINGS    = 1704,
    CUDNN_ATTR_RESAMPLE_STRIDES         = 1705,
    CUDNN_ATTR_RESAMPLE_WINDOW_DIMS     = 1706,
    CUDNN_ATTR_RESAMPLE_NAN_PROPAGATION = 1707,
    CUDNN_ATTR_RESAMPLE_PADDING_MODE    = 1708,

    CUDNN_ATTR_OPERATION_RESAMPLE_FWD_XDESC   = 1710,
    CUDNN_ATTR_OPERATION_RESAMPLE_FWD_YDESC   = 1711,
    CUDNN_ATTR_OPERATION_RESAMPLE_FWD_IDXDESC = 1712,
    CUDNN_ATTR_OPERATION_RESAMPLE_FWD_ALPHA   = 1713,
    CUDNN_ATTR_OPERATION_RESAMPLE_FWD_BETA    = 1714,
    CUDNN_ATTR_OPERATION_RESAMPLE_FWD_DESC    = 1716,

    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_DXDESC  = 1720,
    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_DYDESC  = 1721,
    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_IDXDESC = 1722,
    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_ALPHA   = 1723,
    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_BETA    = 1724,
    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_DESC    = 1725,
    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_XDESC   = 1726,
    CUDNN_ATTR_OPERATION_RESAMPLE_BWD_YDESC   = 1727,

    CUDNN_ATTR_OPERATION_CONCAT_AXIS          = 1800,
    CUDNN_ATTR_OPERATION_CONCAT_INPUT_DESCS   = 1801,
    CUDNN_ATTR_OPERATION_CONCAT_INPLACE_INDEX = 1802,
    CUDNN_ATTR_OPERATION_CONCAT_OUTPUT_DESC   = 1803,

    CUDNN_ATTR_OPERATION_SIGNAL_MODE     = 1900,
    CUDNN_ATTR_OPERATION_SIGNAL_FLAGDESC = 1901,
    CUDNN_ATTR_OPERATION_SIGNAL_VALUE    = 1902,
    CUDNN_ATTR_OPERATION_SIGNAL_XDESC    = 1903,
    CUDNN_ATTR_OPERATION_SIGNAL_YDESC    = 1904,

    CUDNN_ATTR_OPERATION_NORM_FWD_MODE                     = 2000,
    CUDNN_ATTR_OPERATION_NORM_FWD_PHASE                    = 2001,
    CUDNN_ATTR_OPERATION_NORM_FWD_XDESC                    = 2002,
    CUDNN_ATTR_OPERATION_NORM_FWD_MEAN_DESC                = 2003,
    CUDNN_ATTR_OPERATION_NORM_FWD_INV_VARIANCE_DESC        = 2004,
    CUDNN_ATTR_OPERATION_NORM_FWD_SCALE_DESC               = 2005,
    CUDNN_ATTR_OPERATION_NORM_FWD_BIAS_DESC                = 2006,
    CUDNN_ATTR_OPERATION_NORM_FWD_EPSILON_DESC             = 2007,
    CUDNN_ATTR_OPERATION_NORM_FWD_EXP_AVG_FACTOR_DESC      = 2008,
    CUDNN_ATTR_OPERATION_NORM_FWD_INPUT_RUNNING_MEAN_DESC  = 2009,
    CUDNN_ATTR_OPERATION_NORM_FWD_INPUT_RUNNING_VAR_DESC   = 2010,
    CUDNN_ATTR_OPERATION_NORM_FWD_OUTPUT_RUNNING_MEAN_DESC = 2011,
    CUDNN_ATTR_OPERATION_NORM_FWD_OUTPUT_RUNNING_VAR_DESC  = 2012,
    CUDNN_ATTR_OPERATION_NORM_FWD_YDESC                    = 2013,
    CUDNN_ATTR_OPERATION_NORM_FWD_PEER_STAT_DESCS          = 2014,

    CUDNN_ATTR_OPERATION_NORM_BWD_MODE              = 2100,
    CUDNN_ATTR_OPERATION_NORM_BWD_XDESC             = 2101,
    CUDNN_ATTR_OPERATION_NORM_BWD_MEAN_DESC         = 2102,
    CUDNN_ATTR_OPERATION_NORM_BWD_INV_VARIANCE_DESC = 2103,
    CUDNN_ATTR_OPERATION_NORM_BWD_DYDESC            = 2104,
    CUDNN_ATTR_OPERATION_NORM_BWD_SCALE_DESC        = 2105,
    CUDNN_ATTR_OPERATION_NORM_BWD_EPSILON_DESC      = 2106,
    CUDNN_ATTR_OPERATION_NORM_BWD_DSCALE_DESC       = 2107,
    CUDNN_ATTR_OPERATION_NORM_BWD_DBIAS_DESC        = 2108,
    CUDNN_ATTR_OPERATION_NORM_BWD_DXDESC            = 2109,
    CUDNN_ATTR_OPERATION_NORM_BWD_PEER_STAT_DESCS   = 2110,

    CUDNN_ATTR_OPERATION_RESHAPE_XDESC = 2200,
    CUDNN_ATTR_OPERATION_RESHAPE_YDESC = 2201,

    CUDNN_ATTR_RNG_DISTRIBUTION                   = 2300,
    CUDNN_ATTR_RNG_NORMAL_DIST_MEAN               = 2301,
    CUDNN_ATTR_RNG_NORMAL_DIST_STANDARD_DEVIATION = 2302,
    CUDNN_ATTR_RNG_UNIFORM_DIST_MAXIMUM           = 2303,
    CUDNN_ATTR_RNG_UNIFORM_DIST_MINIMUM           = 2304,
    CUDNN_ATTR_RNG_BERNOULLI_DIST_PROBABILITY     = 2305,

    CUDNN_ATTR_OPERATION_RNG_YDESC       = 2310,
    CUDNN_ATTR_OPERATION_RNG_SEED        = 2311,
    CUDNN_ATTR_OPERATION_RNG_DESC        = 2312,
    CUDNN_ATTR_OPERATION_RNG_OFFSET_DESC = 2313,

} cudnnBackendAttributeName_t;
</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendAttributeType_t"><a name="cudnnBackendAttributeType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendAttributeType_t" name="cudnnBackendAttributeType_t" shape="rect">9.1.1.2.&nbsp;<kbd class="ph userinput">cudnnBackendAttributeType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract">The enumeration type <samp class="ph codeph">cudnnBackendAttributeType_t</samp> specifies the data
                                 type of an attribute of a cuDNN backend descriptor. It is used to specify the type of data
                                 pointed to by the <samp class="ph codeph">void *arrayOfElements</samp> argument of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_TYPE_HANDLE = 0,
    CUDNN_TYPE_DATA_TYPE,
    CUDNN_TYPE_BOOLEAN,
    CUDNN_TYPE_INT64,
    CUDNN_TYPE_FLOAT,
    CUDNN_TYPE_DOUBLE,
    CUDNN_TYPE_VOID_PTR,
    CUDNN_TYPE_CONVOLUTION_MODE,
    CUDNN_TYPE_HEUR_MODE,
    CUDNN_TYPE_KNOB_TYPE,
    CUDNN_TYPE_NAN_PROPOGATION,
    CUDNN_TYPE_NUMERICAL_NOTE,
    CUDNN_TYPE_LAYOUT_TYPE,
    CUDNN_TYPE_ATTRIB_NAME,
    CUDNN_TYPE_POINTWISE_MODE,
    CUDNN_TYPE_BACKEND_DESCRIPTOR,
    CUDNN_TYPE_GENSTATS_MODE,
    CUDNN_TYPE_BN_FINALIZE_STATS_MODE,
    CUDNN_TYPE_REDUCTION_OPERATOR_TYPE,
    CUDNN_TYPE_BEHAVIOR_NOTE,
    CUDNN_TYPE_TENSOR_REORDERING_MODE,
    CUDNN_TYPE_RESAMPLE_MODE,
    CUDNN_TYPE_PADDING_MODE,
    CUDNN_TYPE_INT32,
    CUDNN_TYPE_CHAR,
    CUDNN_TYPE_SIGNAL_MODE,
    CUDNN_TYPE_FRACTION,
    CUDNN_TYPE_NORM_MODE,
    CUDNN_TYPE_NORM_FWD_PHASE,
    CUDNN_TYPE_RNG_DISTRIBUTION
} cudnnBackendAttributeType_t;
</pre><div class="p">
                                 <div class="tablenoborder"><a name="cudnnBackendAttributeType_t__table_pwl_x4d_qmb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnBackendAttributeType_t__table_pwl_x4d_qmb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 51. Attribute Types for <samp class="ph codeph">cudnnBackendAttributeType_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">cudnnBackendAttributeType_t</samp></th>
                                             <th class="entry" valign="top" width="50%" id="d54e98990" rowspan="1" colspan="1">Attribute type</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_HANDLE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_DATA_TYPE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_BOOLEAN</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><samp class="ph codeph">bool</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_INT64</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><samp class="ph codeph">int64_t</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_FLOAT</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><samp class="ph codeph">float</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><samp class="ph codeph">double</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_VOID_PTR</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><samp class="ph codeph">void *</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_CONVOLUTION_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnConvolutionMode_t" shape="rect">cudnnConvolutionMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_HEUR_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendHeurMode_t" title="cudnnBackendHeurMode_t is an enumerated type that indicates the operation mode of a CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR." shape="rect">cudnnBackendHeurMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_KNOB_TYPE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendKnobType_t" shape="rect">cudnnBackendKnobType_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_NAN_PROPOGATION</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnNanPropagation_t" shape="rect">cudnnNanPropagation_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_NUMERICAL_NOTE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendNumericalNote_t" shape="rect">cudnnBackendNumericalNote_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_LAYOUT_TYPE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendLayoutType_t" shape="rect">cudnnBackendLayoutType_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_ATTRIB_NAME</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_POINTWISE_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnPointwiseMode_t" title="cudnnPointwiseMode_t is an enumerated type to indicate the intended pointwise math operation in the backend pointwise operation descriptor." shape="rect">cudnnPointwiseMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_GENSTATS_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnGenStatsMode_t" title="cudnnGenStatsMode_t is an enumerated type to indicate the statistics mode in the backend statistics generation operation." shape="rect">cudnnGenStatsMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_BN_FINALIZE_STATS_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBnFinalizeStatsMode_t" title="cudnnBnFinalizeStatsMode_t is an enumerated type that exposes the different mathematical operation modes that converts batchnorm statistics and the trained scale and bias to the equivalent scale and bias to be applied in the next normalization stage for inference and training use cases." shape="rect">cudnnBnFinalizeStatsMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_REDUCTION_OPERATOR_TYPE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnReduceTensorOp_t" shape="rect">cudnnReduceTensorOp_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_BEHAVIOR_NOTE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendBehaviorNote_t" shape="rect">cudnnBackendBehaviorNote_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_TENSOR_REORDERING_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendTensorReordering_t" shape="rect">cudnnBackendTensorReordering_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_RESAMPLE_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnResampleMode_t" title="cudnnResampleMode_t is an enumerated type to indicate the resample mode in the backend resample operations." shape="rect">cudnnResampleMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_PADDING_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnPaddingMode_t" title="cudnnPaddingMode_t is an enumerated type to indicate the padding mode in the backend resample operations." shape="rect">cudnnPaddingMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_INT32</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><samp class="ph codeph">int32_t</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_CHAR</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><samp class="ph codeph">char</samp></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_SIGNAL_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnSignalMode_t" title="cudnnSignalMode_t is an enumerated type to indicate the signaling mode in the backend signal operation." shape="rect">cudnnSignalMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_FRACTION</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnFraction_t" title="cudnnFraction_t is a structure that allows a user to define int64_t fractions." shape="rect">cudnnFraction_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_NORM_MODE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendNormMode_t" title="cudnnBackendNormMode_t is an enumerated type to indicate the normalization mode in the backend normalization forward and normalization backward operations." shape="rect">cudnnBackendNormMode_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_NORM_FWD_PHASE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnBackendNormFwdPhase_t" title="cudnnBackendNormFwdPhase_t is an enumerated type used to distinguish the inference and training phase of the normalization forward operation." shape="rect">cudnnBackendNormFwdPhase_t</a></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e98986" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_TYPE_RNG_DISTRIBUTION</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e98990" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnRngDistribution_t" title="cudnnRngDistribution_t is an enumerated type to indicate the distribution to be used in the backend Rng (random number generator) operation." shape="rect">cudnnRngDistribution_t</a></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendBehaviorNote_t"><a name="cudnnBackendBehaviorNote_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendBehaviorNote_t" name="cudnnBackendBehaviorNote_t" shape="rect">9.1.1.3.&nbsp;<kbd class="ph userinput">cudnnBackendBehaviorNote_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendBehaviorNote_t </samp>is an enumerated type that indicates
                                 queryable behavior notes of an engine. Users can query for an array of behavior notes from
                                 an <samp class="ph codeph">CUDNN_BACKEND_ENGINE_DESC</samp> using the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> function. <span class="shortdesc"></span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_BEHAVIOR_NOTE_RUNTIME_COMPILATION             = 0,
    CUDNN_BEHAVIOR_NOTE_REQUIRES_FILTER_INT8x32_REORDER = 1,
    CUDNN_BEHAVIOR_NOTE_REQUIRES_BIAS_INT8x32_REORDER   = 2,
    CUDNN_BEHAVIOR_NOTE_TYPE_COUNT,
} cudnnBackendBehaviorNote_t;
</pre></div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendDescriptorType_t"><a name="cudnnBackendDescriptorType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendDescriptorType_t" name="cudnnBackendDescriptorType_t" shape="rect">9.1.1.4.&nbsp;<kbd class="ph userinput">cudnnBackendDescriptorType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendDescriptor_t</samp> is an enumerated type that indicates the
                                 type of backend descriptors. Users create a backend descriptor of a particular type by
                                 passing a value from this enumerate to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendCreateDescriptor" title="This function allocates memory in the descriptor for a given descriptor type and at the location pointed by the descriptor." shape="rect">cudnnBackendCreateDescriptor()</a></samp> function. <span class="shortdesc"></span></div>
                              <div class="p"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_BACKEND_POINTWISE_DESCRIPTOR = 0,
    CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR,
    CUDNN_BACKEND_ENGINE_DESCRIPTOR,
    CUDNN_BACKEND_ENGINECFG_DESCRIPTOR,
    CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR,
    CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR,
    CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR,
    CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR,
    CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR,
    CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR,
    CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR,
    CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR,
    CUDNN_BACKEND_TENSOR_DESCRIPTOR,
    CUDNN_BACKEND_MATMUL_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_BN_FINALIZE_STATISTICS_DESCRIPTOR,
    CUDNN_BACKEND_REDUCTION_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_BN_BWD_WEIGHTS_DESCRIPTOR,
    CUDNN_BACKEND_RESAMPLE_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR,
    CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR,
} cudnnBackendDescriptorType_t;
</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendHeurMode_t"><a name="cudnnBackendHeurMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendHeurMode_t" name="cudnnBackendHeurMode_t" shape="rect">9.1.1.5.&nbsp;<kbd class="ph userinput">cudnnBackendHeurMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnBackendHeurMode_t</samp> is an enumerated type that indicates the
                                    operation mode of a <samp class="ph codeph">CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR</samp>.</span></div>
                              <div class="p"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_HEUR_MODE_INSTANT  = 0,
    CUDNN_HEUR_MODE_B        = 1,
    CUDNN_HEUR_MODE_FALLBACK = 2,
    CUDNN_HEUR_MODE_A        = 3
}
</pre></div>
                              <div class="section" id="cudnnBackendHeurMode_t__section_wpx_tdr_2jb"><a name="cudnnBackendHeurMode_t__section_wpx_tdr_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_HEUR_MODE_A &amp; CUDNN_HEUR_MODE_INSTANT</samp></dt>
                                       <dd class="dd">
                                          <p class="p"><samp class="ph codeph">CUDNN_HEUR_MODE_A</samp> provides the exact same
                                             functionality as<samp class="ph codeph"> CUDNN_HEUR_MODE_INSTANT</samp>. The
                                             purpose of this renaming is to better match the naming of
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_B</samp>. Consider the use of
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_INSTANT</samp> as deprecated; instead,
                                             use <samp class="ph codeph">CUDNN_HEUR_MODE_A</samp>.
                                          </p>
                                          <p class="p"><samp class="ph codeph">CUDNN_HEUR_MODE_A</samp> utilizes a decision tree heuristic
                                             which provides optimal inference time on the CPU in comparison to
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_B</samp>.
                                          </p>
                                          <div class="p"><samp class="ph codeph">CUDNN_HEUR_MODE_A</samp> and
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_INSTANT</samp> support the following
                                             operation node or operation graph:<a name="cudnnBackendHeurMode_t__ul_cdp_q1x_cwb" shape="rect">
                                                <!-- --></a><ul class="ul" id="cudnnBackendHeurMode_t__ul_cdp_q1x_cwb">
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#convolutionfwd" target="_blank" shape="rect"><samp class="ph codeph">ConvolutionFwd</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#convolutionbwfilter" target="_blank" shape="rect"><samp class="ph codeph">ConvlutionBwFilter</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#convolutionbwdata" target="_blank" shape="rect"><samp class="ph codeph">ConvolutionBwData</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#convbnfprop" target="_blank" shape="rect"><samp class="ph codeph">ConvBNfprop</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#convbnwgrad" target="_blank" shape="rect"><samp class="ph codeph">ConvBNwgrad</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#convbiasact" target="_blank" shape="rect"><samp class="ph codeph">ConvBiasAct</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#convscalebiasact" target="_blank" shape="rect"><samp class="ph codeph">ConvScaleBiasAct</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#dgraddrelubnbwdweight" target="_blank" shape="rect"><samp class="ph codeph">DgradDreluBNBwdWeight</samp></a></li>
                                                <li class="li"><a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#runtime-fusion-engine" target="_blank" shape="rect">patterns supported by the
                                                      runtime fusion engine</a></li>
                                             </ul>
                                             
                                             All other operation graphs are not supported.
                                          </div>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_HEUR_MODE_B</samp></dt>
                                       <dd class="dd">
                                          <div class="p">Can utilize the neural net based heuristics to improve generalization
                                             performance compared to <samp class="ph codeph">CUDNN_HEUR_MODE_INSTANT</samp>. In
                                             cases where the neural net is utilized, inference time on the CPU
                                             will be increased by 10-100x compared to
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_INSTANT</samp>. These neural net
                                             heuristics are not supported for any of the following cases:<a name="cudnnBackendHeurMode_t__ul_z1t_kmj_5pb" shape="rect">
                                                <!-- --></a><ul class="ul" id="cudnnBackendHeurMode_t__ul_z1t_kmj_5pb">
                                                <li class="li">3-D convolutions</li>
                                                <li class="li">Grouped convolutions (groupCount larger than 1)</li>
                                                <li class="li">Dilated convolutions (any dilation for any spatial dimension
                                                   larger than 1)
                                                </li>
                                             </ul>
                                          </div>
                                          <p class="p">Further, the neural net is only enabled on x86 platforms when cuDNN
                                             is run on an A100 GPU. In cases where the neural net is not
                                             supported, <samp class="ph codeph">CUDNN_HEUR_MODE_B</samp> will also fall back to
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_INSTANT</samp>.
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_B</samp> will fall back to
                                             <samp class="ph codeph">CUDNN_HEUR_MODE_INSTANT</samp> in cases where the
                                             overhead of <samp class="ph codeph">CUDNN_HEUR_MODE_B</samp> is projected to
                                             reduce overall network performance.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_HEUR_MODE_FALLBACK</samp></dt>
                                       <dd class="dd">This heuristic mode is intended to be used for finding fallback options
                                          which provide functional support (without any expectation of providing
                                          optimal GPU performance). 
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendKnobType_t"><a name="cudnnBackendKnobType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendKnobType_t" name="cudnnBackendKnobType_t" shape="rect">9.1.1.6.&nbsp;<kbd class="ph userinput">cudnnBackendKnobType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendKnobType_t</samp> is an enumerated type that indicates the type
                                 of performance knobs. Performance knobs are runtime settings to an engine that will affect
                                 its performance. Users can query for an array of performance knobs and their valid value
                                 range from a <samp class="ph codeph">CUDNN_BACKEND_ENGINE_DESCRIPTOR</samp> using the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> function. Users can set the choice for
                                 each knob using the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp> function with
                                 a <samp class="ph codeph">CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR</samp> descriptor. <span class="shortdesc"></span></div>
                              <div class="p"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_KNOB_TYPE_SPLIT_K          = 0,
    CUDNN_KNOB_TYPE_SWIZZLE          = 1,
    CUDNN_KNOB_TYPE_TILE_SIZE        = 2,
    CUDNN_KNOB_TYPE_USE_TEX          = 3,
    CUDNN_KNOB_TYPE_EDGE             = 4,
    CUDNN_KNOB_TYPE_KBLOCK           = 5,
    CUDNN_KNOB_TYPE_LDGA             = 6,
    CUDNN_KNOB_TYPE_LDGB             = 7,
    CUDNN_KNOB_TYPE_CHUNK_K          = 8,
    CUDNN_KNOB_TYPE_SPLIT_H          = 9,
    CUDNN_KNOB_TYPE_WINO_TILE        = 10,
    CUDNN_KNOB_TYPE_MULTIPLY         = 11,
    CUDNN_KNOB_TYPE_SPLIT_K_BUF      = 12,
    CUDNN_KNOB_TYPE_TILEK            = 13,
    CUDNN_KNOB_TYPE_STAGES           = 14,
    CUDNN_KNOB_TYPE_REDUCTION_MODE   = 15,
    CUDNN_KNOB_TYPE_CTA_SPLIT_K_MODE = 16,
    CUDNN_KNOB_TYPE_SPLIT_K_SLC      = 17,
    CUDNN_KNOB_TYPE_IDX_MODE         = 18,
    CUDNN_KNOB_TYPE_SLICED           = 19,
    CUDNN_KNOB_TYPE_SPLIT_RS         = 20,
    CUDNN_KNOB_TYPE_SINGLEBUFFER     = 21,
    CUDNN_KNOB_TYPE_LDGC             = 22,
    CUDNN_KNOB_TYPE_SPECFILT         = 23,
    CUDNN_KNOB_TYPE_KERNEL_CFG       = 24,
    CUDNN_KNOB_TYPE_WORKSPACE        = 25,

    CUDNN_KNOB_TYPE_COUNTS = 26,
} cudnnBackendKnobType_t;
</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendLayoutType_t"><a name="cudnnBackendLayoutType_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendLayoutType_t" name="cudnnBackendLayoutType_t" shape="rect">9.1.1.7.&nbsp;<kbd class="ph userinput">cudnnBackendLayoutType_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendLayoutType_t</samp> is an enumerated type that indicates
                                 queryable layout requirements of an engine. Users can query for layout requirements from a
                                 <samp class="ph codeph">CUDNN_BACKEND_ENGINE_DESC</samp> descriptor using the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> function. <span class="shortdesc"></span></div>
                              <div class="p"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_LAYOUT_TYPE_PREFERRED_NCHW   = 0,
    CUDNN_LAYOUT_TYPE_PREFERRED_NHWC   = 1,
    CUDNN_LAYOUT_TYPE_PREFERRED_PAD4CK = 2,
    CUDNN_LAYOUT_TYPE_PREFERRED_PAD8CK = 3,
    CUDNN_LAYOUT_TYPE_COUNT            = 4,
} cudnnBackendLayoutType_t;
</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendNormFwdPhase_t"><a name="cudnnBackendNormFwdPhase_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendNormFwdPhase_t" name="cudnnBackendNormFwdPhase_t" shape="rect">9.1.1.8.&nbsp;<kbd class="ph userinput">cudnnBackendNormFwdPhase_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnBackendNormFwdPhase_t</samp> is an enumerated type used to
                                    distinguish the inference and training phase of the normalization forward
                                    operation.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_NORM_FWD_INFERENCE = 0,
    CUDNN_NORM_FWD_TRAINING  = 1,
} cudnnBackendNormFwdPhase_t;
</pre></div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendNormMode_t"><a name="cudnnBackendNormMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendNormMode_t" name="cudnnBackendNormMode_t" shape="rect">9.1.1.9.&nbsp;<kbd class="ph userinput">cudnnBackendNormMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnBackendNormMode_t</samp> is an enumerated type to indicate the
                                    normalization mode in the backend normalization forward and normalization backward
                                    operations.</span></div>
                              <div class="p">For reference:<a name="cudnnBackendNormMode_t__ul_tws_gs1_jwb" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnBackendNormMode_t__ul_tws_gs1_jwb">
                                    <li class="li">The definition of layer normalization can be found in the <a class="xref" href="https://arxiv.org/abs/1607.06450" target="_blank" shape="rect">Layer
                                          Normalization</a> paper.
                                    </li>
                                    <li class="li">The definition of instance normalization can be found in the <a class="xref" href="https://arxiv.org/abs/1607.08022" target="_blank" shape="rect">Instance Normalization: The Missing Ingredient for Fast Stylization</a>
                                       paper.
                                    </li>
                                    <li class="li">The definition of batch normalization can be found in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">Batch
                                          Normalization: Accelerating Deep Network Training by Reducing Internal
                                          Covariate Shift</a> paper.
                                    </li>
                                    <li class="li">The definition of root mean square normalization can be found in the <a class="xref" href="https://arxiv.org/pdf/1910.07467.pdf" target="_blank" shape="rect">Root Mean Square Layer Normalization</a> paper.
                                    </li>
                                 </ul>
                              </div>
                              <p class="p"><samp class="ph codeph">CUDNN_GROUP_NORM</samp> is not yet supported. If you try to use it, cuDNN
                                 returns a <samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp> error.
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_LAYER_NORM    = 0,
    CUDNN_INSTANCE_NORM = 1,
    CUDNN_BATCH_NORM    = 2,
    CUDNN_GROUP_NORM    = 3,
    CUDNN_RMS_NORM      = 4,

} cudnnBackendNormMode_t
</pre></div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendNumericalNote_t"><a name="cudnnBackendNumericalNote_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendNumericalNote_t" name="cudnnBackendNumericalNote_t" shape="rect">9.1.1.10.&nbsp;<kbd class="ph userinput">cudnnBackendNumericalNote_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendNumericalNot_t</samp> is an enumerated type that indicates
                                 queryable numerical properties of an engine. Users can query for an array of numerical notes
                                 from an <samp class="ph codeph">CUDNN_BACKEND_ENGINE_DESC</samp> using the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> function. <span class="shortdesc"></span></div>
                              <div class="p"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_NUMERICAL_NOTE_TENSOR_CORE = 0,
    CUDNN_NUMERICAL_NOTE_DOWN_CONVERT_INPUTS,
    CUDNN_NUMERICAL_NOTE_REDUCED_PRECISION_REDUCTION,
    CUDNN_NUMERICAL_NOTE_FFT,
    CUDNN_NUMERICAL_NOTE_NONDETERMINISTIC,
    CUDNN_NUMERICAL_NOTE_WINOGRAD,
    CUDNN_NUMERICAL_NOTE_WINOGRAD_TILE_4x4,
    CUDNN_NUMERICAL_NOTE_WINOGRAD_TILE_6x6,
    CUDNN_NUMERICAL_NOTE_WINOGRAD_TILE_13x13,
    CUDNN_NUMERICAL_NOTE_TYPE_COUNT,
} cudnnBackendNumericalNote_t;
</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendTensorReordering_t"><a name="cudnnBackendTensorReordering_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendTensorReordering_t" name="cudnnBackendTensorReordering_t" shape="rect">9.1.1.11.&nbsp;<kbd class="ph userinput">cudnnBackendTensorReordering_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendTensorReordering_t</samp> is an enumerated type that indicates
                                 tensor reordering as a property of the tensor descriptor. Users can get and set this
                                 property in a <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp> via <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> functions. <span class="shortdesc"></span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_TENSOR_REORDERING_NONE    = 0,
    CUDNN_TENSOR_REORDERING_INT8x32 = 1,
    CUDNN_TENSOR_REORDERING_F16x16  = 2,
} cudnnBackendTensorReordering_t;
</pre></div>
                        </div>
                        <div class="topic concept nested3" id="cudnnBnFinalizeStatsMode_t"><a name="cudnnBnFinalizeStatsMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBnFinalizeStatsMode_t" name="cudnnBnFinalizeStatsMode_t" shape="rect">9.1.1.12.&nbsp;<kbd class="ph userinput">cudnnBnFinalizeStatsMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnBnFinalizeStatsMode_t</samp> is an enumerated type that exposes
                                    the different mathematical operation modes that converts batchnorm statistics and the
                                    trained scale and bias to the equivalent scale and bias to be applied in the next
                                    normalization stage for inference and training use cases.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_BN_FINALIZE_STATISTICS_TRAINING  = 0,
    CUDNN_BN_FINALIZE_STATISTICS_INFERENCE = 1,
} cudnnBnFinalizeStatsMode_t;
</pre><div class="p">
                                 <div class="tablenoborder"><a name="cudnnBnFinalizeStatsMode_t__table_xnh_s34_mtb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnBnFinalizeStatsMode_t__table_xnh_s34_mtb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 52. BN Statistics for <samp class="ph codeph">cudnnBnFinalizeStatsMode_t</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e99935" rowspan="1" colspan="1">BN Statistics Mode</th>
                                             <th class="entry" valign="top" width="50%" id="d54e99938" rowspan="1" colspan="1">Description</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e99935" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BN_FINALIZE_STATISTICS_TRAINING</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e99938" rowspan="1" colspan="1">
                                                <p class="p">Computes the equivalent scale and bias from
                                                   <samp class="ph codeph">ySum</samp>, <samp class="ph codeph">ySqSum</samp> and learned
                                                   <samp class="ph codeph">scale</samp>, <samp class="ph codeph">bias</samp>.
                                                </p>
                                                <p class="p">Optionally, update running statistics and generate saved stats
                                                   for interoperability with
                                                   <samp class="ph codeph">cudnnBatchNormalizationBackward()</samp>,
                                                   <samp class="ph codeph">cudnnBatchNormalizationBackwardEx()</samp>, or
                                                   <samp class="ph codeph">cudnnNormalizationBackward()</samp>.
                                                </p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e99935" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BN_FINALIZE_STATISTICS_INFERENCE</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e99938" rowspan="1" colspan="1">Computes the equivalent scale and bias from the learned running
                                                statistics and the learned <samp class="ph codeph">scale</samp>,
                                                <samp class="ph codeph">bias</samp>.
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnFraction_t"><a name="cudnnFraction_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFraction_t" name="cudnnFraction_t" shape="rect">9.1.1.13.&nbsp;<kbd class="ph userinput">cudnnFraction_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnFraction_t</samp> is a structure that allows a user to define
                                    <samp class="ph codeph">int64_t</samp> fractions.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudnnFractionStruct {
    int64_t numerator;
    int64_t denominator;
} cudnnFraction_t;
</pre></div>
                        </div>
                        <div class="topic concept nested3" id="cudnnGenStatsMode_t"><a name="cudnnGenStatsMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGenStatsMode_t" name="cudnnGenStatsMode_t" shape="rect">9.1.1.14.&nbsp;<kbd class="ph userinput">cudnnGenStatsMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnGenStatsMode_t</samp> is an enumerated type to indicate the statistics
                                    			mode in the backend statistics generation operation.</span></div>
                              <div class="section" id="cudnnGenStatsMode_t__section_pld_g2r_2jb"><a name="cudnnGenStatsMode_t__section_pld_g2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_GENSTATS_SUM_SQSUM</samp></dt>
                                       <dd class="dd">In this mode, the sum and sum of squares of the input tensor along the
                                          							specified dimensions are computed and written out. The reduction
                                          							dimensions currently supported are limited per channel, however
                                          							additional support may be added upon request.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnPaddingMode_t"><a name="cudnnPaddingMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPaddingMode_t" name="cudnnPaddingMode_t" shape="rect">9.1.1.15.&nbsp;<kbd class="ph userinput">cudnnPaddingMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnPaddingMode_t</samp> is an enumerated type to indicate the padding
                                    mode in the backend resample operations.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_ZERO_PAD     = 0,
    CUDNN_NEG_INF_PAD  = 1,
    CUDNN_EDGE_VAL_PAD = 2,
} cudnnPaddingMode_t;
</pre></div>
                        </div>
                        <div class="topic concept nested3" id="cudnnPointwiseMode_t"><a name="cudnnPointwiseMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPointwiseMode_t" name="cudnnPointwiseMode_t" shape="rect">9.1.1.16.&nbsp;<kbd class="ph userinput">cudnnPointwiseMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnPointwiseMode_t</samp> is an enumerated type to indicate the intended
                                    			pointwise math operation in the backend pointwise operation descriptor.</span></div>
                              <div class="section" id="cudnnPointwiseMode_t__section_pld_g2r_2jb"><a name="cudnnPointwiseMode_t__section_pld_g2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_ADD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise addition between two tensors is computed.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_ADD_SQUARE</samp></dt>
                                       <dd class="dd">In this mode, a pointwise addition between the first tensor and the
                                          							square of the second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_DIV</samp></dt>
                                       <dd class="dd">In this mode, a pointwise true division of the first tensor by second
                                          							tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_MAX</samp></dt>
                                       <dd class="dd">In this mode, a pointwise maximum is taken between two tensors.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_MIN</samp></dt>
                                       <dd class="dd">In this mode, a pointwise minimum is taken between two tensors.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_MOD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise floating-point remainder of the first tensor's
                                          							division by the second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_MUL</samp></dt>
                                       <dd class="dd">In this mode, a pointwise multiplication between two tensors is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_POW</samp></dt>
                                       <dd class="dd">In this mode, a pointwise value from the first tensor to the power of
                                          							the second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SUB</samp></dt>
                                       <dd class="dd">In this mode, a pointwise subtraction between two tensors is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_ABS</samp></dt>
                                       <dd class="dd">In this mode, a pointwise absolute value of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_CEIL</samp></dt>
                                       <dd class="dd">In this mode, a pointwise ceiling of the input tensor is computed.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_COS</samp></dt>
                                       <dd class="dd">In this mode, a pointwise trigonometric cosine of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_EXP</samp></dt>
                                       <dd class="dd">In this mode, a pointwise exponential of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_FLOOR</samp></dt>
                                       <dd class="dd">In this mode, a pointwise floor of the input tensor is computed.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_LOG</samp></dt>
                                       <dd class="dd">In this mode, a pointwise natural logarithm of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_NEG</samp></dt>
                                       <dd class="dd">In this mode, a pointwise numerical negative of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_RSQRT</samp></dt>
                                       <dd class="dd">In this mode, a pointwise reciprocal of the square root of the input
                                          							tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SIN</samp></dt>
                                       <dd class="dd">In this mode, a pointwise trigonometric sine of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SQRT</samp></dt>
                                       <dd class="dd">In this mode, a pointwise square root of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_TAN</samp></dt>
                                       <dd class="dd">In this mode, a pointwise trigonometric tangent of the input tensor is
                                          							computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_ERF</samp></dt>
                                       <dd class="dd">In this mode, a pointwise Error Function is computed.</dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_IDENTITY</samp></dt>
                                       <dd class="dd">In this mode, no computation is performed. As with other pointwise
                                          							modes, this mode provides implicit conversions by specifying the data
                                          							type of the input tensor as one type, and the data type of the output
                                          							tensor as another.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_RELU_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise rectified linear activation function of the
                                          							input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_TANH_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise tanh activation function of the input tensor
                                          							is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SIGMOID_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise sigmoid activation function of the input
                                          							tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_ELU_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise Exponential Linear Unit activation function of
                                          							the input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_GELU_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise Gaussian Error Linear Unit activation function
                                          							of the input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SOFTPLUS_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise softplus activation function of the input
                                          							tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SWISH_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise swish activation function of the input tensor
                                          							is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_GELU_APPROX_TANH_FWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise tanh approximation of the Gaussian Error Linear Unit activation
                                          							function of the input tensor is computed. The tanh GELU approximation is
                                          							computed as 
                                          								
                                          <math xmlns="http://www.w3.org/1998/Math/MathML">
                                             <mrow>
                                                <mn>0.5</mn>
                                                <mi>x</mi>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <mn>1</mn>
                                                   <mo>+</mo>
                                                   <mi>tanh</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>[</mo>
                                                   <mrow>
                                                      <msqrt>
                                                         <mrow>
                                                            <mn>2</mn>
                                                            <mo>/</mo>
                                                            <mi></mi>
                                                            <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                         </mrow>
                                                      </msqrt>
                                                      <mo>(</mo>
                                                      <mrow>
                                                         <mi>x</mi>
                                                         <mo>+</mo>
                                                         <mn>0.044715</mn>
                                                         <msup>
                                                            <mi>x</mi>
                                                            <mn>3</mn>
                                                         </msup>
                                                      </mrow>
                                                      <mo>)</mo>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   </mrow>
                                                   <mo>]</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                </mrow>
                                                <mo>)</mo>
                                             </mrow>
                                          </math>
                                          <p class="p">For more information, refer to the <a class="xref" href="https://arxiv.org/pdf/1606.08415.pdf" target="_blank" shape="rect">GAUSSIAN ERROR LINEAR UNIT (GELUS)</a>
                                             								paper.
                                          </p>
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_RELU_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of rectified linear
                                          							activation of the input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_TANH_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of tanh activation of the
                                          							input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SIGMOID_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of sigmoid activation of the
                                          							input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_ELU_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of Exponential Linear Unit
                                          							activation of the input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_GELU_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of Gaussian Error Linear Unit
                                          							activation of the input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SOFTPLUS_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of softplus activation of the
                                          							input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_SWISH_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of swish activation of the
                                          							input tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_GELU_APPROX_TANH_BWD</samp></dt>
                                       <dd class="dd">In this mode, a pointwise first derivative of the tanh approximation of
                                          							the Gaussian Error Linear Unit activation of the input tensor is
                                          							computed. This is computed as 
                                          								
                                          <math xmlns="http://www.w3.org/1998/Math/MathML">
                                             <mrow>
                                                <mn>0.5</mn>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mo>(</mo>
                                                <mrow>
                                                   <mn>1</mn>
                                                   <mo>+</mo>
                                                   <mi>tanh</mi>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <mi>b</mi>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>(</mo>
                                                      <mrow>
                                                         <mi>x</mi>
                                                         <mo>+</mo>
                                                         <msup>
                                                            <mi>cx</mi>
                                                            <mn>3</mn>
                                                         </msup>
                                                      </mrow>
                                                      <mo>)</mo>
                                                   </mrow>
                                                   <mo>)</mo>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>+</mo>
                                                   <msup>
                                                      <mi>bxsech</mi>
                                                      <mn>2</mn>
                                                   </msup>
                                                   <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <mi>b</mi>
                                                      <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                      <mo>(</mo>
                                                      <mrow>
                                                         <msup>
                                                            <mi>cx</mi>
                                                            <mn>3</mn>
                                                         </msup>
                                                         <mo>+</mo>
                                                         <mi>x</mi>
                                                      </mrow>
                                                      <mo>)</mo>
                                                   </mrow>
                                                   <mo>)</mo>
                                                   <mo>(</mo>
                                                   <mrow>
                                                      <msup>
                                                         <mrow>
                                                            <mn>3</mn>
                                                            <mi>cx</mi>
                                                         </mrow>
                                                         <mn>2</mn>
                                                      </msup>
                                                      <mo>+</mo>
                                                      <mn>1</mn>
                                                   </mrow>
                                                   <mo>)</mo>
                                                </mrow>
                                                <mo>)</mo>
                                                <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                                <mi>dy</mi>
                                             </mrow>
                                          </math>
                                          							 where 
                                          								
                                          <math xmlns="http://www.w3.org/1998/Math/MathML">
                                             <mrow>
                                                <mi>b</mi>
                                             </mrow>
                                          </math>
                                          							 is 
                                          								
                                          <math xmlns="http://www.w3.org/1998/Math/MathML">
                                             <mrow>
                                                <msqrt>
                                                   <mfrac>
                                                      <mn>2</mn>
                                                      <mi></mi>
                                                   </mfrac>
                                                </msqrt>
                                             </mrow>
                                          </math>
                                          							 and 
                                          								
                                          <math xmlns="http://www.w3.org/1998/Math/MathML">
                                             <mrow>
                                                <mi>c</mi>
                                             </mrow>
                                          </math>
                                          							 is 
                                          								
                                          <math xmlns="http://www.w3.org/1998/Math/MathML">
                                             <mrow>
                                                <mi>0.044715</mi>
                                             </mrow>
                                          </math>
                                          							.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_CMP_EQ</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor equal to the
                                          							second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_CMP_NEQ</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor not equal to
                                          							the second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_CMP_GT</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor greater than
                                          							the second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_CMP_GE</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor greater than
                                          							equal to the second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_CMP_LT</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor less than the
                                          							second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_CMP_LE</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor less than
                                          							equal to the second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_AND</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor logical
                                          								<samp class="ph codeph">AND</samp> second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_OR</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of the first tensor logical
                                          								<samp class="ph codeph">OR</samp> second tensor is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_LOGICAL_NOT</samp></dt>
                                       <dd class="dd">In this mode, a pointwise truth value of input tensor's logical
                                          								<samp class="ph codeph">NOT</samp> is computed.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_GEN_INDEX</samp></dt>
                                       <dd class="dd">In this mode, a pointwise index value of the input tensor is generated
                                          							along a given axis.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_BINARY_SELECT</samp></dt>
                                       <dd class="dd">In this mode, a pointwise value is selected amongst two input tensors
                                          							based on a given predicate tensor.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_POINTWISE_RECIPROCAL</samp></dt>
                                       <dd class="dd">In this mode, a pointwise reciprocal of the input tensor is computed. In
                                          							other words, for every element x in the input tensor, 1/x is
                                          							computed.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnResampleMode_t"><a name="cudnnResampleMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnResampleMode_t" name="cudnnResampleMode_t" shape="rect">9.1.1.17.&nbsp;<kbd class="ph userinput">cudnnResampleMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnResampleMode_t</samp> is an enumerated type to indicate the
                                    resample mode in the backend resample operations.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_RESAMPLE_NEAREST                 = 0,
    CUDNN_RESAMPLE_BILINEAR                = 1,
    CUDNN_RESAMPLE_AVGPOOL                 = 2,
    CUDNN_RESAMPLE_AVGPOOL_INCLUDE_PADDING = 2,
    CUDNN_RESAMPLE_AVGPOOL_EXCLUDE_PADDING = 4,
    CUDNN_RESAMPLE_MAXPOOL                 = 3,
} cudnnResampleMode_t;</pre></div>
                        </div>
                        <div class="topic concept nested3" id="cudnnRngDistribution_t"><a name="cudnnRngDistribution_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRngDistribution_t" name="cudnnRngDistribution_t" shape="rect">9.1.1.18.&nbsp;<kbd class="ph userinput">cudnnRngDistribution_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnRngDistribution_t</samp> is an enumerated type to indicate the
                                    distribution to be used in the backend <samp class="ph codeph">Rng</samp> (random number generator)
                                    operation.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_RNG_DISTRIBUTION_BERNOULLI,
    CUDNN_RNG_DISTRIBUTION_UNIFORM,
    CUDNN_RNG_DISTRIBUTION_NORMAL,
} cudnnRngDistribution_t;
</pre><div class="section" id="cudnnRngDistribution_t__section_pld_g2r_2jb"><a name="cudnnRngDistribution_t__section_pld_g2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNG_DISTRIBUTION_BERNOULLI</samp></dt>
                                       <dd class="dd">In this mode, the bernoulli distribution is used for the random number
                                          generation. The attribute
                                          <samp class="ph codeph">CUDNN_ATTR_RNG_BERNOULLI_DIST_PROBABILITY</samp> can be
                                          used to specify the probability of generating 1s.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_RNG_DISTRIBUTION_UNIFORM</samp></dt>
                                       <dd class="dd">In this mode, the normal distribution is used for the random number
                                          generation. The attribute
                                          <samp class="ph codeph">CUDNN_ATTR_RNG_NORMAL_DIST_MEAN</samp> and
                                          <samp class="ph codeph">CUDNN_ATTR_RNG_NORMAL_DIST_STANDARD_DEVIATION</samp> can
                                          be used to specify the mean and standard deviation of the random number
                                          generator.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="cudnnSignalMode_t"><a name="cudnnSignalMode_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSignalMode_t" name="cudnnSignalMode_t" shape="rect">9.1.1.19.&nbsp;<kbd class="ph userinput">cudnnSignalMode_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"><samp class="ph codeph">cudnnSignalMode_t</samp> is an enumerated type to indicate the
                                    signaling mode in the backend signal operation.</span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
    CUDNN_SIGNAL_SET  = 0,
    CUDNN_SIGNAL_WAIT = 1,
} cudnnSignalMode_t;
</pre><div class="section" id="cudnnSignalMode_t__section_pld_g2r_2jb"><a name="cudnnSignalMode_t__section_pld_g2r_2jb" shape="rect">
                                    <!-- --></a><h5 class="title sectiontitle">Values</h5>
                                 <div class="p">
                                    <dl class="dl">
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SIGNAL_SET</samp></dt>
                                       <dd class="dd">In this mode, the flag variable is updated with the provided signal
                                          value atomically.
                                       </dd>
                                       <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_SIGNAL_WAIT</samp></dt>
                                       <dd class="dd">In this mode, the operation blocks until the flag variable keeps
                                          comparing equal to the provided signal value.
                                       </dd>
                                    </dl>
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnn-cnn-infer-so-found"><a name="cudnn-cnn-infer-so-found" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnn-cnn-infer-so-found" name="cudnn-cnn-infer-so-found" shape="rect">9.1.2.&nbsp;Data Types Found In <kbd class="ph userinput">cudnn_backend.h</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">These are the data types found in <samp class="ph codeph">cudnn_backend.h</samp>.</span></div>
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" id="cudnnBackendDescriptor_t"><a name="cudnnBackendDescriptor_t" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendDescriptor_t" name="cudnnBackendDescriptor_t" shape="rect">9.1.2.1.&nbsp;<kbd class="ph userinput">cudnnBackendDescriptor_t</kbd></a></h3>
                           <div class="body conbody">
                              <div class="abstract"><samp class="ph codeph">cudnnBackendDescriptor_t</samp> is a typedef void pointer to one of many
                                 opaque <samp class="ph codeph">descriptor</samp> structures. The type of structure that it points to is
                                 determined by the argument when allocating the memory for the opaque structure using
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendCreateDescriptor" title="This function allocates memory in the descriptor for a given descriptor type and at the location pointed by the descriptor." shape="rect">cudnnBackendCreateDescriptor()</a></samp>. <span class="shortdesc"></span></div>
                              <p class="p">Attributes of a <samp class="ph codeph">descriptor</samp> can be set using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp>. After all required attributes of a
                                 <samp class="ph codeph">descriptor</samp> are set, the <samp class="ph codeph">descriptor</samp> can be
                                 finalized by <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp>. From a finalized
                                 <samp class="ph codeph">descriptor</samp>, one can query its queryable attributes using
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp>. Finally, the memory
                                 allocated for a <samp class="ph codeph">descriptor</samp> can be freed using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDestroyDescriptor" shape="rect">cudnnBackendDestroyDescriptor()</a></samp>.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="backend-api-functions"><a name="backend-api-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#backend-api-functions" name="backend-api-functions" shape="rect">9.2.&nbsp;API Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">These are the API functions in the cuDNN Backend API.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="cudnnBackendCreateDescriptor"><a name="cudnnBackendCreateDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendCreateDescriptor" name="cudnnBackendCreateDescriptor" shape="rect">9.2.1.&nbsp;<kbd class="ph userinput">cudnnBackendCreateDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function allocates memory in the <samp class="ph codeph">descriptor</samp> for a given
                                 <samp class="ph codeph">descriptor</samp> type and at the location pointed by the
                                 <samp class="ph codeph">descriptor</samp>.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnBackendCreateDescriptor(cudnnBackendDescriptorType_t descriptorType, cudnnBackendDescriptor_t *descriptor)</pre><div class="p">
                              <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">cudnnBackendDescriptor_t</samp> is a pointer to void
                                 <samp class="ph codeph">*</samp>.
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendCreateDescriptor__section_ckg_xzc_z3b"><a name="cudnnBackendCreateDescriptor__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptorType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. One among the enumerated <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptorType_t" shape="rect">cudnnBackendDescriptorType_t</a></samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptor</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to an instance of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp> to be created.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendCreateDescriptor__section_zpy_xzc_z3b"><a name="cudnnBackendCreateDescriptor__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The creation was successful.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Creating a descriptor of a given type is not supported.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The memory allocation failed.</dd>
                                 </dl>
                              </div>
                              <p class="p">Additional return values depend on the arguments used as explained in the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBackendDestroyDescriptor"><a name="cudnnBackendDestroyDescriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendDestroyDescriptor" name="cudnnBackendDestroyDescriptor" shape="rect">9.2.2.&nbsp;<kbd class="ph userinput">cudnnBackendDestroyDescriptor()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function destroys instances of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp> that were previously created using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendCreateDescriptor" title="This function allocates memory in the descriptor for a given descriptor type and at the location pointed by the descriptor." shape="rect">cudnnBackendCreateDescriptor()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnBackendDestroyDescriptor(cudnnBackendDescriptor_tdescriptor)</pre><div class="section" id="cudnnBackendDestroyDescriptor__section_ckg_xzc_z3b"><a name="cudnnBackendDestroyDescriptor__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptor</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Instance of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp> previously created
                                       by <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendCreateDescriptor" title="This function allocates memory in the descriptor for a given descriptor type and at the location pointed by the descriptor." shape="rect">cudnnBackendCreateDescriptor()</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendDestroyDescriptor__section_zpy_xzc_z3b"><a name="cudnnBackendDestroyDescriptor__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The memory was destroyed successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                                    <dd class="dd">The destruction of memory failed.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">Undefined Behavior</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">descriptor</samp> was altered between the
                                       <samp class="ph codeph">Create</samp> and <samp class="ph codeph">Destroy
                                          Descriptor</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">Undefined</samp></dt>
                                    <dd class="dd">The value pointed by the <samp class="ph codeph">descriptor</samp> will be
                                       <samp class="ph codeph">Undefined</samp> after the memory is free and done.
                                    </dd>
                                 </dl>
                              </div>
                              <p class="p">Additional return values depend on the arguments used as explained in the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBackendExecute"><a name="cudnnBackendExecute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendExecute" name="cudnnBackendExecute" shape="rect">9.2.3.&nbsp;<kbd class="ph userinput">cudnnBackendExecute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function executes the given <samp class="ph codeph">Engine Configuration Plan</samp> on
                                 the <samp class="ph codeph">VariantPack</samp> and the finalized <samp class="ph codeph">ExecutionPlan</samp> on the
                                 data. The data and the working space are encapsulated in the
                                 <samp class="ph codeph">VariantPack</samp>.</span></div><pre xml:space="preserve">cudnnStatus_ cudnnBackendExecute(cudnnHandle_t handle, cudnnBackendDescriptor_t executionPlan, cudnnBackendDescriptor_t varianPack)</pre><div class="section" id="cudnnBackendExecute__section_ckg_xzc_z3b"><a name="cudnnBackendExecute__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph"><strong class="ph b">executionPlan</strong></samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the cuDNN handle to be destroyed.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph"><strong class="ph b">variantPack</strong></samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Pointer to the finalized <samp class="ph codeph">VariantPack</samp>
                                       consisting of:<a name="cudnnBackendExecute__ul_jcd_3kb_5kb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBackendExecute__ul_jcd_3kb_5kb">
                                          <li class="li">Data pointer for each non-virtual pointer of the operation set
                                             in the execution plan.
                                          </li>
                                          <li class="li">Pointer to user-allocated workspace in global memory at least as
                                             large as the size queried from
                                             <samp class="ph codeph">CUDNN_BACKEND_</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendExecute__section_zpy_xzc_z3b"><a name="cudnnBackendExecute__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">ExecutionPlan</samp> was executed successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An incorrect or inconsistent value is encountered. Some examples:<a name="cudnnBackendExecute__ul_l5c_fb3_gmb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBackendExecute__ul_l5c_fb3_gmb">
                                          <li class="li">A required data pointer is invalid.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">Some internal errors were encountered.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                                    <dd class="dd">An error was encountered executing the plan with the variant pack.</dd>
                                 </dl>
                              </div>
                              <p class="p">Additional return values depend on the arguments used as explained in the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBackendFinalize"><a name="cudnnBackendFinalize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendFinalize" name="cudnnBackendFinalize" shape="rect">9.2.4.&nbsp;<kbd class="ph userinput">cudnnBackendFinalize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function finalizes the memory pointed to by the <samp class="ph codeph">descriptor</samp>. The
                              type of finalization is done depending on the <samp class="ph codeph">descriptorType</samp> argument with
                              which the <samp class="ph codeph">descriptor</samp> was created using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendCreateDescriptor" title="This function allocates memory in the descriptor for a given descriptor type and at the location pointed by the descriptor." shape="rect">cudnnBackendCreateDescriptor()</a></samp> or initialized using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendInitialize" title="This function repurposes a pre-allocated memory pointed to by a descriptor of size sizeInByte to a backend descriptor of type descriptorType. The finalized state of the descriptor is set to false." shape="rect">cudnnBackendInitialize()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnbBackendFinalize(cudnnBackendDescriptor descriptor)</pre><p class="p"><samp class="ph codeph">cudnnBackendFinalize()</samp> also checks all the attributes set between the
                              create/initialization and finalize phase. If successful,
                              <samp class="ph codeph">cudnnBackendFinalize()</samp> returns
                              <samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp> and the finalized state of the
                              <samp class="ph codeph">descriptor</samp> is set to <samp class="ph codeph">true</samp>. In this state, setting
                              attributes using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendSetAttribute" shape="rect">cudnnBackendSetAttribute()</a></samp> is not
                              allowed. Getting attributes using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> is only allowed when the finalized state of the
                              <samp class="ph codeph">descriptor</samp> is <samp class="ph codeph">true</samp>.
                           </p>
                           <div class="section" id="cudnnBackendFinalize__section_ckg_xzc_z3b"><a name="cudnnBackendFinalize__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptor</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Instance of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp> to finalize.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendFinalize__section_zpy_xzc_z3b"><a name="cudnnBackendFinalize__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">descriptor</samp> was finalized successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid <samp class="ph codeph">descriptor</samp> attribute values or combination
                                       thereof is encountered.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">Descriptor attribute values or combinations therefore not supported by
                                       the current version of cuDNN are encountered.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                                    <dd class="dd">Some internal errors are encountered.</dd>
                                 </dl>
                              </div>
                              <p class="p">Additional return values depend on the arguments used as explained in the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBackendGetAttribute"><a name="cudnnBackendGetAttribute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendGetAttribute" name="cudnnBackendGetAttribute" shape="rect">9.2.5.&nbsp;<kbd class="ph userinput">cudnnBackendGetAttribute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function retrieves the value(s) of an attribute of a <samp class="ph codeph">descriptor</samp>.
                              <samp class="ph codeph">attributeName</samp> is the name of the attribute whose value is requested.
                              The <samp class="ph codeph">attributeType</samp> is the type of attribute.
                              <samp class="ph codeph">requestsedElementCount</samp> is the number of elements to be potentially
                              retrieved. The number of elements for the requested attribute is stored in
                              <samp class="ph codeph">elementCount</samp>. The retrieved values are stored in
                              <samp class="ph codeph">arrayOfElements</samp>. When the attribute is expected to have a single value,
                              <samp class="ph codeph">arrayOfElements</samp> can be pointer to the output value. This function will
                              return <samp class="ph codeph">CUDNN_STATUS_NOT_INTIALIZED</samp> if the <em class="ph i">descriptor</em> has not been
                              successfully finalized using <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnBackendFinalize" target="_blank" shape="rect">cudnnBackendFinalize()</a>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnBackendGetAttribute(
    cudnnBackendDescriptor_t descriptor,
    cudnnBackendAttributeName_t attributeName,
    cudnnBackendAttributeType_t attributeType,
    int64_t requestedElementCount,
    int64_t *elementCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *arrayOfElements);
</pre><div class="section" id="cudnnBackendGetAttribute__section_ckg_xzc_z3b"><a name="cudnnBackendGetAttribute__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptor</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Instance of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp> whose attribute the
                                       user wants to retrieve.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attributeName</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The name of the attribute being get from the on the
                                       <samp class="ph codeph">descriptor</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attributeType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The type of attribute.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">requestedElementCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of elements to output to
                                       <samp class="ph codeph">arrayOfElements</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">elementCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Output pointer for the number of elements the
                                       <samp class="ph codeph">descriptor</samp> attribute has. Note that
                                       <samp class="ph codeph">cudnnBackendGetAttribute()</samp> will only write the
                                       least of this and <samp class="ph codeph">requestedElementCount</samp> elements to
                                       <samp class="ph codeph">arrayOfElements</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">arrayOfElements</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Array of elements of the datatype of the
                                       <samp class="ph codeph">attributeType</samp>. The datatype of the
                                       <samp class="ph codeph">attributeType</samp> is listed in the mapping table of
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeType_t" shape="rect">cudnnBackendAttributeType_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendGetAttribute__section_zpy_xzc_z3b"><a name="cudnnBackendGetAttribute__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">attributeName</samp> was given to the
                                       <samp class="ph codeph">descriptor</samp> successfully.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">One or more invalid or inconsistent argument values were encountered.
                                       Some examples:<a name="cudnnBackendGetAttribute__ul_hrd_lb3_gmb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBackendGetAttribute__ul_hrd_lb3_gmb">
                                          <li class="li"><samp class="ph codeph">attributeName</samp> is not a valid attribute for the
                                             descriptor.
                                          </li>
                                          <li class="li"><samp class="ph codeph">attributeType</samp> is not one of the valid types for
                                             the attribute.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">descriptor</samp> has not been successfully finalized
                                       using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                              <p class="p">Additional return values depend on the arguments used as explained in the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBackendInitialize"><a name="cudnnBackendInitialize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendInitialize" name="cudnnBackendInitialize" shape="rect">9.2.6.&nbsp;<kbd class="ph userinput">cudnnBackendInitialize()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">This function repurposes a pre-allocated memory pointed to by a
                                 <samp class="ph codeph">descriptor</samp> of size <samp class="ph codeph">sizeInByte</samp> to a backend
                                 <samp class="ph codeph">descriptor</samp> of type <samp class="ph codeph">descriptorType</samp>. The finalized
                                 state of the <samp class="ph codeph">descriptor</samp> is set to <samp class="ph codeph">false</samp>.</span></div><pre xml:space="preserve">cudnnStatus_t cudnnBackendInitialize(cudnnBackendDescriptor_t descriptor, cudnnBackendDescriptorType_t descriptorType, size_t sizeInBytes)</pre><div class="section" id="cudnnBackendInitialize__section_ckg_xzc_z3b"><a name="cudnnBackendInitialize__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptor</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Instance of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp> to be
                                       initialized.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptorType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Enumerated value for the type of cuDNN backend
                                       <samp class="ph codeph">descriptor</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">sizeInBytes</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Size of memory pointed to by
                                       <samp class="ph codeph">descriptor</samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendInitialize__section_zpy_xzc_z3b"><a name="cudnnBackendInitialize__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The memory was initialized successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid or inconsistent argument value is encountered. For
                                       example:<a name="cudnnBackendInitialize__ul_qrj_xcc_5kb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBackendInitialize__ul_qrj_xcc_5kb">
                                          <li class="li"><samp class="ph codeph">descriptor</samp> is a <samp class="ph codeph">nullptr</samp></li>
                                          <li class="li"><samp class="ph codeph">sizeInBytes</samp> is less than the size required by
                                             the <samp class="ph codeph">descriptor</samp> type
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                              <p class="p">Additional return values depend on the arguments used as explained in the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="cudnnBackendSetAttribute"><a name="cudnnBackendSetAttribute" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBackendSetAttribute" name="cudnnBackendSetAttribute" shape="rect">9.2.7.&nbsp;<kbd class="ph userinput">cudnnBackendSetAttribute()</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">This function sets an attribute of a <samp class="ph codeph">descriptor</samp> to value(s) provided
                              as a pointer. <samp class="ph codeph">descriptor</samp> is the <samp class="ph codeph">descriptor</samp> to be set.
                              <samp class="ph codeph">attributeName</samp> is the name of the attribute to be set.
                              <samp class="ph codeph">attributeType</samp> is the type of attribute. The value to which the
                              attribute is set, is pointed by the <samp class="ph codeph">arrayOfElements</samp>. The number of elements
                              is given by <samp class="ph codeph">elementCount</samp>. This function will return
                              <samp class="ph codeph">CUDNN_STATUS_NOT_INTIALIZED</samp> if the <samp class="ph codeph">descriptor</samp> is
                              already successfully finalized using <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp>. <span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnBackendSetAttribute(
    cudnnBackendDescriptor_t descriptor,
    cudnnBackendAttributeName_t attributeName,
    cudnnBackendAttributeType_t attributeType,
    int64_t elementCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *arrayOfElements);
</pre><div class="section" id="cudnnBackendSetAttribute__section_ckg_xzc_z3b"><a name="cudnnBackendSetAttribute__section_ckg_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Parameters</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">descriptor</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Instance of <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendDescriptor_t" shape="rect">cudnnBackendDescriptor_t</a></samp> whose attribute is
                                       being set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attributeName<strong class="ph b"></strong></samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The name of the attribute being set on the
                                       <samp class="ph codeph">descriptor</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">attributeType</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The type of attribute.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">elementCount</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. Number of elements being set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">arrayOfElements</samp></dt>
                                    <dd class="dd"><em class="ph i">Input</em>. The starting location for an array from where to read the
                                       values from. The elements of the array are expected to be of the
                                       datatype of the <samp class="ph codeph">attributeType</samp>. The datatype of the
                                       <samp class="ph codeph">attributeType</samp> is listed in the mapping table of
                                       <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeType_t" shape="rect">cudnnBackendAttributeType_t</a></samp>.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="cudnnBackendSetAttribute__section_zpy_xzc_z3b"><a name="cudnnBackendSetAttribute__section_zpy_xzc_z3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Returns</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">attributeName</samp> was set to the
                                       <samp class="ph codeph">descriptor</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                                    <dd class="dd">The backend <samp class="ph codeph">descriptor</samp> pointed to by the
                                       <samp class="ph codeph">descriptor</samp> is already in the finalized state.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The function is called with arguments that correspond to invalid values.
                                       Some possible causes are:<a name="cudnnBackendSetAttribute__ul_xlp_5z1_blb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnBackendSetAttribute__ul_xlp_5z1_blb">
                                          <li class="li"><samp class="ph codeph">attributeName</samp> is not a settable attribute of
                                             <samp class="ph codeph">descriptor</samp></li>
                                          <li class="li"><samp class="ph codeph">attributeType</samp> is incorrect for this
                                             <samp class="ph codeph">attributeName</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">elemCount</samp> value is unexpected.
                                          </li>
                                          <li class="li"><samp class="ph codeph">arrayOfElements</samp> contains values invalid for the
                                             <samp class="ph codeph">attributeType</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The value(s) to which the attributes are being set is not supported by
                                       the current version of cuDNN.
                                    </dd>
                                 </dl>
                              </div>
                              <p class="p">Additional return values depend on the arguments used as explained in the <a class="xref" href="index.html#cudnn-backend-api" title="This chapter documents the current implemented behavior of the cudnnBackend* API introduced in cuDNN version 8.x. Users specify the computational case, set up an execution plan for it, and execute the computation via numerous descriptors. The typical use pattern for a descriptor with attributes consists of the following sequence of API calls:" shape="rect">cuDNN Backend API</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="backend-descriptor-type"><a name="backend-descriptor-type" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#backend-descriptor-type" name="backend-descriptor-type" shape="rect">9.3.&nbsp;Backend Descriptor Types</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">This section enumerates all valid attributes of various descriptors.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR"><a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR" name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR" shape="rect">9.3.1.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend convolution descriptor specifies the
                                 parameters for a convolution operator for both forward and backward propagation: compute
                                 data type, convolution mode, filter dilation and stride, and padding on both
                                 sides.</span></div>
                           <div class="section" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend convolution descriptor are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_COMP_TYPE</samp></dt>
                                    <dd class="dd">The compute type of the convolution operator.<a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DATA_TYPE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_CONV_MODE</samp></dt>
                                    <dd class="dd">Convolution or cross-correlation mode.<a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_CONVOLUTION_MODE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_DILATIONS</samp></dt>
                                    <dd class="dd">Filter dilation.<a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one or more, but at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS</samp> elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_FILTER_STRIDES</samp></dt>
                                    <dd class="dd">Filter stride.<a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one or more, but at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS</samp> elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_PRE_PADDINGS</samp></dt>
                                    <dd class="dd">Padding at the beginning of each spatial dimension.<a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_h1y_lvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_h1y_lvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one or more, but at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS</samp> elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_POST_PADDINGS</samp></dt>
                                    <dd class="dd">Padding at the end of each spatial dimension.<a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_tk3_nvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_tk3_nvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one or more, but at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS</samp> elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS</samp></dt>
                                    <dd class="dd">The number of spatial dimensions in the convolution.<a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_r13_dvr_5tb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__ul_r13_dvr_5tb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>, one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</samp> can have the following
                                 return values:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An <samp class="ph codeph">elemCount</samp> argument for setting
                                       <samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_DILATIONS</samp>,
                                       <samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_FILTER_STRIDES</samp>,
                                       <samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_PRE_PADDINGS</samp>, and
                                       <samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_POST_PADDINGS</samp> is not equal
                                       to the value set for
                                       <samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR"><a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_ENGINE_DESCRIPTOR" name="CUDNN_BACKEND_ENGINE_DESCRIPTOR" shape="rect">9.3.2.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_ENGINE_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with descriptor type value
                                 <samp class="ph codeph">CUDNN_BACKEND_ENGINE_DESCRIPTOR</samp>, cuDNN backend engine descriptor
                                 describes an engine to compute an operation graph. An engine is a grouping of kernels
                                 with similar compute and numerical attributes.</span></div>
                           <div class="section" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend convolution descriptor are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_ENGINE_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINE_OPERATION_GRAPH</samp></dt>
                                    <dd class="dd">The operation graph to compute.<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINE_GLOBAL_INDEX</samp></dt>
                                    <dd class="dd">The index for the engine.<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Valid values are between 0 and
                                             <samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_ENGINE_GLOBAL_COUNT-1</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINE_KNOB_INFO</samp></dt>
                                    <dd class="dd">The descriptors of performance knobs of the engine.<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINE_NUMERICAL_NOTE</samp></dt>
                                    <dd class="dd">The numerical attributes of the engine.<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_NUMERICAL_NOTE</samp>; zero or more
                                             elements.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINE_LAYOUT_INFO</samp></dt>
                                    <dd class="dd">The preferred tensor layouts of the engine.<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_h1y_lvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_h1y_lvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINE_BEHAVIOR_NOTE</samp></dt>
                                    <dd class="dd">The behavior attributes of the engine.<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_c3y_lnr_pyb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_c3y_lnr_pyb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BEHAVIOR_NOTE</samp>; zero or more
                                             elements.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINE_SM_COUNT_TARGET</samp></dt>
                                    <dd class="dd">The number of SMs to target.<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_qhz_lnr_pyb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_qhz_lnr_pyb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT32</samp>; one element.
                                          </li>
                                          <li class="li">Valid values are between 0 and the number of SMs on the device,
                                             where 0 is default meaning all the SMs will be used.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__section_vpd_jyx_smb"><a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__section_vpd_jyx_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The descriptor attribute set is not supported by the current version of
                                       cuDNN. Some examples include:<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_xjn_pyx_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_xjn_pyx_smb">
                                          <li class="li">The value of <samp class="ph codeph">CUDNN_ATTR_ENGINE_GLOBAL_INDEX</samp> is
                                             not in a valid range.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">The descriptor attribute set is inconsistent or in an unexpected state.
                                       Some examples include:<a name="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_kq3_g2z_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINE_DESCRIPTOR__ul_kq3_g2z_smb">
                                          <li class="li">The operation graph descriptor set is not already
                                             finalized.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR"><a name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_ENGINECFG_DESCRIPTOR" name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR" shape="rect">9.3.3.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_ENGINECFG_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINECFG_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend engine configuration descriptor consists of
                                 an engine descriptor and an array of knob choice descriptors. Users can query from
                                 engine config information about intermediates: computational intermediate results that
                                 can be reused between executions.</span></div>
                           <div class="section" id="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINECFG_ENGINE</samp></dt>
                                    <dd class="dd">The backend engine.<a name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>: one element, a
                                             backend descriptor of type
                                             <samp class="ph codeph">CUDNN_BACKEND_ENGINE_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINECFG_KNOB_CHOICES</samp></dt>
                                    <dd class="dd">The engine tuning knobs and choices.<a name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>: zero or more
                                             elements, backend descriptors of type
                                             <samp class="ph codeph">CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINECFG_INTERMEDIATE_INFO</samp></dt>
                                    <dd class="dd">Information of the computational intermediate of this engine config.<a name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>: one element, a
                                             backend descriptor of type
                                             <samp class="ph codeph">CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                          <li class="li">Currently unsupported. Placeholder for future
                                             implementation.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__section_jgn_c1y_smb"><a name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__section_jgn_c1y_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">The descriptor attribute set is not supported by the current version of
                                       cuDNN. Some examples include:<a name="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_gyw_21y_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINECFG_DESCRIPTOR__ul_gyw_21y_smb">
                                          <li class="li">The value knob.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR"><a name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR" name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR" shape="rect">9.3.4.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend engine heuristics descriptor allows users to
                                 obtain for an operation graph engine configuration descriptors ranked by performance
                                 according to cuDNNs heuristics. </span></div>
                           <div class="section" id="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINEHEUR_OPERATION_GRAPH</samp></dt>
                                    <dd class="dd">The operation graph for which heuristics result in a query.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp></dt>
                                    <dd class="dd">One element.<a name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINEHEUR_MODE</samp></dt>
                                    <dd class="dd">The heuristic mode to query the result.<a name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_HEUR_MODE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINEHEUR_RESULTS</samp></dt>
                                    <dd class="dd">The result of the heuristics query.<a name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; zero or more
                                             elements of descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_ENGINECFG_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Get-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_ENGINEHEUR_SM_COUNT_TARGET</samp></dt>
                                    <dd class="dd">The number of SMs to target.<a name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_ofr_vnr_pyb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__ul_ofr_vnr_pyb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT32</samp>; one element.
                                          </li>
                                          <li class="li">Valid values are between 0 and the number of SMs on the device,
                                             where 0 is default meaning all the SMs will be used.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_ENGINEHEUR_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">Return values of <samp class="ph codeph">cudnnBackendFinalize(desc)</samp> where
                                 <samp class="ph codeph">desc</samp> is a cuDNN backend engine heuristics descriptor:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR"><a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR" name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR" shape="rect">9.3.5.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend execution plan descriptor allows the user to
                                 specify an execution plan, consists of a cuDNN handle, an engine configuration, and
                                 optionally an array of intermediates to compute.</span></div>
                           <div class="section" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_EXECUTION_PLAN_HANDLE</samp></dt>
                                    <dd class="dd">A cuDNN handle.<a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_HANDLE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_EXECUTION_PLAN_ENGINE_CONFIG</samp></dt>
                                    <dd class="dd">An engine configuration to execute.<a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_BACKEND_ENGINECFG_DESCRIPTOR</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_EXECUTION_PLAN_RUN_ONLY_INTERMEDIATE_UIDS</samp></dt>
                                    <dd class="dd">Unique identifiers of intermediates to compute.<a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; zero or more elements.
                                          </li>
                                          <li class="li">Optional attribute. If set, the execution plan will only compute
                                             the specified intermediate and not any of the output tensors on
                                             the operation graph in the engine configuration.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_EXECUTION_PLAN_COMPUTED_INTERMEDIATE_UIDS</samp></dt>
                                    <dd class="dd">Unique identifiers of precomputed intermediates.<a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; zero or more elements.
                                          </li>
                                          <li class="li">Optional attribute. If set, the plan will expect and use
                                             pointers for each intermediate in the variant pack descriptor
                                             during execution.
                                          </li>
                                          <li class="li">Not supported currently: placeholder for future
                                             implementation.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_EXECUTION_PLAN_WORKSPACE_SIZE</samp></dt>
                                    <dd class="dd">The size of the workspace buffer required to execute this plan.<a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_h1y_lvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_h1y_lvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_EXECUTION_PLAN_JSON_REPRESENTATION</samp></dt>
                                    <dd class="dd">The JSON representation of the serialized execution plan. Serialization
                                       and deserialization can be done by getting and setting this attribute,
                                       respectively.<a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_mqf_prv_ysb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__ul_mqf_prv_ysb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_CHAR</samp>; many elements, the same amount
                                             as the size of a null-terminated string of the json
                                             representation of the execution plan.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">Return values of <samp class="ph codeph">cudnnBackendFinalize(desc)</samp> where
                                 <samp class="ph codeph">desc</samp> is a cuDNN backend execution plan descriptor:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR"><a name="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR" name="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR" shape="rect">9.3.6.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend intermediate descriptor is a read-only
                                 descriptor that contains information about an execution intermediate. An execution
                                 intermediate is some intermediate computation for an engine config in device memory that
                                 can be reused between plan execution to amortize the kernel. Each intermediate is
                                 identified by a unique ID. Users can query for the device memory size of the
                                 intermediate. An intermediate can depend on the data of one or more tensors identified
                                 by the tensor UIDs or one more attribute of the operation graph.</span></div>
                           <p class="p">This is a read-only descriptor. Users cannot set the descriptor attributes or finalize
                              the descriptor. User query for a finalized descriptor from an engine config
                              descriptor.
                           </p>
                           <div class="section" id="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_INTERMEDIATE_INFO_UNIQUE_ID</samp></dt>
                                    <dd class="dd">A unique identifier of the intermediate.<a name="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_INTERMEDIATE_INFO_SIZE</samp></dt>
                                    <dd class="dd">The required device memory size for the intermediate.<a name="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_INTERMEDIATE_INFO_DEPENDENT_DATA_UIDS</samp></dt>
                                    <dd class="dd">UID of tensors on which the intermediate depends.<a name="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; zero or more elements.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_INTERMEDIATE_INFO_DEPENDENT_ATTRIBUTES</samp></dt>
                                    <dd class="dd">Placeholder for future implementation.</dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_INTERMEDIATE_INFO_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">User does not finalize this descriptor. <samp class="ph codeph">cudnnBackendFinalize(desc)</samp>
                                 with a backend intermediate descriptor returns
                                 <samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR"><a name="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR" name="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR" shape="rect">9.3.7.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend knob choice descriptor consists of the type
                                 of knobs to be set and the value to which the knob is set.</span></div>
                           <div class="section" id="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_KNOB_CHOICE_KNOB_TYPE</samp></dt>
                                    <dd class="dd">The type of knobs to be set.<a name="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_KNOB_TYPE</samp>: one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_KNOB_CHOICE_KNOB_VALUE</samp></dt>
                                    <dd class="dd"><a name="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>: one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_KNOB_CHOICE_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">Return values of <samp class="ph codeph">cudnnBackendFinalize(desc)</samp> where
                                 <samp class="ph codeph">desc</samp> is a cuDNN backend knob choice descriptor:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The knob choice descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR"><a name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR" name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR" shape="rect">9.3.8.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_INFO_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend knob info descriptor consists of the type and
                                 valid value range of an engine performance knob. Valid value range is given in terms of
                                 minimum, maximum, and stride of valid values. This is a purely informative descriptor
                                 type. Setting descriptor attributes is not supported. User obtains an array of finalized
                                 descriptors, one for each knob type, from a finalized backend descriptor.</span></div>
                           <div class="section" id="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_KNOB_INFO_TYPE</samp></dt>
                                    <dd class="dd">The type of the performance knob.<a name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_KNOB_TYPE</samp>: one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_KNOB_INFO_MAXIMUM_VALUE</samp></dt>
                                    <dd class="dd">The smallest valid value choice value for this knob.<a name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>: one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_KNOB_INFO_MINIMUM_VALUE</samp></dt>
                                    <dd class="dd">The largest valid choice value for this knob.<a name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>: one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_KNOB_INFO_STRIDE</samp></dt>
                                    <dd class="dd">The stride of valid choice values for this knob.<a name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>: one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_KNOB_INFO_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">This descriptor is read-only; it is retrieved and finalized from a cuDNN backend
                                 engine configuration descriptor. Users cannot set or finalize. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR"><a name="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR" name="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR" shape="rect">9.3.9.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with descriptor type value
                                 <samp class="ph codeph">CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR</samp>, cuDNN backend layout info
                                 descriptor provides information on the preferred layout for a tensor.</span></div>
                           <div class="section" id="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_LAYOUT_INFO_TENSOR_UID</samp></dt>
                                    <dd class="dd">The UID of the tensor.<a name="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_LAYOUT_INFO_TYPES</samp></dt>
                                    <dd class="dd">The preferred layout of the tensor.<a name="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_LAYOUT_TYPE</samp>: zero or more element
                                             <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendLayoutType_t" shape="rect">cudnnBackendLayoutType_t</a></samp>.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_LAYOUT_INFO_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">This descriptor is read-only; it is retrieved and finalized from a cuDNN backend
                                 engine configuration descriptor. Users cannot set its attribute or finalize it. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_MATMUL_DESCRIPTOR"><a name="CUDNN_BACKEND_MATMUL_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_MATMUL_DESCRIPTOR" name="CUDNN_BACKEND_MATMUL_DESCRIPTOR" shape="rect">9.3.10.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_MATMUL_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_MATMUL_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend <samp class="ph codeph">matmul</samp> descriptor specifies
                                 any metadata needed for the <samp class="ph codeph">matmul</samp> operation.</span></div>
                           <div class="section" id="CUDNN_BACKEND_MATMUL_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_MATMUL_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_MATMUL_COMP_TYPE</samp></dt>
                                    <dd class="dd">The compute precision used for the <samp class="ph codeph">matmul</samp> operation.<a name="CUDNN_BACKEND_MATMUL_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_MATMUL_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DATA_TYPE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_MATMUL_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_MATMUL_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">Return values of <samp class="ph codeph">cudnnBackendFinalize(desc)</samp> where
                                 <samp class="ph codeph">desc</samp> is a cuDNN backend <samp class="ph codeph">matmul</samp> descriptor:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR" shape="rect">9.3.11.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend concatenation operation descriptor specifies
                                 an operation node for concatenating a given vector of tensors along a given
                                 concatenation axis.</span></div>
                           <p class="p">This operation also supports an in-place mode, where one of the input tensors is already
                              assumed to be at the correct location in the output tensor, that is, they share the same
                              device buffer.
                           </p>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend concat operation descriptor are values of enumeration
                                 type <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp>  with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_CONCAT_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONCAT_AXIS</samp></dt>
                                    <dd class="dd">The dimension which tensors are being concatenated over.<a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_v3v_qhx_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_v3v_qhx_d5b">
                                          <li class="li">Type: <samp class="ph codeph">CUDNN_TYPE_INT64</samp></li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONCAT_INPUT_DESCS</samp></dt>
                                    <dd class="dd">A vector of input tensor descriptors, which are concatenated in the same
                                       order as provided in this vector.<a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_sv4_thx_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_sv4_thx_d5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one or more
                                             elements of descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONCAT_INPLACE_INDEX</samp></dt>
                                    <dd class="dd">The index of input tensor in the vector of input tensor descriptors that
                                       is already present in-place in the output tensor.<a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_dvs_yhx_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_dvs_yhx_d5b">
                                          <li class="li">Type: <samp class="ph codeph">CUDNN_TYPE_INT64</samp></li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONCAT_OUTPUT_DESC</samp></dt>
                                    <dd class="dd">The output tensor descriptor for the result from concatenation of input
                                       tensors.<a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_tnw_13x_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_tnw_13x_d5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR()</samp> can have the
                                 following return values:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       causes:<a name="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_djz_d3x_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONCAT_DESCRIPTOR__ul_djz_d3x_d5b">
                                          <li class="li">The tensors involved in the operation should have the same shape
                                             in all dimensions except the dimension that they are being
                                             concatenated over.
                                          </li>
                                          <li class="li">The output tensor shape in the concatenating dimension should
                                             equal the sum of tensor shape of all input tensors in that same
                                             dimension.
                                          </li>
                                          <li class="li">Concatenation axis should be a valid tensor dimension.</li>
                                          <li class="li">If provided, the in-place input tensor index should be a valid
                                             index in the vector of input tensor descriptors.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR" shape="rect">9.3.12.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend convolution backward data operation
                                 descriptor specifies an operation node for convolution backward data to compute the
                                 gradient of input data 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dx</mi>
                                    </mrow>
                                 </math>
                                 with filter tensor 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>w</mi>
                                    </mrow>
                                 </math>
                                 and gradient of response 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dy</mi>
                                    </mrow>
                                 </math>
                                 with output  scaling and residue add with  scaling. That is,
                                 the equation 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dx</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mi></mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <mi>w</mi>
                                          <msup>
                                             <mo>*</mo>
                                             <mo></mo>
                                          </msup>
                                          <mi>dy</mi>
                                       </mrow>
                                       <mo>)</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>+</mo>
                                       <mi></mi>
                                       <mi>dx</mi>
                                    </mrow>
                                 </math>
                                 , where 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msup>
                                          <mo>*</mo>
                                          <mo></mo>
                                       </msup>
                                    </mrow>
                                 </math>
                                 denotes the convolution backward data operator.</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend convolution descriptor are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA</samp></dt>
                                    <dd class="dd">The alpha value.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_FLOAT</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp>; one or more
                                             elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA</samp></dt>
                                    <dd class="dd">The beta value.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_FLOAT</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp>; one or more
                                             elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_CONV_DESC</samp></dt>
                                    <dd class="dd">The convolution operator descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_W</samp></dt>
                                    <dd class="dd">The convolution filter tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DX</samp></dt>
                                    <dd class="dd">The image gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_h1y_lvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_h1y_lvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DY</samp></dt>
                                    <dd class="dd">The response gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_tk3_nvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_tk3_nvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">In finalizing the convolution operation, the tensor dimensions of the tensor
                                 <samp class="ph codeph">DX</samp>, <samp class="ph codeph">W</samp>, and <samp class="ph codeph">DY</samp> are bound based
                                 on the same interpretations as the <samp class="ph codeph">X</samp>, <samp class="ph codeph">W</samp>, and
                                 <samp class="ph codeph">Y</samp> tensor dimensions described in the <samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR, &amp;desc); the cuDNN backend convolution forward operation descriptor specifies an operation node for forward convolution to compute the response tensor of image tensor convoluted with filter tensor with output scaling  and residual add with  scaling. That is, the equation , where * is the convolution operator in the forward direction." shape="rect">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</a></samp> section.
                              </p>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR()</samp>
                                 can have the following return values: 
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       cause:<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_v2h_qyl_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR__ul_v2h_qyl_4mb">
                                          <li class="li">The <samp class="ph codeph">DX</samp>, <samp class="ph codeph">W</samp>, and
                                             <samp class="ph codeph">DY</samp> tensors do not constitute a valid
                                             convolution operation under the convolution operator.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR" shape="rect">9.3.13.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend convolution backward filter operation
                                 descriptor specifies an operation node for convolution backward filter to compute the
                                 gradient of filter 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dw</mi>
                                    </mrow>
                                 </math>
                                 with image tensor 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>x</mi>
                                    </mrow>
                                 </math>
                                 and gradient of response 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dy</mi>
                                    </mrow>
                                 </math>
                                 with output  scaling and residue add with  scaling. That is,
                                 the equation: 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dw</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mi></mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <mi>x</mi>
                                          <msup>
                                             <mo>*</mo>
                                             <mo>~</mo>
                                          </msup>
                                          <mi>dy</mi>
                                       </mrow>
                                       <mo>)</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>+</mo>
                                       <mi></mi>
                                       <mi>dw</mi>
                                    </mrow>
                                 </math>
                                 , where 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <msup>
                                          <mo>*</mo>
                                          <mo>~</mo>
                                       </msup>
                                    </mrow>
                                 </math>
                                 denotes the convolution backward filter operator.</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend convolution descriptor are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA</samp></dt>
                                    <dd class="dd">The alpha value.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_FLOAT</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp>; one or more
                                             elements.
                                          </li>
                                          <li class="li">Required attribute. Required to be set before finalization.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA</samp></dt>
                                    <dd class="dd">The beta value.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_FLOAT</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp>; one or more
                                             elements.
                                          </li>
                                          <li class="li">Required attribute. Required to be set before finalization.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_CONV_DESC</samp></dt>
                                    <dd class="dd">The convolution operator descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute. Required to be set before finalization.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DW</samp></dt>
                                    <dd class="dd">The convolution filter tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute. Required to be set before finalization.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_X</samp></dt>
                                    <dd class="dd">The image gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_h1y_lvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_h1y_lvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute. Required to be set before finalization.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DY</samp></dt>
                                    <dd class="dd">The response gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_tk3_nvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_tk3_nvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute. Required to be set before finalization.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">In finalizing the convolution operation, the tensor dimensions of the tensor
                                 <samp class="ph codeph">X</samp>, <samp class="ph codeph">DW</samp>, and <samp class="ph codeph">DY</samp> are bound based
                                 on the same interpretations as the <samp class="ph codeph">X</samp>, <samp class="ph codeph">W</samp>, and
                                 <samp class="ph codeph">Y</samp> tensor dimensions described in the <samp class="ph codeph"><a class="xref" href="index.html#CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR" title="Created with cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR, &amp;desc); the cuDNN backend convolution forward operation descriptor specifies an operation node for forward convolution to compute the response tensor of image tensor convoluted with filter tensor with output scaling  and residual add with  scaling. That is, the equation , where * is the convolution operator in the forward direction." shape="rect">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</a></samp> section.
                              </p>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR()</samp>
                                 can have the following return values: 
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       cause:<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_hq2_vzl_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR__ul_hq2_vzl_4mb">
                                          <li class="li">The <samp class="ph codeph">X</samp>, <samp class="ph codeph">DW</samp>, and
                                             <samp class="ph codeph">DY</samp> tensors do not constitute a valid
                                             convolution operation under the convolution operator.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR" shape="rect">9.3.14.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend convolution forward operation descriptor
                                 specifies an operation node for forward convolution to compute the response tensor 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>y</mi>
                                    </mrow>
                                 </math>
                                 of image tensor 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>x</mi>
                                    </mrow>
                                 </math>
                                 convoluted with filter tensor 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>w</mi>
                                    </mrow>
                                 </math>
                                 with output scaling  and residual add with  scaling. That is,
                                 the equation 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>y</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mi></mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <mi>w</mi>
                                          <msup>
                                             <mo>*</mo>
                                          </msup>
                                          <mi>x</mi>
                                       </mrow>
                                       <mo>)</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>+</mo>
                                       <mi></mi>
                                       <mi>y</mi>
                                    </mrow>
                                 </math>
                                 , where * is the convolution operator in the forward
                                 direction.</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend convolution descriptor are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA</samp></dt>
                                    <dd class="dd">The alpha value.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_FLOAT</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp>; one or more
                                             elements.
                                          </li>
                                          <li class="li">Required to be set before finalization.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA</samp></dt>
                                    <dd class="dd">The beta value.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_FLOAT</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp>; one or more
                                             elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_CONV_DESC</samp></dt>
                                    <dd class="dd">The convolution operator descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_W</samp></dt>
                                    <dd class="dd">The convolution filter tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_X</samp></dt>
                                    <dd class="dd">The image tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_h1y_lvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_h1y_lvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_Y</samp></dt>
                                    <dd class="dd">The response tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_tk3_nvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_tk3_nvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS</samp></dt>
                                    <dd class="dd">The number of spatial dimensions in the convolution.<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_r13_dvr_5tb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_r13_dvr_5tb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>, one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">In finalizing the convolution operation, the tensor dimensions of the tensor
                                 <samp class="ph codeph">X</samp>, <samp class="ph codeph">W</samp>, and <samp class="ph codeph">Y</samp> are bound based
                                 on the following interpretations: 
                              </p>
                              <p class="p">The <samp class="ph codeph">CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS</samp> attribute of
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_CONV_DESC</samp> is the
                                 number of spatial dimension of the convolution. The number of dimensions for tensor
                                 <samp class="ph codeph">X</samp>, <samp class="ph codeph">W</samp>, and <samp class="ph codeph">Y</samp> must be larger
                                 than the number of spatial dimensions by 2 or 3 depending on how users choose to
                                 specify the convolution tensors.
                              </p>
                              <div class="p">If the number of tensor dimension is the number of spatial dimensions plus 2:<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_lrk_3cm_4mb" shape="rect">
                                    <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_lrk_3cm_4mb">
                                    <li class="li"><samp class="ph codeph">X</samp> tensor dimension and stride arrays are <samp class="ph codeph">[N, GC,
                                          ]</samp></li>
                                    <li class="li"><samp class="ph codeph">W</samp> tensor dimension and stride arrays are <samp class="ph codeph">[KG, C,
                                          ]</samp></li>
                                    <li class="li"><samp class="ph codeph">Y</samp> tensor dimension and stride arrays are <samp class="ph codeph">[N, GK,
                                          ]</samp></li>
                                 </ul>
                                 
                                 where the ellipsis <samp class="ph codeph"></samp> are shorthand for spatial dimensions of
                                 each tensor, <samp class="ph codeph">G</samp> is the number of convolution groups, and
                                 <samp class="ph codeph">C</samp> and <samp class="ph codeph">K</samp> are the number of input and output
                                 feature maps per group. In this interpretation, it is assumed that the memory layout
                                 for each group is packed. <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp>
                                 asserts the tensors dimensions and strides are consistent with this interpretation
                                 or it returns <samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp>.
                              </div>
                              <div class="p">If the number of tensor dimension is the number of spatial dimensions plus 3:<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_omm_mcm_4mb" shape="rect">
                                    <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_omm_mcm_4mb">
                                    <li class="li"><samp class="ph codeph">X</samp> tensor dimension and stride arrays are <samp class="ph codeph">[N, G, C,
                                          ]</samp></li>
                                    <li class="li"><samp class="ph codeph">W</samp> tensor dimension and stride arrays are <samp class="ph codeph">[G, K, C,
                                          ]</samp></li>
                                    <li class="li"><samp class="ph codeph">Y</samp> tensor dimension and stride arrays are <samp class="ph codeph">[N, G, K,
                                          ]</samp></li>
                                 </ul>
                                 
                                 where the ellipsis <samp class="ph codeph"></samp> are shorthand for spatial dimensions of
                                 each tensor, <samp class="ph codeph">G</samp> is the number of convolution groups, and
                                 <samp class="ph codeph">C</samp> and <samp class="ph codeph">K</samp> are the number of input and output
                                 feature maps per group. In this interpretation, users can specify an unpacked group
                                 stride. <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> asserts the
                                 tensors dimensions and strides are consistent with this interpretation or it returns
                                 <samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp>.
                              </div>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR</samp> can have
                                 the following return values:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       cause:<a name="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_nxx_qcm_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR__ul_nxx_qcm_4mb">
                                          <li class="li">The <samp class="ph codeph">X</samp>, <samp class="ph codeph">W</samp>, and
                                             <samp class="ph codeph">Y</samp> tensors do not constitute a valid
                                             convolution operation under the convolution operator.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR" shape="rect">9.3.15.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Represents an operation that will generate per-channel statistics. The specific
                                 statistics that will be generated depends on the
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_MODE</samp> attribute in the descriptor.
                                 Currently, only <samp class="ph codeph">CUDNN_GENSTATS_SUM_SQSUM</samp>is supported for the
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_MODE</samp>. It will generate the sum and
                                 quadratic sum of per-channel elements of the input tensor <samp class="ph codeph">x</samp>. The output
                                 dimension should be all 1 except the <samp class="ph codeph">C</samp> dimension. Also, the
                                 <samp class="ph codeph">C</samp> dimension of outputs should equal the <samp class="ph codeph">C</samp>
                                 dimension of the input. This opaque struct can be created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor()</samp>
                                 (<samp class="ph codeph">CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR</samp>).</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR__section_lxz_dsd_cnb"><a name="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR__section_lxz_dsd_cnb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_MODE</samp></dt>
                                    <dd class="dd">Sets the<samp class="ph codeph"> CUDNN_TYPE_GENSTATS_MODE</samp><samp class="ph codeph"></samp>of the
                                       operation. This attribute is required.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_MATH_PREC</samp></dt>
                                    <dd class="dd">The math precision of the computation. This attribute is required.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_XDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the input tensor <samp class="ph codeph">X</samp>. This
                                       attribute is required.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SUMDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the output tensor <samp class="ph codeph">sum</samp>. This
                                       attribute is required.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_GENSTATS_SQSUMDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the output tensor
                                       <samp class="ph codeph">quadratic</samp><samp class="ph codeph">sum</samp>. This attribute is
                                       required.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR__section_zjk_3sd_cnb"><a name="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR__section_zjk_3sd_cnb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">In the finalization stage, the attributes are cross checked to make sure there are no
                                 conflicts. The status below may be returned:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       causes are:<a name="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR__ul_xyz_ksd_cnb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_GEN_STATS_DESCRIPTOR__ul_xyz_ksd_cnb">
                                          <li class="li">The number of dimensions do not match between the input and
                                             output tensors.
                                          </li>
                                          <li class="li">The input/output tensor dimensions do not agree with the above
                                             description.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR" shape="rect">9.3.16.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract">Created with
                              <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR,
                                 &amp;desc)</samp>; the cuDNN backend <samp class="ph codeph">matmul</samp> operation descriptor
                              specifies an operation node for <samp class="ph codeph">matmul</samp> to compute the matrix product C by
                              multiplying matrix A and matrix B, as shown in the following equation: 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>C</mi>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mo>=</mo>
                                    <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                    <mi>A</mi>
                                    <mi>B</mi>
                                 </mrow>
                              </math><span class="shortdesc"></span></div>
                           <div class="p">When using the <samp class="ph codeph">matmul</samp> operation, the matrices are expected to be at
                              least rank-2 tensors. The last two dimensions are expected to correspond to either M, K
                              or N. All the preceding dimensions are interpreted as batch dimensions. If there are
                              zero batch dimensions then the requirements are as follows:
                              
                              
                              <div class="tablenoborder"><a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__table_a4p_4mg_jvb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__table_a4p_4mg_jvb" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 53. <samp class="ph codeph">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</samp> for Zero Batch
                                          Dimensions</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="25%" id="d54e105914" rowspan="1" colspan="1">Case</th>
                                          <th class="entry" valign="top" width="25%" id="d54e105917" rowspan="1" colspan="1">Matrix A</th>
                                          <th class="entry" valign="top" width="25%" id="d54e105920" rowspan="1" colspan="1">Matrix B</th>
                                          <th class="entry" valign="top" width="25%" id="d54e105923" rowspan="1" colspan="1">Matrix C</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e105914" rowspan="1" colspan="1">Single matmul</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105917" rowspan="1" colspan="1">M x K</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105920" rowspan="1" colspan="1">K x N</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105923" rowspan="1" colspan="1">M x N</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="p">For a single batch dimension we have the following requirements:
                              
                              
                              <div class="tablenoborder"><a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__table_u1d_1tw_prb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__table_u1d_1tw_prb" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 54. <samp class="ph codeph">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</samp> for a Single Batch
                                          Dimension</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="25%" id="d54e105972" rowspan="1" colspan="1">Case</th>
                                          <th class="entry" valign="top" width="25%" id="d54e105975" rowspan="1" colspan="1">Matrix A</th>
                                          <th class="entry" valign="top" width="25%" id="d54e105978" rowspan="1" colspan="1">Matrix B</th>
                                          <th class="entry" valign="top" width="25%" id="d54e105981" rowspan="1" colspan="1">Matrix C</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e105972" rowspan="1" colspan="1">Single matmul</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105975" rowspan="1" colspan="1">1 x M x K</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105978" rowspan="1" colspan="1">1 x K x N</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105981" rowspan="1" colspan="1">1 x M x N</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e105972" rowspan="1" colspan="1">Batch matmul</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105975" rowspan="1" colspan="1">B x M x K</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105978" rowspan="1" colspan="1">B x K x N</td>
                                          <td class="entry" rowspan="3" valign="top" width="25%" headers="d54e105981" colspan="1">B x M x N</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e105972" rowspan="1" colspan="1">Broadcast A</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105975" rowspan="1" colspan="1">(B/c) x M x K</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105978" rowspan="1" colspan="1">B x K x N</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e105972" rowspan="1" colspan="1">Broadcast B</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105975" rowspan="1" colspan="1">B x M x K</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e105978" rowspan="1" colspan="1">(B/c) x K x N</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <div class="p">where:<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_nfx_3tw_prb" shape="rect">
                                 <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_nfx_3tw_prb">
                                 <li class="li">B indicates the batch size</li>
                                 <li class="li">M is the number of rows of the matrix A</li>
                                 <li class="li">K is the number or columns of the input matrix A (which is the same as the
                                    number of rows as the input matrix B)
                                 </li>
                                 <li class="li">N is the number of columns of the input matrix B</li>
                                 <li class="li">c is a constant integer and a factor of B.</li>
                              </ul>
                           </div>
                           <p class="p">If either the batch size of matrix A or B is set to B/c, this indicates that the matrix
                              will be broadcasted in the batch matmul. The resulting output matrix C will be a tensor
                              of B x M x N.
                           </p>
                           <div class="p">The above broadcasting convention is extended to all the batch dimensions. Concretely,
                              for tensors with three batch dimensions:
                              
                              
                              <div class="tablenoborder"><a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__table_u3w_tng_jvb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__table_u3w_tng_jvb" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 55. <samp class="ph codeph">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</samp> for a Three Batch
                                          Dimension</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="25%" id="d54e106092" rowspan="1" colspan="1">Case</th>
                                          <th class="entry" valign="top" width="25%" id="d54e106095" rowspan="1" colspan="1">Matrix A</th>
                                          <th class="entry" valign="top" width="25%" id="d54e106098" rowspan="1" colspan="1">Matrix B</th>
                                          <th class="entry" valign="top" width="25%" id="d54e106101" rowspan="1" colspan="1">Matrix C</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e106092" rowspan="1" colspan="1">Multiple batched matmul</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e106095" rowspan="1" colspan="1">B1 x 1 x B3 x M x K</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e106098" rowspan="1" colspan="1">1 x B2 x (B3/c) x K x N</td>
                                          <td class="entry" valign="top" width="25%" headers="d54e106101" rowspan="1" colspan="1">B1 x B2 x B3 x M x N</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                           <p class="p">The functionality of having multiple batch dimensions allows you to have layouts where
                              the batch is not packed at a single stride. This case is especially seen in multi-head
                              attention. c is only allowed to be B (leading to a batch dimension for 1) for matmul and
                              matmul fusions. The other possible values of c are supported for Grouped Query Attention
                              in the cuDNN Fused Flash Attention.
                           </p>
                           <p class="p">The addressing of the matrix elements from a given tensor can be specified using strides
                              in the tensor descriptor. The strides represent the spacing between elements for each
                              tensor dimension. Considering a matrix tensor A (B x M x N) with strides [BS, MS, NS],
                              it indicates that the actual matrix element A[x, y, z] is found at (A_base_address + x *
                              BS + y * MS + z * NS) from the linear memory space allocated for tensor A. With our
                              current support, the innermost dimension must be packed, which requires either MS=1 or
                              NS=1. Otherwise, there are no other technical constraints with regard to how the strides
                              can be specified in a tensor descriptor as it should follow the aforementioned
                              addressing formula and the strides as specified by the user.
                           </p>
                           <div class="p">This representation provides support for some common usages, such as leading dimension
                              and matrix transpose as we will explain through the following examples.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ol_pxv_xlb_wrb" shape="rect">
                                 <!-- --></a><ol class="ol" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ol_pxv_xlb_wrb">
                                 <li class="li">The most basic case is a fully packed row-major batch matrix, without any
                                    consideration of leading dimension or transpose. In this case, BS = M*N, MS = N
                                    and NS = 1.
                                 </li>
                                 <li class="li">Matrix transpose can be achieved by exchanging the inner and outer dimensions
                                    using strides. Namely:<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ol_zdm_zlb_wrb" shape="rect">
                                       <!-- --></a><ol class="ol" type="a" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ol_zdm_zlb_wrb">
                                       <li class="li">To specify a non-transposed matrix: BS = M*N, MS = N and NS = 1.</li>
                                       <li class="li">To specify matrix transpose: BS = M*N, MS = 1 and NS = M.</li>
                                    </ol>
                                 </li>
                                 <li class="li">Leading dimension, a widely used concept in BLAS-like APIs, describes the inner
                                    dimension of the 2D array memory allocation (as opposed to the conceptual matrix
                                    dimension). It resembles the stride in a way that it defines the spacing between
                                    elements in the outer dimension. The most typical use cases where it shows
                                    difference from the matrix inner dimension is when the matrix is only part of
                                    the data in the allocated memory, addressing submatrices, or addressing matrices
                                    from an aligned memory allocation. Therefore, the leading dimension LDA in a
                                    column-major matrix A must satisfy LDA &gt;= M, whereas in a row-major matrix A, it
                                    must satisfy LDA &gt;= N. To transition from the leading dimension concept to using
                                    strides, this entails MS &gt;= N and NS = 1 or MS = 1 and NS &gt;= M. Keep in mind
                                    that, while these are some practical use cases, these inequalities do not impose
                                    technical constraints with respect to an acceptable specification of the
                                    strides.
                                 </li>
                              </ol>
                           </div>
                           <p class="p">Other commonly used GEMM features, such as alpha/beta output blending, can also be
                              achieved using this <samp class="ph codeph">matmul</samp> operation along with other pointwise
                              operations.
                           </p>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <p class="p">The commonly used GEMM operation can also be achieved using this
                                 <samp class="ph codeph">matmul</samp> operation along with other pointwise operations for
                                 output blending.
                              </p>
                              <div class="p">Attributes of a cuDNN backend <samp class="ph codeph">matmul</samp> descriptor are values of
                                 enumeration type <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp>
                                 with prefix <samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_ADESC</samp></dt>
                                    <dd class="dd">The matrix A descriptor.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_BDESC</samp></dt>
                                    <dd class="dd">The matrix B descriptor.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_CDESC</samp></dt>
                                    <dd class="dd">The matrix C descriptor.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_IRREGULARLY_STRIDED_BATCH_COUNT</samp></dt>
                                    <dd class="dd">Number of <samp class="ph codeph">matmul</samp> operations to perform in the batch on
                                       matrix. Default = 1.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Default value is 1.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_GEMM_M_OVERRIDE_DESC</samp></dt>
                                    <dd class="dd">The tensor <samp class="ph codeph">gemm_m_override</samp> descriptor. Allows you to
                                       override the M dimension of a batch matrix multiplication through this
                                       tensor. It is only supported as documented in the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#fused-multi-head-att-fprop" target="_blank" shape="rect">Fused Attention
                                          <samp class="ph codeph">fprop</samp></a>, <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#fused-multi-head-att-bprop" target="_blank" shape="rect">Fused Attention
                                          <samp class="ph codeph">bprop</samp></a>, <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#flash-fused-multi-head-att-fprop" target="_blank" shape="rect">Fused Flash Attention
                                          <samp class="ph codeph">fprop</samp></a>, and <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#flash-fused-multi-head-att-bprop" target="_blank" shape="rect">Fused Flash Attention
                                          <samp class="ph codeph">bprop</samp></a> sections.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_jpd_34g_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_jpd_34g_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_GEMM_N_OVERRIDE_DESC</samp></dt>
                                    <dd class="dd">The tensor <samp class="ph codeph">gemm_n_override</samp> descriptor. Allows you to
                                       override the N dimension of a batch matrix multiplication through this
                                       tensor. It is only supported as documented in the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#fused-multi-head-att-fprop" target="_blank" shape="rect">Fused Attention
                                          <samp class="ph codeph">fprop</samp></a>, <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#fused-multi-head-att-bprop" target="_blank" shape="rect">Fused Attention
                                          <samp class="ph codeph">bprop</samp></a>, <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#flash-fused-multi-head-att-fprop" target="_blank" shape="rect">Fused Flash Attention
                                          <samp class="ph codeph">fprop</samp></a>, and <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#flash-fused-multi-head-att-bprop" target="_blank" shape="rect">Fused Flash Attention
                                          <samp class="ph codeph">bprop</samp></a> sections.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_u4w_k4g_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_u4w_k4g_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_GEMM_K_OVERRIDE_DESC</samp></dt>
                                    <dd class="dd">The tensor <samp class="ph codeph">gemm_k_override</samp> descriptor. Allows you to
                                       override the K dimension of a batch matrix multiplication through this
                                       tensor. It is only supported as documented in the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#fused-multi-head-att-fprop" target="_blank" shape="rect">Fused Attention
                                          <samp class="ph codeph">fprop</samp></a>, <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#fused-multi-head-att-bprop" target="_blank" shape="rect">Fused Attention
                                          <samp class="ph codeph">bprop</samp></a>, <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#flash-fused-multi-head-att-fprop" target="_blank" shape="rect">Fused Flash Attention
                                          <samp class="ph codeph">fprop</samp></a>, and <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#flash-fused-multi-head-att-bprop" target="_blank" shape="rect">Fused Flash Attention
                                          <samp class="ph codeph">bprop</samp></a> sections.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_lhh_n4g_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_lhh_n4g_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_DESC</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">matmul</samp> operation descriptor.<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_k3b_5lc_5qb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_k3b_5lc_5qb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_MATMUL_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">In the finalization of the <samp class="ph codeph">matmul</samp> operation, the tensor dimensions
                                 of the matrices A, B and C will be checked to ensure that they satisfy the
                                 requirements of matrix multiplication:
                              </p>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR</samp> can have the
                                 following return values:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">An unsupported attribute value was encountered. Some possible cause:<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_ff3_wsy_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_ff3_wsy_smb">
                                          <li class="li">If not all of the matrices A, B and C are at least rank-2
                                             tensors.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       causes:<a name="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_dzm_zlc_5qb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR__ul_dzm_zlc_5qb">
                                          <li class="li">The
                                             <samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_IRREGULARLY_STRIDED_BATCH_COUNT</samp>
                                             specified is a negative value.
                                          </li>
                                          <li class="li">The
                                             <samp class="ph codeph">CUDNN_ATTR_OPERATION_MATMUL_IRREGULARLY_STRIDED_BATCH_COUNT</samp>
                                             and one or more of the batch sizes of the matrices A, B and C
                                             are not equal to one. That is to say there is a conflict where
                                             both irregularly and regularly strided batched matrix
                                             multiplication are specified, which is not a valid use
                                             case.
                                          </li>
                                          <li class="li">The dimensions of the matrices A, B and C do not satisfy the
                                             requirements of matrix multiplication.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR" shape="rect">9.3.17.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR,
                                    &amp;desc)</samp>, the cuDNN backend normalization backward operation specifies a
                                 node for a backward normalization that takes as input the gradient tensor
                                 <samp class="ph codeph">dY</samp> and outputs the gradient tensor <samp class="ph codeph">dX</samp> and weight
                                 gradients <samp class="ph codeph">dScale</samp> and <samp class="ph codeph">dBias</samp>. The normalization mode is
                                 set using the <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_MODE</samp> attribute.</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__section_mpw_qrh_1xb"><a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__section_mpw_qrh_1xb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Limitations</h4>
                              <div class="p"><a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_pyl_trh_1xb" shape="rect">
                                    <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_pyl_trh_1xb">
                                    <li class="li">Does not support <samp class="ph codeph">CUDNN_GROUP_NORM</samp> mode. 
                                    </li>
                                 </ul>
                                 <div class="tablenoborder"><a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__table_bsf_zqp_ywb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__table_bsf_zqp_ywb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 56. Supported Configurations for
                                             <samp class="ph codeph">CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="5" valign="top" id="d54e106603" rowspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_MODE</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="20%" id="d54e106610" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_LAYER_NORM</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e106614" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_INSTANCE_NORM</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e106618" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BATCH_NORM</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e106622" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_GROUP_NORM</samp></th>
                                             <th class="entry" valign="top" width="20%" id="d54e106626" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_RMS_NORM</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="20%" headers="d54e106603 d54e106610" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e106603 d54e106614" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e106603 d54e106618" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e106603 d54e106622" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="20%" headers="d54e106603 d54e106626" rowspan="1" colspan="1">Yes</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="note note"><span class="notetitle">Note:</span> In addition to single GPU, <samp class="ph codeph">CUDNN_BATCH_NORM</samp> also supports
                                    single node multi-GPU batch norm, while other normalization modes only support
                                    running on a single GPU. For more information, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#dreluforkdbn" target="_blank" shape="rect">DReluForkDBn</a> pattern.
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_MODE</samp></dt>
                                    <dd class="dd">Chooses the normalization mode for the norm backward operation.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_NORM_MODE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_XDESC</samp></dt>
                                    <dd class="dd">Input tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_MEAN_DESC</samp></dt>
                                    <dd class="dd">Saved mean input tensor descriptor for reusing the mean computed during
                                       the forward computation of the training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_INV_VARIANCE_DESC</samp></dt>
                                    <dd class="dd">Saved inverse variance input tensor descriptor for reusing the mean
                                       computed during the forward computation of the training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_DYDESC</samp></dt>
                                    <dd class="dd">Gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_k3b_5lc_5qb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_k3b_5lc_5qb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_DYDESC</samp></dt>
                                    <dd class="dd">Gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_tnw_xsv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_tnw_xsv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_SCALE_DESC</samp></dt>
                                    <dd class="dd">Normalization scale descriptor. Note that the bias descriptor is not
                                       necessary for the backward pass.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_xrf_zsv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_xrf_zsv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_EPSILON_DESC</samp></dt>
                                    <dd class="dd">Scalar input tensor descriptor for the epsilon value. The epsilon values
                                       are needed only if the saved mean and variances are not passed as inputs
                                       to the operation.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_bkm_1tv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_bkm_1tv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_DSCALE_DESC</samp></dt>
                                    <dd class="dd">Scale gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_bkw_btv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_bkw_btv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_DBIAS_DESC</samp></dt>
                                    <dd class="dd">Bias gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_hbf_dtv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_hbf_dtv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_DXDESC</samp></dt>
                                    <dd class="dd">Input gradient tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_izl_2tv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_izl_2tv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_BWD_PEER_STAT_DESCS</samp></dt>
                                    <dd class="dd">Vector of tensor descriptors for the communication buffers used in
                                       multi-GPU normalization. Typically, one buffer is provided for every GPU
                                       in the node. This is an optional attribute only used for multi-GPU
                                       tensor stats reduction.<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_lmr_ftv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_lmr_ftv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one or more
                                             elements of descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">In the finalization stage, the attributes are checked to ensure there are no
                                 conflicts. 
                              </p>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       causes are:<a name="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_ff3_wsy_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_BACKWARD_DESCRIPTOR__ul_ff3_wsy_smb">
                                          <li class="li">The tensor dimensions of the gradient tensors
                                             <samp class="ph codeph">dY</samp>, <samp class="ph codeph">dX</samp>, and input tensor
                                             <samp class="ph codeph">X</samp>, do not match.
                                          </li>
                                          <li class="li">The channel count C for the <samp class="ph codeph">mean</samp>,
                                             <samp class="ph codeph">scale</samp>, and <samp class="ph codeph">inv_variance</samp>
                                             tensors do not match.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR" shape="rect">9.3.18.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR,
                                    &amp;desc)</samp>, the cuDNN backend normalization forward operation specifies a
                                 node for a forward normalization that takes as input a tensor X and produces a
                                 normalized output Y with the normalization mode set by the
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_MODE</samp> attribute. The operation
                                 supports optional running stats computation and allows for storing the computed means
                                 and variances for reuse in the backwards calculation depending on the setting of the
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_PHASE</samp> attribute.</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__section_cbg_msh_1xb"><a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__section_cbg_msh_1xb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Limitations</h4>
                              <div class="p"><a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_bjw_msh_1xb" shape="rect">
                                    <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_bjw_msh_1xb">
                                    <li class="li">Does not support <samp class="ph codeph">CUDNN_GROUP_NORM</samp> mode.
                                    </li>
                                    <li class="li">Batch norm only supports forward training and not forward inference.</li>
                                 </ul>
                                 <div class="tablenoborder"><a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__table_bsf_zqp_ywb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__table_bsf_zqp_ywb" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 57. Supported Configurations for
                                             <samp class="ph codeph">CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR</samp></span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" rowspan="2" valign="top" width="16.666666666666664%" id="d54e107084" colspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_PHASE</samp></th>
                                             <th class="entry" colspan="5" valign="top" id="d54e107088" rowspan="1"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_MODE</samp></th>
                                          </tr>
                                          <tr class="row">
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e107095" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_LAYER_NORM</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e107099" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_INSTANCE_NORM</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e107103" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_BATCH_NORM</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e107107" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_GROUP_NORM</samp></th>
                                             <th class="entry" valign="top" width="16.666666666666664%" id="d54e107111" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_RMS_NORM</samp></th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107084 d54e107095" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_NORM_FWD_TRAINING</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107099" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107103" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107107" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107111" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088" rowspan="1" colspan="1">Yes</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107084 d54e107095" rowspan="1" colspan="1"><samp class="ph codeph">CUDNN_NORM_FWD_INFERENCE</samp></td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107099" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107103" rowspan="1" colspan="1">Yes</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107107" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088 d54e107111" rowspan="1" colspan="1">No</td>
                                             <td class="entry" valign="top" width="16.666666666666664%" headers="d54e107088" rowspan="1" colspan="1">Yes</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <div class="note note"><span class="notetitle">Note:</span> In addition to single-GPU, batch normalization supports running on single node
                                    multi-GPUs, while other normalization modes only support running on a single
                                    GPU. For more information, refer to the <a class="xref" href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#bnaddrelu" target="_blank" shape="rect">BNAddRelu</a> pattern.
                                 </div>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_MODE</samp></dt>
                                    <dd class="dd">Chooses the normalization mode for the norm forward operation.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_o42_ttv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_o42_ttv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_NORM_MODE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_PHASE</samp></dt>
                                    <dd class="dd">Selects the training or inference phase for the norm forward
                                       operation.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_ksr_5tv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_ksr_5tv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_NORM_FWD_PHASE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_XDESC</samp></dt>
                                    <dd class="dd">Input tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_e2x_vtv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_e2x_vtv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_MEAN_DESC</samp></dt>
                                    <dd class="dd">Estimated mean input tensor descriptor for the inference phase and the
                                       computed mean output tensor descriptor for the training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_y32_xtv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_y32_xtv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_INV_VARIANCE_DESC</samp></dt>
                                    <dd class="dd">Estimated inverse variance input tensor descriptor for the inference
                                       phase and the computed inverse variance output tensor descriptor for the
                                       training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_frz_ytv_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_frz_ytv_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_SCALE_DESC</samp></dt>
                                    <dd class="dd">Normalization scale input tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_oyd_15v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_oyd_15v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_BIAS_DESC</samp></dt>
                                    <dd class="dd">Normalization bias input tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_hrk_b5v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_hrk_b5v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_EPSILON_DESC</samp></dt>
                                    <dd class="dd">Scalar input tensor descriptor for the epsilon value used in
                                       normalization calculation.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_lpd_d5v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_lpd_d5v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_EXP_AVG_FACTOR_DESC</samp></dt>
                                    <dd class="dd">Scalar input tensor descriptor for the exponential average factor value
                                       used in running stats computation.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_ar4_25v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_ar4_25v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_INPUT_RUNNING_MEAN_DESC</samp></dt>
                                    <dd class="dd">Input running mean tensor descriptor for the running stats computation
                                       in the training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_uy5_f5v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_uy5_f5v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_INPUT_RUNNING_VAR_DESC</samp></dt>
                                    <dd class="dd">Input running variance tensor descriptor for the running stats
                                       computation in the training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_dkb_h5v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_dkb_h5v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_OUTPUT_RUNNING_MEAN_DESC</samp></dt>
                                    <dd class="dd">Output running mean tensor descriptor for the running stats computation
                                       in the training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_sbg_35v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_sbg_35v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_OUTPUT_RUNNING_VAR_DESC</samp></dt>
                                    <dd class="dd">Output running variance tensor descriptor for the running stats
                                       computation in the training phase.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_nqc_k5v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_nqc_k5v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_YDESC</samp></dt>
                                    <dd class="dd">Tensor descriptor for the output of the normalization operation.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_kxf_l5v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_kxf_l5v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_NORM_FWD_PEER_STAT_DESCS</samp></dt>
                                    <dd class="dd">Vector of tensor descriptors for the communication buffers used in
                                       multi-GPU normalization. Typically, one buffer is provided for every GPU
                                       in the node. This is an optional attribute only used for multi-GPU
                                       tensor stats reduction.<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_osz_m5v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_osz_m5v_l5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one or more
                                             elements of descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">In the finalization stage, the attributes are checked to ensure there are no
                                 conflicts. 
                              </p>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       causes are:<a name="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_cgy_45v_l5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_NORM_FORWARD_DESCRIPTOR__ul_cgy_45v_l5b">
                                          <li class="li">The output tensor dimensions do not match the input tensor
                                             dimensions.
                                          </li>
                                          <li class="li">The channel count C for the <samp class="ph codeph">mean</samp>,
                                             <samp class="ph codeph">scale</samp>, <samp class="ph codeph">bias</samp>, and
                                             <samp class="ph codeph">inv_variance</samp> tensors do not match.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR" shape="rect">9.3.19.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Represents a pointwise operation that implements the equation 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>Y</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mi>op</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <mi>alpha1</mi>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo lspace="2px" rspace="2px">*</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>X</mi>
                                       </mrow>
                                       <mo>)</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mi>or</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mi>Y</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>=</mo>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mi>op</mi>
                                       <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                       <mo>(</mo>
                                       <mrow>
                                          <mi>alpha1</mi>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>*</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>X</mi>
                                          <mo>,</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>alpha2</mi>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mo>*</mo>
                                          <mtext fontfamily="Times New Roman">&nbsp;</mtext>
                                          <mi>B</mi>
                                       </mrow>
                                       <mo>)</mo>
                                    </mrow>
                                 </math>
                                 depending on the operation type. The actual type of operation represented
                                 by <samp class="ph codeph">op()</samp> above depends on the
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_PW_DESCRIPTOR</samp> attribute in the
                                 descriptor. This operation descriptor supports operations with single-input
                                 single-output.</span></div>
                           <p class="p">For a list of supported operations, refer to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnPointwiseMode_t" title="cudnnPointwiseMode_t is an enumerated type to indicate the intended pointwise math operation in the backend pointwise operation descriptor." shape="rect">cudnnPointwiseMode_t</a></samp> section.
                           </p>
                           <p class="p">For dual-input pointwise operations, broadcasting is assumed when a tensor dimension in
                              one of the tensors is 1 while the other tensors corresponding dimension is not 1. 
                           </p>
                           <p class="p">For three-input single-output pointwise operations, we do not support broadcasting in any
                              tensor.
                           </p>
                           <p class="p">This opaque struct can be created with <samp class="ph codeph">cudnnBackendCreateDescriptor()</samp>
                              (<samp class="ph codeph">CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR</samp>).
                           </p>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_PW_DESCRIPTOR</samp></dt>
                                    <dd class="dd">Sets the descriptor containing the mathematical settings of the
                                       pointwise operation. This attribute is required.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_XDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the input tensor 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>X</mi>
                                          </mrow>
                                       </math>
                                       . This attribute is required for pointwise mathematical
                                       functions or activation forward propagation computations.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_BDESC</samp></dt>
                                    <dd class="dd">If the operation requires 2 inputs, such as add or multiply, this
                                       attribute sets the second input tensor . If the operation requires
                                       only 1 input, this field is not used and should not be set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_YDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the output tensor 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>Y</mi>
                                          </mrow>
                                       </math>
                                       . This attribute is required for pointwise mathematical
                                       functions or activation forward propagation computations.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_TDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the tensor <samp class="ph codeph">T</samp>. This attribute is
                                       required for <samp class="ph codeph">CUDNN_ATTR_POINTWISE_MODE</samp> set to
                                       <samp class="ph codeph">CUDNN_POINTWISE_BINARY_SELECT</samp> and acts as the mask
                                       based on which the selection is done. 
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_ALPHA1</samp></dt>
                                    <dd class="dd">Sets the scalar 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>alpha1</mi>
                                          </mrow>
                                       </math>
                                       value in the equation. Can be in float or half. This
                                       attribute is optional, if not set, the default value is
                                       <samp class="ph codeph">1.0</samp>.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_ALPHA2</samp></dt>
                                    <dd class="dd">If the operation requires two inputs, such as <samp class="ph codeph">add</samp> or
                                       <samp class="ph codeph">multiply</samp>, this attribute sets the scalar 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>alpha2</mi>
                                          </mrow>
                                       </math>
                                       value in the equation. Can be in float or half. This
                                       attribute is optional, if not set, the default value is
                                       <samp class="ph codeph">1.0</samp>. If the operation requires only 1 input, this
                                       field is not used and should not be set.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_DXDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the output tensor 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>dX</mi>
                                          </mrow>
                                       </math>
                                       . This attribute is required for pointwise activation back
                                       propagation computations.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_POINTWISE_DYDESC</samp></dt>
                                    <dd class="dd">Sets the descriptor for the input tensor 
                                       
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>dY</mi>
                                          </mrow>
                                       </math>
                                       . This attribute is required for pointwise activation back
                                       propagation computations.
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR__section_q2g_dhd_cnb"><a name="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR__section_q2g_dhd_cnb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">In the finalization stage, the attributes are cross checked to make sure there are no
                                 conflicts. The status below may be returned:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       causes are:<a name="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR__ul_phl_fhd_cnb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_POINTWISE_DESCRIPTOR__ul_phl_fhd_cnb">
                                          <li class="li">The number of dimensions do not match between the input and
                                             output tensors.
                                          </li>
                                          <li class="li">The input/output tensor dimensions do not agree with the above
                                             described automatic broadcasting rules.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR" shape="rect">9.3.20.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">The cuDNN backend <samp class="ph codeph">reduction</samp> operation descriptor represents an
                                 operation node that implements reducing values of an input tensor <samp class="ph codeph">X</samp> in
                                 one or more dimensions to get an output tensor <samp class="ph codeph">Y</samp>. The math operation
                                 and compute data type used for reducing tensor values is specified via
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_DESC</samp>.</span></div>
                           <div class="p">This operation descriptor can be created with
                              <pre xml:space="preserve">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR,
        &amp;desc);</pre></div>
                           <p class="p">The output tensor <samp class="ph codeph">Y</samp> should be the size as that of input tensor
                              <samp class="ph codeph">X</samp>, except dimensions where its size is 1.
                           </p>
                           <p class="p">There is a special use case for Grouped Query Attention and Multi Query Attention in
                              cuDNN Fused Flash Attention where some dimensions in the output tensor
                              <samp class="ph codeph">Y</samp> can also be factors of the corresponding dimensions in the input
                              tensor <samp class="ph codeph">X</samp>.
                           </p>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend <samp class="ph codeph">reduction</samp> descriptor are values of
                                 enumeration type <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with
                                 prefix <samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_XDESC</samp></dt>
                                    <dd class="dd">The matrix <samp class="ph codeph">X</samp> descriptor.<a name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp> one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_YDESC</samp></dt>
                                    <dd class="dd">The matrix <samp class="ph codeph">Y</samp> descriptor.<a name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp> one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_REDUCTION_DESC</samp></dt>
                                    <dd class="dd">The <samp class="ph codeph">reduction</samp> operation descriptor.<a name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp> one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_REDUCTION_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__section_jgn_c1y_smb"><a name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__section_jgn_c1y_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <p class="p">In the finalization of the <samp class="ph codeph">reduction</samp> operation, the dimensions of
                                 tensors <samp class="ph codeph">X</samp> and <samp class="ph codeph">Y</samp> are checked to ensure that they
                                 satisfy the requirements of the reduction operation.
                              </p>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR</samp> can have the
                                 following return values:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Some possible
                                       causes:<a name="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_pcz_jjr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_REDUCTION_DESCRIPTOR__ul_pcz_jjr_btb">
                                          <li class="li">The dimensions of the tensors <samp class="ph codeph">X</samp> and
                                             <samp class="ph codeph">Y</samp> do not satisfy the requirements of the
                                             reduction operation.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR" shape="rect">9.3.21.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend resample backward operation descriptor
                                 specifies an operation node for backward resampling. It computes the input tensor
                                 gradient 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dx</mi>
                                    </mrow>
                                 </math>
                                 from output tensor gradient 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>dy</mi>
                                    </mrow>
                                 </math>
                                 with backward resampling done according to
                                 <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_MODE</samp> with output scaling  and residual add
                                 with  scaling.</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_DESC</samp></dt>
                                    <dd class="dd">Resample operation descriptor
                                       (<samp class="ph codeph">CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</samp>) instance
                                       containing metadata about the operation.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_DXDESC</samp></dt>
                                    <dd class="dd">Input tensor gradient descriptor.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_DYDESC</samp></dt>
                                    <dd class="dd">Output tensor gradient descriptor.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_IDXDESC</samp></dt>
                                    <dd class="dd">Tensor containing maxpool or nearest neighbor resampling indices to be
                                       used in backprop.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_ALPHA</samp></dt>
                                    <dd class="dd">Sets the alpha parameter used in blending.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_cjb_jrp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_cjb_jrp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FLOAT</samp>; one element.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                          <li class="li">Default value is <samp class="ph codeph">1.0</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_BETA</samp></dt>
                                    <dd class="dd">Sets the beta parameter used in blending.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_rfz_krp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_rfz_krp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FLOAT</samp>; one element.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                          <li class="li">Default value is <samp class="ph codeph">0.0</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_XDESC</samp></dt>
                                    <dd class="dd">Input tensor <samp class="ph codeph">X</samp> descriptor.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_tkx_dbx_cwb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_tkx_dbx_cwb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                          <li class="li">Required for NCHW layout.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_BWD_YDESC</samp></dt>
                                    <dd class="dd">Input tensor <samp class="ph codeph">Y</samp> descriptor.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_drr_gbx_cwb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_drr_gbx_cwb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                          <li class="li">Required for NCHW layout</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">In the finalization stage, the attributes are cross checked to make sure there are no
                                 conflicts. The status below may be returned:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Possible
                                       causes are:<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_utz_5sy_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_BWD_DESCRIPTOR__ul_utz_5sy_smb">
                                          <li class="li">The output shape calculated based on the padding and strides
                                             does not match the given output tensor dimensions.
                                          </li>
                                          <li class="li">The shape of <samp class="ph codeph">YDESC</samp> and <samp class="ph codeph">IDXDESC</samp>
                                             (if given) do not match.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR" shape="rect">9.3.22.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend resample forward operation descriptor
                                 specifies an operation node for forward resampling. It computes the output tensor 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>y</mi>
                                    </mrow>
                                 </math>
                                 of image tensor 
                                 
                                 <math xmlns="http://www.w3.org/1998/Math/MathML">
                                    <mrow>
                                       <mi>x</mi>
                                    </mrow>
                                 </math>
                                 resampled according to <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_MODE</samp>, with
                                 output scaling  and residual add with  scaling.</span></div>
                           <p class="p">The resampling mode acts independently on each spatial dimension. For spatial dimension 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>i</mi>
                                 </mrow>
                              </math>
                              , the output spatial dimension size 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>y_i</mi>
                                 </mrow>
                              </math>
                              can be calculated by combining input images spatial dimension size 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>x_i</mi>
                                 </mrow>
                              </math>
                              , post padding 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>post_i</mi>
                                 </mrow>
                              </math>
                              , pre padding 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>pre_i</mi>
                                 </mrow>
                              </math>
                              , stride 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>s_i</mi>
                                 </mrow>
                              </math>
                              , window size 
                              
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <mi>w_i</mi>
                                 </mrow>
                              </math>
                              as: <samp class="ph codeph"><em class="ph i">y_i = 1+(x_i + post_i + pre_i - w_i) / s_i</em></samp></p>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_DESC</samp></dt>
                                    <dd class="dd">Resample operation descriptor
                                       (<samp class="ph codeph">CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</samp>) instance
                                       containing metadata about the operation.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_XDESC</samp></dt>
                                    <dd class="dd">Input tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_YDESC</samp></dt>
                                    <dd class="dd">Output tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_IDXDESC</samp></dt>
                                    <dd class="dd">Tensor containing maxpool or nearest neighbor resampling indices to be
                                       used in backprop.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute (primarily used for use cases involving
                                             training).
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_ALPHA</samp></dt>
                                    <dd class="dd">Sets the alpha parameter used in blending.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_cjb_jrp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_cjb_jrp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FLOAT</samp>; one element.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                          <li class="li">Default value is <samp class="ph codeph">1.0</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_BETA</samp></dt>
                                    <dd class="dd">Sets the beta parameter used in blending.<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_rfz_krp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_rfz_krp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FLOAT</samp>; one element.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                          <li class="li">Default value is <samp class="ph codeph">0.0</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">In the finalization stage, the attributes are cross checked to make sure there are no
                                 conflicts. The status below may be returned:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered. Possible
                                       causes are:<a name="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_utz_5sy_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RESAMPLE_FWD_DESCRIPTOR__ul_utz_5sy_smb">
                                          <li class="li">The output shape calculated based on the padding and strides
                                             does not match the given output tensor dimensions.
                                          </li>
                                          <li class="li">The shape of the <samp class="ph codeph">YDESC</samp> and
                                             <samp class="ph codeph">IDXDESC</samp> (if given) do not match.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR" shape="rect">9.3.23.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend <samp class="ph codeph">Rng</samp> operation descriptor
                                 specifies an operation node for generating a tensor with random numbers based on the
                                 probability distribution specified in the <samp class="ph codeph">Rng</samp> descriptor.</span></div>
                           <p class="p">The random numbers are generated using a <a class="xref" href="https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/core/PhiloxRNGEngine.h" target="_blank" shape="rect">Philox random number generator (RNG) as described in
                                 Pytorch</a>. The Philox object takes a seed value, a subsequence for starting the
                              generation, and an offset for the subsequence. Seed and offset can be set by using the
                              attributes. The subsequence is internally set, to ensure independent random numbers.
                           </p>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RNG_DESC</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">Rng</samp> descriptor
                                       (<samp class="ph codeph">CUDNN_BACKEND_RNG_DESCRIPTOR</samp>) instance containing
                                       metadata about the operation.<a name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_mwy_bqg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_mwy_bqg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_RNG_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RNG_YDESC</samp></dt>
                                    <dd class="dd">Output tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_t5r_dqg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_t5r_dqg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RNG_SEED</samp></dt>
                                    <dd class="dd">Sets the seed for the random number generator which creates the
                                       <samp class="ph codeph">Y</samp> tensor. It can be a host INT64 value or a backend
                                       descriptor binded to a value on the device. Only supports a tensor with
                                       all dimensions set to 1 and all strides set to 1.<a name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_jkv_fqg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_jkv_fqg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element or
                                             <samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element
                                             of descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                          <li class="li">Default value is <samp class="ph codeph">0</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RNG_OFFSET_DESC</samp></dt>
                                    <dd class="dd">Tensor descriptor for the offset used in the RNG Philox object. Only
                                       supports a tensor with all dimensions set to 1 and all strides set to
                                       1.<a name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_vll_r42_3wb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__ul_vll_r42_3wb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_RNG_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">In the finalization stage, the attributes are cross checked to make sure there are no
                                 conflicts. The status below may be returned:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RNG_OFFSET_DESC</samp> or
                                       <samp class="ph codeph">CUDNN_ATTR_OPERATION_RNG_SEED</samp> do not have all
                                       dimensions and strides set to 1.
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR" name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR" shape="rect">9.3.24.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend signal operation descriptor specifies an
                                 operation node for updating or waiting on a flag variable. Signaling operations can be
                                 used to communicate between cuDNN operation graphs, even with operation graphs in
                                 another GPU.</span></div>
                           <p class="p">This operation, to connect to other nodes in the graph, also has a pass-through input
                              tensor, which is not operated on and is just passed along to the output tensor. This
                              mandatory pass-through input tensor helps in determining the predecessor node after
                              which the signal operation should be executed. The optional output tensor helps in
                              determining the successor node before which the signal execution should have completed.
                              It is also guaranteed that for a non-virtual tensor as the output tensor, all writes for
                              the tensor will have taken place before the signal value is updated by the
                              operation.
                           </p>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_SIGNAL_MODE</samp></dt>
                                    <dd class="dd">The signaling mode to use.<a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_qbq_kzx_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_qbq_kzx_d5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_SIGNAL_MODE</samp>;
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_SIGNAL_FLAGDESC</samp></dt>
                                    <dd class="dd">Flag tensor descriptor.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_RESAMPLE_FWD_YDESC</samp></dt>
                                    <dd class="dd">Output tensor descriptor.<a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_SIGNAL_VALUE</samp></dt>
                                    <dd class="dd">The scalar value to compare or update the flag variable with.<a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_wlq_szx_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_wlq_szx_d5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp></li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_SIGNAL_XDESC</samp></dt>
                                    <dd class="dd">A pass-through input tensor to enable connecting this signal operation
                                       to other nodes in the graph.<a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_tvl_5zx_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_tvl_5zx_d5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATION_SIGNAL_YDESC</samp></dt>
                                    <dd class="dd">The output tensor for the pass-through input tensor.<a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_k2c_wzx_d5b" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__ul_k2c_wzx_d5b">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one element of
                                             descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_TENSOR_DESCRIPTOR</samp>.
                                          </li>
                                          <li class="li">Optional attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATION_SIGNAL_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">In the finalization stage, the attributes are cross checked to make sure there are no
                                 conflicts. The status below may be returned:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">Invalid or inconsistent attribute values are encountered.</dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR"><a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR" name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR" shape="rect">9.3.25.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with descriptor type value
                                 <samp class="ph codeph">CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR</samp>, cuDNN backend operation
                                 graph descriptor describes an operation graph, a small network of one or more operations
                                 connected by virtual tensors. Operation graph defines users computation case or
                                 mathematical expression that they wish to compute.</span></div>
                           <div class="section" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend convolution descriptor are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_HANDLE</samp></dt>
                                    <dd class="dd">A cuDNN handle.<a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_HANDLE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_OPS</samp></dt>
                                    <dd class="dd">Operation nodes to form the operation graph.<a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one or more
                                             elements of descriptor type
                                             <samp class="ph codeph">CUDNN_BACKEND_OPERATION_*_DESCRIPTOR()</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_ENGINE_GLOBAL_COUNT</samp></dt>
                                    <dd class="dd">The number of engines to support the operation graph.<a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Read-only attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_ENGINE_SUPPORTED_COUNT</samp></dt>
                                    <dd class="dd">The number of engines that support the operation graph.<a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Read-only attribute; placeholder only: currently not
                                             supported.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid attribute value was encountered. For example:<a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_utz_5sy_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_utz_5sy_smb">
                                          <li class="li">One of the backend descriptors in
                                             <samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_OPS</samp> is not
                                             finalized.
                                          </li>
                                          <li class="li">The value <samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_HANDLE</samp> is
                                             not a valid cuDNN handle.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">An unsupported attribute value was encountered. For example:<a name="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_ff3_wsy_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR__ul_ff3_wsy_smb">
                                          <li class="li">The combination of operations of attribute
                                             <samp class="ph codeph">CUDNN_ATTR_OPERATIONGRAPH_OPS</samp> is not
                                             supported.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR"><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_POINTWISE_DESCRIPTOR" name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR" shape="rect">9.3.26.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_POINTWISE_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_POINTWISE_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend pointwise descriptor specifies the parameters
                                 for a pointwise operator like mode, math precision, nan propagation and so
                                 on.</span></div>
                           <div class="section" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend convolution descriptor are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_POINTWISE_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_MODE</samp></dt>
                                    <dd class="dd">Mode of the pointwise operation.<a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_POINTWISE_MODE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_MATH_PREC</samp></dt>
                                    <dd class="dd">The math precision of the computation.<a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DATA_TYPE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_NAN_PROPAGATION</samp></dt>
                                    <dd class="dd">Specifies a method by which to propagate NaNs.<a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_yff_vkr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_yff_vkr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_NAN_PROPOGATION</samp>; one element.
                                          </li>
                                          <li class="li">Required only for comparison based pointwise modes, like
                                             ReLU.
                                          </li>
                                          <li class="li">Current support only includes enum value
                                             <samp class="ph codeph">CUDNN_PROPAGATE_NAN</samp>.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_RELU_LOWER_CLIP</samp></dt>
                                    <dd class="dd">Sets the lower clip value for ReLU. <samp class="ph codeph">If (value &lt; lower_clip)
                                          value = lower_clip + lower_clip_slope * (value -
                                          lower_clip);</samp><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_mfq_xkr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_mfq_xkr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE / CUDNN_TYPE_FLOAT</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">0.0f</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_RELU_UPPER_CLIP</samp></dt>
                                    <dd class="dd">Sets the upper clip value for ReLU. <samp class="ph codeph">If (value &gt; upper_clip)
                                          value = upper_clip;</samp><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_th4_2lr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_th4_2lr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE / CUDNN_TYPE_FLOAT</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">Numeric limit max</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_RELU_LOWER_CLIP_SLOPE</samp></dt>
                                    <dd class="dd">Sets the lower clip slope value for ReLU. <samp class="ph codeph">If (value &lt;
                                          lower_clip) value = lower_clip + lower_clip_slope * (value -
                                          lower_clip);</samp><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_xlp_glr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_xlp_glr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE / CUDNN_TYPE_FLOAT</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">0.0f</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_ELU_ALPHA</samp></dt>
                                    <dd class="dd">Sets the alpha value for ELU. <samp class="ph codeph">If (value &lt; 0.0) value = alpha
                                          * (e^value - 1.0);</samp><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_lk3_jlr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_lk3_jlr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE / CUDNN_TYPE_FLOAT</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">1.0f</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_SOFTPLUS_BETA</samp></dt>
                                    <dd class="dd">Sets the beta value for softplus. <samp class="ph codeph">value = log (1 + e^(beta *
                                          value)) / beta</samp><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_y1k_llr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_y1k_llr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE / CUDNN_TYPE_FLOAT</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">1.0f</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_SWISH_BETA</samp></dt>
                                    <dd class="dd">Sets the beta value for swish. <samp class="ph codeph">value = value / (1 + e^(-beta *
                                          value))</samp><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_l5v_mlr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_l5v_mlr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE / CUDNN_TYPE_FLOAT</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">1.0f</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_POINTWISE_AXIS</samp></dt>
                                    <dd class="dd">Sets the axis value for <samp class="ph codeph">GEN_INDEX</samp>. The index will be
                                       generated for this axis.<a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_tqh_4lr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__ul_tqh_4lr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">-1</samp>.
                                          </li>
                                          <li class="li">Needs to lie between [0,input_dim_size-1]. For example, if your
                                             input has dimensions [N,C,H,W], the axis can be set to anything
                                             in [0,3].
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__section_jgn_c1y_smb"><a name="CUDNN_BACKEND_POINTWISE_DESCRIPTOR__section_jgn_c1y_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_POINTWISE_DESCRIPTOR</samp> can have the following
                                 return values:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_REDUCTION_DESCRIPTOR"><a name="CUDNN_BACKEND_REDUCTION_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_REDUCTION_DESCRIPTOR" name="CUDNN_BACKEND_REDUCTION_DESCRIPTOR" shape="rect">9.3.27.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_REDUCTION_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_REDUCTION_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend <samp class="ph codeph">reduction</samp> descriptor
                                 specifies any metadata, including the math operation and compute data type, needed for
                                 the <samp class="ph codeph">reduction </samp>operation.</span></div>
                           <div class="section" id="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_REDUCTION_OPERATOR</samp></dt>
                                    <dd class="dd">The math operation used for the <samp class="ph codeph">reduction</samp> operation.<a name="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_REDUCTION_OPERATOR_TYPE</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_REDUCTION_COMP_TYPE</samp></dt>
                                    <dd class="dd">The compute precision used for the <samp class="ph codeph">reduction</samp>
                                       operation.<a name="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DATA_TYPE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__section_jgn_c1y_smb"><a name="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__section_jgn_c1y_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">Return values of <samp class="ph codeph">cudnnBackendFinalize(desc)</samp> where
                                 <samp class="ph codeph">desc</samp> is <samp class="ph codeph">CUDNN_BACKEND_REDUCTION_DESCRIPTOR</samp>
                                 are:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">An unsupported attribute value was encountered. Some possible causes
                                       are:<a name="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__ul_qbk_2kr_btb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_REDUCTION_DESCRIPTOR__ul_qbk_2kr_btb">
                                          <li class="li"><samp class="ph codeph">CUDNN_ATTR_REDUCTION_OPERATOR</samp> is not set to
                                             either of <samp class="ph codeph">CUDNN_REDUCE_TENSOR_ADD</samp>,
                                             <samp class="ph codeph">CUDNN_REDUCE_TENSOR_MUL</samp>,
                                             <samp class="ph codeph">CUDNN_REDUCE_TENSOR_MIN</samp>, or
                                             <samp class="ph codeph">CUDNN_REDUCE_TENSOR_MAX</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR"><a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_RESAMPLE_DESCRIPTOR" name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR" shape="rect">9.3.28.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_RESAMPLE_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend resample descriptor specifies the parameters
                                 for a resample operation (upsampling or downsampling) in both forward and backward
                                 propagation.</span></div>
                           <div class="section" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_MODE</samp></dt>
                                    <dd class="dd">Specifies mode of resampling, for example, average pool,
                                       nearest-neighbor, etc.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_RESAMPLE_MODE</samp>; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">CUDNN_RESAMPLE_NEAREST</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_COMP_TYPE</samp></dt>
                                    <dd class="dd">Compute data type for the resampling operator.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DATA_TYPE</samp>; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_NAN_PROPAGATION</samp></dt>
                                    <dd class="dd">Specifies a method by which to propagate NaNs.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_NAN_PROPAGATION</samp>; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_SPATIAL_DIMS</samp></dt>
                                    <dd class="dd">Specifies the number of spatial dimensions to perform the resampling
                                       over.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_PADDING_MODE</samp></dt>
                                    <dd class="dd">Specifies which values to use for padding.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_cjb_jrp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_cjb_jrp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_PADDING_MODE</samp>; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">CUDNN_ZERO_PAD</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_STRIDES</samp></dt>
                                    <dd class="dd">Stride in each dimension for the kernel/filter.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_rfz_krp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_rfz_krp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FRACTION</samp>; at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS - 2</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_PRE_PADDINGS</samp></dt>
                                    <dd class="dd">Padding added to the beginning of the input tensor in each dimension.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_jd1_lrp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_jd1_lrp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FRACTION</samp>; at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS - 2</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_POST_PADDINGS</samp></dt>
                                    <dd class="dd">Padding added to the end of the input tensor in each dimension.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_e1b_lrp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_e1b_lrp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FRACTION</samp>; at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS - 2</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_WINDOW_DIMS</samp></dt>
                                    <dd class="dd">Spatial dimensions of filter.<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_h5b_lrp_prb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_h5b_lrp_prb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp> or
                                             <samp class="ph codeph">CUDNN_TYPE_FRACTION</samp>; at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS - 2</samp>.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">The return values for <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> when
                                 called with a <samp class="ph codeph">CUDNN_BACKEND_RESAMPLE_DESCRIPTOR</samp> is:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">An unsupported attribute value was encountered. Some possible causes
                                       are:<a name="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_utz_5sy_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RESAMPLE_DESCRIPTOR__ul_utz_5sy_smb">
                                          <li class="li">An <samp class="ph codeph">elemCount</samp> argument for setting
                                             <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_WINDOW_DIMS</samp>,
                                             <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_STRIDES</samp>,
                                             <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_PRE_PADDINGS</samp>, and
                                             <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_POST_PADDINGS</samp> is not
                                             equal to the value set for
                                             <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_SPATIAL_DIMS</samp>.
                                          </li>
                                          <li class="li"><samp class="ph codeph">CUDNN_ATTR_RESAMPLE_MODE</samp> is set to
                                             <samp class="ph codeph">CUDNN_RESAMPLE_BILINEAR</samp> and any of the
                                             <samp class="ph codeph">CUDNN_ATTR_RESAMPLE_WINDOW_DIMS</samp> are not set
                                             to <samp class="ph codeph">2</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_RNG_DESCRIPTOR"><a name="CUDNN_BACKEND_RNG_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_RNG_DESCRIPTOR" name="CUDNN_BACKEND_RNG_DESCRIPTOR" shape="rect">9.3.29.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_RNG_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_RNG_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend <samp class="ph codeph">Rng</samp> descriptor specifies any
                                 metadata, including the probability distribution that will be used to generate the
                                 tensor and the distributions corresponding parameters.</span></div>
                           <div class="section" id="CUDNN_BACKEND_RNG_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_RNG_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION</samp></dt>
                                    <dd class="dd">The probability distribution used for the <samp class="ph codeph">rng</samp>
                                       operation.<a name="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_lp4_krg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_lp4_krg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_RNG_DISTRIBUTION</samp>; one element.
                                          </li>
                                          <li class="li">Default value is
                                             <samp class="ph codeph">CUDNN_RNG_DISTRIBUTION_BERNOULLI</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RNG_NORMAL_DIST_MEAN</samp></dt>
                                    <dd class="dd">The mean value for the normal distribution, used if
                                       <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                          CUDNN_RNG_DISTRIBUTION_NORMAL</samp>.<a name="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_nyx_mrg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_nyx_mrg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> ; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">-1</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RNG_NORMAL_DIST_STANDARD_DEVIATION</samp></dt>
                                    <dd class="dd">The standard deviation value for the normal distribution, used if
                                       <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                          CUDNN_RNG_DISTRIBUTION_NORMAL</samp>.<a name="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_bw2_prg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_bw2_prg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> ; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">-1</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RNG_UNIFORM_DIST_MAXIMUM</samp></dt>
                                    <dd class="dd">The maximum value for the range used in uniform distribution, used if
                                       <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                          CUDNN_RNG_DISTRIBUTION_UNIFORM</samp>.<a name="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_epj_5rg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_epj_5rg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> ; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">-1</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RNG_UNIFORM_DIST_MINIMUM</samp></dt>
                                    <dd class="dd">The minimum value for the range used in uniform distribution, used if
                                       <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                          CUDNN_RNG_DISTRIBUTION_UNIFORM</samp>.<a name="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_zxc_wrg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_zxc_wrg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> ; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">-1</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_RNG_BERNOULLI_DIST_PROBABILITY</samp></dt>
                                    <dd class="dd">The probability of generating 1s in the tensor, used if
                                       <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                          CUDNN_RNG_DISTRIBUTION_BERNOULLI</samp>.<a name="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_nfx_xrg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_nfx_xrg_jvb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DOUBLE</samp> ; one element.
                                          </li>
                                          <li class="li">Default value is <samp class="ph codeph">-1</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_RNG_DESCRIPTOR__section_njv_jsy_smb"><a name="CUDNN_BACKEND_RNG_DESCRIPTOR__section_njv_jsy_smb" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">Return values of <samp class="ph codeph">cudnnBackendFinalize(desc)</samp> where
                                 <samp class="ph codeph">desc</samp> is <samp class="ph codeph">CUDNN_BACKEND_RNG_DESCRIPTOR</samp> are:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid attribute value was encountered. For example:<a name="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_ntz_zrg_jvb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_RNG_DESCRIPTOR__ul_ntz_zrg_jvb">
                                          <li class="li">If <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                                CUDNN_RNG_DISTRIBUTION_NORMAL</samp> and the standard
                                             deviation supplied is negative.
                                          </li>
                                          <li class="li">If <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                                CUDNN_RNG_DISTRIBUTION_UNIFORM</samp> and the maximum
                                             value of the range is lower than minimum value.
                                          </li>
                                          <li class="li">If <samp class="ph codeph">CUDNN_ATTR_RNG_DISTRIBUTION =
                                                CUDNN_RNG_DISTRIBUTION_BERNOULLI</samp> and the
                                             probability supplied is negative.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR"><a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_TENSOR_DESCRIPTOR" name="CUDNN_BACKEND_TENSOR_DESCRIPTOR" shape="rect">9.3.30.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_TENSOR_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_TENSOR_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend tensor allows users to specify the memory
                                 storage of a generic tensor. A tensor is identified by a unique identifier and described
                                 by its data type, its data byte-alignment requirements, and the extents and strides of
                                 its dimensions. Optionally, a tensor element can be vector in one of its dimensions. A
                                 tensor can also be set to be virtual when it is an intermediate variable in a
                                 computation graph and not mapped to physical global memory storage.</span></div>
                           <div class="section" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">Attributes of a cuDNN backend tensor descriptors are values of enumeration type
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendAttributeName_t" shape="rect">cudnnBackendAttributeName_t</a></samp> with prefix
                                 <samp class="ph codeph">CUDNN_ATTR_TENSOR_</samp>:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_UNIQUE_ID</samp></dt>
                                    <dd class="dd">An integer that uniquely identifies the tensor.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_DATA_TYPE</samp></dt>
                                    <dd class="dd">Data type of tensor.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_DATA_TYPE</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_BYTE_ALIGNMENT</samp></dt>
                                    <dd class="dd">Byte alignment of pointers for this tensor.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_DIMENSIONS</samp></dt>
                                    <dd class="dd">Tensor dimensions.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS</samp> elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_STRIDES</samp></dt>
                                    <dd class="dd">Tensor strides.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_h1y_lvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_h1y_lvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; at most
                                             <samp class="ph codeph">CUDNN_MAX_DIMS</samp> elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_VECTOR_COUNT</samp></dt>
                                    <dd class="dd">Size of vectorization.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_tk3_nvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_tk3_nvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">1</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_VECTORIZED_DIMENSION</samp></dt>
                                    <dd class="dd">Index of the vectorized dimension.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_wch_tdm_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_wch_tdm_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; one element.
                                          </li>
                                          <li class="li">Required to be set before finalization if
                                             <samp class="ph codeph">CUDNN_ATTR_TENSOR_VECTOR_COUNT</samp> is set to a
                                             value different than its default; otherwise its ignored.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_IS_VIRTUAL</samp></dt>
                                    <dd class="dd">Indicates whether the tensor is virtual. A virtual tensor is an
                                       intermediate tensor in the operation graph that exists in transient and
                                       not read from or written to in global device memory.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_nxj_wdm_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_nxj_wdm_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BOOL</samp>; one element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">false</samp></li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_TENSOR_RAGGED_OFFSET_DESC</samp></dt>
                                    <dd class="dd">A ragged tensor, that is, a tensor with nested variable length lists as
                                       inner dimensions, will have another tensor called the ragged offset
                                       descriptor that contains offsets in memory to the next variable length
                                       list.<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_z5h_tbh_1xb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_z5h_tbh_1xb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_BACKEND_DESCRIPTOR</samp>; one
                                             element.
                                          </li>
                                          <li class="li">Default value: <samp class="ph codeph">None</samp></li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> with a
                                 <samp class="ph codeph">CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR</samp> can have the following
                                 return values:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                                    <dd class="dd">An invalid attribute value was encountered. For example:<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_q2y_1ty_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_q2y_1ty_smb">
                                          <li class="li">Any of the tensor dimensions or strides is not positive.</li>
                                          <li class="li">The value of the tensor alignment attribute is not divisible by
                                             the size of the data type.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                                    <dd class="dd">An unsupported attribute value was encountered. For example:<a name="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_cft_cty_smb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_TENSOR_DESCRIPTOR__ul_cft_cty_smb">
                                          <li class="li">The data type attribute is <samp class="ph codeph">CUDNN_DATA_INT8x4</samp>,
                                             <samp class="ph codeph">CUDNN_DATA_UINT8x4</samp>, or
                                             <samp class="ph codeph">CUDNN_DATA_INT8x32</samp>.
                                          </li>
                                          <li class="li">The data type attribute is <samp class="ph codeph">CUDNN_DATA_INT8</samp> and
                                             <samp class="ph codeph">CUDNN_ATTR_TENSOR_VECTOR_COUNT</samp> value is not
                                             <samp class="ph codeph">1</samp>, <samp class="ph codeph">4</samp>, or
                                             <samp class="ph codeph">32</samp>.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR"><a name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR" name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR" shape="rect">9.3.31.&nbsp;<kbd class="ph userinput">CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR</kbd></a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc">Created with
                                 <samp class="ph codeph">cudnnBackendCreateDescriptor(CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR,
                                    &amp;desc)</samp>; the cuDNN backend variant pack plan allows users to set up
                                 pointers to device buffers to various non-virtual tensors, identified by unique
                                 identifiers, of the operation graph, workspace, and computation
                                 intermediates.</span></div>
                           <div class="section" id="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__section_pst_skn_y3b"><a name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__section_pst_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Attributes</h4>
                              <div class="p">
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_VARIANT_PACK_UNIQUE_IDS</samp></dt>
                                    <dd class="dd">A unique identifier of tensor for each data pointer.<a name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_azh_cvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_azh_cvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_INT64</samp>; zero of more elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_VARIANT_PACK_DATA_POINTERS</samp></dt>
                                    <dd class="dd">Tensor data device pointers.<a name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_wdf_2vf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_wdf_2vf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_VOID_PTR</samp>; zero or more
                                             elements.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_VARIANT_PACK_INTERMEDIATES</samp></dt>
                                    <dd class="dd">Intermediate device pointers.<a name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_bh2_hvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_bh2_hvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_VOID_PTR</samp>; zero or more
                                             elements.
                                          </li>
                                          <li class="li">Setting attribute unsupported. Placeholder for support to be
                                             added in a future version.
                                          </li>
                                       </ul>
                                    </dd>
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_ATTR_VARIANT_PACK_WORKSPACE</samp></dt>
                                    <dd class="dd">Workspace to device pointer.<a name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_rvp_jvf_4mb" shape="rect">
                                          <!-- --></a><ul class="ul" id="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__ul_rvp_jvf_4mb">
                                          <li class="li"><samp class="ph codeph">CUDNN_TYPE_VOID_PTR</samp>; one element.
                                          </li>
                                          <li class="li">Required attribute.</li>
                                       </ul>
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                           <div class="section" id="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__section_vzb_skn_y3b"><a name="CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR__section_vzb_skn_y3b" shape="rect">
                                 <!-- --></a><h4 class="title sectiontitle">Finalization</h4>
                              <div class="p">The return values for <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendFinalize" shape="rect">cudnnBackendFinalize()</a></samp> when
                                 called with a cuDNN backend variant pack descriptor is:
                                 <dl class="dl">
                                    <dt class="dt dltermexpand"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                                    <dd class="dd">The descriptor was finalized successfully.</dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="use-cases"><a name="use-cases" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#use-cases" name="use-cases" shape="rect">9.4.&nbsp;Use Cases</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc">This section describes some typical use cases of the cuDNN backend API; for
                              example, setting up a simple operation graph, setting up an engine config for that
                              operation graph, and finally setting up an execution plan and executing it with data
                              pointers set in a variant pack descriptor.</span></div>
                        <p class="p"></p>
                     </div>
                     <div class="topic task nested2" id="use-case-op-graph-group-convo"><a name="use-case-op-graph-group-convo" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#use-case-op-graph-group-convo" name="use-case-op-graph-group-convo" shape="rect">9.4.1.&nbsp;Setting Up An Operation Graph For A Grouped Convolution</a></h3>
                        <div class="body taskbody">
                           <div class="abstract"><span class="shortdesc">This use case creates an operation graph with a single grouped 3D convolution
                                 forward operation. It starts by setting up the input and output tensors, binding them to
                                 a convolution forward operation, and finally setting up an operation graph with a single
                                 node.</span></div>
                           <ol class="ol steps">
                              <li class="li step"><span class="ph cmd">Create tensor descriptors.</span><pre xml:space="preserve">cudnnBackendDescriptor_t xDesc;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_TENSOR_DESCRIPTOR, &amp;xDesc);

cudnnDataType_t dtype = CUDNN_DATA_FLOAT;
cudnnBackendSetAttribute(xDesc, CUDNN_ATTR_TENSOR_DATA_TYPE,
                         CUDNN_TYPE_DATA_TYPE, 1, &amp;dtype);

int64_t xDim[] = {n, g, c, d, h, w};
int64_t xStr[] = {g * c * d * h * w, c *d *h *w, d *h *w, h *w, w, 1};
int64_t xUi = 'x';
int64_t alignment = 4;

cudnnBackendSetAttribute(xDesc, CUDNN_ATTR_TENSOR_DIMENSIONS,
                         CUDNN_TYPE_INT64, 6, xDim);

cudnnBackendSetAttribute(xDesc, CUDNN_ATTR_TENSOR_STRIDES,
                         CUDNN_TYPE_INT64, 6, xStr);

cudnnBackendSetAttribute(xDesc, CUDNN_ATTR_TENSOR_UNIQUE_ID,
                         CUDNN_TYPE_INT64, 1, &amp;xUi);

cudnnBackendSetAttribute(xDesc, CUDNN_ATTR_TENSOR_BYTE_ALIGNMENT,
                         CUDNN_TYPE_INT64, 1, &amp;alignment);

cudnnBackendFinalize(xDesc);</pre></li>
                              <li class="li step"><span class="ph cmd">Repeat the above step for the convolution filter and output tensor descriptor.
                                    The six filter tensor dimensions are <samp class="ph codeph">[g, k, c, t, r, s]</samp> and the
                                    six output tensor dimensions are <samp class="ph codeph">[n, g, k, o, p, q]</samp>,
                                    respectively. Below, when finalizing a convolution operator to which the tensors
                                    are bound, dimension consistency is checked, meaning all <samp class="ph codeph">n</samp>,
                                    <samp class="ph codeph">g</samp>, <samp class="ph codeph">c</samp>, <samp class="ph codeph">k</samp> values shared
                                    among the three tensors are required to be the same. Otherwise,
                                    <samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp> status is returned.</span><div class="p">For backward compatibility with how tensors are specified in <samp class="ph codeph"><a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a></samp> and used in convolution API, it
                                    is also possible to specify a 5D tensor with the following dimension:<a name="use-case-op-graph-group-convo__ul_c11_ddz_smb" shape="rect">
                                       <!-- --></a><ul class="ul" id="use-case-op-graph-group-convo__ul_c11_ddz_smb">
                                       <li class="li">image: <samp class="ph codeph">[n, g*c, d, h, w]</samp></li>
                                       <li class="li">filter: <samp class="ph codeph">[g*k, c, t, r, s]</samp></li>
                                       <li class="li">response: <samp class="ph codeph">[n, g*k, o, p, q]</samp></li>
                                    </ul>
                                 </div>
                                 <p class="p">In this format, a similar consistency check is performed when finalizing a
                                    convolution operator descriptor to which the tensors are bound.
                                 </p>
                              </li>
                              <li class="li step"><span class="ph cmd">Create, set, and finalize a convolution operator descriptor.</span><pre xml:space="preserve">cudnnBackendDescriptor_t cDesc;
int64_t nbDims = 3;
cudnnDataType_t compType = CUDNN_DATA_FLOAT;
cudnnConvolutionMode_t mode = CUDNN_CONVOLUTION;
int64_t pad[] = {0, 0, 0};
int64_t filterStr[] = {1, 1, 1};
int64_t dilation[] = {1, 1, 1};

cudnnBackendCreateDescriptor(CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR, &amp;cDesc);

cudnnBackendSetAttribute(cDesc, CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS,
                         CUDNN_TYPE_INT64, 1, &amp;nbDims);

cudnnBackendSetAttribute(cDesc, CUDNN_ATTR_CONVOLUTION_COMP_TYPE,
                         CUDNN_TYPE_DATA_TYPE, 1, &amp;compType);

cudnnBackendSetAttribute(cDesc, CUDNN_ATTR_CONVOLUTION_CONV_MODE,
                         CUDNN_TYPE_CONVOLUTION_MODE, 1, &amp;mode);

cudnnBackendSetAttribute(cDesc, CUDNN_ATTR_CONVOLUTION_PRE_PADDINGS,
                         CUDNN_TYPE_INT64, nbDims, pad);

cudnnBackendSetAttribute(cDesc, CUDNN_ATTR_CONVOLUTION_POST_PADDINGS,
                         CUDNN_TYPE_INT64, nbDims, pad);

cudnnBackendSetAttribute(cDesc, CUDNN_ATTR_CONVOLUTION_DILATIONS,
                         CUDNN_TYPE_INT64, nbDims, dilation);

cudnnBackendSetAttribute(cDesc, CUDNN_ATTR_CONVOLUTION_FILTER_STRIDES,
                         CUDNN_TYPE_INT64, nbDims, filterStr);
cudnnBackendFinalize(cDesc);</pre></li>
                              <li class="li step"><span class="ph cmd">Create, set, and finalize a convolution forward operation descriptor.</span><pre xml:space="preserve">cudnnBackendDescriptor_t fprop;
float alpha = 1.0;
float beta = 0.5;

cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR,
                   &amp;fprop);
cudnnBackendSetAttribute(fprop, CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_X,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;xDesc);
cudnnBackendSetAttribute(fprop, CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_W,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;wDesc);
cudnnBackendSetAttribute(fprop, CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_Y,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;yDesc);
cudnnBackendSetAttribute(fprop,
CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_CONV_DESC,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;cDesc);

cudnnBackendSetAttribute(fprop, CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA,
                         CUDNN_TYPE_FLOAT, 1, &amp;alpha);
cudnnBackendSetAttribute(fprop, CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA,
                         CUDNN_TYPE_FLOAT, 1, &amp;beta);

cudnnBackendFinalize(fprop);</pre></li>
                              <li class="li step"><span class="ph cmd">Create, set, and finalize an operation graph descriptor.</span><pre xml:space="preserve">cudnnBackendDescriptor_t op_graph;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR, &amp;op_graph);
cudnnBackendSetAttribute(op_graph, CUDNN_ATTR_OPERATIONGRAPH_OPS,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;fprop);
cudnnBackendSetAttribute(op_graph, CUDNN_ATTR_OPERATIONGRAPH_HANDLE,
                         CUDNN_TYPE_HANDLE, 1, &amp;handle);
cudnnBackendFinalize(op_graph);</pre></li>
                           </ol>
                        </div>
                     </div>
                     <div class="topic task nested2" id="use-case-engine-config"><a name="use-case-engine-config" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#use-case-engine-config" name="use-case-engine-config" shape="rect">9.4.2.&nbsp;Setting Up An Engine Configuration</a></h3>
                        <div class="body taskbody">
                           <div class="abstract"><span class="shortdesc">This use case describes the steps with which users can set up an engine config
                                 from a previously finalized operation graph. This is an example in which users would
                                 like to use the engine with  <samp class="ph codeph">CUDNN_ATTR_ENGINE_GLOBAL_INDEX 0</samp> for this
                                 operation graph and does not set any performance knobs.</span></div>
                           <ol class="ol steps">
                              <li class="li step"><span class="ph cmd">Create, set, and finalize an engine descriptor.</span><div class="p"><pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">cudnnBackendDescriptor_t engine;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINE_DESCRIPTOR, &amp;engine);
cudnnBackendSetAttribute(engine, CUDNN_ATTR_ENGINE_OPERATION_GRAPH,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;op_graph);
int64_t gidx = 0;
cudnnBackendSetAttribute(engine, CUDNN_ATTR_ENGINE_GLOBAL_INDEX,
                         CUDNN_TYPE_INT64, 1, &amp;gidx);
cudnnBackendFinalize(engine);</kbd></pre></div>
                                 <p class="p">The user can query a finalized engine descriptor with <samp class="ph codeph"><a class="xref" href="index.html#cudnnBackendGetAttribute" shape="rect">cudnnBackendGetAttribute()</a></samp> API call for its
                                    attributes, including the performance knobs that it has. For simplicity,
                                    this use case skips this step and assumes the user is setting up an engine
                                    config descriptor below without making any changes to performance knobs.
                                 </p>
                              </li>
                              <li class="li step"><span class="ph cmd">Create, set, and finalize an engine config descriptor.</span><pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">cudnnBackendDescriptor_t engcfg;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_ENGINECFG_DESCRIPTOR, &amp;engcfg);
cudnnBackendSetAttribute(engcfg, CUDNN_ATTR_ENGINECFG_ENGINE,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;engine);
cudnnBackendFinalize(engcfg);
</kbd></pre></li>
                           </ol>
                        </div>
                     </div>
                     <div class="topic task nested2" id="use-case-execute-plan"><a name="use-case-execute-plan" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#use-case-execute-plan" name="use-case-execute-plan" shape="rect">9.4.3.&nbsp;Setting Up And Executing A Plan</a></h3>
                        <div class="body taskbody">
                           <div class="abstract"><span class="shortdesc">This use case describes the steps with which users set up an execution plan with
                                 a previously finalized engine config descriptor, set up the data pointer variant pack,
                                 and finally execute the plan.</span></div>
                           <ol class="ol steps">
                              <li class="li step"><span class="ph cmd">Create, set, and finalize an execution plan descriptor. Obtain workspace size
                                    to allocate.</span><div class="p"><pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">cudnnBackendDescriptor_t plan;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR, &amp;plan);
cudnnBackendSetAttribute(plan, CUDNN_ATTR_EXECUTION_PLAN_HANDLE, CUDNN_TYPE_HANDLE, 1, &amp;handle);
cudnnBackendSetAttribute(plan, CUDNN_ATTR_EXECUTION_PLAN_ENGINE_CONFIG,
                         CUDNN_TYPE_BACKEND_DESCRIPTOR, 1, &amp;engcfg);
cudnnBackendFinalize(plan);

int64_t workspaceSize;
cudnnBackendGetAttribute(plan, CUDNN_ATTR_EXECUTION_PLAN_WORKSPACE_SIZE,
                         CUDNN_TYPE_INT64, 1, NULL, &amp;workspaceSize);</kbd></pre></div>
                              </li>
                              <li class="li step"><span class="ph cmd">Create, set and finalize a variant pack descriptor.</span><pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">void *dev_ptrs[3] = {xData, wData, yData}; // device pointer
int64_t uids[3] = {'x', 'w', 'y'};
void *workspace;

cudnnBackendDescriptor_t varpack;
cudnnBackendCreateDescriptor(CUDNN_BACKEND_VARIANT_PACK_DESCRIPTOR, &amp;varpack);
cudnnBackendSetAttribute(varpack, CUDNN_ATTR_VARIANT_PACK_DATA_POINTERS,
                         CUDNN_TYPE_VOID_PTR, 3, dev_ptrs);
cudnnBackendSetAttribute(varpack, CUDNN_ATTR_VARIANT_PACK_UNIQUE_IDS,
                         CUDNN_TYPE_INT64, 3, uids);
cudnnBackendSetAttribute(varpack, CUDNN_ATTR_VARIANT_PACK_WORKSPACE,
                         CUDNN_TYPE_VOID_PTR, 1, &amp;workspace);
cudnnBackendFinalize(varpack);</kbd></pre></li>
                              <li class="li step"><span class="ph cmd">Execute the plan with a variant pack.</span><pre class="pre screen" xml:space="preserve"><kbd class="ph userinput">cudnnBackendExecute(handle, plan, varpack);</kbd></pre></li>
                           </ol>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="notices-header"><a name="notices-header" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#notices-header" name="notices-header" shape="rect">Notices</a></h2>
                  <div class="topic reference nested1" id="notice"><a name="notice" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#notice" name="notice" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices" id="notice__section_kbg_pmm_flb"><a name="notice__section_kbg_pmm_flb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle notices">Notice</h3>
                           <p class="p" id="notice__notice-para-1"><a name="notice__notice-para-1" shape="rect">
                                 <!-- --></a>This document is provided for information purposes
                              only and shall not be regarded as a warranty of a certain
                              functionality, condition, or quality of a product. NVIDIA
                              Corporation (NVIDIA) makes no representations or warranties,
                              expressed or implied, as to the accuracy or completeness of the
                              information contained in this document and assumes no responsibility
                              for any errors contained herein. NVIDIA shall have no liability for
                              the consequences or use of such information or for any infringement
                              of patents or other rights of third parties that may result from its
                              use. This document is not a commitment to develop, release, or
                              deliver any Material (defined below), code, or functionality.
                           </p>
                           <p class="p" id="notice__notice-para-2"><a name="notice__notice-para-2" shape="rect">
                                 <!-- --></a>NVIDIA reserves the right to make corrections,
                              modifications, enhancements, improvements, and any other changes to
                              this document, at any time without notice.
                           </p>
                           <p class="p" id="notice__notice-para-3"><a name="notice__notice-para-3" shape="rect">
                                 <!-- --></a>Customer should obtain the latest relevant information
                              before placing orders and should verify that such information is
                              current and complete.
                           </p>
                           <p class="p" id="notice__notice-para-4"><a name="notice__notice-para-4" shape="rect">
                                 <!-- --></a>NVIDIA products are sold subject to the NVIDIA
                              standard terms and conditions of sale supplied at the time of order
                              acknowledgement, unless otherwise agreed in an individual sales
                              agreement signed by authorized representatives of NVIDIA and
                              customer (Terms of Sale). NVIDIA hereby expressly objects to
                              applying any customer general terms and conditions with regards to
                              the purchase of the NVIDIA product referenced in this document. No
                              contractual obligations are formed either directly or indirectly by
                              this document.
                           </p>
                           <p class="p" id="notice__notice-para-5"><a name="notice__notice-para-5" shape="rect">
                                 <!-- --></a>NVIDIA products are not designed, authorized, or
                              warranted to be suitable for use in medical, military, aircraft,
                              space, or life support equipment, nor in applications where failure
                              or malfunction of the NVIDIA product can reasonably be expected to
                              result in personal injury, death, or property or environmental
                              damage. NVIDIA accepts no liability for inclusion and/or use of
                              NVIDIA products in such equipment or applications and therefore such
                              inclusion and/or use is at customers own risk.
                           </p>
                           <p class="p" id="notice__notice-para-6"><a name="notice__notice-para-6" shape="rect">
                                 <!-- --></a>NVIDIA makes no representation or warranty that
                              products based on this document will be suitable for any specified
                              use. Testing of all parameters of each product is not necessarily
                              performed by NVIDIA. It is customers sole responsibility to
                              evaluate and determine the applicability of any information
                              contained in this document, ensure the product is suitable and fit
                              for the application planned by customer, and perform the necessary
                              testing for the application in order to avoid a default of the
                              application or the product. Weaknesses in customers product designs
                              may affect the quality and reliability of the NVIDIA product and may
                              result in additional or different conditions and/or requirements
                              beyond those contained in this document. NVIDIA accepts no liability
                              related to any default, damage, costs, or problem which may be based
                              on or attributable to: (i) the use of the NVIDIA product in any
                              manner that is contrary to this document or (ii) customer product
                              designs.
                           </p>
                           <p class="p" id="notice__notice-para-7"><a name="notice__notice-para-7" shape="rect">
                                 <!-- --></a>No license, either expressed or implied, is granted
                              under any NVIDIA patent right, copyright, or other NVIDIA
                              intellectual property right under this document. Information
                              published by NVIDIA regarding third-party products or services does
                              not constitute a license from NVIDIA to use such products or
                              services or a warranty or endorsement thereof. Use of such
                              information may require a license from a third party under the
                              patents or other intellectual property rights of the third party, or
                              a license from NVIDIA under the patents or other intellectual
                              property rights of NVIDIA.
                           </p>
                           <p class="p" id="notice__notice-para-8"><a name="notice__notice-para-8" shape="rect">
                                 <!-- --></a>Reproduction of information in this document is
                              permissible only if approved in advance by NVIDIA in writing,
                              reproduced without alteration and in full compliance with all
                              applicable export laws and regulations, and accompanied by all
                              associated conditions, limitations, and notices.
                           </p>
                           <p class="p" id="notice__notice-para-9"><a name="notice__notice-para-9" shape="rect">
                                 <!-- --></a>THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS,
                              REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER
                              DOCUMENTS (TOGETHER AND SEPARATELY, MATERIALS) ARE BEING PROVIDED
                              AS IS. NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY,
                              OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS
                              ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND
                              FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY
                              LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING
                              WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL,
                              PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF
                              THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT,
                              EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.
                              Notwithstanding any damages that customer might incur for any reason
                              whatsoever, NVIDIAs aggregate and cumulative liability towards
                              customer for the products described herein shall be limited in
                              accordance with the Terms of Sale for the product.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="arm"><a name="arm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#arm" name="arm" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices" id="arm__section_n3n_kf2_qtb"><a name="arm__section_n3n_kf2_qtb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle notices">Arm</h3>
                           <p class="p">Arm, AMBA and Arm Powered are registered trademarks of Arm Limited. Cortex, MPCore
                              and Mali are trademarks of Arm Limited. "Arm" is used to represent Arm Holdings plc;
                              its operating company Arm Limited; and the regional subsidiaries Arm Inc.; Arm KK;
                              Arm Korea Limited.; Arm Taiwan Limited; Arm France SAS; Arm Consulting (Shanghai)
                              Co. Ltd.; Arm Germany GmbH; Arm Embedded Technologies Pvt. Ltd.; Arm Norway, AS and
                              Arm Sweden AB.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="hdmi"><a name="hdmi" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#hdmi" name="hdmi" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">HDMI</h3>
                           <p class="p">HDMI, the HDMI logo, and High-Definition Multimedia Interface are trademarks or
                              registered trademarks of HDMI Licensing LLC.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="blackberry"><a name="blackberry" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#blackberry" name="blackberry" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Blackberry/QNX</h3>
                           <p class="p">Copyright  2020 BlackBerry Limited. All rights reserved.</p>
                           <p class="p">Trademarks, including but not limited to BLACKBERRY, EMBLEM Design, QNX, AVIAGE,
                              MOMENTICS, NEUTRINO and QNX CAR are the trademarks or registered trademarks of
                              BlackBerry Limited, used under license, and the exclusive rights to such trademarks
                              are expressly reserved. 
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="google"><a name="google" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#google" name="google" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Google</h3>
                           <p class="p">Android, Android TV, Google Play and the Google Play logo are trademarks of Google,
                              Inc.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="trademarks"><a name="trademarks" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#trademarks" name="trademarks" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Trademarks</h3>
                           <p class="p">NVIDIA, the NVIDIA logo, and BlueField, CUDA, DALI, DRIVE, Hopper, JetPack, Jetson
                              AGX Xavier, Jetson Nano, Maxwell, NGC, Nsight, Orin, Pascal, Quadro, Tegra,
                              TensorRT, Triton, Turing and Volta are trademarks and/or registered trademarks of
                              NVIDIA Corporation in the United States and other countries. Other company and
                              product names may be trademarks of the respective companies with which they are
                              associated.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="copyright-past-to-present"><a name="copyright-past-to-present" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#copyright-past-to-present" name="copyright-past-to-present" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Copyright</h3>
                           <p class="p"> <span class="ph">2014</span>-<span class="ph">2024</span> NVIDIA Corporation &amp;
                              affiliates. All rights reserved.
                           </p>
                        </div>
                     </div>
                  </div>
               </div>
               
               
            </article>
            <footer id="footer"><img src="../common/formatting/NVIDIA-LogoBlack.svg"></img><div><a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a> |
                  <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">Manage My Privacy</a> |
                  <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">Do Not Sell or Share My Data</a> |
                  <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a> |
                  <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a> |
                  <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a> |
                  <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a> |
                  <a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a></div>
               <div class="copyright">Copyright  2024 NVIDIA Corporation</div>
            </footer>
         </div>
      </div>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/formatting/common.min.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
      <script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>
      <script type="text/javascript">_satellite.pageBottom();</script></body>

<!-- Mirrored from docs.nvidia.com/deeplearning/cudnn/archives/cudnn-897/api/index.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 06 Aug 2024 07:09:11 GMT -->
</html>